{"version":3,"file":"stylist-vendors-db4b2390.ab1e3d476af6cd3d07b2.js","mappings":"gLAqCIA,EAAgB,SAASC,EAAGC,GAI5B,OAHAF,EAAgBG,OAAOC,gBAClB,CAAEC,UAAW,cAAgBC,OAAS,SAAUL,EAAGC,GAAKD,EAAEI,UAAYH,CAAG,GAC1E,SAAUD,EAAGC,GAAK,IAAK,IAAIK,KAAKL,EAAOA,EAAEM,eAAeD,KAAIN,EAAEM,GAAKL,EAAEK,GAAI,EACtEP,EAAcC,EAAGC,EAC5B,EAEA,SAASO,EAAUR,EAAGC,GAElB,SAASQ,IAAOC,KAAKC,YAAcX,CAAG,CADtCD,EAAcC,EAAGC,GAEjBD,EAAEY,UAAkB,OAANX,EAAaC,OAAOW,OAAOZ,IAAMQ,EAAGG,UAAYX,EAAEW,UAAW,IAAIH,EACnF,CAEA,IAAIK,EAAW,WAQX,OAPAA,EAAWZ,OAAOa,QAAU,SAAkBC,GAC1C,IAAK,IAAIC,EAAGC,EAAI,EAAGC,EAAIC,UAAUC,OAAQH,EAAIC,EAAGD,IAE5C,IAAK,IAAIZ,KADTW,EAAIG,UAAUF,GACOhB,OAAOU,UAAUL,eAAee,KAAKL,EAAGX,KAAIU,EAAEV,GAAKW,EAAEX,IAE9E,OAAOU,CACX,EACOF,EAASS,MAAMb,KAAMU,UAChC,EAEA,SAASI,EAAUC,EAASC,EAAYC,EAAGC,GAEvC,OAAO,IAAKD,IAAMA,EAAIE,WAAU,SAAUC,EAASC,GAC/C,SAASC,EAAUC,GAAS,IAAMC,EAAKN,EAAUO,KAAKF,GAAS,CAAE,MAAOG,GAAKL,EAAOK,EAAI,CAAE,CAC1F,SAASC,EAASJ,GAAS,IAAMC,EAAKN,EAAiB,MAAEK,GAAS,CAAE,MAAOG,GAAKL,EAAOK,EAAI,CAAE,CAC7F,SAASF,EAAKI,GAJlB,IAAeL,EAIaK,EAAOC,KAAOT,EAAQQ,EAAOL,QAJ1CA,EAIyDK,EAAOL,MAJhDA,aAAiBN,EAAIM,EAAQ,IAAIN,GAAE,SAAUG,GAAWA,EAAQG,EAAQ,KAIjBO,KAAKR,EAAWK,EAAW,CAC7GH,GAAMN,EAAYA,EAAUL,MAAME,EAASC,GAAc,KAAKS,OAClE,GACJ,CAEA,SAASM,EAAYhB,EAASiB,GAC1B,IAAsGC,EAAGC,EAAG5B,EAAG6B,EAA3GC,EAAI,CAAEC,MAAO,EAAGC,KAAM,WAAa,GAAW,EAAPhC,EAAE,GAAQ,MAAMA,EAAE,GAAI,OAAOA,EAAE,EAAI,EAAGiC,KAAM,GAAIC,IAAK,IAChG,OAAOL,EAAI,CAAEV,KAAMgB,EAAK,GAAI,MAASA,EAAK,GAAI,OAAUA,EAAK,IAAwB,oBAAXC,SAA0BP,EAAEO,OAAOC,UAAY,WAAa,OAAO3C,IAAM,GAAImC,EACvJ,SAASM,EAAKhC,GAAK,OAAO,SAAUmC,GAAK,OACzC,SAAcC,GACV,GAAIZ,EAAG,MAAM,IAAIa,UAAU,mCAC3B,KAAOV,OACH,GAAIH,EAAI,EAAGC,IAAM5B,EAAY,EAARuC,EAAG,GAASX,EAAU,OAAIW,EAAG,GAAKX,EAAS,SAAO5B,EAAI4B,EAAU,SAAM5B,EAAEM,KAAKsB,GAAI,GAAKA,EAAET,SAAWnB,EAAIA,EAAEM,KAAKsB,EAAGW,EAAG,KAAKhB,KAAM,OAAOvB,EAE3J,OADI4B,EAAI,EAAG5B,IAAGuC,EAAK,CAAS,EAARA,EAAG,GAAQvC,EAAEiB,QACzBsB,EAAG,IACP,KAAK,EAAG,KAAK,EAAGvC,EAAIuC,EAAI,MACxB,KAAK,EAAc,OAAXT,EAAEC,QAAgB,CAAEd,MAAOsB,EAAG,GAAIhB,MAAM,GAChD,KAAK,EAAGO,EAAEC,QAASH,EAAIW,EAAG,GAAIA,EAAK,CAAC,GAAI,SACxC,KAAK,EAAGA,EAAKT,EAAEI,IAAIO,MAAOX,EAAEG,KAAKQ,MAAO,SACxC,QACI,KAAkBzC,GAAZA,EAAI8B,EAAEG,MAAY5B,OAAS,GAAKL,EAAEA,EAAEK,OAAS,MAAkB,IAAVkC,EAAG,IAAsB,IAAVA,EAAG,IAAW,CAAET,EAAI,EAAG,QAAU,CAC3G,GAAc,IAAVS,EAAG,MAAcvC,GAAMuC,EAAG,GAAKvC,EAAE,IAAMuC,EAAG,GAAKvC,EAAE,IAAM,CAAE8B,EAAEC,MAAQQ,EAAG,GAAI,KAAO,CACrF,GAAc,IAAVA,EAAG,IAAYT,EAAEC,MAAQ/B,EAAE,GAAI,CAAE8B,EAAEC,MAAQ/B,EAAE,GAAIA,EAAIuC,EAAI,KAAO,CACpE,GAAIvC,GAAK8B,EAAEC,MAAQ/B,EAAE,GAAI,CAAE8B,EAAEC,MAAQ/B,EAAE,GAAI8B,EAAEI,IAAIQ,KAAKH,GAAK,KAAO,CAC9DvC,EAAE,IAAI8B,EAAEI,IAAIO,MAChBX,EAAEG,KAAKQ,MAAO,SAEtBF,EAAKb,EAAKpB,KAAKG,EAASqB,EAC5B,CAAE,MAAOV,GAAKmB,EAAK,CAAC,EAAGnB,GAAIQ,EAAI,CAAG,CAAE,QAAUD,EAAI3B,EAAI,CAAG,CACzD,GAAY,EAARuC,EAAG,GAAQ,MAAMA,EAAG,GAAI,MAAO,CAAEtB,MAAOsB,EAAG,GAAKA,EAAG,QAAK,EAAQhB,MAAM,EAC9E,CAtBgDL,CAAK,CAACf,EAAGmC,GAAK,CAAG,CAuBrE,CAwBA,SAASK,EAAyBC,GAC9B,IAAIC,EAAWD,EAAkBE,MAAM,GACnCC,EAAmB,SAAUH,EAAmB,GAChDI,EAAmB,UAAWD,EAAkB,EAAE,IACtD,OAAO,SAAUC,EAAkBH,EACvC,CAiBA,SAASI,EAAaC,EAAeC,GACjC,OAAO,QAAQ,WACX,OAAO,OAAQ,UAAWD,EAAe,SAAUC,IAAa,QACpE,GACJ,CAgBA,SAASC,EAAuBC,EAAkBT,GAC9C,IAAIU,EAAKV,EAAkBE,MAAOS,EAAgBD,EAAG,GAAIE,EAAeF,EAAG,GAAIT,EAAWS,EAAG,GAC7F,OAAO,QAAQ,WACX,IAvCcG,EAAOC,EAuCjBC,EAAehB,EAAyBC,GACxCgB,EAAc,aAAc,QAAS,EAAGf,EAAU,EAAG,SAAU,GAC/DG,EAAmB,OAAQ,SAAUW,EAAcC,GAAc,SACjEC,EAAU,UAAWb,EAAkB,CAACO,EAAeC,IACvDM,EAA8B,MAAOD,EAAS,SAAU,EAAG,UAC/D,OAAO,OA5COJ,EA4CaK,EA5CNJ,EA4CmCL,EA3CrD,MAAOI,EAAOC,IA2C0D,SAAU,EAAG,SAC5F,GACJ,CAoCA,IAAIK,EAA2B,WAC3B,SAASA,EAAUC,EAAOC,GACtBvE,KAAKsE,MAAQA,EACbtE,KAAKuE,aAAeA,EACpB,IAAIC,EAAaxE,KAAKsE,MAAMG,OAAO,GAAGrB,MACtC,eAAmC,IAAnBoB,EAAW,KAAkC,IAAnBA,EAAW,IAAY,WAAc,MAAO,gBAAgBE,OAAOF,EAAW,GAAI,MAAME,OAAOF,EAAW,GAAI,MACpJ,6BAA+B,GACvC,CA6CA,OA1BAH,EAAUnE,UAAUyE,QAAU,SAAUC,GACpC,IAAIC,EAAQ7E,KACZ,OAAO,QAAQ,WACX,IAAI8E,EAAUD,EAAME,gBAAgB,OAAQH,EAAO,YAC/CI,EAAU,aAAcF,EAAS,GAEjCG,EADUJ,EAAMP,MAAMK,QAAQK,GACVE,KAAI,SAAUhD,GAAK,OAAO,UAAWA,EAAG,CAAC,GAAK,IAClEiD,EAAeN,EAAMO,kBAAkBH,GAC3C,MAAO,CACHI,cAAe,UAAWF,EAAaG,SACvCC,QAASJ,EAAaI,QACtBC,gBAAiBL,EAAaK,gBAC9BC,gBAAiBN,EAAaM,gBAC9BC,aAAcP,EAAaO,aAC3BC,aAAcR,EAAaQ,aAC3BC,YAAaT,EAAaS,YAC1BC,YAAaV,EAAaU,YAElC,GACJ,EAIAxB,EAAUnE,UAAU4F,QAAU,WAC1B9F,KAAKsE,MAAMwB,SACf,EACOzB,CACX,CArD8B,GAuE1B0B,EAA2B,SAAUC,GAErC,SAASD,IACL,OAAkB,OAAXC,GAAmBA,EAAOnF,MAAMb,KAAMU,YAAcV,IAC/D,CAkBA,OArBAF,EAAUiG,EAAWC,GAIrBD,EAAU7F,UAAU6E,gBAAkB,SAAUH,GAE5C,OAAO,QAAQ,WAAc,OAAO,MAAO,MAAOA,EAAO,OAAQ,EAAM,GAC3E,EACAmB,EAAU7F,UAAUkF,kBAAoB,SAAUa,GAE9C,MAAO,CACHV,QAFUU,EAAQ,GAGlBP,aAHqCO,EAAQ,GAI7CN,aAJgEM,EAAQ,GAKxEL,YAL0FK,EAAQ,GAMlGX,QANgHW,EAAQ,GAOxHT,gBAP8IS,EAAQ,GAQtJR,gBAR4KQ,EAAQ,GASpLJ,YATsMI,EAAQ,GAWtN,EACOF,CACX,CAvB8B,CAuB5B1B,GAkBE6B,EAAa,CACb,OAAQ,UAAW,WAAY,UAAW,WAAY,eACtD,gBAAiB,YAAa,aAAc,YAAa,aACzD,UAAW,WAAY,WAAY,YAAa,YAAa,cAE7DC,EAAgBD,EAAWvF,OAC3ByF,EAAWF,EAAWG,QAAO,SAAUzE,EAAQ0E,EAAW9F,GAE1D,OADAoB,EAAO0E,GAAa9F,EACboB,CACX,GAAG,CAAC,GA8CJ,SAAS2E,EAAS3C,EAAI4C,EAAIC,GACtB,IAAIC,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GAC3BgD,EAAmBJ,EAAG,GAAIK,EAAmBL,EAAG,GAChDM,EAAOL,EAAQM,IAAKC,EAAOP,EAAQQ,OAGvC,MAAO,CADMJ,GAFyCJ,EAAQS,KAAaT,EAAQU,MAEpCR,GADlCC,GAAoBE,EAAOE,EAAON,GAGnD,CACA,SAASU,EAAelF,EAAGmF,EAAGC,EAAU/B,GACpC,MAAO,CACHrD,EAAGqD,EAAQgC,IAAIrF,EAAGmF,EAAGC,GACrBD,EAAG9B,EAAQgC,IAAIrF,EAAGmF,EAAGC,EAAWnB,GAExC,CACA,SAASqB,EAAeC,EAAMlD,EAAcgB,GACxC,IACI3B,EAAKwD,EADMK,EAAKC,SAAqBD,EAAKE,SAAqBF,EAAKG,GAClBrC,GAAUrD,EAAI0B,EAAG1B,EAAGmF,EAAIzD,EAAGyD,EACjF,MAAO,CACHA,EAAGI,EAAKE,SAAWpD,EAAe8C,EAClCnF,EAAGuF,EAAKC,SAAWnD,EAAerC,EAE1C,CACA,SAAS2F,EAAMC,EAAGC,EAAKC,GACnB,OAAIF,EAAIC,EACGA,EAEPD,EAAIE,EACGA,EAEJF,CACX,CAMA,SAASG,EAAWH,EAAGvI,GACnB,MAAO,CAAE8H,EAAGS,EAAET,EAAI9H,EAAE8H,EAAGnF,EAAG4F,EAAE5F,EAAI3C,EAAE2C,EACtC,CAkBA,SAASgG,EAAgBC,EAAWC,EAAMC,QACjB,IAAjBA,IAA2BA,EAAe,IAG9C,IAFA,IAAIC,EAAW,EACXC,EAAS,EACJ3I,EAAI,EAAGA,EAAIuI,EAAUxH,OAAQf,IAC9BwI,EAAKI,UAAU5I,GAAG6I,MAAQJ,IAC1BE,GAAU,EACVD,GAAYI,KAAKC,IAAKR,EAAUvI,GAAGyH,EAAIe,EAAKI,UAAU5I,GAAGgJ,SAASvB,EAAI,GAClEqB,KAAKC,IAAKR,EAAUvI,GAAGsC,EAAIkG,EAAKI,UAAU5I,GAAGgJ,SAAS1G,EAAI,IAStE,OANe,IAAXqG,EACAD,EAAWO,IAGXP,GAAsBC,EAEnBD,CACX,CAQA,SAASQ,EAAaC,EAAUC,EAAeC,EAAmBC,EAAmBtD,EAAauD,EAAavF,GAQ3G,IAPA,IAAI8C,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GAC3BwF,EAAcH,EAAkBF,GAChCM,EAAKD,EAAYlH,EAAIgH,EAAoBE,EAAY/B,EACrDiC,EAAK1D,EAAYO,GAAiB,EAAIkD,GAAML,GAC5CO,EAAK3D,EAAYO,GAAiB,EAAIkD,EAAK,GAAKL,GAChD9G,EAAI6G,EAAS7G,EAAIoH,EACjBjC,EAAI0B,EAAS1B,EAAIkC,EACZjJ,EAAI,EAAGA,EAAI6I,EAAa7I,IAAK,CAClC4B,EAAIwG,KAAKX,IAAI7F,EAAGwE,EAAS,GAEzB,IAAI8C,EAASP,EAAkB,CAAE5B,EADjCA,EAAIqB,KAAKX,IAAIV,EAAGV,EAAQ,GACezE,EAAGA,IACtCuH,EAAOD,EAAOtH,EAAIgH,EAAoBM,EAAOnC,EAGjDnF,GAFAoH,EAAK1D,EAAYO,GAAiB,EAAIsD,GAAQT,GAG9C3B,GAFAkC,EAAK3D,EAAYO,GAAiB,EAAIsD,EAAO,GAAKT,EAGtD,CACA,MAAO,CAAE3B,EAAGA,EAAGnF,EAAGA,EACtB,CACA,SAASwH,EAAyBX,EAAUnD,EAAa+D,EAAOC,EAAmBhG,EAAI4C,EAAI0C,EAAmBW,EAAIC,EAAQX,GAQtH,IAPA,IAAIrC,EAAOlD,EAAG,GAAImG,EAAOnG,EAAG,GACxBoG,EAASxD,EAAG,GAAIyD,EAASzD,EAAG,GAC5BE,EAASmD,EAAG,GAAIlD,EAAQkD,EAAG,GAC3BK,EAAQ,GACRjB,EAAoB,SAAUkB,GAC9B,OAjCR,SAAkCvB,EAAUhF,EAAI4C,EAAIsD,GAChD,IAAIhD,EAAOlD,EAAG,GAAImG,EAAOnG,EAAG,GACxBoG,EAASxD,EAAG,GAAIyD,EAASzD,EAAG,GAC5BtE,EAAIwG,KAAK0B,QAAQtD,EAAO8B,EAAS1G,EAAI,GAAO+H,EAAS,GAAOH,GAEhE,MAAO,CAAEzC,EADDqB,KAAK0B,QAAQL,EAAOnB,EAASvB,EAAI,GAAO2C,EAAS,GAAOF,GACjD5H,EAAGA,EACtB,CA2BemI,CAAyBF,EAAM,CAACrD,EAAMiD,GAAO,CAACC,EAAQC,GAASH,EAC1E,EACSQ,EAAiB,EAAGA,EAAiBV,EAAmBU,IAAkB,CAC/E,IAAInC,EAAYW,EAAaC,EAAUuB,EAAgBrB,EAAmBC,EAAmBtD,EAAauD,EAAa,CAACzC,EAAQC,IAChIuD,EAAMlH,KAAKmF,EACf,CAGA,IAFA,IAAIoC,GAAQ,EACRC,EAAW3B,IACN4B,EAAI,EAAGA,EAAId,EAAMhJ,OAAQ8J,IAAK,CACnC,IAAIC,EAAOxC,EAAgBgC,EAAOP,EAAMc,IACpCC,EAAOF,IACPD,EAAOE,EACPD,EAAWE,EAEnB,CACA,OAAOH,CACX,CACA,SAASI,EAAoB/G,EAAIkG,GAC7B,IAAIlD,EAAmBhD,EAAG,GAAIiD,EAAmBjD,EAAG,GAGpD,MAAO,CAFiB8E,KAAK0B,OAAOvD,EAAmB,GAAOiD,EAAS,GAC/CpB,KAAK0B,OAAOxD,EAAmB,GAAOkD,EAAS,GAE3E,CA4DA,SAASc,EAAyBlF,EAAcE,EAAaiF,EAAiBnE,EAAQC,EAAOmD,EAAQlG,EAAI6C,EAAS0C,EAAa2B,EAAaC,GAWxI,IAVA,IAAIC,EAAWpH,EAAG,GAAIqH,EAAUrH,EAAG,GAE/B4C,EAAKd,EAAatC,MAAO8H,EAAa1E,EAAG,GAAI2E,EAAY3E,EAAG,GAE5DqD,EAAKjE,EAAYxC,MAAMgI,MAAM,EAAG,GAAIC,EAAYxB,EAAG,GAAIyB,EAAWzB,EAAG,GACrE0B,EAAoB,UAAW3F,EAAa,CAACyF,EAAWC,EAAU,EAAGnF,IAIrEqF,EAAW,IAAIC,aAAaV,EAAe5E,EAAgB,GAAGuF,KAAK,GAC9DlL,EAAI,EAAGA,EAAIqK,EAAgBlK,OAAQH,IAGxC,IAFA,IAAImL,EAAanL,EAAI2F,EAAgB,EACjCiC,EAAOyC,EAAgBrK,GAClBoL,EAAK,EAAGA,EAAKzF,EAAeyF,IAAM,CACvC,IAAItE,EAAWc,EAAKI,UAAUoD,GAC1BC,EAASF,EAAkB,EAALC,EAC1BJ,EAASK,GAAUvE,EAASmB,MAC5B+C,EAASK,EAAS,GAAKvE,EAASsB,SAAS1G,EACzCsJ,EAASK,EAAS,GAAKvE,EAASsB,SAASvB,CAC7C,CAEJ,IAAIyE,EAAKvF,EAAS,CAACG,EAAQC,GAAQ,CAACqE,EAAUC,GAAUxE,GAAUuD,EAAS8B,EAAG,GAAI7B,EAAS6B,EAAG,GAC1FC,EAAc,SAAUP,EAAU,CAACT,EAAc5E,EAAe,IAChEW,EAAOL,EAAQM,IAAKgD,EAAOtD,EAAQS,KACnC8E,EAAU,CACVC,cAAe,CAAC,eAAgB,cAAe,SAC/CC,YAAa,CAAChB,EAAYC,GAC1BgB,SAAU,gyCAAgyCzH,OAAOoC,EAAM,MAAMpC,OAAOuF,EAAQ,MAAMvF,OAAOoF,EAAQ,2EAA2EpF,OAAOqF,EAAM,MAAMrF,OAAOsF,EAAQ,MAAMtF,OAAOoF,EAAQ,4FAA4FpF,OAAOqG,EAAc,oGAAoGrG,OAAOyB,EAAe,8PAA8PzB,OAAOyE,EAAa,4DAA4DzE,OAAOgC,EAAS,EAAK,wDAAwDhC,OAAOiC,EAAQ,EAAK,kGAAkGjC,OAAOoC,EAAM,MAAMpC,OAAOuF,EAAQ,MAAMvF,OAAOoF,EAAQ,8FAA8FpF,OAAOqF,EAAM,MAAMrF,OAAOsF,EAAQ,MAAMtF,OAAOoF,EAAQ,yXAAyXpF,OAAOoG,EAAa,kfAG5zF,OADmB,YACCsB,cAAcJ,EAAS,CAACtG,EAAc6F,EAAmBQ,GACjF,CAwBA,SAASM,IACL,MAAwB,WAAjB,IAAAC,aACX,CACA,SAASC,EAA0B7G,EAAcE,EAAa+D,EAAOjD,EAAQC,EAAOmD,EAAQlG,EAAI6C,EAAS+F,EAAcrD,EAAasD,EAAkB1B,GAClJ,IAAIC,EAAWpH,EAAG,GAAIqH,EAAUrH,EAAG,GAKnC,YAJqB,IAAjB4I,IAA2BA,EAAe,SAC1B,IAAhBrD,IAA0BA,EAAc,QACnB,IAArBsD,IAA+BA,EAAmB,SACjC,IAAjB1B,IAA2BA,EAAe,IACvCjK,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAI6K,EAAiB6B,EAAyBC,EAAqBC,EAAmBC,EACtF,OAAO9K,EAAY/B,MAAM,SAAUwG,GAC/B,OAAQA,EAAGnE,OACP,KAAK,EAED,OADAwI,EAAkBlB,EAAMmD,QAAO,SAAU1E,GAAQ,OAAOA,EAAKK,OAAS+D,CAAc,IAC/EH,KACLM,EAAsB,QAAQ,WAC1B,IAAII,EAAkBnC,EAAyBlF,EAAcE,EAAaiF,EAAiBnE,EAAQC,EAAOmD,EAAQ,CAACkB,EAAUC,GAAUxE,EAAS0C,EAAasD,EAAkB1B,GAC3KiC,EAAc,WAAYC,qBAAqBF,EAAgBG,OAAQH,EAAgB3J,MAAO2J,EAAgBI,OAClH,OAAOtC,EAAgB3F,KAAI,SAAU9C,EAAGqI,GAAK,OAzBrE,SAA+B/E,EAAc+E,GACzC,OAAO,QAAQ,WAAc,OAAO,OAAQ,QAAS/E,EAAc,SAAU+E,IAAK,QAAU,GAChG,CAuB4E2C,CAAsBJ,EAAavC,EAAI,GAC/F,IACO,CAAC,EAAatJ,QAAQkM,IAAIV,EAAoBzH,KAAI,SAAUlB,GAAQ,OAAOA,EAAKsJ,MAAQ,OANjE,CAAC,EAAa,GAOhD,KAAK,EAID,OAHAZ,EACKlG,EAAGlE,OACRqK,EAAoBY,SAAQ,SAAUlG,GAAK,OAAOA,EAAEvB,SAAW,IACxD,CAAC,EAAa,GACzB,KAAK,EAAG,MAAO,CAAC,EAAaJ,EAAa4H,QAC1C,KAAK,EAED,OADAV,EAAoBpG,EAAGlE,OAChB,CAAC,EAAasD,EAAY0H,QACrC,KAAK,EACDT,EAAkBrG,EAAGlE,OACrBoK,EApJpB,SAAgChH,EAAcE,EAAaiF,EAAiBnE,EAAQC,EAAOmD,EAAQlG,EAAI6C,EAAS0C,EAAaS,GACzH,IAAIoB,EAAWpH,EAAG,GAAIqH,EAAUrH,EAAG,QACT,IAAtBgG,IAAgCA,EAAoB,GAKxD,IAJA,IAAI4D,EAAa3C,EAAgB3F,KAAI,SAAUmC,GAAK,OAAO,IAAIoG,WAAW/G,EAASC,GAAO+E,KAAK,EAAI,IAC/F5E,EAAOL,EAAQM,IAAKgD,EAAOtD,EAAQS,KACnCV,EAAKD,EAAS,CAACG,EAAQC,GAAQ,CAACqE,EAAUC,GAAUxE,GAAUuD,EAASxD,EAAG,GAAIyD,EAASzD,EAAG,GAC1F0C,EAAoByB,EAAoB,CAACK,EAAUC,GAAUnB,GAAQ,GAChEtJ,EAAI,EAAGA,EAAIkG,EAAQlG,GAAK,EAC7B,IAAK,IAAIkN,EAAI,EAAGA,EAAI/G,EAAO+G,GAAK,EAAG,CAC/B,IAAIjN,EAAID,EAAImG,EAAQ+G,EAEpB,GAAa,IADFhI,EAAajF,GACR,CACZ,IAAI8J,EAAOb,EAAyB,CAAErC,EAAGqG,EAAGxL,EAAG1B,GAAKoF,EAAaiF,EAAiBjB,EAAmB,CAAC9C,EAAMiD,GAAO,CAACC,EAAQC,GAASf,EAAmB,CAACxC,EAAQC,GAAQmD,EAAQX,GAC7KoB,GAAQ,IACRiD,EAAWjD,GAAM9J,GAAK,EAE9B,CACJ,CAEJ,OAAO+M,CACX,CAgI8CG,CAAuBf,EAAmBC,EAAiBhC,EAAiBnE,EAAQC,EAAOmD,EAAQ,CAACkB,EAAUC,GAAUxE,EAAS0C,GAC3J3C,EAAGnE,MAAQ,EACf,KAAK,EAAG,MAAO,CAAC,EAAcqK,EAAwBxH,KAAI,SAAUoI,EAAM9M,GAAK,MAAO,CAAG8M,KAAMA,EAAMlF,KAAMyC,EAAgBrK,GAAImG,MAAOA,EAAOD,OAAQA,EAAW,KAExK,GACJ,GACJ,CACA,SAASkH,EAA8BlI,EAAcE,EAAaiI,EAAkBlE,EAAOjD,EAAQC,EAAOmD,EAAQlG,EAAI6C,EAAS+F,EAAcrD,EAAasD,EAAkB1B,GACxK,IAAIC,EAAWpH,EAAG,GAAIqH,EAAUrH,EAAG,GAKnC,YAJqB,IAAjB4I,IAA2BA,EAAe,SAC1B,IAAhBrD,IAA0BA,EAAc,QACnB,IAArBsD,IAA+BA,EAAmB,SACjC,IAAjB1B,IAA2BA,EAAe,IACvCjK,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAI6K,EAAiBiD,EAA+BC,EAAmBnB,EAAmBC,EAAiBmB,EAC3G,OAAOjM,EAAY/B,MAAM,SAAUwG,GAC/B,OAAQA,EAAGnE,OACP,KAAK,EAED,OADAwI,EAAkBlB,EAAMmD,QAAO,SAAU1E,GAAQ,OAAOA,EAAKK,OAAS+D,CAAc,IAC/EH,KACL0B,EAAoB,QAAQ,WACxB,IAAIhB,EAAkBnC,EAAyBlF,EAAcE,EAAaiF,EAAiBnE,EAAQC,EAAOmD,EAAQ,CAACkB,EAAUC,GAAUxE,EAAS0C,EAAasD,EAAkB1B,GAC3KiC,EAAc,WAAYC,qBAAqBF,EAAgBG,OAAQH,EAAgB3J,MAAO2J,EAAgBI,OAClH,OAAOtC,EAAgB3F,KAAI,SAAU9C,EAAGqI,GACpC,OA5D5B,SAAmC/E,EAAcuI,EAAWxD,GACxD,OAAO,QAAQ,WAAc,OAAO,MAAO,MAAO,OAAQ,QAAS/E,EAAc,SAAU+E,IAAK,SAAU,MAAOwD,EAAW,IAAK,EAAI,GACzI,CA0DmCC,CAA0BlB,EAAaa,EAAkBpD,EACpE,GACJ,IACO,CAAC,EAAatJ,QAAQkM,IAAIU,EAAkB7I,KAAI,SAAUmC,GAAK,OAAOA,EAAEiG,MAAQ,OARzD,CAAC,EAAa,GAShD,KAAK,EAID,OAHAQ,EACKtH,EAAGlE,OACRyL,EAAkBR,SAAQ,SAAUlG,GAAK,OAAOA,EAAEvB,SAAW,IACtD,CAAC,EAAa,GACzB,KAAK,EAAG,MAAO,CAAC,EAAaJ,EAAa4H,QAC1C,KAAK,EAED,OADAV,EAAoBpG,EAAGlE,OAChB,CAAC,EAAasD,EAAY0H,QACrC,KAAK,EAED,OADAT,EAAkBrG,EAAGlE,OACd,CAAC,EAAauL,EAAiBP,QAC1C,KAAK,EACDU,EAAsBxH,EAAGlE,OACzBwL,EAzKpB,SAAoCpI,EAAcE,EAAauI,EAAiBtD,EAAiBnE,EAAQC,EAAOmD,EAAQlG,EAAI6C,EAAS0C,EAAaS,GAC9I,IAAIoB,EAAWpH,EAAG,GAAIqH,EAAUrH,EAAG,QACT,IAAtBgG,IAAgCA,EAAoB,GAKxD,IAJA,IAAI4D,EAAa3C,EAAgB3F,KAAI,SAAUmC,GAAK,OAAO,IAAI+G,WAAW1H,EAASC,GAAO+E,MAAM,EAAI,IAChG5E,EAAOL,EAAQM,IAAKgD,EAAOtD,EAAQS,KACnCV,EAAKD,EAAS,CAACG,EAAQC,GAAQ,CAACqE,EAAUC,GAAUxE,GAAUuD,EAASxD,EAAG,GAAIyD,EAASzD,EAAG,GAC1F0C,EAAoByB,EAAoB,CAACK,EAAUC,GAAUnB,GAAQ,GAChEtJ,EAAI,EAAGA,EAAIkG,EAAQlG,GAAK,EAC7B,IAAK,IAAIkN,EAAI,EAAGA,EAAI/G,EAAO+G,GAAK,EAAG,CAC/B,IAAIjN,EAAID,EAAImG,EAAQ+G,EAEpB,GAAa,IADFhI,EAAajF,GACR,CACZ,IAAI8J,EAAOb,EAAyB,CAAErC,EAAGqG,EAAGxL,EAAG1B,GAAKoF,EAAaiF,EAAiBjB,EAAmB,CAAC9C,EAAMiD,GAAO,CAACC,EAAQC,GAASf,EAAmB,CAACxC,EAAQC,GAAQmD,EAAQX,GAC7KoB,GAAQ,IACRiD,EAAWjD,GAAM9J,GAAK0N,EAAgB1N,GAE9C,CACJ,CAEJ,OAAO+M,CACX,CAqJoDa,CAA2BzB,EAAmBC,EAAiBmB,EAAqBnD,EAAiBnE,EAAQC,EAAOmD,EAAQ,CAACkB,EAAUC,GAAUxE,EAAS0C,GAC1L3C,EAAGnE,MAAQ,EACf,KAAK,EAAG,MAAO,CAAC,EAAcyL,EAA8B5I,KAAI,SAAUoI,EAAM7C,GAAK,MAAO,CAAGrC,KAAMyC,EAAgBJ,GAAI6C,KAAMA,EAAM5G,OAAQA,EAAQC,MAAOA,EAAU,KAE9K,GACJ,GACJ,CAoBA,SAAS2H,EAAK7D,GACV,OAAO/B,KAAK6F,MAAM9D,EAAI,EAC1B,CA1Y2B,CACvB,CAAC,UAAW,gBAAiB,CAAC,YAAa,gBAC3C,CAAC,YAAa,aAAc,CAAC,UAAW,YACxC,CAAC,WAAY,aAAc,CAAC,WAAY,iBACxC,CAAC,aAAc,iBAAkB,CAAC,aAAc,cAChD,CAAC,WAAY,aAAc,CAAC,YAAa,cACzC,CAAC,eAAgB,iBAAkB,CAAC,UAAW,aAkB9BvF,KAAI,SAAUtB,GAC/B,IAAI4K,EAAa5K,EAAG,GAAI6K,EAAa7K,EAAG,GACxC,MAAO,CAAEwC,EAASoI,GAAapI,EAASqI,GAC5C,IAgXA,IAAIC,EAAyB,WACzB,SAASA,EAAQC,EAASC,GACtB5O,KAAK6O,cAAgB,IAAIlP,MAAMgP,GAC/B3O,KAAK8O,kBAAoB,EACzB9O,KAAK4O,gBAAkBA,CAC3B,CAsDA,OArDAF,EAAQxO,UAAU6O,QAAU,SAAU1H,GAClCrH,KAAK6O,gBAAgB7O,KAAK8O,kBAAoBzH,EAC9CrH,KAAKgP,KAAKhP,KAAK8O,iBACnB,EACAJ,EAAQxO,UAAU+O,QAAU,WACxB,IAAIjH,EAAMhI,KAAK6O,cAAc,GAI7B,OAHA7O,KAAKkP,SAAS,EAAGlP,KAAK8O,oBACtB9O,KAAKmP,KAAK,GACVnP,KAAK6O,cAAc7O,KAAK8O,iBAAmB,GAAK,KACzC9G,CACX,EACA0G,EAAQxO,UAAUkP,MAAQ,WACtB,OAAkC,IAA3BpP,KAAK8O,gBAChB,EACAJ,EAAQxO,UAAUmP,KAAO,WACrB,OAAOrP,KAAK8O,iBAAmB,CACnC,EACAJ,EAAQxO,UAAUmN,IAAM,WACpB,OAAOrN,KAAK6O,cAAczD,MAAM,EAAGpL,KAAK8O,iBAAmB,EAC/D,EACAJ,EAAQxO,UAAU8H,IAAM,WACpB,OAAOhI,KAAK6O,cAAc,EAC9B,EACAH,EAAQxO,UAAU8O,KAAO,SAAUvE,GAC/B,KAAOA,EAAI,GAAKzK,KAAKsP,KAAKhB,EAAK7D,GAAIA,IAC/BzK,KAAKkP,SAASzE,EAAG6D,EAAK7D,IACtBA,EAAI6D,EAAK7D,EAEjB,EACAiE,EAAQxO,UAAUiP,KAAO,SAAU1E,GAC/B,KAAO,EAAIA,GAAKzK,KAAK8O,kBAAkB,CACnC,IAAIpB,EAAI,EAAIjD,EAIZ,GAHIiD,EAAI1N,KAAK8O,kBAAoB9O,KAAKsP,KAAK5B,EAAGA,EAAI,IAC9CA,KAEC1N,KAAKsP,KAAK7E,EAAGiD,GACd,MAEJ1N,KAAKkP,SAASzE,EAAGiD,GACjBjD,EAAIiD,CACR,CACJ,EACAgB,EAAQxO,UAAUqP,WAAa,SAAU/O,GACrC,OAAOR,KAAK4O,gBAAgB5O,KAAK6O,cAAcrO,GACnD,EACAkO,EAAQxO,UAAUoP,KAAO,SAAU9O,EAAGkN,GAClC,OAAO1N,KAAKuP,WAAW/O,GAAKR,KAAKuP,WAAW7B,EAChD,EACAgB,EAAQxO,UAAUgP,SAAW,SAAU1O,EAAGkN,GACtC,IAAIpN,EAAIN,KAAK6O,cAAcrO,GAC3BR,KAAK6O,cAAcrO,GAAKR,KAAK6O,cAAcnB,GAC3C1N,KAAK6O,cAAcnB,GAAKpN,CAC5B,EACOoO,CACX,CA5D4B,GA8E5B,SAASc,EAA4BC,EAAYhH,EAAOf,EAAUC,EAAU+H,EAAoBC,GAK5F,IAJA,IAAI/L,EAAK+L,EAAOvM,MAAOsD,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GAC9CgM,GAAe,EACfC,EAASnH,KAAKV,IAAIN,EAAWgI,EAAoB,GACjDI,EAAOpH,KAAKX,IAAIL,EAAWgI,EAAqB,EAAGhJ,GAC9CqJ,EAAWF,EAAQE,EAAWD,IAAQC,EAAU,CAGrD,IAFA,IAAIC,EAAStH,KAAKV,IAAIL,EAAW+H,EAAoB,GACjDO,EAAOvH,KAAKX,IAAIJ,EAAW+H,EAAqB,EAAG/I,GAC9CuJ,EAAWF,EAAQE,EAAWD,IAAQC,EAC3C,GAAIP,EAAOpI,IAAIwI,EAAUG,EAAUT,GAAchH,EAAO,CACpDmH,GAAe,EACf,KACJ,CAEJ,IAAKA,EACD,KAER,CACA,OAAOA,CACX,CA+CA,IAAIO,EA7gBa,CACb,CAAC,OAAQ,WAAY,CAAC,UAAW,WAAY,CAAC,OAAQ,YACtD,CAAC,WAAY,YAAa,CAAC,OAAQ,gBACnC,CAAC,eAAgB,aAAc,CAAC,YAAa,aAC7C,CAAC,eAAgB,WAAY,CAAC,UAAW,YACzC,CAAC,WAAY,aAAc,CAAC,OAAQ,iBACpC,CAAC,gBAAiB,cAAe,CAAC,aAAc,cAChD,CAAC,gBAAiB,YAAa,CAAC,WAAY,aAC5C,CAAC,YAAa,eAqgBoBjL,KAAI,SAAUtB,GAChD,IAAIwM,EAAiBxM,EAAG,GAAIyM,EAAgBzM,EAAG,GAC/C,MAAO,CAAEwC,EAASgK,GAAiBhK,EAASiK,GAChD,IACIC,EAAqBH,EAAqBjL,KAAI,SAAUtB,GAExD,OADmBA,EAAG,EAE1B,IACI2M,EAAqBJ,EAAqBjL,KAAI,SAAUtB,GAExD,OADoBA,EAAG,EAE3B,IAQA,SAAS4M,EAAyBC,EAAOlM,EAAcmC,EAAQC,GAC3D,MAAO,CACHzE,EAAG2F,EAAMa,KAAK0B,MAAMqG,EAAMvO,EAAIqC,GAAe,EAAGmC,EAAS,GACzDW,EAAGQ,EAAMa,KAAK0B,MAAMqG,EAAMpJ,EAAI9C,GAAe,EAAGoC,EAAQ,GAEhE,CAQA,SAAS+J,EAAyBC,EAAQC,EAAgBC,EAAkBC,EAAcvL,EAAShB,EAAcwM,EAAeC,QACnG,IAArBA,IAA+BA,EAAmB,GAOtD,IANA,IAAIpN,EAAKkN,EAAa1N,MAAOsD,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GAGpDqN,EAzBR,SAAyBN,EAAQF,EAAOM,GACpC,IAAIG,EAAWH,EAAc3N,MAAM,GAAK,EACxC,MAAO,CACHlB,EAAG6O,EAAcxJ,IAAIkJ,EAAMvO,EAAGuO,EAAMpJ,EAAGsJ,GACvCtJ,EAAG0J,EAAcxJ,IAAIkJ,EAAMvO,EAAGuO,EAAMpJ,EAAG6J,EAAWP,GAE1D,CAmBuBQ,CAAgBR,EADPH,EAAyBI,EAAehI,SAAUrE,EAAcmC,EAAQC,GAClCoK,GAE9DK,EADiBnJ,EAAW2I,EAAehI,SAAUqI,GAEhDzQ,EAAI,EAAGA,EAAIwQ,EAAkBxQ,IAAK,CACvC,IAAI6Q,EAAwBb,EAAyBY,EAAgB7M,EAAcmC,EAAQC,GACvF2K,EAAclK,EAAeiK,EAAsBnP,EAAGmP,EAAsBhK,EAAGwJ,EAAkBtL,GACrG6L,EAAiBnJ,EAAW,CACxBZ,EAAGgK,EAAsBhK,EAAI9C,EAC7BrC,EAAGmP,EAAsBnP,EAAIqC,GAC9B,CAAE8C,EAAGiK,EAAYjK,EAAGnF,EAAGoP,EAAYpP,GAC1C,CACA,IAAIqP,EAAwBf,EAAyBY,EAAgB7M,EAAcmC,EAAQC,GACvF8B,EAAQqI,EAAavJ,IAAIgK,EAAsBrP,EAAGqP,EAAsBlK,EAAGwJ,GAC/E,MAAO,CAAEjI,SAAUwI,EAAgB3J,KAAMvB,EAAW2K,GAAmBpI,MAAOA,EAClF,CAOA,SAAS+I,EAAWC,EAAM9B,EAAQpK,EAAShB,EAAcmN,EAAkBC,GACvE,IAAIxO,EAAWwM,EAAOvM,MAAM,GACxB8N,EAAWZ,EAAmB3P,OAC9BiR,EAAoB,IAAIjS,MAAMwD,GAE9B0O,EAAWJ,EAAKhK,KAAMqK,EAAYL,EAAKhJ,MACvCsJ,EAAYvK,EAAeqK,EAAUtN,EAAcgB,GACvDqM,EAAkBC,EAASjK,IAAM,CAC7Ba,MAAOqJ,EACPrK,KAAMvB,EAAW2L,EAASjK,IAC1BgB,SAAUmJ,GAId,IAAK,IAAIC,EAAOd,EAAW,EAAGc,GAAQ,IAAKA,EAAM,CAC7C,IAAIC,EAAmB3B,EAAmB0B,GACtCnB,EAAmBN,EAAmByB,GACtCJ,EAAkBK,KACjBL,EAAkBf,KACnBe,EAAkBf,GAAoBH,EAAyBsB,EAAMJ,EAAkBK,GAAmBpB,EAAkBlB,EAAQpK,EAAShB,EAAcoN,GAEnK,CAGA,IAASK,EAAO,EAAGA,EAAOd,IAAYc,EAAM,CACpCC,EAAmB1B,EAAmByB,GACtCnB,EAAmBP,EAAmB0B,GACtCJ,EAAkBK,KACjBL,EAAkBf,KACnBe,EAAkBf,GAAoBH,EAAyBsB,EAAMJ,EAAkBK,GAAmBpB,EAAkBlB,EAAQpK,EAAShB,EAAcmN,GAEnK,CACA,OAAOE,CACX,CAkBA,SAASM,EAAoCvI,EAAOwI,EAAkBvO,EAAI6L,GACtE,IAAIpI,EAAIzD,EAAGyD,EAAGnF,EAAI0B,EAAG1B,EACrB,OAAOyH,EAAMyI,MAAK,SAAUxO,GACxB,IACIyO,EADYzO,EAAG4E,UACmBiH,GAAY7G,SAClD,OAjkBR,SAAyB0J,EAAIC,EAAIC,EAAIC,GACjC,IAAInJ,EAAKkJ,EAAKF,EACV/I,EAAKkJ,EAAKF,EACd,OAAOjJ,EAAKA,EAAKC,EAAKA,CAC1B,CA6jBemJ,CAAgBxQ,EAAGmF,EAAGgL,EAAsBnQ,EAAGmQ,EAAsBhL,IACxE8K,CACR,GACJ,CAKA,SAASQ,EAAiBC,EAAeT,EAAkBP,GACvD,IAAIiB,EAA8BjB,EAAkBvL,QAAO,SAAUzE,EAAQgC,EAAI6L,GAC7E,IAAI7G,EAAWhF,EAAGgF,SAAUH,EAAQ7E,EAAG6E,MAIvC,OAHKyJ,EAAoCU,EAAeT,EAAkBvJ,EAAU6G,KAChF7N,GAAU6G,GAEP7G,CACX,GAAG,GACH,OAAOiR,EAA+BjB,EAAkBjR,MAC5D,CA4DA,SAASmS,EAAoBhC,EAAciC,EAAeC,EAAwBC,EAAwB1O,EAAc2O,EAAmBC,EAAgBC,QAChI,IAAnBD,IAA6BA,EAAiB,SAChC,IAAdC,IAAwBA,EAAY,IAMxC,IALA,IAAIzJ,EAAQ,GACR0J,EA5OR,SAAiCF,EAAgBzD,EAAoBC,GAMjE,IALA,IAAI/L,EAAK+L,EAAOvM,MAAOsD,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GAAI0P,EAAe1P,EAAG,GACpEyP,EAAQ,IAAI3E,EAAQhI,EAASC,EAAQ2M,GAAc,SAAU1P,GAE7D,OADYA,EAAG6E,KAEnB,IACSf,EAAW,EAAGA,EAAWhB,IAAUgB,EACxC,IAAK,IAAIC,EAAW,EAAGA,EAAWhB,IAASgB,EACvC,IAAK,IAAI8H,EAAa,EAAGA,EAAa6D,IAAgB7D,EAAY,CAC9D,IAAIhH,EAAQkH,EAAOpI,IAAIG,EAAUC,EAAU8H,GAGvChH,EAAQ0K,GAIR3D,EAA4BC,EAAYhH,EAAOf,EAAUC,EAAU+H,EAAoBC,IACvF0D,EAAMtE,QAAQ,CAAEtG,MAAOA,EAAOhB,KAAM,CAAEC,SAAUA,EAAUC,SAAUA,EAAUC,GAAI6H,IAE1F,CAGR,OAAO4D,CACX,CAqNgBE,CAAwBJ,EA5Dd,EA4DmDrC,GACrEqB,EAAmBiB,EAAYA,EAG5BzJ,EAAMhJ,OAASuS,IAAsBG,EAAMjE,SAAS,CAEvD,IAAIqC,EAAO4B,EAAMpE,UAKjB,IAAIiD,EAAoCvI,EAAOwI,EADzB3K,EAAeiK,EAAKhK,KAAMlD,EAAcwO,GACoBtB,EAAKhK,KAAKG,IAA5F,CAIA,IAAIY,EAAYgJ,EAAWC,EAAMX,EAAciC,EAAexO,EAAcyO,EAAwBC,GAChGxK,EAAQkK,EAAiBhJ,EAAOwI,EAAkB3J,GACtDmB,EAAM3G,KAAK,CAAEwF,UAAWA,EAAWC,MAAOA,GAJ1C,CAKJ,CACA,OAAOkB,CACX,CAkBA,IAuFI/F,EAvFA4P,EAAe,EAAE,QAAS,OAAS,QACnCC,EAAwB,SAAUzN,GAElC,SAASyN,IACL,OAAkB,OAAXzN,GAAmBA,EAAOnF,MAAMb,KAAMU,YAAcV,IAC/D,CAiBA,OApBAF,EAAU2T,EAAQzN,GAIlByN,EAAOvT,UAAU6E,gBAAkB,SAAUH,GACzC,OAAO,MAAOA,EAAO4O,EACzB,EACAC,EAAOvT,UAAUkF,kBAAoB,SAAUa,GAC3C,IAAIR,EAAkBQ,EAAQ,GAAIT,EAAkBS,EAAQ,GAAIX,EAAUW,EAAQ,GAAIL,EAAcK,EAAQ,GAAIV,EAAUU,EAAQ,GAAIN,EAAeM,EAAQ,GAC7J,MAAO,CACHV,QAASA,EACTG,aAH4KO,EAAQ,GAIpLN,aAAcA,EACdC,YAAaA,EACbN,QAASA,EACTE,gBAAiBA,EACjBC,gBAAiBA,EACjBI,YATsMI,EAAQ,GAWtN,EACOwN,CACX,CAtB2B,CAsBzBpP,GAkBEqP,EAAoB,0EACpBC,EAAqB,2EAqEzB,SAASC,EAAahP,GAClB,GAAoC,qBAAxB,mBACRA,aAAiBiP,mBACa,qBAAtB,iBACJjP,aAAiBkP,iBACU,qBAAvB,kBACJlP,aAAiBmP,iBACrB,OA9BR,SAAqCnP,GACjC,GAAI,iBAAkBA,GAAgC,IAAvBA,EAAMoP,cAC9B,gBAAiBpP,GAA+B,IAAtBA,EAAMqP,YACnC,MAAO,CAACrP,EAAMoP,aAAcpP,EAAMqP,aAEjC,GAAoB,MAAhBrP,EAAM8B,QAAiC,MAAf9B,EAAM+B,MACnC,MAAO,CAAC/B,EAAM8B,OAAQ9B,EAAM+B,OAG5B,MAAM,IAAIuN,MAAM,8DAExB,CAmBeC,CAA4BvP,GAElC,GAA2B,qBAAhB,WAA+BA,aAAiBwP,UAC5D,MAAO,CAACxP,EAAM8B,OAAQ9B,EAAM+B,OAE3B,GAAkC,qBAAvB,kBACZ/B,aAAiByP,iBACjB,OAzBR,SAAiCzP,GAC7B,OAAIA,EAAM0P,aAAa,WAAa1P,EAAM0P,aAAa,SAI5C,CAAC1P,EAAM8B,OAAQ9B,EAAM+B,OAGrB,CAAC/B,EAAM2P,YAAa3P,EAAM4P,WAEzC,CAeeC,CAAwB7P,GAE9B,GAAIA,aAAiB,SACtB,MAAO,CAACA,EAAMxB,MAAM,GAAIwB,EAAMxB,MAAM,IAGpC,MAAM,IAAI8Q,MAAM,8BAA8BxP,OAAOE,EAAO,KAEpE,CAIA,SAAS8P,EAAuBC,EAAiBpQ,GAC7C,OAJJ,SAAgCqQ,EAAYrQ,GACxC,OAAQqQ,EAAa,GAAKrQ,IAAiB,CAC/C,CAEQsQ,CAAuBF,EAAiBpQ,GACjCoQ,EAEJjM,KAAK6F,MAAMoG,EAAkBpQ,GAAgBA,EAAe,CACvE,CACA,IAAIuQ,EAAqC,CACrCC,IAAK,MACLC,OAAQ,SACRC,KAAM,OACNC,KAAM,QAENC,IAAmCvR,EAAK,CAAC,GACtCkR,EAAmCC,KAAO,IAC7CnR,EAAGkR,EAAmCE,QAAU,GAChDpR,EAAGkR,EAAmCG,MAAQ,IAC9CrR,EAAGkR,EAAmCI,MAAQ,EAC9CtR,GAoBJ,SAASwR,EAAgCC,EAAoB9Q,EAAcX,GACvE,IAAI0R,EAAc1R,EAAG,GAAI2R,EAAa3R,EAAG,GACrC4R,EAnBR,SAAwCH,GACpC,GAAkC,kBAAvBA,EAAiC,CACxC,IAAIzT,EAASuT,EAAgCE,GAG7C,OAFA,cAAiC,kBAAXzT,GAAqB,WAAc,MAAO,kDAAkD8C,OAAOlF,OAAOiW,OAAOX,GAClIY,KAAK,KAAM,aAAahR,OAAO2Q,EAAoB,IAAM,IACvDzT,CACX,CAQI,OANA,cAA6C,kBAAvByT,GAClBA,GAVkB,GAWlBA,GAZkB,IAY6B,WAC/C,MAAO,sDAAsD3Q,OAb3C,GAa2E,SAASA,OAZpF,EAYoH,UAClI,OAAOA,OAAO2Q,EACtB,IACOA,CAEf,CAGuCM,CAA+BN,GAClE,MAAO,CACHX,EAAuBY,EAAcE,EAA8BjR,GACnEmQ,EAAuBa,EAAaC,EAA8BjR,GAE1E,CAmDA,SAASqR,EAA+BC,EAAQjS,EAAI4C,EAAIqD,EAAIiM,GACxD,IAAIC,EAAoBnS,EAAG,GAAIoS,EAAmBpS,EAAG,GACjDqS,EAAyBzP,EAAG,GAAI0P,EAAwB1P,EAAG,GAC3DsF,EAAKjC,EAAG,GAAI/C,EAAOgF,EAAG,GAAI9E,EAAO8E,EAAG,GAAIqK,EAAKtM,EAAG,GAAIE,EAAOoM,EAAG,GAAIC,EAAOD,EAAG,GAEhF,YAD+B,IAA3BL,IAAqCA,GAAyB,GAC3D,QAAQ,WACX,IAAIO,EAAqB,QAASC,eAAeT,EAAQ,CAACI,EAAwBC,IAAwB,GAI1G,OAHIJ,IACAO,EAAqB,UAAWA,IAK5C,SAAoCE,EAAkB3S,EAAI4C,GACtD,IAAIgQ,EAAiB5S,EAAG,GAAI6S,EAAgB7S,EAAG,GAC3CiG,EAAKrD,EAAG,GAAIM,EAAO+C,EAAG,GAAI7C,EAAO6C,EAAG,GAAIiC,EAAKtF,EAAG,GAAIuD,EAAO+B,EAAG,GAAIsK,EAAOtK,EAAG,GAChF,OAAO,QAAQ,WACX,IAAI4K,EAAe,aAAcH,GACjC,OAAO,UAAW,QACbI,cAAcD,EAAc,CAAC,CAC1B5P,GAAQ0P,EAAiB1P,EAAOE,EAAO,GACvC+C,GAAQ0M,EAAgB1M,EAAOqM,EAAO,IACrCtP,EAAO0P,EAAiB,IACpBA,EAAiB1P,EAAOE,EAAO,IACnC+C,EAAO0M,EAAgB,IAAQA,EAAgB1M,EAAOqM,EAAO,KAC9D,CAAC,GAAI,CAACI,EAAgBC,IAAiB,CAAC,GACpD,GACJ,CAjBeG,CAA2BP,EAAoB,CAACN,EAAmBC,GAAmB,CAAC,CAAClP,EAAME,GAAO,CAAC+C,EAAMqM,IACvH,GACJ,CAgBA,SAASS,GAAejS,EAAOhB,GAC3B,IAAIkT,EAAUlT,EAAG,GAAImT,EAAUnT,EAAG,GAC9B4C,EAAKoN,EAAahP,GAAQ8B,EAASF,EAAG,GAAIG,EAAQH,EAAG,GACrDwQ,EAAeD,EAAUD,EAEzBjN,EAAK,CAAC,EAAG,EAAG,EAAG,GAAI/C,EAAO+C,EAAG,GAAI7C,EAAO6C,EAAG,GAAIE,EAAOF,EAAG,GAAIuM,EAAOvM,EAAG,GAD9DlD,EAAQD,EAERsQ,GAETlQ,EAAO,EACPE,EAAO,EACP+C,EAAOrB,KAAK0B,MAAM,IAAO4M,EAAetQ,EAASC,IACjDyP,EAAO1N,KAAK0B,MAAM,IAAO4M,EAAetQ,EAASC,MAIjDG,EAAO4B,KAAK0B,MAAM,IAAQ,EAAM4M,EAAgBrQ,EAAQD,IACxDM,EAAO0B,KAAK0B,MAAM,IAAQ,EAAM4M,EAAgBrQ,EAAQD,IACxDqD,EAAO,EACPqM,EAAO,GAEX,IAAIa,EAAU,QAAQ,WAClB,IAAIC,EAnGZ,SAAuBtS,GAGnB,OAAOA,aAAiB,SAAYA,EAAQ,qBAAsBA,EACtE,CA+F0BuS,CAAcvS,GAEhC,OADAsS,EAAc,QAASA,EAAa,CAAC,CAACpQ,EAAME,GAAO,CAAC+C,EAAMqM,GAAO,CAAC,EAAG,KAC9D,QAASE,eAAeY,EAAa,CAACJ,EAASC,GAC1D,IACA,MAAO,CAAEE,QAASA,EAASxQ,QAAS,CAAEM,IAAKD,EAAMI,KAAM6C,EAAM5C,MAAOiP,EAAMnP,OAAQD,GACtF,CACA,SAASoQ,GAAkBC,GACvB,OAAOvW,EAAUd,UAAM,OAAQ,GAAQ,WACnC,OAAO+B,EAAY/B,MAAM,SAAU4D,GAC/B,MAAO,CAAC,EAAczC,QAAQkM,IAAIgK,EAAQnS,KAAI,SAAU2Q,GAAU,OAAOA,EAAOyB,QAAU,KAC9F,GACJ,GACJ,CA8CA,SAASC,GAAkB5N,EAAO/F,EAAI4C,EAAIC,EAAS+Q,GAC/C,IAAI9Q,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GAC3B6T,EAAwBjR,EAAG,GAAIkR,EAAuBlR,EAAG,GAGzDmR,EAhCR,SAAoBhO,EAAOM,EAAQD,EAAQ4N,EAASC,GAGhD,YAFgB,IAAZD,IAAsBA,EAAU,QACpB,IAAZC,IAAsBA,EAAU,GACrB,IAAX7N,GAA2B,IAAXC,GAA4B,IAAZ2N,GAA6B,IAAZC,EAC1ClO,EAEJA,EAAMzE,KAAI,SAAUkD,GAAQ,OAxBvC,SAAmBA,EAAM6B,EAAQD,EAAQ4N,EAASC,GAG9C,YAFgB,IAAZD,IAAsBA,EAAU,QACpB,IAAZC,IAAsBA,EAAU,GAC7B,CACHpP,MAAOL,EAAKK,MACZD,UAAWJ,EAAKI,UAAUtD,KAAI,SAAUtB,GACpC,IAAI6E,EAAQ7E,EAAG6E,MAAOhB,EAAO7D,EAAG6D,KAAMmB,EAAWhF,EAAGgF,SACpD,MAAO,CACHH,MAAOA,EACPhB,KAAMA,EACNmB,SAAU,CACNvB,EAAGuB,EAASvB,EAAI2C,EAAS6N,EACzB3V,EAAG0G,EAAS1G,EAAI+H,EAAS2N,GAGrC,IAER,CAO8CE,CAAU1P,EAAM6B,EAAQD,EAAQ4N,EAASC,EAAU,GACjG,CAyBsBE,CAAWpO,GAFfjD,EAASD,EAAQM,IAAMN,EAAQQ,QAAU,GACzCN,EAAQF,EAAQS,KAAOT,EAAQU,OAAS,GACDV,EAAQM,KAAMN,EAAQS,MAC3E,OAAIsQ,EAZR,SAA6B7N,EAAOqO,GAChC,OAAIA,GAAc,EACPrO,EAEJA,EAAMzE,KAAI,SAAUkD,GAAQ,OAjBvC,SAA4BA,EAAM4P,GAC9B,MAAO,CACHvP,MAAOL,EAAKK,MACZD,UAAWJ,EAAKI,UAAUtD,KAAI,SAAUtB,GACpC,IAAI6E,EAAQ7E,EAAG6E,MAAOhB,EAAO7D,EAAG6D,KAAMmB,EAAWhF,EAAGgF,SACpD,MAAO,CACHH,MAAOA,EACPhB,KAAMA,EACNmB,SAAU,CAAEvB,EAAG2Q,EAAa,EAAIpP,EAASvB,EAAGnF,EAAG0G,EAAS1G,GAEhE,IAER,CAK8C+V,CAAmB7P,EAAM4P,EAAa,GACpF,CAQeE,CAAoBP,EAAahR,GAGjCgR,CAEf,CAkBA,IAAIQ,IAA2B,EAC3BC,IAA2B,EAa3BC,GAAsB,CACtBC,aAAc,cACd/T,aAAc,GACdgU,WAAY,EACZC,WAAY,KAEZC,GAAqB,CAAC,cAAe,YACrCC,GAAe,CACf,YAAe,CAAC,EAAG,GAAI,IACvB,SAAY,CAAC,GAAI,KAEjBC,GAAmB,CACnB,YAAe,CAAC,GAAM,IAAM,GAC5B,SAAY,CAAC,IAEbC,GAAoB,CAAC,EAAG,EAAG,GAoC/B,IAAIC,GAA0B,CAC1BrB,gBAAgB,EAChBnC,mBAAoB,SACpByD,sBAAuB,GACvBC,cAAe,GACf5F,eAAgB,GAChBC,UAAW,IAEX4F,GAAyC,CACzCxB,gBAAgB,EAChBnC,mBAAoB,SACpByD,sBAAuB,GACvBC,cAAe,GACf5F,eAAgB,GAChBC,UAAW,GACX3G,iBAAkB,GAClBtD,YAAa,IAEjB,SAAS8P,GAA8BC,GACnC,IAAIJ,EAAwBI,EAAOJ,sBAAuBC,EAAgBG,EAAOH,cAAe5F,EAAiB+F,EAAO/F,eAAgBC,EAAY8F,EAAO9F,UAC3J,GAAI0F,EAAwB,GAAOA,EAAwB,EACvD,MAAM,IAAI5E,MAAM,yBAAyBxP,OAAOoU,EAAuB,MACnE,iCAER,GAAIC,GAAiB,EACjB,MAAM,IAAI7E,MAAM,yBAAyBxP,OAAOqU,EAAe,MAC3D,iBAER,GAAI5F,EAAiB,GAAOA,EAAiB,EACzC,MAAM,IAAIe,MAAM,0BAA0BxP,OAAOyO,EAAgB,MAC7D,iCAER,GAAIC,GAAa,EACb,MAAM,IAAIc,MAAM,qBAAqBxP,OAAO0O,EAAW,KAE/D,CACA,SAAS+F,GAA2CD,GAChD,IAAIJ,EAAwBI,EAAOJ,sBAAuBC,EAAgBG,EAAOH,cAAe5F,EAAiB+F,EAAO/F,eAAgBC,EAAY8F,EAAO9F,UAAW3G,EAAmByM,EAAOzM,iBAAkBtD,EAAc+P,EAAO/P,YACvO,GAAI2P,EAAwB,GAAOA,EAAwB,EACvD,MAAM,IAAI5E,MAAM,yBAAyBxP,OAAOoU,EAAuB,MACnE,iCAER,GAAIC,GAAiB,EACjB,MAAM,IAAI7E,MAAM,yBAAyBxP,OAAOqU,EAAe,MAC3D,iBAER,GAAI5F,EAAiB,GAAOA,EAAiB,EACzC,MAAM,IAAIe,MAAM,0BAA0BxP,OAAOyO,EAAgB,MAC7D,iCAER,GAAIC,GAAa,EACb,MAAM,IAAIc,MAAM,qBAAqBxP,OAAO0O,EAAW,MAE3D,GAAI3G,EAAmB,GAAKA,EAAmB,EAC3C,MAAM,IAAIyH,MAAM,4BAA4BxP,OAAO+H,EAAkB,KACjE,iCAER,GAAItD,GAAe,GAAKA,EAAc,GAClC,MAAM,IAAI+K,MAAM,uBAAuBxP,OAAOyE,EAAa,KACvD,6BAEZ,CACA,IAAIiQ,GAAyB,WACzB,SAASA,EAAQC,GACbrZ,KAAKsZ,UAAYD,CACrB,CA8aA,OA7aAD,EAAQlZ,UAAUqZ,6BAA+B,SAAU3U,GACvD,IAAIhB,EAAK5D,KAAKsZ,UAAU3U,QAAQC,GAChC,MAAO,CACH4U,cAFmD5V,EAAG8B,aAGtDL,cAHoFzB,EAAGyB,cAIvFE,QAJgH3B,EAAG2B,QAKnHC,gBAL8I5B,EAAG4B,gBAMjJC,gBANoL7B,EAAG6B,gBAQ/L,EACA2T,EAAQlZ,UAAUuZ,oCAAsC,SAAU7U,GAC9D,IAAIhB,EAAK5D,KAAKsZ,UAAU3U,QAAQC,GAChC,MAAO,CACH4U,cAFmD5V,EAAG8B,aAGtDgU,kBAHmF9V,EAAG+B,aAItFN,cAJoHzB,EAAGyB,cAKvHE,QALgJ3B,EAAG2B,QAMnJC,gBAN8K5B,EAAG4B,gBAOjLC,gBAPoN7B,EAAG6B,gBAS/N,EACA2T,EAAQlZ,UAAUyZ,iDAAmD,SAAU/U,GAC3E,IAAIhB,EAAK5D,KAAKsZ,UAAU3U,QAAQC,GAChC,MAAO,CACH4U,cAFmD5V,EAAG8B,aAGtDE,YAHkFhC,EAAGgC,YAIrFP,cAJkHzB,EAAGyB,cAKrHE,QAL8I3B,EAAG2B,QAMjJC,gBAN4K5B,EAAG4B,gBAO/KC,gBAPkN7B,EAAG6B,gBAQrNE,aARqP/B,EAAG+B,aAUhQ,EAoCAyT,EAAQlZ,UAAU0Z,wBAA0B,SAAUhV,EAAOyQ,EAAoByD,GAC7E,IAAIjU,EAAQ7E,UACkB,IAA1B8Y,IAAoCA,EAAwB,IAChE,IAAIlV,EAAKgQ,EAAahP,GAAQ8B,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GACrDiW,EAAmCzE,EAAgCC,EAAoBrV,KAAKsZ,UAAU/U,aAAc,CAACmC,EAAQC,IAC7HH,EAAKqQ,GAAejS,EAAOiV,GAAmC5C,EAAUzQ,EAAGyQ,QAASxQ,EAAUD,EAAGC,QACjGoD,EAAK,QAAQ,WACb,IAAIjG,EAAKiB,EAAM0U,6BAA6BtC,GAAUuC,EAAgB5V,EAAG4V,cAAenU,EAAgBzB,EAAGyB,cAAeE,EAAU3B,EAAG2B,QAASC,EAAkB5B,EAAG4B,gBAAiBC,EAAkB7B,EAAG6B,gBACvMe,EAAKyQ,EAAQ7T,MAAO0W,EAAgBtT,EAAG,GAAIuT,EAAevT,EAAG,GAC7DwT,EAAsBpE,EAA+B4D,EAAe,CAAC9S,EAAQC,GAAQ,CAACmT,EAAeC,GAAe,CAAC,CAACtT,EAAQM,IAAKN,EAAQQ,QAAS,CAACR,EAAQS,KAAMT,EAAQU,QAASgR,IACxL,MAAO,CACHzS,aAAcnC,EAAa,UAAWyW,GAAsBlB,GAC5DzT,cAAeA,EACfE,QAASA,EACTC,gBAAiBA,EACjBC,gBAAiBA,EAEzB,IAAIC,EAAemE,EAAGnE,aAAcL,EAAgBwE,EAAGxE,cAAeE,EAAUsE,EAAGtE,QAASC,EAAkBqE,EAAGrE,gBAAiBC,EAAkBoE,EAAGpE,gBAEvJ,OADAwR,EAAQnR,UACD,CACHJ,aAAcA,EACdL,cAAeA,EACfE,QAASA,EACTC,gBAAiBA,EACjBC,gBAAiBA,EACjBgB,QAASA,EACToT,iCAAkCA,EAE1C,EA0BAT,EAAQlZ,UAAU+Z,cAAgB,SAAUrV,EAAOsU,GAE/C,YADe,IAAXA,IAAqBA,EAASL,IAC3B/X,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAI4D,EAAI8B,EAAcL,EAAeE,EAASC,EAAiBC,EAAiBgB,EAASoT,EAAkCrT,EAAIE,EAAQC,EAAO/E,EAAQsY,EAAeC,EAAWC,EAAYC,EAAqBC,EAAqB3Q,EACtO,OAAO5H,EAAY/B,MAAM,SAAU6J,GAC/B,OAAQA,EAAGxH,OACP,KAAK,EAKD,OAHA4W,GADAC,EAAS9Y,EAASA,EAAS,CAAC,EAAGyY,IAA0BK,IAEzDtV,EAAK5D,KAAK4Z,wBAAwBhV,EAAOsU,EAAO7D,mBAAoB6D,EAAOJ,uBAAwBpT,EAAe9B,EAAG8B,aAAcL,EAAgBzB,EAAGyB,cAAeE,EAAU3B,EAAG2B,QAASC,EAAkB5B,EAAG4B,gBAAiBC,EAAkB7B,EAAG6B,gBAAiBgB,EAAU7C,EAAG6C,QAASoT,EAAmCjW,EAAGiW,iCACnUrT,EAAKd,EAAatC,MAAOsD,EAASF,EAAG,GAAIG,EAAQH,EAAG,GAC7C,CAAC,EAAad,EAAa4H,QACtC,KAAK,EAGD,OAFA1L,EAASiI,EAAGvH,OACZoD,EAAaI,UACN,CAAC,EAAasR,GAAkB,CAAC/R,EAAeE,EAASC,EAAiBC,KACrF,KAAK,EASD,OARAyU,EAAgBrQ,EAAGvH,OACnB6X,EAAYD,EAAc,GAAIE,EAAaF,EAAc,GAAIG,EAAsBH,EAAc,GAAII,EAAsBJ,EAAc,GAEzIvQ,EAAQ4N,GADR5N,EAAQmJ,EAAoBqH,EAAWC,EAAYC,EAAqBC,EAAqBta,KAAKsZ,UAAU/U,aAAc2U,EAAOH,cAAeG,EAAO/F,eAAgB+F,EAAO9F,WAC7I,CAAC1M,EAAQC,GAAQkT,EAAkCpT,EAAS2R,IAC7F/S,EAAcS,UACdP,EAAQO,UACRN,EAAgBM,UAChBL,EAAgBK,UACT,CAAC,EAAc,CAAEY,OAAQA,EAAQC,MAAOA,EAAO2G,KAAM1L,EAAQ2Y,SAAU5Q,IAE1F,GACJ,GACJ,EAwBAyP,EAAQlZ,UAAUsa,mBAAqB,SAAU5V,EAAOsU,GAEpD,YADe,IAAXA,IAAqBA,EAASF,IAC3BlY,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAI4D,EAAI8C,EAAQC,EAAOkT,EAAkCrT,EAAIyQ,EAASxQ,EAASoD,EAAInE,EAAcE,EAAa6U,EAAkBC,EAAYC,EAAoBC,EAAoBV,EAAeC,EAAWC,EAAYC,EAAqBC,EAAqB3Q,EAAOkR,EACvQhW,EAAQ7E,KACZ,OAAO+B,EAAY/B,MAAM,SAAU8L,GAC/B,OAAQA,EAAGzJ,OACP,KAAK,EAuBD,OArBA8W,GADAD,EAAS9Y,EAASA,EAAS,CAAC,EAAG4Y,IAAyCE,IAExEtV,EAAKgQ,EAAahP,GAAQ8B,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GACrDiW,EAAmCzE,EAAgC8D,EAAO7D,mBAAoBrV,KAAKsZ,UAAU/U,aAAc,CAACmC,EAAQC,IACpIH,EAAKqQ,GAAejS,EAAOiV,GAAmC5C,EAAUzQ,EAAGyQ,QAASxQ,EAAUD,EAAGC,QACjGoD,EAAK,QAAQ,WACT,IAEIiR,EAFAlX,EAAKiB,EAAM8U,iDAAiD1C,GAAUuC,EAAgB5V,EAAG4V,cAAe5T,EAAchC,EAAGgC,YAAaP,EAAgBzB,EAAGyB,cAAeE,EAAU3B,EAAG2B,QAASC,EAAkB5B,EAAG4B,gBAAiBC,EAAkB7B,EAAG6B,gBACzPuU,EAAsBpE,EAA+B4D,EAAe,CAAC9S,EAAQC,GAAQkT,EAAkC,CAAC,CAACpT,EAAQM,IAAKN,EAAQQ,QAAS,CAACR,EAAQS,KAAMT,EAAQU,QAASgR,IAM3L,OAHI2C,EAAoBlV,EAGjB,CACHF,aAFenC,EAAa,UAAWyW,GAAsBd,EAAOJ,uBAGpElT,YAAakV,EACbL,iBAAkBpV,EAClBqV,WAAYnV,EACZoV,mBAAoBnV,EACpBoV,mBAAoBnV,EAE5B,IAAIC,EAAemE,EAAGnE,aAAcE,EAAciE,EAAGjE,YAAa6U,EAAmB5Q,EAAG4Q,iBAAkBC,EAAa7Q,EAAG6Q,WAAYC,EAAqB9Q,EAAG8Q,mBAAoBC,EAAqB/Q,EAAG+Q,mBACnM,CAAC,EAAaxD,GAAkB,CAACqD,EAAkBC,EAAYC,EAAoBC,KAC9F,KAAK,EAKD,OAJAV,EAAgBpO,EAAGxJ,OACnB6X,EAAYD,EAAc,GAAIE,EAAaF,EAAc,GAAIG,EAAsBH,EAAc,GAAII,EAAsBJ,EAAc,GAEzIvQ,EAAQ4N,GADR5N,EAAQmJ,EAAoBqH,EAAWC,EAAYC,EAAqBC,EAAqBta,KAAKsZ,UAAU/U,aAAc2U,EAAOH,cAAeG,EAAO/F,eAAgB+F,EAAO9F,WAC7I,CAAC1M,EAAQC,GAAQkT,EAAkCpT,EAAS2R,IACtF,CAAC,EAAa7L,EAA0B7G,EAAcE,EAAa+D,EAAOjD,EAAQC,EAAO3G,KAAKsZ,UAAU/U,aAAcsV,EAAkCpT,EAASyS,EAAO/F,eAAgB+F,EAAO/P,YAAa+P,EAAOzM,iBAAkByM,EAAOH,gBACvP,KAAK,EASD,OARA8B,EAAgB/O,EAAGxJ,OACnB2U,EAAQnR,UACRJ,EAAaI,UACbF,EAAYE,UACZ2U,EAAiB3U,UACjB4U,EAAW5U,UACX6U,EAAmB7U,UACnB8U,EAAmB9U,UACZ,CAAC,EAAc+U,GAElC,GACJ,GACJ,EAqCAzB,EAAQlZ,UAAU6a,6BAA+B,SAAUnW,EAAOyQ,EAAoByD,GAClF,IAAIjU,EAAQ7E,UACkB,IAA1B8Y,IAAoCA,EAAwB,IAChE,IAAIlV,EAAKgQ,EAAahP,GAAQ8B,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GACrDiW,EAAmCzE,EAAgCC,EAAoBrV,KAAKsZ,UAAU/U,aAAc,CAACmC,EAAQC,IAC7HH,EAAKqQ,GAAejS,EAAOiV,GAAmC5C,EAAUzQ,EAAGyQ,QAASxQ,EAAUD,EAAGC,QACjGoD,EAAK,QAAQ,WACb,IAAIjG,EAAKiB,EAAM4U,oCAAoCxC,GAAUuC,EAAgB5V,EAAG4V,cAAeE,EAAoB9V,EAAG8V,kBAAmBrU,EAAgBzB,EAAGyB,cAAeE,EAAU3B,EAAG2B,QAASC,EAAkB5B,EAAG4B,gBAAiBC,EAAkB7B,EAAG6B,gBACxPe,EAAKyQ,EAAQ7T,MAAO0W,EAAgBtT,EAAG,GAAIuT,EAAevT,EAAG,GAC7DwT,EAAsBpE,EAA+B4D,EAAe,CAAC9S,EAAQC,GAAQ,CAACmT,EAAeC,GAAe,CAAC,CAACtT,EAAQM,IAAKN,EAAQQ,QAAS,CAACR,EAAQS,KAAMT,EAAQU,QAASgR,IACpL6C,EAAyBpF,EAA+B8D,EAAmB,CAAChT,EAAQC,GAAQ,CAACmT,EAAeC,GAAe,CAAC,CAACtT,EAAQM,IAAKN,EAAQQ,QAAS,CAACR,EAAQS,KAAMT,EAAQU,QAASgR,IAE/L,MAAO,CACHtK,iBAAkBnK,EAFHH,EAAa,UAAWyW,GAAsBlB,GAENkC,GACvD3V,cAAeA,EACfE,QAASA,EACTC,gBAAiBA,EACjBC,gBAAiBA,EAEzB,IAAIoI,EAAmBhE,EAAGgE,iBAAkBxI,EAAgBwE,EAAGxE,cAAeE,EAAUsE,EAAGtE,QAASC,EAAkBqE,EAAGrE,gBAAiBC,EAAkBoE,EAAGpE,gBAE/J,OADAwR,EAAQnR,UACD,CACH+H,iBAAkBA,EAClBxI,cAAeA,EACfE,QAASA,EACTC,gBAAiBA,EACjBC,gBAAiBA,EACjBgB,QAASA,EACToT,iCAAkCA,EAE1C,EA2BAT,EAAQlZ,UAAU+a,mBAAqB,SAAUrW,EAAOsU,GAEpD,YADe,IAAXA,IAAqBA,EAASL,IAC3B/X,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAI4D,EAAIiK,EAAkBxI,EAAeE,EAASC,EAAiBC,EAAiBgB,EAASoT,EAAkCrT,EAAIE,EAAQC,EAAO2G,EAAM4M,EAAeC,EAAWC,EAAYC,EAAqBC,EAAqB3Q,EACxO,OAAO5H,EAAY/B,MAAM,SAAU6J,GAC/B,OAAQA,EAAGxH,OACP,KAAK,EAKD,OAHA4W,GADAC,EAAS9Y,EAASA,EAAS,CAAC,EAAGyY,IAA0BK,IAEzDtV,EAAK5D,KAAK+a,6BAA6BnW,EAAOsU,EAAO7D,mBAAoB6D,EAAOJ,uBAAwBjL,EAAmBjK,EAAGiK,iBAAkBxI,EAAgBzB,EAAGyB,cAAeE,EAAU3B,EAAG2B,QAASC,EAAkB5B,EAAG4B,gBAAiBC,EAAkB7B,EAAG6B,gBAAiBgB,EAAU7C,EAAG6C,QAASoT,EAAmCjW,EAAGiW,iCAChVrT,EAAKqH,EAAiBzK,MAAOsD,EAASF,EAAG,GAAIG,EAAQH,EAAG,GACjD,CAAC,EAAaqH,EAAiBP,QAC1C,KAAK,EAGD,OAFAA,EAAOzD,EAAGvH,OACVuL,EAAiB/H,UACV,CAAC,EAAasR,GAAkB,CAAC/R,EAAeE,EAASC,EAAiBC,KACrF,KAAK,EASD,OARAyU,EAAgBrQ,EAAGvH,OACnB6X,EAAYD,EAAc,GAAIE,EAAaF,EAAc,GAAIG,EAAsBH,EAAc,GAAII,EAAsBJ,EAAc,GAEzIvQ,EAAQ4N,GADR5N,EAAQmJ,EAAoBqH,EAAWC,EAAYC,EAAqBC,EAAqBta,KAAKsZ,UAAU/U,aAAc2U,EAAOH,cAAeG,EAAO/F,eAAgB+F,EAAO9F,WAC7I,CAAC1M,EAAQC,GAAQkT,EAAkCpT,EAAS2R,IAC7F/S,EAAcS,UACdP,EAAQO,UACRN,EAAgBM,UAChBL,EAAgBK,UACT,CAAC,EAAc,CAAEY,OAAQA,EAAQC,MAAOA,EAAO2G,KAAMA,EAAMiN,SAAU5Q,IAExF,GACJ,GACJ,EAwBAyP,EAAQlZ,UAAUgb,wBAA0B,SAAUtW,EAAOsU,GAEzD,YADe,IAAXA,IAAqBA,EAASF,IAC3BlY,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAI4D,EAAI8C,EAAQC,EAAOkT,EAAkCrT,EAAIyQ,EAASxQ,EAASoD,EAAInE,EAAcE,EAAa6U,EAAkBC,EAAYC,EAAoBC,EAAoB/M,EAAkBqM,EAAeC,EAAWC,EAAYC,EAAqBC,EAAqB3Q,EAAOkR,EACzRhW,EAAQ7E,KACZ,OAAO+B,EAAY/B,MAAM,SAAU8L,GAC/B,OAAQA,EAAGzJ,OACP,KAAK,EAyBD,OAvBA8W,GADAD,EAAS9Y,EAASA,EAAS,CAAC,EAAG4Y,IAAyCE,IAExEtV,EAAKgQ,EAAahP,GAAQ8B,EAAS9C,EAAG,GAAI+C,EAAQ/C,EAAG,GACrDiW,EAAmCzE,EAAgC8D,EAAO7D,mBAAoBrV,KAAKsZ,UAAU/U,aAAc,CAACmC,EAAQC,IACpIH,EAAKqQ,GAAejS,EAAOiV,GAAmC5C,EAAUzQ,EAAGyQ,QAASxQ,EAAUD,EAAGC,QACjGoD,EAAK,QAAQ,WACT,IAAIjG,EAAKiB,EAAM8U,iDAAiD1C,GAAUuC,EAAgB5V,EAAG4V,cAAe5T,EAAchC,EAAGgC,YAAaP,EAAgBzB,EAAGyB,cAAeE,EAAU3B,EAAG2B,QAASC,EAAkB5B,EAAG4B,gBAAiBC,EAAkB7B,EAAG6B,gBAAiBE,EAAe/B,EAAG+B,aAE5RqU,EAAsBpE,EAA+B4D,EAAe,CAAC9S,EAAQC,GAAQkT,EAAkC,CAAC,CAACpT,EAAQM,IAAKN,EAAQQ,QAAS,CAACR,EAAQS,KAAMT,EAAQU,QAASgR,IAEvLgD,EAA+BvF,EAA+BjQ,EAAc,CAACe,EAAQC,GAAQkT,EAAkC,CAAC,CAACpT,EAAQM,IAAKN,EAAQQ,QAAS,CAACR,EAAQS,KAAMT,EAAQU,QAASgR,IAC/L2C,EAAoBlV,EACpBF,EAAenC,EAAa,UAAWyW,GAAsBd,EAAOJ,uBACpEjL,EA9xDhC,SAAoC3K,GAChC,IAAIU,EAAKV,EAAkBE,MAAOS,EAAgBD,EAAG,GAAIE,EAAeF,EAAG,GAAIT,EAAWS,EAAG,GAC7F,OAAO,QAAQ,WACX,IAAIK,EAAehB,EAAyBC,GACxCgB,EAAc,aAAc,QAAS,EAAGf,EAAU,EAAG,SAAU,GAC/DG,EAAmB,OAAQ,SAAUW,EAAcC,GAAc,SACrE,OAAO,UAAWZ,EAAkB,CAACO,EAAeC,GACxD,GACJ,CAsxDmDsX,CAA2BD,GAClD,MAAO,CACHzV,aAAcA,EACdE,YAAakV,EACbL,iBAAkBpV,EAClBqV,WAAYnV,EACZoV,mBAAoBnV,EACpBoV,mBAAoBnV,EACpBoI,iBAAkBA,EAE1B,IAAInI,EAAemE,EAAGnE,aAAcE,EAAciE,EAAGjE,YAAa6U,EAAmB5Q,EAAG4Q,iBAAkBC,EAAa7Q,EAAG6Q,WAAYC,EAAqB9Q,EAAG8Q,mBAAoBC,EAAqB/Q,EAAG+Q,mBAAoB/M,EAAmBhE,EAAGgE,iBAC7O,CAAC,EAAauJ,GAAkB,CAACqD,EAAkBC,EAAYC,EAAoBC,KAC9F,KAAK,EAKD,OAJAV,EAAgBpO,EAAGxJ,OACnB6X,EAAYD,EAAc,GAAIE,EAAaF,EAAc,GAAIG,EAAsBH,EAAc,GAAII,EAAsBJ,EAAc,GAEzIvQ,EAAQ4N,GADR5N,EAAQmJ,EAAoBqH,EAAWC,EAAYC,EAAqBC,EAAqBta,KAAKsZ,UAAU/U,aAAc2U,EAAOH,cAAeG,EAAO/F,eAAgB+F,EAAO9F,WAC7I,CAAC1M,EAAQC,GAAQkT,EAAkCpT,EAAS2R,IACtF,CAAC,EAAaxK,EAA8BlI,EAAcE,EAAaiI,EAAkBlE,EAAOjD,EAAQC,EAAO3G,KAAKsZ,UAAU/U,aAAcsV,EAAkCpT,EAASyS,EAAO/F,eAAgB+F,EAAO/P,YAAa+P,EAAOzM,iBAAkByM,EAAOH,gBAC7Q,KAAK,EAUD,OATA8B,EAAgB/O,EAAGxJ,OACnB2U,EAAQnR,UACRJ,EAAaI,UACbF,EAAYE,UACZ2U,EAAiB3U,UACjB4U,EAAW5U,UACX6U,EAAmB7U,UACnB8U,EAAmB9U,UACnB+H,EAAiB/H,UACV,CAAC,EAAc+U,GAElC,GACJ,GACJ,EACAzB,EAAQlZ,UAAU4F,QAAU,WACxB9F,KAAKsZ,UAAUxT,SACnB,EACOsT,CACX,CAlb4B,GAsb5B,SAASiC,GAAcnC,GACnB,OAAOpY,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAIuE,EAAcgU,EAAYC,EAAY8C,EAAKC,EAAYC,EAC3D,OAAOzZ,EAAY/B,MAAM,SAAU4D,GAC/B,OAAQA,EAAGvB,OACP,KAAK,EAID,GAHAkC,EAAe2U,EAAO3U,aACtBgU,EAAaW,EAAOX,WACpBC,EAAaU,EAAOV,WACV,MAAN,EACA,MAAM,IAAItE,MAAM,kJAIpB,OADAoH,EA13BpB,SAA6BxR,EAAQ0O,EAAYD,GAC7C,IAAIkD,EAAQ,CAAE,EAAK,MAAO,IAAM,MAAO,GAAM,OACzCC,EAAY,eAAehX,OAAOoF,EAAQ,SAE9C,OAAmB,IAAfyO,EACO5E,EAAqB,SAASjP,OAAO+W,EAAMjD,GAAa,KAAOkD,EAG/D/H,EAAqB,QAAQjP,OAAO6T,EAAY,KAAK7T,OAAO+W,EAAMjD,GAAa,KAClFkD,CAEZ,CA+2B0BC,CAAoBpX,EAAciU,EAAYD,GAC7C,CAAC,EAAa,KAAsBW,EAAO0C,UAAYN,IAClE,KAAK,EAGD,OAFAC,EAAa3X,EAAGtB,OAChBkZ,EAAY,IAAIzV,EAAUwV,EAAYhX,GAC/B,CAAC,EAAc,IAAI6U,GAAQoC,IAE9C,GACJ,GACJ,CAIA,SAASK,GAAW3C,GAChB,OAAOpY,EAAUd,UAAM,OAAQ,GAAQ,WACnC,IAAIuE,EAAcgU,EAAY+C,EAAKC,EAAYO,EAC/C,OAAO/Z,EAAY/B,MAAM,SAAU4D,GAC/B,OAAQA,EAAGvB,OACP,KAAK,EAGD,GAFAkC,EAAe2U,EAAO3U,aACtBgU,EAAaW,EAAOX,WACV,MAAN,EACA,MAAM,IAAIrE,MAAM,kJAIpB,OADAoH,EA/5BpB,SAA4BxR,EAAQyO,GAChC,IAAImD,EAAY,eAAehX,OAAOoF,EAAQ,SAE9C,OAAmB,IAAfyO,EACO7E,EAAoB,SAAWgI,EAG/BhI,EAAoB,QAAQhP,OAAO6T,EAAY,KAAOmD,CAErE,CAs5B0BK,CAAmBxX,EAAcgU,GAChC,CAAC,EAAa,KAAsBW,EAAO0C,UAAYN,IAClE,KAAK,EAGD,OAFAC,EAAa3X,EAAGtB,OAChBwZ,EAAS,IAAIrI,EAAO8H,EAAYhX,GACzB,CAAC,EAAc,IAAI6U,GAAQ0C,IAE9C,GACJ,GACJ,CAaA,SAASE,GAAK9C,GAEV,YADe,IAAXA,IAAqBA,EAASb,IAC3BvX,EAAUd,UAAM,OAAQ,GAAQ,WACnC,OAAO+B,EAAY/B,MAAM,SAAU4D,GAE/B,MAA4B,cAD5BsV,EAvlBZ,SAA6BA,GAKzB,GAH2B,OAD3BA,EAASA,GAAUb,IACRC,eACPY,EAAOZ,aAAe,eAEtBG,GAAmBwD,QAAQ/C,EAAOZ,cAAgB,EAClD,MAAM,IAAIpE,MAAM,wBAAwBxP,OAAOwU,EAAOZ,aAAc,MAChE,oBAAoB5T,OAAO+T,KAKnC,GAH2B,MAAvBS,EAAO3U,eACP2U,EAAO3U,aAAe,IAEtBmU,GAAaQ,EAAOZ,cAAc2D,QAAQ/C,EAAO3U,cAAgB,EACjE,MAAM,IAAI2P,MAAM,wBAAwBxP,OAAOwU,EAAO3U,aAAc,MAChE,oBAAoBG,OAAOgU,GAAaQ,EAAOZ,cAAe,KAC9D,oBAAoB5T,OAAOwU,EAAOZ,aAAc,MAKxD,GAHyB,MAArBY,EAAOV,aACPU,EAAOV,WAAa,GAEpBG,GAAiBO,EAAOZ,cAAc2D,QAAQ/C,EAAOV,YAAc,EACnE,MAAM,IAAItE,MAAM,sBAAsBxP,OAAOwU,EAAOV,WAAY,MAC5D,oBAAoB9T,OAAOiU,GAAiBO,EAAOZ,cAAe,KAClE,oBAAoB5T,OAAOwU,EAAOZ,aAAc,MAKxD,GAHyB,MAArBY,EAAOX,aACPW,EAAOX,WAAa,GAEpBK,GAAkBqD,QAAQ/C,EAAOX,YAAc,EAC/C,MAAM,IAAIrE,MAAM,sBAAsBxP,OAAOwU,EAAOX,WAAY,MAC5D,oBAAoB7T,OAAOkU,GAAmB,KAC9C,oBAAoBlU,OAAOwU,EAAOZ,aAAc,MAExD,OAAOY,CACX,CAqjBqBgD,CAAoBhD,IAClBZ,aACA,CAAC,EAAcuD,GAAW3C,IAEJ,gBAAxBA,EAAOZ,aACL,CAAC,EAAc+C,GAAcnC,IAG7B,CAAC,EAAc,KAE9B,GACJ,GACJ,C","sources":["webpack://StylistWidget/./node_modules/@tensorflow-models/body-pix/dist/body-pix.esm.js"],"sourcesContent":["/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport { getBackend } from '@tensorflow/tfjs-core';\n\n/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nfunction __extends(d, b) {\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nvar __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    };\r\n    return __assign.apply(this, arguments);\r\n};\r\n\r\nfunction __awaiter(thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nfunction __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Takes the sigmoid of the part heatmap output and generates a 2d one-hot\n * tensor with ones where the part's score has the maximum value.\n *\n * @param partHeatmapScores\n */\nfunction toFlattenedOneHotPartMap(partHeatmapScores) {\n    var numParts = partHeatmapScores.shape[2];\n    var partMapLocations = tf.argMax(partHeatmapScores, 2);\n    var partMapFlattened = tf.reshape(partMapLocations, [-1]);\n    return tf.oneHot(partMapFlattened, numParts);\n}\nfunction clipByMask2d(image, mask) {\n    return tf.mul(image, mask);\n}\n/**\n * Takes the sigmoid of the segmentation output, and generates a segmentation\n * mask with a 1 or 0 at each pixel where there is a person or not a person. The\n * segmentation threshold determines the threshold of a score for a pixel for it\n * to be considered part of a person.\n * @param segmentScores A 3d-tensor of the sigmoid of the segmentation output.\n * @param segmentationThreshold The minimum that segmentation values must have\n * to be considered part of the person.  Affects the generation of the\n * segmentation mask and the clipping of the colored part image.\n *\n * @returns A segmentation mask with a 1 or 0 at each pixel where there is a\n * person or not a person.\n */\nfunction toMaskTensor(segmentScores, threshold) {\n    return tf.tidy(function () {\n        return tf.cast(tf.greater(segmentScores, tf.scalar(threshold)), 'int32');\n    });\n}\n/**\n * Takes the sigmoid of the person and part map output, and returns a 2d tensor\n * of an image with the corresponding value at each pixel corresponding to the\n * part with the highest value. These part ids are clipped by the segmentation\n * mask. Wherever the a pixel is clipped by the segmentation mask, its value\n * will set to -1, indicating that there is no part in that pixel.\n * @param segmentScores A 3d-tensor of the sigmoid of the segmentation output.\n * @param partHeatmapScores A 3d-tensor of the sigmoid of the part heatmap\n * output. The third dimension corresponds to the part.\n *\n * @returns A 2d tensor of an image with the corresponding value at each pixel\n * corresponding to the part with the highest value. These part ids are clipped\n * by the segmentation mask.  It will have values of -1 for pixels that are\n * outside of the body and do not have a corresponding part.\n */\nfunction decodePartSegmentation(segmentationMask, partHeatmapScores) {\n    var _a = partHeatmapScores.shape, partMapHeight = _a[0], partMapWidth = _a[1], numParts = _a[2];\n    return tf.tidy(function () {\n        var flattenedMap = toFlattenedOneHotPartMap(partHeatmapScores);\n        var partNumbers = tf.expandDims(tf.range(0, numParts, 1, 'int32'), 1);\n        var partMapFlattened = tf.cast(tf.matMul(flattenedMap, partNumbers), 'int32');\n        var partMap = tf.reshape(partMapFlattened, [partMapHeight, partMapWidth]);\n        var partMapShiftedUpForClipping = tf.add(partMap, tf.scalar(1, 'int32'));\n        return tf.sub(clipByMask2d(partMapShiftedUpForClipping, segmentationMask), tf.scalar(1, 'int32'));\n    });\n}\nfunction decodeOnlyPartSegmentation(partHeatmapScores) {\n    var _a = partHeatmapScores.shape, partMapHeight = _a[0], partMapWidth = _a[1], numParts = _a[2];\n    return tf.tidy(function () {\n        var flattenedMap = toFlattenedOneHotPartMap(partHeatmapScores);\n        var partNumbers = tf.expandDims(tf.range(0, numParts, 1, 'int32'), 1);\n        var partMapFlattened = tf.cast(tf.matMul(flattenedMap, partNumbers), 'int32');\n        return tf.reshape(partMapFlattened, [partMapHeight, partMapWidth]);\n    });\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * BodyPix supports using various convolution neural network models\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\n * The following BaseModel interface defines a unified interface for\n * creating such BodyPix base models. Currently both MobileNet (in\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\n * interface. New base models that conform to the BaseModel interface can be\n * added to BodyPix.\n */\nvar BaseModel = /** @class */ (function () {\n    function BaseModel(model, outputStride) {\n        this.model = model;\n        this.outputStride = outputStride;\n        var inputShape = this.model.inputs[0].shape;\n        tf.util.assert((inputShape[1] === -1) && (inputShape[2] === -1), function () { return \"Input shape [\".concat(inputShape[1], \", \").concat(inputShape[2], \"] \") +\n            \"must both be equal to or -1\"; });\n    }\n    /**\n     * Predicts intermediate Tensor representations.\n     *\n     * @param input The input RGB image of the base model.\n     * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\n     *\n     * @return A dictionary of base model's intermediate predictions.\n     * The returned dictionary should contains the following elements:\n     * - heatmapScores: A Tensor3D that represents the keypoint heatmap scores.\n     * - offsets: A Tensor3D that represents the offsets.\n     * - displacementFwd: A Tensor3D that represents the forward displacement.\n     * - displacementBwd: A Tensor3D that represents the backward displacement.\n     * - segmentation: A Tensor3D that represents the segmentation of all\n     * people.\n     * - longOffsets: A Tensor3D that represents the long offsets used for\n     * instance grouping.\n     * - partHeatmaps: A Tensor3D that represents the body part segmentation.\n     */\n    BaseModel.prototype.predict = function (input) {\n        var _this = this;\n        return tf.tidy(function () {\n            var asFloat = _this.preprocessInput(tf.cast(input, 'float32'));\n            var asBatch = tf.expandDims(asFloat, 0);\n            var results = _this.model.predict(asBatch);\n            var results3d = results.map(function (y) { return tf.squeeze(y, [0]); });\n            var namedResults = _this.nameOutputResults(results3d);\n            return {\n                heatmapScores: tf.sigmoid(namedResults.heatmap),\n                offsets: namedResults.offsets,\n                displacementFwd: namedResults.displacementFwd,\n                displacementBwd: namedResults.displacementBwd,\n                segmentation: namedResults.segmentation,\n                partHeatmaps: namedResults.partHeatmaps,\n                longOffsets: namedResults.longOffsets,\n                partOffsets: namedResults.partOffsets\n            };\n        });\n    };\n    /**\n     * Releases the CPU and GPU memory allocated by the model.\n     */\n    BaseModel.prototype.dispose = function () {\n        this.model.dispose();\n    };\n    return BaseModel;\n}());\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar MobileNet = /** @class */ (function (_super) {\n    __extends(MobileNet, _super);\n    function MobileNet() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    MobileNet.prototype.preprocessInput = function (input) {\n        // Normalize the pixels [0, 255] to be between [-1, 1].\n        return tf.tidy(function () { return tf.sub(tf.div(input, 127.5), 1.0); });\n    };\n    MobileNet.prototype.nameOutputResults = function (results) {\n        var offsets = results[0], segmentation = results[1], partHeatmaps = results[2], longOffsets = results[3], heatmap = results[4], displacementFwd = results[5], displacementBwd = results[6], partOffsets = results[7];\n        return {\n            offsets: offsets,\n            segmentation: segmentation,\n            partHeatmaps: partHeatmaps,\n            longOffsets: longOffsets,\n            heatmap: heatmap,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n            partOffsets: partOffsets\n        };\n    };\n    return MobileNet;\n}(BaseModel));\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar PART_NAMES = [\n    'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\n    'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\n    'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\n];\nvar NUM_KEYPOINTS = PART_NAMES.length;\nvar PART_IDS = PART_NAMES.reduce(function (result, jointName, i) {\n    result[jointName] = i;\n    return result;\n}, {});\nvar CONNECTED_PART_NAMES = [\n    ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\n    ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\n    ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\n    ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\n    ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\n    ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\n];\n/*\n * Define the skeleton. This defines the parent->child relationships of our\n * tree. Arbitrarily this defines the nose as the root of the tree, however\n * since we will infer the displacement for both parent->child and\n * child->parent, we can define the tree root as any node.\n */\nvar POSE_CHAIN = [\n    ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\n    ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\n    ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\n    ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\n    ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\n    ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\n    ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\n    ['rightKnee', 'rightAnkle']\n];\nCONNECTED_PART_NAMES.map(function (_a) {\n    var jointNameA = _a[0], jointNameB = _a[1];\n    return ([PART_IDS[jointNameA], PART_IDS[jointNameB]]);\n});\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction getScale(_a, _b, padding) {\n    var height = _a[0], width = _a[1];\n    var inputResolutionY = _b[0], inputResolutionX = _b[1];\n    var padT = padding.top, padB = padding.bottom, padL = padding.left, padR = padding.right;\n    var scaleY = inputResolutionY / (padT + padB + height);\n    var scaleX = inputResolutionX / (padL + padR + width);\n    return [scaleX, scaleY];\n}\nfunction getOffsetPoint(y, x, keypoint, offsets) {\n    return {\n        y: offsets.get(y, x, keypoint),\n        x: offsets.get(y, x, keypoint + NUM_KEYPOINTS)\n    };\n}\nfunction getImageCoords(part, outputStride, offsets) {\n    var heatmapY = part.heatmapY, heatmapX = part.heatmapX, keypoint = part.id;\n    var _a = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets), y = _a.y, x = _a.x;\n    return {\n        x: part.heatmapX * outputStride + x,\n        y: part.heatmapY * outputStride + y\n    };\n}\nfunction clamp(a, min, max) {\n    if (a < min) {\n        return min;\n    }\n    if (a > max) {\n        return max;\n    }\n    return a;\n}\nfunction squaredDistance(y1, x1, y2, x2) {\n    var dy = y2 - y1;\n    var dx = x2 - x1;\n    return dy * dy + dx * dx;\n}\nfunction addVectors(a, b) {\n    return { x: a.x + b.x, y: a.y + b.y };\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction computeDistance(embedding, pose, minPartScore) {\n    if (minPartScore === void 0) { minPartScore = 0.3; }\n    var distance = 0.0;\n    var numKpt = 0;\n    for (var p = 0; p < embedding.length; p++) {\n        if (pose.keypoints[p].score > minPartScore) {\n            numKpt += 1;\n            distance += Math.pow((embedding[p].x - pose.keypoints[p].position.x), 2) +\n                Math.pow((embedding[p].y - pose.keypoints[p].position.y), 2);\n        }\n    }\n    if (numKpt === 0) {\n        distance = Infinity;\n    }\n    else {\n        distance = distance / numKpt;\n    }\n    return distance;\n}\nfunction convertToPositionInOuput(position, _a, _b, stride) {\n    var padT = _a[0], padL = _a[1];\n    var scaleX = _b[0], scaleY = _b[1];\n    var y = Math.round(((padT + position.y + 1.0) * scaleY - 1.0) / stride);\n    var x = Math.round(((padL + position.x + 1.0) * scaleX - 1.0) / stride);\n    return { x: x, y: y };\n}\nfunction getEmbedding(location, keypointIndex, convertToPosition, outputResolutionX, longOffsets, refineSteps, _a) {\n    var height = _a[0], width = _a[1];\n    var newLocation = convertToPosition(location);\n    var nn = newLocation.y * outputResolutionX + newLocation.x;\n    var dy = longOffsets[NUM_KEYPOINTS * (2 * nn) + keypointIndex];\n    var dx = longOffsets[NUM_KEYPOINTS * (2 * nn + 1) + keypointIndex];\n    var y = location.y + dy;\n    var x = location.x + dx;\n    for (var t = 0; t < refineSteps; t++) {\n        y = Math.min(y, height - 1);\n        x = Math.min(x, width - 1);\n        var newPos = convertToPosition({ x: x, y: y });\n        var nn_1 = newPos.y * outputResolutionX + newPos.x;\n        dy = longOffsets[NUM_KEYPOINTS * (2 * nn_1) + keypointIndex];\n        dx = longOffsets[NUM_KEYPOINTS * (2 * nn_1 + 1) + keypointIndex];\n        y = y + dy;\n        x = x + dx;\n    }\n    return { x: x, y: y };\n}\nfunction matchEmbeddingToInstance(location, longOffsets, poses, numKptForMatching, _a, _b, outputResolutionX, _c, stride, refineSteps) {\n    var padT = _a[0], padL = _a[1];\n    var scaleX = _b[0], scaleY = _b[1];\n    var height = _c[0], width = _c[1];\n    var embed = [];\n    var convertToPosition = function (pair) {\n        return convertToPositionInOuput(pair, [padT, padL], [scaleX, scaleY], stride);\n    };\n    for (var keypointsIndex = 0; keypointsIndex < numKptForMatching; keypointsIndex++) {\n        var embedding = getEmbedding(location, keypointsIndex, convertToPosition, outputResolutionX, longOffsets, refineSteps, [height, width]);\n        embed.push(embedding);\n    }\n    var kMin = -1;\n    var kMinDist = Infinity;\n    for (var k = 0; k < poses.length; k++) {\n        var dist = computeDistance(embed, poses[k]);\n        if (dist < kMinDist) {\n            kMin = k;\n            kMinDist = dist;\n        }\n    }\n    return kMin;\n}\nfunction getOutputResolution(_a, stride) {\n    var inputResolutionY = _a[0], inputResolutionX = _a[1];\n    var outputResolutionX = Math.round((inputResolutionX - 1.0) / stride + 1.0);\n    var outputResolutionY = Math.round((inputResolutionY - 1.0) / stride + 1.0);\n    return [outputResolutionX, outputResolutionY];\n}\nfunction decodeMultipleMasksCPU(segmentation, longOffsets, posesAboveScore, height, width, stride, _a, padding, refineSteps, numKptForMatching) {\n    var inHeight = _a[0], inWidth = _a[1];\n    if (numKptForMatching === void 0) { numKptForMatching = 5; }\n    var dataArrays = posesAboveScore.map(function (x) { return new Uint8Array(height * width).fill(0); });\n    var padT = padding.top, padL = padding.left;\n    var _b = getScale([height, width], [inHeight, inWidth], padding), scaleX = _b[0], scaleY = _b[1];\n    var outputResolutionX = getOutputResolution([inHeight, inWidth], stride)[0];\n    for (var i = 0; i < height; i += 1) {\n        for (var j = 0; j < width; j += 1) {\n            var n = i * width + j;\n            var prob = segmentation[n];\n            if (prob === 1) {\n                var kMin = matchEmbeddingToInstance({ x: j, y: i }, longOffsets, posesAboveScore, numKptForMatching, [padT, padL], [scaleX, scaleY], outputResolutionX, [height, width], stride, refineSteps);\n                if (kMin >= 0) {\n                    dataArrays[kMin][n] = 1;\n                }\n            }\n        }\n    }\n    return dataArrays;\n}\nfunction decodeMultiplePartMasksCPU(segmentation, longOffsets, partSegmentaion, posesAboveScore, height, width, stride, _a, padding, refineSteps, numKptForMatching) {\n    var inHeight = _a[0], inWidth = _a[1];\n    if (numKptForMatching === void 0) { numKptForMatching = 5; }\n    var dataArrays = posesAboveScore.map(function (x) { return new Int32Array(height * width).fill(-1); });\n    var padT = padding.top, padL = padding.left;\n    var _b = getScale([height, width], [inHeight, inWidth], padding), scaleX = _b[0], scaleY = _b[1];\n    var outputResolutionX = getOutputResolution([inHeight, inWidth], stride)[0];\n    for (var i = 0; i < height; i += 1) {\n        for (var j = 0; j < width; j += 1) {\n            var n = i * width + j;\n            var prob = segmentation[n];\n            if (prob === 1) {\n                var kMin = matchEmbeddingToInstance({ x: j, y: i }, longOffsets, posesAboveScore, numKptForMatching, [padT, padL], [scaleX, scaleY], outputResolutionX, [height, width], stride, refineSteps);\n                if (kMin >= 0) {\n                    dataArrays[kMin][n] = partSegmentaion[n];\n                }\n            }\n        }\n    }\n    return dataArrays;\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction decodeMultipleMasksWebGl(segmentation, longOffsets, posesAboveScore, height, width, stride, _a, padding, refineSteps, minKptScore, maxNumPeople) {\n    var inHeight = _a[0], inWidth = _a[1];\n    // The height/width of the image/canvas itself.\n    var _b = segmentation.shape, origHeight = _b[0], origWidth = _b[1];\n    // The height/width of the output of the model.\n    var _c = longOffsets.shape.slice(0, 2), outHeight = _c[0], outWidth = _c[1];\n    var shapedLongOffsets = tf.reshape(longOffsets, [outHeight, outWidth, 2, NUM_KEYPOINTS]);\n    // Make pose tensor of shape [MAX_NUM_PEOPLE, NUM_KEYPOINTS, 3] where\n    // the last 3 coordinates correspond to the score, h and w coordinate of that\n    // keypoint.\n    var poseVals = new Float32Array(maxNumPeople * NUM_KEYPOINTS * 3).fill(0.0);\n    for (var i = 0; i < posesAboveScore.length; i++) {\n        var poseOffset = i * NUM_KEYPOINTS * 3;\n        var pose = posesAboveScore[i];\n        for (var kp = 0; kp < NUM_KEYPOINTS; kp++) {\n            var keypoint = pose.keypoints[kp];\n            var offset = poseOffset + kp * 3;\n            poseVals[offset] = keypoint.score;\n            poseVals[offset + 1] = keypoint.position.y;\n            poseVals[offset + 2] = keypoint.position.x;\n        }\n    }\n    var _d = getScale([height, width], [inHeight, inWidth], padding), scaleX = _d[0], scaleY = _d[1];\n    var posesTensor = tf.tensor(poseVals, [maxNumPeople, NUM_KEYPOINTS, 3]);\n    var padT = padding.top, padL = padding.left;\n    var program = {\n        variableNames: ['segmentation', 'longOffsets', 'poses'],\n        outputShape: [origHeight, origWidth],\n        userCode: \"\\n    int convertToPositionInOutput(int pos, int pad, float scale, int stride) {\\n      return round(((float(pos + pad) + 1.0) * scale - 1.0) / float(stride));\\n    }\\n\\n    float convertToPositionInOutputFloat(\\n        int pos, int pad, float scale, int stride) {\\n      return ((float(pos + pad) + 1.0) * scale - 1.0) / float(stride);\\n    }\\n\\n    float dist(float x1, float y1, float x2, float y2) {\\n      return pow(x1 - x2, 2.0) + pow(y1 - y2, 2.0);\\n    }\\n\\n    float sampleLongOffsets(float h, float w, int d, int k) {\\n      float fh = fract(h);\\n      float fw = fract(w);\\n      int clH = int(ceil(h));\\n      int clW = int(ceil(w));\\n      int flH = int(floor(h));\\n      int flW = int(floor(w));\\n      float o11 = getLongOffsets(flH, flW, d, k);\\n      float o12 = getLongOffsets(flH, clW, d, k);\\n      float o21 = getLongOffsets(clH, flW, d, k);\\n      float o22 = getLongOffsets(clH, clW, d, k);\\n      float o1 = mix(o11, o12, fw);\\n      float o2 = mix(o21, o22, fw);\\n      return mix(o1, o2, fh);\\n    }\\n\\n    int findNearestPose(int h, int w) {\\n      float prob = getSegmentation(h, w);\\n      if (prob < 1.0) {\\n        return -1;\\n      }\\n\\n      // Done(Tyler): convert from output space h/w to strided space.\\n      float stridedH = convertToPositionInOutputFloat(\\n        h, \".concat(padT, \", \").concat(scaleY, \", \").concat(stride, \");\\n      float stridedW = convertToPositionInOutputFloat(\\n        w, \").concat(padL, \", \").concat(scaleX, \", \").concat(stride, \");\\n\\n      float minDist = 1000000.0;\\n      int iMin = -1;\\n      for (int i = 0; i < \").concat(maxNumPeople, \"; i++) {\\n        float curDistSum = 0.0;\\n        int numKpt = 0;\\n        for (int k = 0; k < \").concat(NUM_KEYPOINTS, \"; k++) {\\n          float dy = sampleLongOffsets(stridedH, stridedW, 0, k);\\n          float dx = sampleLongOffsets(stridedH, stridedW, 1, k);\\n\\n          float y = float(h) + dy;\\n          float x = float(w) + dx;\\n\\n          for (int s = 0; s < \").concat(refineSteps, \"; s++) {\\n            int yRounded = round(min(y, float(\").concat(height - 1.0, \")));\\n            int xRounded = round(min(x, float(\").concat(width - 1.0, \")));\\n\\n            float yStrided = convertToPositionInOutputFloat(\\n              yRounded, \").concat(padT, \", \").concat(scaleY, \", \").concat(stride, \");\\n            float xStrided = convertToPositionInOutputFloat(\\n              xRounded, \").concat(padL, \", \").concat(scaleX, \", \").concat(stride, \");\\n\\n            float dy = sampleLongOffsets(yStrided, xStrided, 0, k);\\n            float dx = sampleLongOffsets(yStrided, xStrided, 1, k);\\n\\n            y = y + dy;\\n            x = x + dx;\\n          }\\n\\n          float poseScore = getPoses(i, k, 0);\\n          float poseY = getPoses(i, k, 1);\\n          float poseX = getPoses(i, k, 2);\\n          if (poseScore > \").concat(minKptScore, \") {\\n            numKpt = numKpt + 1;\\n            curDistSum = curDistSum + dist(x, y, poseX, poseY);\\n          }\\n        }\\n        if (numKpt > 0 && curDistSum / float(numKpt) < minDist) {\\n          minDist = curDistSum / float(numKpt);\\n          iMin = i;\\n        }\\n      }\\n      return iMin;\\n    }\\n\\n    void main() {\\n        ivec2 coords = getOutputCoords();\\n        int nearestPose = findNearestPose(coords[0], coords[1]);\\n        setOutput(float(nearestPose));\\n      }\\n  \")\n    };\n    var webglBackend = tf.backend();\n    return webglBackend.compileAndRun(program, [segmentation, shapedLongOffsets, posesTensor]);\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction toPersonKSegmentation(segmentation, k) {\n    return tf.tidy(function () { return tf.cast(tf.equal(segmentation, tf.scalar(k)), 'int32'); });\n}\nfunction toPersonKPartSegmentation(segmentation, bodyParts, k) {\n    return tf.tidy(function () { return tf.sub(tf.mul(tf.cast(tf.equal(segmentation, tf.scalar(k)), 'int32'), tf.add(bodyParts, 1)), 1); });\n}\nfunction isWebGlBackend() {\n    return getBackend() === 'webgl';\n}\nfunction decodePersonInstanceMasks(segmentation, longOffsets, poses, height, width, stride, _a, padding, minPoseScore, refineSteps, minKeypointScore, maxNumPeople) {\n    var inHeight = _a[0], inWidth = _a[1];\n    if (minPoseScore === void 0) { minPoseScore = 0.2; }\n    if (refineSteps === void 0) { refineSteps = 8; }\n    if (minKeypointScore === void 0) { minKeypointScore = 0.3; }\n    if (maxNumPeople === void 0) { maxNumPeople = 10; }\n    return __awaiter(this, void 0, void 0, function () {\n        var posesAboveScore, personSegmentationsData, personSegmentations, segmentationsData, longOffsetsData;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    posesAboveScore = poses.filter(function (pose) { return pose.score >= minPoseScore; });\n                    if (!isWebGlBackend()) return [3 /*break*/, 2];\n                    personSegmentations = tf.tidy(function () {\n                        var masksTensorInfo = decodeMultipleMasksWebGl(segmentation, longOffsets, posesAboveScore, height, width, stride, [inHeight, inWidth], padding, refineSteps, minKeypointScore, maxNumPeople);\n                        var masksTensor = tf.engine().makeTensorFromDataId(masksTensorInfo.dataId, masksTensorInfo.shape, masksTensorInfo.dtype);\n                        return posesAboveScore.map(function (_, k) { return toPersonKSegmentation(masksTensor, k); });\n                    });\n                    return [4 /*yield*/, Promise.all(personSegmentations.map(function (mask) { return mask.data(); }))];\n                case 1:\n                    personSegmentationsData =\n                        (_b.sent());\n                    personSegmentations.forEach(function (x) { return x.dispose(); });\n                    return [3 /*break*/, 5];\n                case 2: return [4 /*yield*/, segmentation.data()];\n                case 3:\n                    segmentationsData = _b.sent();\n                    return [4 /*yield*/, longOffsets.data()];\n                case 4:\n                    longOffsetsData = _b.sent();\n                    personSegmentationsData = decodeMultipleMasksCPU(segmentationsData, longOffsetsData, posesAboveScore, height, width, stride, [inHeight, inWidth], padding, refineSteps);\n                    _b.label = 5;\n                case 5: return [2 /*return*/, personSegmentationsData.map(function (data, i) { return ({ data: data, pose: posesAboveScore[i], width: width, height: height }); })];\n            }\n        });\n    });\n}\nfunction decodePersonInstancePartMasks(segmentation, longOffsets, partSegmentation, poses, height, width, stride, _a, padding, minPoseScore, refineSteps, minKeypointScore, maxNumPeople) {\n    var inHeight = _a[0], inWidth = _a[1];\n    if (minPoseScore === void 0) { minPoseScore = 0.2; }\n    if (refineSteps === void 0) { refineSteps = 8; }\n    if (minKeypointScore === void 0) { minKeypointScore = 0.3; }\n    if (maxNumPeople === void 0) { maxNumPeople = 10; }\n    return __awaiter(this, void 0, void 0, function () {\n        var posesAboveScore, partSegmentationsByPersonData, partSegmentations, segmentationsData, longOffsetsData, partSegmentaionData;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    posesAboveScore = poses.filter(function (pose) { return pose.score >= minPoseScore; });\n                    if (!isWebGlBackend()) return [3 /*break*/, 2];\n                    partSegmentations = tf.tidy(function () {\n                        var masksTensorInfo = decodeMultipleMasksWebGl(segmentation, longOffsets, posesAboveScore, height, width, stride, [inHeight, inWidth], padding, refineSteps, minKeypointScore, maxNumPeople);\n                        var masksTensor = tf.engine().makeTensorFromDataId(masksTensorInfo.dataId, masksTensorInfo.shape, masksTensorInfo.dtype);\n                        return posesAboveScore.map(function (_, k) {\n                            return toPersonKPartSegmentation(masksTensor, partSegmentation, k);\n                        });\n                    });\n                    return [4 /*yield*/, Promise.all(partSegmentations.map(function (x) { return x.data(); }))];\n                case 1:\n                    partSegmentationsByPersonData =\n                        (_b.sent());\n                    partSegmentations.forEach(function (x) { return x.dispose(); });\n                    return [3 /*break*/, 6];\n                case 2: return [4 /*yield*/, segmentation.data()];\n                case 3:\n                    segmentationsData = _b.sent();\n                    return [4 /*yield*/, longOffsets.data()];\n                case 4:\n                    longOffsetsData = _b.sent();\n                    return [4 /*yield*/, partSegmentation.data()];\n                case 5:\n                    partSegmentaionData = _b.sent();\n                    partSegmentationsByPersonData = decodeMultiplePartMasksCPU(segmentationsData, longOffsetsData, partSegmentaionData, posesAboveScore, height, width, stride, [inHeight, inWidth], padding, refineSteps);\n                    _b.label = 6;\n                case 6: return [2 /*return*/, partSegmentationsByPersonData.map(function (data, k) { return ({ pose: posesAboveScore[k], data: data, height: height, width: width }); })];\n            }\n        });\n    });\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\nfunction half(k) {\n    return Math.floor(k / 2);\n}\nvar MaxHeap = /** @class */ (function () {\n    function MaxHeap(maxSize, getElementValue) {\n        this.priorityQueue = new Array(maxSize);\n        this.numberOfElements = -1;\n        this.getElementValue = getElementValue;\n    }\n    MaxHeap.prototype.enqueue = function (x) {\n        this.priorityQueue[++this.numberOfElements] = x;\n        this.swim(this.numberOfElements);\n    };\n    MaxHeap.prototype.dequeue = function () {\n        var max = this.priorityQueue[0];\n        this.exchange(0, this.numberOfElements--);\n        this.sink(0);\n        this.priorityQueue[this.numberOfElements + 1] = null;\n        return max;\n    };\n    MaxHeap.prototype.empty = function () {\n        return this.numberOfElements === -1;\n    };\n    MaxHeap.prototype.size = function () {\n        return this.numberOfElements + 1;\n    };\n    MaxHeap.prototype.all = function () {\n        return this.priorityQueue.slice(0, this.numberOfElements + 1);\n    };\n    MaxHeap.prototype.max = function () {\n        return this.priorityQueue[0];\n    };\n    MaxHeap.prototype.swim = function (k) {\n        while (k > 0 && this.less(half(k), k)) {\n            this.exchange(k, half(k));\n            k = half(k);\n        }\n    };\n    MaxHeap.prototype.sink = function (k) {\n        while (2 * k <= this.numberOfElements) {\n            var j = 2 * k;\n            if (j < this.numberOfElements && this.less(j, j + 1)) {\n                j++;\n            }\n            if (!this.less(k, j)) {\n                break;\n            }\n            this.exchange(k, j);\n            k = j;\n        }\n    };\n    MaxHeap.prototype.getValueAt = function (i) {\n        return this.getElementValue(this.priorityQueue[i]);\n    };\n    MaxHeap.prototype.less = function (i, j) {\n        return this.getValueAt(i) < this.getValueAt(j);\n    };\n    MaxHeap.prototype.exchange = function (i, j) {\n        var t = this.priorityQueue[i];\n        this.priorityQueue[i] = this.priorityQueue[j];\n        this.priorityQueue[j] = t;\n    };\n    return MaxHeap;\n}());\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction scoreIsMaximumInLocalWindow(keypointId, score, heatmapY, heatmapX, localMaximumRadius, scores) {\n    var _a = scores.shape, height = _a[0], width = _a[1];\n    var localMaximum = true;\n    var yStart = Math.max(heatmapY - localMaximumRadius, 0);\n    var yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\n    for (var yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\n        var xStart = Math.max(heatmapX - localMaximumRadius, 0);\n        var xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\n        for (var xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\n            if (scores.get(yCurrent, xCurrent, keypointId) > score) {\n                localMaximum = false;\n                break;\n            }\n        }\n        if (!localMaximum) {\n            break;\n        }\n    }\n    return localMaximum;\n}\n/**\n * Builds a priority queue with part candidate positions for a specific image in\n * the batch. For this we find all local maxima in the score maps with score\n * values above a threshold. We create a single priority queue across all parts.\n */\nfunction buildPartWithScoreQueue(scoreThreshold, localMaximumRadius, scores) {\n    var _a = scores.shape, height = _a[0], width = _a[1], numKeypoints = _a[2];\n    var queue = new MaxHeap(height * width * numKeypoints, function (_a) {\n        var score = _a.score;\n        return score;\n    });\n    for (var heatmapY = 0; heatmapY < height; ++heatmapY) {\n        for (var heatmapX = 0; heatmapX < width; ++heatmapX) {\n            for (var keypointId = 0; keypointId < numKeypoints; ++keypointId) {\n                var score = scores.get(heatmapY, heatmapX, keypointId);\n                // Only consider parts with score greater or equal to threshold as\n                // root candidates.\n                if (score < scoreThreshold) {\n                    continue;\n                }\n                // Only consider keypoints whose score is maximum in a local window.\n                if (scoreIsMaximumInLocalWindow(keypointId, score, heatmapY, heatmapX, localMaximumRadius, scores)) {\n                    queue.enqueue({ score: score, part: { heatmapY: heatmapY, heatmapX: heatmapX, id: keypointId } });\n                }\n            }\n        }\n    }\n    return queue;\n}\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar parentChildrenTuples = POSE_CHAIN.map(function (_a) {\n    var parentJoinName = _a[0], childJoinName = _a[1];\n    return ([PART_IDS[parentJoinName], PART_IDS[childJoinName]]);\n});\nvar parentToChildEdges = parentChildrenTuples.map(function (_a) {\n    var childJointId = _a[1];\n    return childJointId;\n});\nvar childToParentEdges = parentChildrenTuples.map(function (_a) {\n    var parentJointId = _a[0];\n    return parentJointId;\n});\nfunction getDisplacement(edgeId, point, displacements) {\n    var numEdges = displacements.shape[2] / 2;\n    return {\n        y: displacements.get(point.y, point.x, edgeId),\n        x: displacements.get(point.y, point.x, numEdges + edgeId)\n    };\n}\nfunction getStridedIndexNearPoint(point, outputStride, height, width) {\n    return {\n        y: clamp(Math.round(point.y / outputStride), 0, height - 1),\n        x: clamp(Math.round(point.x / outputStride), 0, width - 1)\n    };\n}\n/**\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\n * that the position of the `idSource` part is already known. For this, we\n * follow the displacement vector from the source to target part (stored in\n * the `i`-t channel of the displacement tensor). The displaced keypoint\n * vector is refined using the offset vector by `offsetRefineStep` times.\n */\nfunction traverseToTargetKeypoint(edgeId, sourceKeypoint, targetKeypointId, scoresBuffer, offsets, outputStride, displacements, offsetRefineStep) {\n    if (offsetRefineStep === void 0) { offsetRefineStep = 2; }\n    var _a = scoresBuffer.shape, height = _a[0], width = _a[1];\n    // Nearest neighbor interpolation for the source->target displacements.\n    var sourceKeypointIndices = getStridedIndexNearPoint(sourceKeypoint.position, outputStride, height, width);\n    var displacement = getDisplacement(edgeId, sourceKeypointIndices, displacements);\n    var displacedPoint = addVectors(sourceKeypoint.position, displacement);\n    var targetKeypoint = displacedPoint;\n    for (var i = 0; i < offsetRefineStep; i++) {\n        var targetKeypointIndices = getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n        var offsetPoint = getOffsetPoint(targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId, offsets);\n        targetKeypoint = addVectors({\n            x: targetKeypointIndices.x * outputStride,\n            y: targetKeypointIndices.y * outputStride\n        }, { x: offsetPoint.x, y: offsetPoint.y });\n    }\n    var targetKeyPointIndices = getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n    var score = scoresBuffer.get(targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\n    return { position: targetKeypoint, part: PART_NAMES[targetKeypointId], score: score };\n}\n/**\n * Follows the displacement fields to decode the full pose of the object\n * instance given the position of a part that acts as root.\n *\n * @return An array of decoded keypoints and their scores for a single pose\n */\nfunction decodePose(root, scores, offsets, outputStride, displacementsFwd, displacementsBwd) {\n    var numParts = scores.shape[2];\n    var numEdges = parentToChildEdges.length;\n    var instanceKeypoints = new Array(numParts);\n    // Start a new detection instance at the position of the root.\n    var rootPart = root.part, rootScore = root.score;\n    var rootPoint = getImageCoords(rootPart, outputStride, offsets);\n    instanceKeypoints[rootPart.id] = {\n        score: rootScore,\n        part: PART_NAMES[rootPart.id],\n        position: rootPoint\n    };\n    // Decode the part positions upwards in the tree, following the backward\n    // displacements.\n    for (var edge = numEdges - 1; edge >= 0; --edge) {\n        var sourceKeypointId = parentToChildEdges[edge];\n        var targetKeypointId = childToParentEdges[edge];\n        if (instanceKeypoints[sourceKeypointId] &&\n            !instanceKeypoints[targetKeypointId]) {\n            instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores, offsets, outputStride, displacementsBwd);\n        }\n    }\n    // Decode the part positions downwards in the tree, following the forward\n    // displacements.\n    for (var edge = 0; edge < numEdges; ++edge) {\n        var sourceKeypointId = childToParentEdges[edge];\n        var targetKeypointId = parentToChildEdges[edge];\n        if (instanceKeypoints[sourceKeypointId] &&\n            !instanceKeypoints[targetKeypointId]) {\n            instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores, offsets, outputStride, displacementsFwd);\n        }\n    }\n    return instanceKeypoints;\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nfunction withinNmsRadiusOfCorrespondingPoint(poses, squaredNmsRadius, _a, keypointId) {\n    var x = _a.x, y = _a.y;\n    return poses.some(function (_a) {\n        var keypoints = _a.keypoints;\n        var correspondingKeypoint = keypoints[keypointId].position;\n        return squaredDistance(y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\n            squaredNmsRadius;\n    });\n}\n/* Score the newly proposed object instance without taking into account\n * the scores of the parts that overlap with any previously detected\n * instance.\n */\nfunction getInstanceScore(existingPoses, squaredNmsRadius, instanceKeypoints) {\n    var notOverlappedKeypointScores = instanceKeypoints.reduce(function (result, _a, keypointId) {\n        var position = _a.position, score = _a.score;\n        if (!withinNmsRadiusOfCorrespondingPoint(existingPoses, squaredNmsRadius, position, keypointId)) {\n            result += score;\n        }\n        return result;\n    }, 0.0);\n    return notOverlappedKeypointScores /= instanceKeypoints.length;\n}\n// A point (y, x) is considered as root part candidate if its score is a\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\n// kLocalMaximumRadius.\nvar kLocalMaximumRadius = 1;\n/**\n * Detects multiple poses and finds their parts from part scores and\n * displacement vectors. It returns up to `maxDetections` object instance\n * detections in decreasing root score order. It works as follows: We first\n * create a priority queue with local part score maxima above\n * `scoreThreshold`, considering all parts at the same time. Then we\n * iteratively pull the top  element of the queue (in decreasing score order)\n * and treat it as a root candidate for a new object instance. To avoid\n * duplicate detections, we reject the root candidate if it is within a disk\n * of `nmsRadius` pixels from the corresponding part of a previously detected\n * instance, which is a form of part-based non-maximum suppression (NMS). If\n * the root candidate passes the NMS check, we start a new object instance\n * detection, treating the corresponding part as root and finding the\n * positions of the remaining parts by following the displacement vectors\n * along the tree-structured part graph. We assign to the newly detected\n * instance a score equal to the sum of scores of its parts which have not\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\n * pixels away from the corresponding part of all previously detected\n * instances), divided by the total number of parts `numParts`.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param displacementsFwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the forward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param displacementsBwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the backward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @param maxPoseDetections Maximum number of returned instance detections per\n * image.\n *\n * @param scoreThreshold Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5.\n *\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\n * strictly positive. Two parts suppress each other if they are less than\n * `nmsRadius` pixels away. Defaults to 20.\n *\n * @return An array of poses and their scores, each containing keypoints and\n * the corresponding keypoint scores.\n */\nfunction decodeMultiplePoses(scoresBuffer, offsetsBuffer, displacementsFwdBuffer, displacementsBwdBuffer, outputStride, maxPoseDetections, scoreThreshold, nmsRadius) {\n    if (scoreThreshold === void 0) { scoreThreshold = 0.5; }\n    if (nmsRadius === void 0) { nmsRadius = 20; }\n    var poses = [];\n    var queue = buildPartWithScoreQueue(scoreThreshold, kLocalMaximumRadius, scoresBuffer);\n    var squaredNmsRadius = nmsRadius * nmsRadius;\n    // Generate at most maxDetections object instances per image in\n    // decreasing root part score order.\n    while (poses.length < maxPoseDetections && !queue.empty()) {\n        // The top element in the queue is the next root candidate.\n        var root = queue.dequeue();\n        // Part-based non-maximum suppression: We reject a root candidate if it\n        // is within a disk of `nmsRadius` pixels from the corresponding part of\n        // a previously detected instance.\n        var rootImageCoords = getImageCoords(root.part, outputStride, offsetsBuffer);\n        if (withinNmsRadiusOfCorrespondingPoint(poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\n            continue;\n        }\n        // Start a new detection instance at the position of the root.\n        var keypoints = decodePose(root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer, displacementsBwdBuffer);\n        var score = getInstanceScore(poses, squaredNmsRadius, keypoints);\n        poses.push({ keypoints: keypoints, score: score });\n    }\n    return poses;\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar imageNetMean = [-123.15, -115.90, -103.06];\nvar ResNet = /** @class */ (function (_super) {\n    __extends(ResNet, _super);\n    function ResNet() {\n        return _super !== null && _super.apply(this, arguments) || this;\n    }\n    ResNet.prototype.preprocessInput = function (input) {\n        return tf.add(input, imageNetMean);\n    };\n    ResNet.prototype.nameOutputResults = function (results) {\n        var displacementBwd = results[0], displacementFwd = results[1], heatmap = results[2], longOffsets = results[3], offsets = results[4], partHeatmaps = results[5], segmentation = results[6], partOffsets = results[7];\n        return {\n            offsets: offsets,\n            segmentation: segmentation,\n            partHeatmaps: partHeatmaps,\n            longOffsets: longOffsets,\n            heatmap: heatmap,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n            partOffsets: partOffsets\n        };\n    };\n    return ResNet;\n}(BaseModel));\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar RESNET50_BASE_URL = 'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/';\nvar MOBILENET_BASE_URL = 'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/';\n// The BodyPix 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\n// format.\nfunction resNet50SavedModel(stride, quantBytes) {\n    var graphJson = \"model-stride\".concat(stride, \".json\");\n    // quantBytes=4 corresponding to the non-quantized full-precision SavedModel.\n    if (quantBytes === 4) {\n        return RESNET50_BASE_URL + \"float/\" + graphJson;\n    }\n    else {\n        return RESNET50_BASE_URL + \"quant\".concat(quantBytes, \"/\") + graphJson;\n    }\n}\n// The BodyPix 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\n// format.\nfunction mobileNetSavedModel(stride, multiplier, quantBytes) {\n    var toStr = { 1.0: '100', 0.75: '075', 0.50: '050' };\n    var graphJson = \"model-stride\".concat(stride, \".json\");\n    // quantBytes=4 corresponding to the non-quantized full-precision SavedModel.\n    if (quantBytes === 4) {\n        return MOBILENET_BASE_URL + \"float/\".concat(toStr[multiplier], \"/\") + graphJson;\n    }\n    else {\n        return MOBILENET_BASE_URL + \"quant\".concat(quantBytes, \"/\").concat(toStr[multiplier], \"/\") +\n            graphJson;\n    }\n}\n\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar _a;\nfunction getSizeFromImageLikeElement(input) {\n    if ('offsetHeight' in input && input.offsetHeight !== 0\n        && 'offsetWidth' in input && input.offsetWidth !== 0) {\n        return [input.offsetHeight, input.offsetWidth];\n    }\n    else if (input.height != null && input.width != null) {\n        return [input.height, input.width];\n    }\n    else {\n        throw new Error(\"HTMLImageElement must have height and width attributes set.\");\n    }\n}\nfunction getSizeFromVideoElement(input) {\n    if (input.hasAttribute('height') && input.hasAttribute('width')) {\n        // Prioritizes user specified height and width.\n        // We can't test the .height and .width properties directly,\n        // because they evaluate to 0 if unset.\n        return [input.height, input.width];\n    }\n    else {\n        return [input.videoHeight, input.videoWidth];\n    }\n}\nfunction getInputSize(input) {\n    if ((typeof (HTMLCanvasElement) !== 'undefined' &&\n        input instanceof HTMLCanvasElement) ||\n        (typeof (OffscreenCanvas) !== 'undefined' &&\n            input instanceof OffscreenCanvas) ||\n        (typeof (HTMLImageElement) !== 'undefined' &&\n            input instanceof HTMLImageElement)) {\n        return getSizeFromImageLikeElement(input);\n    }\n    else if (typeof (ImageData) !== 'undefined' && input instanceof ImageData) {\n        return [input.height, input.width];\n    }\n    else if (typeof (HTMLVideoElement) !== 'undefined' &&\n        input instanceof HTMLVideoElement) {\n        return getSizeFromVideoElement(input);\n    }\n    else if (input instanceof tf.Tensor) {\n        return [input.shape[0], input.shape[1]];\n    }\n    else {\n        throw new Error(\"error: Unknown input type: \".concat(input, \".\"));\n    }\n}\nfunction isValidInputResolution(resolution, outputStride) {\n    return (resolution - 1) % outputStride === 0;\n}\nfunction toValidInputResolution(inputResolution, outputStride) {\n    if (isValidInputResolution(inputResolution, outputStride)) {\n        return inputResolution;\n    }\n    return Math.floor(inputResolution / outputStride) * outputStride + 1;\n}\nvar INTERNAL_RESOLUTION_STRING_OPTIONS = {\n    low: 'low',\n    medium: 'medium',\n    high: 'high',\n    full: 'full'\n};\nvar INTERNAL_RESOLUTION_PERCENTAGES = (_a = {},\n    _a[INTERNAL_RESOLUTION_STRING_OPTIONS.low] = 0.25,\n    _a[INTERNAL_RESOLUTION_STRING_OPTIONS.medium] = 0.5,\n    _a[INTERNAL_RESOLUTION_STRING_OPTIONS.high] = 0.75,\n    _a[INTERNAL_RESOLUTION_STRING_OPTIONS.full] = 1.0,\n    _a);\nvar MIN_INTERNAL_RESOLUTION = 0.1;\nvar MAX_INTERNAL_RESOLUTION = 2.0;\nfunction toInternalResolutionPercentage(internalResolution) {\n    if (typeof internalResolution === 'string') {\n        var result = INTERNAL_RESOLUTION_PERCENTAGES[internalResolution];\n        tf.util.assert(typeof result === 'number', function () { return \"string value of inputResolution must be one of \".concat(Object.values(INTERNAL_RESOLUTION_STRING_OPTIONS)\n            .join(','), \" but was \").concat(internalResolution, \".\"); });\n        return result;\n    }\n    else {\n        tf.util.assert(typeof internalResolution === 'number' &&\n            internalResolution <= MAX_INTERNAL_RESOLUTION &&\n            internalResolution >= MIN_INTERNAL_RESOLUTION, function () {\n            return \"inputResolution must be a string or number between \".concat(MIN_INTERNAL_RESOLUTION, \" and \").concat(MAX_INTERNAL_RESOLUTION, \", but \") +\n                \"was \".concat(internalResolution);\n        });\n        return internalResolution;\n    }\n}\nfunction toInputResolutionHeightAndWidth(internalResolution, outputStride, _a) {\n    var inputHeight = _a[0], inputWidth = _a[1];\n    var internalResolutionPercentage = toInternalResolutionPercentage(internalResolution);\n    return [\n        toValidInputResolution(inputHeight * internalResolutionPercentage, outputStride),\n        toValidInputResolution(inputWidth * internalResolutionPercentage, outputStride)\n    ];\n}\nfunction toInputTensor(input) {\n    // TODO: tf.browser.fromPixels types to support OffscreenCanvas\n    // @ts-ignore\n    return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\n}\nfunction resizeAndPadTo(imageTensor, _a, flipHorizontal) {\n    var targetH = _a[0], targetW = _a[1];\n    if (flipHorizontal === void 0) { flipHorizontal = false; }\n    var _b = imageTensor.shape, height = _b[0], width = _b[1];\n    var targetAspect = targetW / targetH;\n    var aspect = width / height;\n    var resizeW;\n    var resizeH;\n    var padL;\n    var padR;\n    var padT;\n    var padB;\n    if (aspect > targetAspect) {\n        // resize to have the larger dimension match the shape.\n        resizeW = targetW;\n        resizeH = Math.ceil(resizeW / aspect);\n        var padHeight = targetH - resizeH;\n        padL = 0;\n        padR = 0;\n        padT = Math.floor(padHeight / 2);\n        padB = targetH - (resizeH + padT);\n    }\n    else {\n        resizeH = targetH;\n        resizeW = Math.ceil(targetH * aspect);\n        var padWidth = targetW - resizeW;\n        padL = Math.floor(padWidth / 2);\n        padR = targetW - (resizeW + padL);\n        padT = 0;\n        padB = 0;\n    }\n    var resizedAndPadded = tf.tidy(function () {\n        // resize to have largest dimension match image\n        var resized;\n        if (flipHorizontal) {\n            resized = tf.image.resizeBilinear(tf.reverse(imageTensor, 1), [resizeH, resizeW]);\n        }\n        else {\n            resized = tf.image.resizeBilinear(imageTensor, [resizeH, resizeW]);\n        }\n        var padded = tf.pad3d(resized, [[padT, padB], [padL, padR], [0, 0]]);\n        return padded;\n    });\n    return { resizedAndPadded: resizedAndPadded, paddedBy: [[padT, padB], [padL, padR]] };\n}\nfunction scaleAndCropToInputTensorShape(tensor, _a, _b, _c, applySigmoidActivation) {\n    var inputTensorHeight = _a[0], inputTensorWidth = _a[1];\n    var resizedAndPaddedHeight = _b[0], resizedAndPaddedWidth = _b[1];\n    var _d = _c[0], padT = _d[0], padB = _d[1], _e = _c[1], padL = _e[0], padR = _e[1];\n    if (applySigmoidActivation === void 0) { applySigmoidActivation = false; }\n    return tf.tidy(function () {\n        var inResizedAndPadded = tf.image.resizeBilinear(tensor, [resizedAndPaddedHeight, resizedAndPaddedWidth], true);\n        if (applySigmoidActivation) {\n            inResizedAndPadded = tf.sigmoid(inResizedAndPadded);\n        }\n        return removePaddingAndResizeBack(inResizedAndPadded, [inputTensorHeight, inputTensorWidth], [[padT, padB], [padL, padR]]);\n    });\n}\nfunction removePaddingAndResizeBack(resizedAndPadded, _a, _b) {\n    var originalHeight = _a[0], originalWidth = _a[1];\n    var _c = _b[0], padT = _c[0], padB = _c[1], _d = _b[1], padL = _d[0], padR = _d[1];\n    return tf.tidy(function () {\n        var batchedImage = tf.expandDims(resizedAndPadded);\n        return tf.squeeze(tf.image\n            .cropAndResize(batchedImage, [[\n                padT / (originalHeight + padT + padB - 1.0),\n                padL / (originalWidth + padL + padR - 1.0),\n                (padT + originalHeight - 1.0) /\n                    (originalHeight + padT + padB - 1.0),\n                (padL + originalWidth - 1.0) / (originalWidth + padL + padR - 1.0)\n            ]], [0], [originalHeight, originalWidth]), [0]);\n    });\n}\nfunction padAndResizeTo(input, _a) {\n    var targetH = _a[0], targetW = _a[1];\n    var _b = getInputSize(input), height = _b[0], width = _b[1];\n    var targetAspect = targetW / targetH;\n    var aspect = width / height;\n    var _c = [0, 0, 0, 0], padT = _c[0], padB = _c[1], padL = _c[2], padR = _c[3];\n    if (aspect < targetAspect) {\n        // pads the width\n        padT = 0;\n        padB = 0;\n        padL = Math.round(0.5 * (targetAspect * height - width));\n        padR = Math.round(0.5 * (targetAspect * height - width));\n    }\n    else {\n        // pads the height\n        padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n        padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n        padL = 0;\n        padR = 0;\n    }\n    var resized = tf.tidy(function () {\n        var imageTensor = toInputTensor(input);\n        imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\n        return tf.image.resizeBilinear(imageTensor, [targetH, targetW]);\n    });\n    return { resized: resized, padding: { top: padT, left: padL, right: padR, bottom: padB } };\n}\nfunction toTensorBuffers3D(tensors) {\n    return __awaiter(this, void 0, void 0, function () {\n        return __generator(this, function (_a) {\n            return [2 /*return*/, Promise.all(tensors.map(function (tensor) { return tensor.buffer(); }))];\n        });\n    });\n}\nfunction scalePose(pose, scaleY, scaleX, offsetY, offsetX) {\n    if (offsetY === void 0) { offsetY = 0; }\n    if (offsetX === void 0) { offsetX = 0; }\n    return {\n        score: pose.score,\n        keypoints: pose.keypoints.map(function (_a) {\n            var score = _a.score, part = _a.part, position = _a.position;\n            return ({\n                score: score,\n                part: part,\n                position: {\n                    x: position.x * scaleX + offsetX,\n                    y: position.y * scaleY + offsetY\n                }\n            });\n        })\n    };\n}\nfunction scalePoses(poses, scaleY, scaleX, offsetY, offsetX) {\n    if (offsetY === void 0) { offsetY = 0; }\n    if (offsetX === void 0) { offsetX = 0; }\n    if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\n        return poses;\n    }\n    return poses.map(function (pose) { return scalePose(pose, scaleY, scaleX, offsetY, offsetX); });\n}\nfunction flipPoseHorizontal(pose, imageWidth) {\n    return {\n        score: pose.score,\n        keypoints: pose.keypoints.map(function (_a) {\n            var score = _a.score, part = _a.part, position = _a.position;\n            return ({\n                score: score,\n                part: part,\n                position: { x: imageWidth - 1 - position.x, y: position.y }\n            });\n        })\n    };\n}\nfunction flipPosesHorizontal(poses, imageWidth) {\n    if (imageWidth <= 0) {\n        return poses;\n    }\n    return poses.map(function (pose) { return flipPoseHorizontal(pose, imageWidth); });\n}\nfunction scaleAndFlipPoses(poses, _a, _b, padding, flipHorizontal) {\n    var height = _a[0], width = _a[1];\n    var inputResolutionHeight = _b[0], inputResolutionWidth = _b[1];\n    var scaleY = (height + padding.top + padding.bottom) / (inputResolutionHeight);\n    var scaleX = (width + padding.left + padding.right) / (inputResolutionWidth);\n    var scaledPoses = scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\n    if (flipHorizontal) {\n        return flipPosesHorizontal(scaledPoses, width);\n    }\n    else {\n        return scaledPoses;\n    }\n}\n\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar APPLY_SIGMOID_ACTIVATION = true;\nvar FLIP_POSES_AFTER_SCALING = false;\n// The default configuration for loading MobileNetV1 based BodyPix.\n//\n// (And for references, the default configuration for loading ResNet\n// based PoseNet is also included).\n//\n// ```\n// const RESNET_CONFIG = {\n//   architecture: 'ResNet50',\n//   outputStride: 32,\n//   quantBytes: 4,\n// } as ModelConfig;\n// ```\nvar MOBILENET_V1_CONFIG = {\n    architecture: 'MobileNetV1',\n    outputStride: 16,\n    quantBytes: 4,\n    multiplier: 0.75,\n};\nvar VALID_ARCHITECTURE = ['MobileNetV1', 'ResNet50'];\nvar VALID_STRIDE = {\n    'MobileNetV1': [8, 16, 32],\n    'ResNet50': [32, 16]\n};\nvar VALID_MULTIPLIER = {\n    'MobileNetV1': [0.50, 0.75, 1.0],\n    'ResNet50': [1.0]\n};\nvar VALID_QUANT_BYTES = [1, 2, 4];\nfunction validateModelConfig(config) {\n    config = config || MOBILENET_V1_CONFIG;\n    if (config.architecture == null) {\n        config.architecture = 'MobileNetV1';\n    }\n    if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\n        throw new Error(\"Invalid architecture \".concat(config.architecture, \". \") +\n            \"Should be one of \".concat(VALID_ARCHITECTURE));\n    }\n    if (config.outputStride == null) {\n        config.outputStride = 16;\n    }\n    if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\n        throw new Error(\"Invalid outputStride \".concat(config.outputStride, \". \") +\n            \"Should be one of \".concat(VALID_STRIDE[config.architecture], \" \") +\n            \"for architecture \".concat(config.architecture, \".\"));\n    }\n    if (config.multiplier == null) {\n        config.multiplier = 1.0;\n    }\n    if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\n        throw new Error(\"Invalid multiplier \".concat(config.multiplier, \". \") +\n            \"Should be one of \".concat(VALID_MULTIPLIER[config.architecture], \" \") +\n            \"for architecture \".concat(config.architecture, \".\"));\n    }\n    if (config.quantBytes == null) {\n        config.quantBytes = 4;\n    }\n    if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\n        throw new Error(\"Invalid quantBytes \".concat(config.quantBytes, \". \") +\n            \"Should be one of \".concat(VALID_QUANT_BYTES, \" \") +\n            \"for architecture \".concat(config.architecture, \".\"));\n    }\n    return config;\n}\nvar PERSON_INFERENCE_CONFIG = {\n    flipHorizontal: false,\n    internalResolution: 'medium',\n    segmentationThreshold: 0.7,\n    maxDetections: 10,\n    scoreThreshold: 0.4,\n    nmsRadius: 20,\n};\nvar MULTI_PERSON_INSTANCE_INFERENCE_CONFIG = {\n    flipHorizontal: false,\n    internalResolution: 'medium',\n    segmentationThreshold: 0.7,\n    maxDetections: 10,\n    scoreThreshold: 0.4,\n    nmsRadius: 20,\n    minKeypointScore: 0.3,\n    refineSteps: 10\n};\nfunction validatePersonInferenceConfig(config) {\n    var segmentationThreshold = config.segmentationThreshold, maxDetections = config.maxDetections, scoreThreshold = config.scoreThreshold, nmsRadius = config.nmsRadius;\n    if (segmentationThreshold < 0.0 || segmentationThreshold > 1.0) {\n        throw new Error(\"segmentationThreshold \".concat(segmentationThreshold, \". \") +\n            \"Should be in range [0.0, 1.0]\");\n    }\n    if (maxDetections <= 0) {\n        throw new Error(\"Invalid maxDetections \".concat(maxDetections, \". \") +\n            \"Should be > 0\");\n    }\n    if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n        throw new Error(\"Invalid scoreThreshold \".concat(scoreThreshold, \". \") +\n            \"Should be in range [0.0, 1.0]\");\n    }\n    if (nmsRadius <= 0) {\n        throw new Error(\"Invalid nmsRadius \".concat(nmsRadius, \".\"));\n    }\n}\nfunction validateMultiPersonInstanceInferenceConfig(config) {\n    var segmentationThreshold = config.segmentationThreshold, maxDetections = config.maxDetections, scoreThreshold = config.scoreThreshold, nmsRadius = config.nmsRadius, minKeypointScore = config.minKeypointScore, refineSteps = config.refineSteps;\n    if (segmentationThreshold < 0.0 || segmentationThreshold > 1.0) {\n        throw new Error(\"segmentationThreshold \".concat(segmentationThreshold, \". \") +\n            \"Should be in range [0.0, 1.0]\");\n    }\n    if (maxDetections <= 0) {\n        throw new Error(\"Invalid maxDetections \".concat(maxDetections, \". \") +\n            \"Should be > 0\");\n    }\n    if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n        throw new Error(\"Invalid scoreThreshold \".concat(scoreThreshold, \". \") +\n            \"Should be in range [0.0, 1.0]\");\n    }\n    if (nmsRadius <= 0) {\n        throw new Error(\"Invalid nmsRadius \".concat(nmsRadius, \".\"));\n    }\n    if (minKeypointScore < 0 || minKeypointScore > 1) {\n        throw new Error(\"Invalid minKeypointScore \".concat(minKeypointScore, \".\") +\n            \"Should be in range [0.0, 1.0]\");\n    }\n    if (refineSteps <= 0 || refineSteps > 20) {\n        throw new Error(\"Invalid refineSteps \".concat(refineSteps, \".\") +\n            \"Should be in range [1, 20]\");\n    }\n}\nvar BodyPix = /** @class */ (function () {\n    function BodyPix(net) {\n        this.baseModel = net;\n    }\n    BodyPix.prototype.predictForPersonSegmentation = function (input) {\n        var _a = this.baseModel.predict(input), segmentation = _a.segmentation, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd;\n        return {\n            segmentLogits: segmentation,\n            heatmapScores: heatmapScores,\n            offsets: offsets,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n        };\n    };\n    BodyPix.prototype.predictForPersonSegmentationAndPart = function (input) {\n        var _a = this.baseModel.predict(input), segmentation = _a.segmentation, partHeatmaps = _a.partHeatmaps, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd;\n        return {\n            segmentLogits: segmentation,\n            partHeatmapLogits: partHeatmaps,\n            heatmapScores: heatmapScores,\n            offsets: offsets,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n        };\n    };\n    BodyPix.prototype.predictForMultiPersonInstanceSegmentationAndPart = function (input) {\n        var _a = this.baseModel.predict(input), segmentation = _a.segmentation, longOffsets = _a.longOffsets, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd, partHeatmaps = _a.partHeatmaps;\n        return {\n            segmentLogits: segmentation,\n            longOffsets: longOffsets,\n            heatmapScores: heatmapScores,\n            offsets: offsets,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n            partHeatmaps: partHeatmaps\n        };\n    };\n    /**\n     * Given an image with people, returns a dictionary of all intermediate\n     * tensors including: 1) a binary array with 1 for the pixels that are part of\n     * the person, and 0 otherwise, 2) heatmapScores, 3) offsets, and 4) paddings.\n     *\n     * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n     * The input image to feed through the network.\n     *\n     * @param internalResolution Defaults to 'medium'. The internal resolution\n     * that the input is resized to before inference. The larger the\n     * internalResolution the more accurate the model at the cost of slower\n     * prediction times. Available values are 'low', 'medium', 'high', 'full', or\n     * a percentage value between 0 and 1. The values 'low', 'medium', 'high', and\n     * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\n     *\n     * @param segmentationThreshold The minimum that segmentation values must have\n     * to be considered part of the person. Affects the generation of the\n     * segmentation mask.\n     *\n     * @return A dictionary containing `segmentation`, `heatmapScores`, `offsets`,\n     * and `padding`:\n     * - `segmentation`: A 2d Tensor with 1 for the pixels that are part of the\n     * person, and 0 otherwise. The width and height correspond to the same\n     * dimensions of the input image.\n     * - `heatmapScores`: A 3d Tensor of the keypoint heatmaps used by\n     * pose estimation decoding.\n     * - `offsets`: A 3d Tensor of the keypoint offsets used by pose\n     * estimation decoding.\n     * - `displacementFwd`: A 3d Tensor of the keypoint forward displacement used\n     * by pose estimation decoding.\n     * - `displacementBwd`: A 3d Tensor of the keypoint backward displacement used\n     * by pose estimation decoding.\n     * - `padding`: The padding (unit pixels) being applied to the input image\n     * before it is fed into the model.\n     */\n    BodyPix.prototype.segmentPersonActivation = function (input, internalResolution, segmentationThreshold) {\n        var _this = this;\n        if (segmentationThreshold === void 0) { segmentationThreshold = 0.5; }\n        var _a = getInputSize(input), height = _a[0], width = _a[1];\n        var internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(internalResolution, this.baseModel.outputStride, [height, width]);\n        var _b = padAndResizeTo(input, internalResolutionHeightAndWidth), resized = _b.resized, padding = _b.padding;\n        var _c = tf.tidy(function () {\n            var _a = _this.predictForPersonSegmentation(resized), segmentLogits = _a.segmentLogits, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd;\n            var _b = resized.shape, resizedHeight = _b[0], resizedWidth = _b[1];\n            var scaledSegmentScores = scaleAndCropToInputTensorShape(segmentLogits, [height, width], [resizedHeight, resizedWidth], [[padding.top, padding.bottom], [padding.left, padding.right]], APPLY_SIGMOID_ACTIVATION);\n            return {\n                segmentation: toMaskTensor(tf.squeeze(scaledSegmentScores), segmentationThreshold),\n                heatmapScores: heatmapScores,\n                offsets: offsets,\n                displacementFwd: displacementFwd,\n                displacementBwd: displacementBwd,\n            };\n        }), segmentation = _c.segmentation, heatmapScores = _c.heatmapScores, offsets = _c.offsets, displacementFwd = _c.displacementFwd, displacementBwd = _c.displacementBwd;\n        resized.dispose();\n        return {\n            segmentation: segmentation,\n            heatmapScores: heatmapScores,\n            offsets: offsets,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n            padding: padding,\n            internalResolutionHeightAndWidth: internalResolutionHeightAndWidth\n        };\n    };\n    /**\n     * Given an image with many people, returns a PersonSegmentation dictionary\n     * that contains the segmentation mask for all people and a single pose.\n     *\n     * Note: The segmentation mask returned by this method covers all people but\n     * the pose works well for one person. If you want to estimate instance-level\n     * multiple person segmentation & pose for each person, use\n     * `segmentMultiPerson` instead.\n     *\n     * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n     * The input image to feed through the network.\n     *\n     * @param config PersonInferenceConfig object that contains\n     * parameters for the BodyPix inference using person decoding.\n     *\n     * @return A SemanticPersonSegmentation dictionary that contains height,\n     * width, the flattened binary segmentation mask and the poses for all people.\n     * The width and height correspond to the same dimensions of the input image.\n     * - `height`: The height of the segmentation data in pixel unit.\n     * - `width`: The width of the segmentation data in pixel unit.\n     * - `data`: The flattened Uint8Array of segmentation data. 1 means the pixel\n     * belongs to a person and 0 means the pixel doesn't belong to a person. The\n     * size of the array is equal to `height` x `width` in row-major order.\n     * - `allPoses`: The 2d poses of all people.\n     */\n    BodyPix.prototype.segmentPerson = function (input, config) {\n        if (config === void 0) { config = PERSON_INFERENCE_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, segmentation, heatmapScores, offsets, displacementFwd, displacementBwd, padding, internalResolutionHeightAndWidth, _b, height, width, result, tensorBuffers, scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, poses;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        config = __assign(__assign({}, PERSON_INFERENCE_CONFIG), config);\n                        validatePersonInferenceConfig(config);\n                        _a = this.segmentPersonActivation(input, config.internalResolution, config.segmentationThreshold), segmentation = _a.segmentation, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd, padding = _a.padding, internalResolutionHeightAndWidth = _a.internalResolutionHeightAndWidth;\n                        _b = segmentation.shape, height = _b[0], width = _b[1];\n                        return [4 /*yield*/, segmentation.data()];\n                    case 1:\n                        result = _c.sent();\n                        segmentation.dispose();\n                        return [4 /*yield*/, toTensorBuffers3D([heatmapScores, offsets, displacementFwd, displacementBwd])];\n                    case 2:\n                        tensorBuffers = _c.sent();\n                        scoresBuf = tensorBuffers[0], offsetsBuf = tensorBuffers[1], displacementsFwdBuf = tensorBuffers[2], displacementsBwdBuf = tensorBuffers[3];\n                        poses = decodeMultiplePoses(scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, this.baseModel.outputStride, config.maxDetections, config.scoreThreshold, config.nmsRadius);\n                        poses = scaleAndFlipPoses(poses, [height, width], internalResolutionHeightAndWidth, padding, FLIP_POSES_AFTER_SCALING);\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        return [2 /*return*/, { height: height, width: width, data: result, allPoses: poses }];\n                }\n            });\n        });\n    };\n    /**\n     * Given an image with multiple people, returns an *array* of\n     * PersonSegmentation object. Each element in the array corresponding to one\n     * of the people in the input image. In other words, it predicts\n     * instance-level multiple person segmentation & pose for each person.\n     *\n     * The model does standard ImageNet pre-processing before inferring through\n     * the model. The image pixels should have values [0-255].\n     *\n     * @param input\n     * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n     * image to feed through the network.\n     *\n     * @param config MultiPersonInferenceConfig object that contains\n     * parameters for the BodyPix inference using multi-person decoding.\n     *\n     * @return An array of PersonSegmentation object, each containing a width,\n     * height, a binary array (1 for the pixels that are part of the\n     * person, and 0 otherwise) and 2D pose. The array size corresponds to the\n     * number of pixels in the image. The width and height correspond to the\n     * dimensions of the image the binary array is shaped to, which are the same\n     * dimensions of the input image.\n     */\n    BodyPix.prototype.segmentMultiPerson = function (input, config) {\n        if (config === void 0) { config = MULTI_PERSON_INSTANCE_INFERENCE_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, height, width, internalResolutionHeightAndWidth, _b, resized, padding, _c, segmentation, longOffsets, heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw, tensorBuffers, scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, poses, instanceMasks;\n            var _this = this;\n            return __generator(this, function (_d) {\n                switch (_d.label) {\n                    case 0:\n                        config = __assign(__assign({}, MULTI_PERSON_INSTANCE_INFERENCE_CONFIG), config);\n                        validateMultiPersonInstanceInferenceConfig(config);\n                        _a = getInputSize(input), height = _a[0], width = _a[1];\n                        internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(config.internalResolution, this.baseModel.outputStride, [height, width]);\n                        _b = padAndResizeTo(input, internalResolutionHeightAndWidth), resized = _b.resized, padding = _b.padding;\n                        _c = tf.tidy(function () {\n                            var _a = _this.predictForMultiPersonInstanceSegmentationAndPart(resized), segmentLogits = _a.segmentLogits, longOffsets = _a.longOffsets, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd;\n                            var scaledSegmentScores = scaleAndCropToInputTensorShape(segmentLogits, [height, width], internalResolutionHeightAndWidth, [[padding.top, padding.bottom], [padding.left, padding.right]], APPLY_SIGMOID_ACTIVATION);\n                            var scaledLongOffsets;\n                            {\n                                scaledLongOffsets = longOffsets;\n                            }\n                            var segmentation = toMaskTensor(tf.squeeze(scaledSegmentScores), config.segmentationThreshold);\n                            return {\n                                segmentation: segmentation,\n                                longOffsets: scaledLongOffsets,\n                                heatmapScoresRaw: heatmapScores,\n                                offsetsRaw: offsets,\n                                displacementFwdRaw: displacementFwd,\n                                displacementBwdRaw: displacementBwd,\n                            };\n                        }), segmentation = _c.segmentation, longOffsets = _c.longOffsets, heatmapScoresRaw = _c.heatmapScoresRaw, offsetsRaw = _c.offsetsRaw, displacementFwdRaw = _c.displacementFwdRaw, displacementBwdRaw = _c.displacementBwdRaw;\n                        return [4 /*yield*/, toTensorBuffers3D([heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw])];\n                    case 1:\n                        tensorBuffers = _d.sent();\n                        scoresBuf = tensorBuffers[0], offsetsBuf = tensorBuffers[1], displacementsFwdBuf = tensorBuffers[2], displacementsBwdBuf = tensorBuffers[3];\n                        poses = decodeMultiplePoses(scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, this.baseModel.outputStride, config.maxDetections, config.scoreThreshold, config.nmsRadius);\n                        poses = scaleAndFlipPoses(poses, [height, width], internalResolutionHeightAndWidth, padding, FLIP_POSES_AFTER_SCALING);\n                        return [4 /*yield*/, decodePersonInstanceMasks(segmentation, longOffsets, poses, height, width, this.baseModel.outputStride, internalResolutionHeightAndWidth, padding, config.scoreThreshold, config.refineSteps, config.minKeypointScore, config.maxDetections)];\n                    case 2:\n                        instanceMasks = _d.sent();\n                        resized.dispose();\n                        segmentation.dispose();\n                        longOffsets.dispose();\n                        heatmapScoresRaw.dispose();\n                        offsetsRaw.dispose();\n                        displacementFwdRaw.dispose();\n                        displacementBwdRaw.dispose();\n                        return [2 /*return*/, instanceMasks];\n                }\n            });\n        });\n    };\n    /**\n     * Given an image with many people, returns a dictionary containing: height,\n     * width, a tensor with a part id from 0-24 for the pixels that are\n     * part of a corresponding body part, and -1 otherwise. This does standard\n     * ImageNet pre-processing before inferring through the model.  The image\n     * should pixels should have values [0-255].\n     *\n     * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n     * The input image to feed through the network.\n     *\n     * @param internalResolution Defaults to 'medium'. The internal resolution\n     * percentage that the input is resized to before inference. The larger the\n     * internalResolution the more accurate the model at the cost of slower\n     * prediction times. Available values are 'low', 'medium', 'high', 'full', or\n     * a percentage value between 0 and 1. The values 'low', 'medium', 'high', and\n     * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\n     *\n     * @param segmentationThreshold The minimum that segmentation values must have\n     * to be considered part of the person.  Affects the clipping of the colored\n     * part image.\n     *\n     * @return  A dictionary containing `partSegmentation`, `heatmapScores`,\n     * `offsets`, and `padding`:\n     * - `partSegmentation`: A 2d Tensor with a part id from 0-24 for\n     * the pixels that are part of a corresponding body part, and -1 otherwise.\n     * - `heatmapScores`: A 3d Tensor of the keypoint heatmaps used by\n     * single-person pose estimation decoding.\n     * - `offsets`: A 3d Tensor of the keypoint offsets used by single-person pose\n     * estimation decoding.\n     * - `displacementFwd`: A 3d Tensor of the keypoint forward displacement\n     * used by pose estimation decoding.\n     * - `displacementBwd`: A 3d Tensor of the keypoint backward displacement used\n     * by pose estimation decoding.\n     * - `padding`: The padding (unit pixels) being applied to the input image\n     * before it is fed into the model.\n     */\n    BodyPix.prototype.segmentPersonPartsActivation = function (input, internalResolution, segmentationThreshold) {\n        var _this = this;\n        if (segmentationThreshold === void 0) { segmentationThreshold = 0.5; }\n        var _a = getInputSize(input), height = _a[0], width = _a[1];\n        var internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(internalResolution, this.baseModel.outputStride, [height, width]);\n        var _b = padAndResizeTo(input, internalResolutionHeightAndWidth), resized = _b.resized, padding = _b.padding;\n        var _c = tf.tidy(function () {\n            var _a = _this.predictForPersonSegmentationAndPart(resized), segmentLogits = _a.segmentLogits, partHeatmapLogits = _a.partHeatmapLogits, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd;\n            var _b = resized.shape, resizedHeight = _b[0], resizedWidth = _b[1];\n            var scaledSegmentScores = scaleAndCropToInputTensorShape(segmentLogits, [height, width], [resizedHeight, resizedWidth], [[padding.top, padding.bottom], [padding.left, padding.right]], APPLY_SIGMOID_ACTIVATION);\n            var scaledPartHeatmapScore = scaleAndCropToInputTensorShape(partHeatmapLogits, [height, width], [resizedHeight, resizedWidth], [[padding.top, padding.bottom], [padding.left, padding.right]], APPLY_SIGMOID_ACTIVATION);\n            var segmentation = toMaskTensor(tf.squeeze(scaledSegmentScores), segmentationThreshold);\n            return {\n                partSegmentation: decodePartSegmentation(segmentation, scaledPartHeatmapScore),\n                heatmapScores: heatmapScores,\n                offsets: offsets,\n                displacementFwd: displacementFwd,\n                displacementBwd: displacementBwd,\n            };\n        }), partSegmentation = _c.partSegmentation, heatmapScores = _c.heatmapScores, offsets = _c.offsets, displacementFwd = _c.displacementFwd, displacementBwd = _c.displacementBwd;\n        resized.dispose();\n        return {\n            partSegmentation: partSegmentation,\n            heatmapScores: heatmapScores,\n            offsets: offsets,\n            displacementFwd: displacementFwd,\n            displacementBwd: displacementBwd,\n            padding: padding,\n            internalResolutionHeightAndWidth: internalResolutionHeightAndWidth\n        };\n    };\n    /**\n     * Given an image with many people, returns a PartSegmentation dictionary that\n     * contains the body part segmentation mask for all people and a single pose.\n     *\n     * Note: The body part segmentation mask returned by this method covers all\n     * people but the pose works well when there is one person. If you want to\n     * estimate instance-level multiple person body part segmentation & pose for\n     * each person, use `segmentMultiPersonParts` instead.\n     *\n     * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n     * The input image to feed through the network.\n     *\n     * @param config PersonInferenceConfig object that contains\n     * parameters for the BodyPix inference using single person decoding.\n     *\n     * @return A SemanticPartSegmentation dictionary that contains height, width,\n     * the flattened binary segmentation mask and the pose for the person. The\n     * width and height correspond to the same dimensions of the input image.\n     * - `height`: The height of the person part segmentation data in pixel unit.\n     * - `width`: The width of the person part segmentation data in pixel unit.\n     * - `data`: The flattened Int32Array of person part segmentation data with a\n     * part id from 0-24 for the pixels that are part of a corresponding body\n     * part, and -1 otherwise. The size of the array is equal to `height` x\n     * `width` in row-major order.\n     * - `allPoses`: The 2d poses of all people.\n     */\n    BodyPix.prototype.segmentPersonParts = function (input, config) {\n        if (config === void 0) { config = PERSON_INFERENCE_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, partSegmentation, heatmapScores, offsets, displacementFwd, displacementBwd, padding, internalResolutionHeightAndWidth, _b, height, width, data, tensorBuffers, scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, poses;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        config = __assign(__assign({}, PERSON_INFERENCE_CONFIG), config);\n                        validatePersonInferenceConfig(config);\n                        _a = this.segmentPersonPartsActivation(input, config.internalResolution, config.segmentationThreshold), partSegmentation = _a.partSegmentation, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd, padding = _a.padding, internalResolutionHeightAndWidth = _a.internalResolutionHeightAndWidth;\n                        _b = partSegmentation.shape, height = _b[0], width = _b[1];\n                        return [4 /*yield*/, partSegmentation.data()];\n                    case 1:\n                        data = _c.sent();\n                        partSegmentation.dispose();\n                        return [4 /*yield*/, toTensorBuffers3D([heatmapScores, offsets, displacementFwd, displacementBwd])];\n                    case 2:\n                        tensorBuffers = _c.sent();\n                        scoresBuf = tensorBuffers[0], offsetsBuf = tensorBuffers[1], displacementsFwdBuf = tensorBuffers[2], displacementsBwdBuf = tensorBuffers[3];\n                        poses = decodeMultiplePoses(scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, this.baseModel.outputStride, config.maxDetections, config.scoreThreshold, config.nmsRadius);\n                        poses = scaleAndFlipPoses(poses, [height, width], internalResolutionHeightAndWidth, padding, FLIP_POSES_AFTER_SCALING);\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        return [2 /*return*/, { height: height, width: width, data: data, allPoses: poses }];\n                }\n            });\n        });\n    };\n    /**\n     * Given an image with multiple people, returns an *array* of PartSegmentation\n     * object. Each element in the array corresponding to one\n     * of the people in the input image. In other words, it predicts\n     * instance-level multiple person body part segmentation & pose for each\n     * person.\n     *\n     * This does standard ImageNet pre-processing before inferring through\n     * the model. The image pixels should have values [0-255].\n     *\n     * @param input\n     * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n     * image to feed through the network.\n     *\n     * @param config MultiPersonInferenceConfig object that contains\n     * parameters for the BodyPix inference using multi-person decoding.\n     *\n     * @return An array of PartSegmentation object, each containing a width,\n     * height, a flattened array (with part id from 0-24 for the pixels that are\n     * part of a corresponding body part, and -1 otherwise) and 2D pose. The width\n     * and height correspond to the dimensions of the image. Each flattened part\n     * segmentation array size is equal to `height` x `width`.\n     */\n    BodyPix.prototype.segmentMultiPersonParts = function (input, config) {\n        if (config === void 0) { config = MULTI_PERSON_INSTANCE_INFERENCE_CONFIG; }\n        return __awaiter(this, void 0, void 0, function () {\n            var _a, height, width, internalResolutionHeightAndWidth, _b, resized, padding, _c, segmentation, longOffsets, heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw, partSegmentation, tensorBuffers, scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, poses, instanceMasks;\n            var _this = this;\n            return __generator(this, function (_d) {\n                switch (_d.label) {\n                    case 0:\n                        config = __assign(__assign({}, MULTI_PERSON_INSTANCE_INFERENCE_CONFIG), config);\n                        validateMultiPersonInstanceInferenceConfig(config);\n                        _a = getInputSize(input), height = _a[0], width = _a[1];\n                        internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(config.internalResolution, this.baseModel.outputStride, [height, width]);\n                        _b = padAndResizeTo(input, internalResolutionHeightAndWidth), resized = _b.resized, padding = _b.padding;\n                        _c = tf.tidy(function () {\n                            var _a = _this.predictForMultiPersonInstanceSegmentationAndPart(resized), segmentLogits = _a.segmentLogits, longOffsets = _a.longOffsets, heatmapScores = _a.heatmapScores, offsets = _a.offsets, displacementFwd = _a.displacementFwd, displacementBwd = _a.displacementBwd, partHeatmaps = _a.partHeatmaps;\n                            // decoding with scaling.\n                            var scaledSegmentScores = scaleAndCropToInputTensorShape(segmentLogits, [height, width], internalResolutionHeightAndWidth, [[padding.top, padding.bottom], [padding.left, padding.right]], APPLY_SIGMOID_ACTIVATION);\n                            // decoding with scaling.\n                            var scaledPartSegmentationScores = scaleAndCropToInputTensorShape(partHeatmaps, [height, width], internalResolutionHeightAndWidth, [[padding.top, padding.bottom], [padding.left, padding.right]], APPLY_SIGMOID_ACTIVATION);\n                            var scaledLongOffsets = longOffsets;\n                            var segmentation = toMaskTensor(tf.squeeze(scaledSegmentScores), config.segmentationThreshold);\n                            var partSegmentation = decodeOnlyPartSegmentation(scaledPartSegmentationScores);\n                            return {\n                                segmentation: segmentation,\n                                longOffsets: scaledLongOffsets,\n                                heatmapScoresRaw: heatmapScores,\n                                offsetsRaw: offsets,\n                                displacementFwdRaw: displacementFwd,\n                                displacementBwdRaw: displacementBwd,\n                                partSegmentation: partSegmentation\n                            };\n                        }), segmentation = _c.segmentation, longOffsets = _c.longOffsets, heatmapScoresRaw = _c.heatmapScoresRaw, offsetsRaw = _c.offsetsRaw, displacementFwdRaw = _c.displacementFwdRaw, displacementBwdRaw = _c.displacementBwdRaw, partSegmentation = _c.partSegmentation;\n                        return [4 /*yield*/, toTensorBuffers3D([heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw])];\n                    case 1:\n                        tensorBuffers = _d.sent();\n                        scoresBuf = tensorBuffers[0], offsetsBuf = tensorBuffers[1], displacementsFwdBuf = tensorBuffers[2], displacementsBwdBuf = tensorBuffers[3];\n                        poses = decodeMultiplePoses(scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf, this.baseModel.outputStride, config.maxDetections, config.scoreThreshold, config.nmsRadius);\n                        poses = scaleAndFlipPoses(poses, [height, width], internalResolutionHeightAndWidth, padding, FLIP_POSES_AFTER_SCALING);\n                        return [4 /*yield*/, decodePersonInstancePartMasks(segmentation, longOffsets, partSegmentation, poses, height, width, this.baseModel.outputStride, internalResolutionHeightAndWidth, padding, config.scoreThreshold, config.refineSteps, config.minKeypointScore, config.maxDetections)];\n                    case 2:\n                        instanceMasks = _d.sent();\n                        resized.dispose();\n                        segmentation.dispose();\n                        longOffsets.dispose();\n                        heatmapScoresRaw.dispose();\n                        offsetsRaw.dispose();\n                        displacementFwdRaw.dispose();\n                        displacementBwdRaw.dispose();\n                        partSegmentation.dispose();\n                        return [2 /*return*/, instanceMasks];\n                }\n            });\n        });\n    };\n    BodyPix.prototype.dispose = function () {\n        this.baseModel.dispose();\n    };\n    return BodyPix;\n}());\n/**\n * Loads the MobileNet BodyPix model.\n */\nfunction loadMobileNet(config) {\n    return __awaiter(this, void 0, void 0, function () {\n        var outputStride, quantBytes, multiplier, url, graphModel, mobilenet;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    outputStride = config.outputStride;\n                    quantBytes = config.quantBytes;\n                    multiplier = config.multiplier;\n                    if (tf == null) {\n                        throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" +\n                            \"also include @tensorflow/tfjs on the page before using this\\n        model.\");\n                    }\n                    url = mobileNetSavedModel(outputStride, multiplier, quantBytes);\n                    return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || url)];\n                case 1:\n                    graphModel = _a.sent();\n                    mobilenet = new MobileNet(graphModel, outputStride);\n                    return [2 /*return*/, new BodyPix(mobilenet)];\n            }\n        });\n    });\n}\n/**\n * Loads the ResNet BodyPix model.\n */\nfunction loadResNet(config) {\n    return __awaiter(this, void 0, void 0, function () {\n        var outputStride, quantBytes, url, graphModel, resnet;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    outputStride = config.outputStride;\n                    quantBytes = config.quantBytes;\n                    if (tf == null) {\n                        throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" +\n                            \"also include @tensorflow/tfjs on the page before using this\\n        model.\");\n                    }\n                    url = resNet50SavedModel(outputStride, quantBytes);\n                    return [4 /*yield*/, tfconv.loadGraphModel(config.modelUrl || url)];\n                case 1:\n                    graphModel = _a.sent();\n                    resnet = new ResNet(graphModel, outputStride);\n                    return [2 /*return*/, new BodyPix(resnet)];\n            }\n        });\n    });\n}\n/**\n * Loads the BodyPix model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the BodyPix loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nfunction load(config) {\n    if (config === void 0) { config = MOBILENET_V1_CONFIG; }\n    return __awaiter(this, void 0, void 0, function () {\n        return __generator(this, function (_a) {\n            config = validateModelConfig(config);\n            if (config.architecture === 'ResNet50') {\n                return [2 /*return*/, loadResNet(config)];\n            }\n            else if (config.architecture === 'MobileNetV1') {\n                return [2 /*return*/, loadMobileNet(config)];\n            }\n            else {\n                return [2 /*return*/, null];\n            }\n        });\n    });\n}\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// method copied from bGlur in https://codepen.io/zhaojun/pen/zZmRQe\nfunction cpuBlur(canvas, image, blur) {\n    var ctx = canvas.getContext('2d');\n    var sum = 0;\n    var delta = 5;\n    var alphaLeft = 1 / (2 * Math.PI * delta * delta);\n    var step = blur < 3 ? 1 : 2;\n    for (var y = -blur; y <= blur; y += step) {\n        for (var x = -blur; x <= blur; x += step) {\n            var weight = alphaLeft * Math.exp(-(x * x + y * y) / (2 * delta * delta));\n            sum += weight;\n        }\n    }\n    for (var y = -blur; y <= blur; y += step) {\n        for (var x = -blur; x <= blur; x += step) {\n            ctx.globalAlpha = alphaLeft *\n                Math.exp(-(x * x + y * y) / (2 * delta * delta)) / sum * blur;\n            ctx.drawImage(image, x, y);\n        }\n    }\n    ctx.globalAlpha = 1;\n}\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar offScreenCanvases = {};\nfunction isSafari() {\n    return (/^((?!chrome|android).)*safari/i.test(navigator.userAgent));\n}\nfunction assertSameDimensions(_a, _b, nameA, nameB) {\n    var widthA = _a.width, heightA = _a.height;\n    var widthB = _b.width, heightB = _b.height;\n    if (widthA !== widthB || heightA !== heightB) {\n        throw new Error(\"error: dimensions must match. \".concat(nameA, \" has dimensions \").concat(widthA, \"x\").concat(heightA, \", \").concat(nameB, \" has dimensions \").concat(widthB, \"x\").concat(heightB));\n    }\n}\nfunction flipCanvasHorizontal(canvas) {\n    var ctx = canvas.getContext('2d');\n    ctx.scale(-1, 1);\n    ctx.translate(-canvas.width, 0);\n}\nfunction drawWithCompositing(ctx, image, compositeOperation) {\n    ctx.globalCompositeOperation = compositeOperation;\n    ctx.drawImage(image, 0, 0);\n}\nfunction createOffScreenCanvas() {\n    if (typeof document !== 'undefined') {\n        return document.createElement('canvas');\n    }\n    else if (typeof OffscreenCanvas !== 'undefined') {\n        return new OffscreenCanvas(0, 0);\n    }\n    else {\n        throw new Error('Cannot create a canvas in this context');\n    }\n}\nfunction ensureOffscreenCanvasCreated(id) {\n    if (!offScreenCanvases[id]) {\n        offScreenCanvases[id] = createOffScreenCanvas();\n    }\n    return offScreenCanvases[id];\n}\nfunction drawAndBlurImageOnCanvas(image, blurAmount, canvas) {\n    var height = image.height, width = image.width;\n    var ctx = canvas.getContext('2d');\n    canvas.width = width;\n    canvas.height = height;\n    ctx.clearRect(0, 0, width, height);\n    ctx.save();\n    if (isSafari()) {\n        cpuBlur(canvas, image, blurAmount);\n    }\n    else {\n        // tslint:disable:no-any\n        ctx.filter = \"blur(\".concat(blurAmount, \"px)\");\n        ctx.drawImage(image, 0, 0, width, height);\n    }\n    ctx.restore();\n}\nfunction drawAndBlurImageOnOffScreenCanvas(image, blurAmount, offscreenCanvasName) {\n    var canvas = ensureOffscreenCanvasCreated(offscreenCanvasName);\n    if (blurAmount === 0) {\n        renderImageToCanvas(image, canvas);\n    }\n    else {\n        drawAndBlurImageOnCanvas(image, blurAmount, canvas);\n    }\n    return canvas;\n}\nfunction renderImageToCanvas(image, canvas) {\n    var width = image.width, height = image.height;\n    canvas.width = width;\n    canvas.height = height;\n    var ctx = canvas.getContext('2d');\n    ctx.drawImage(image, 0, 0, width, height);\n}\n/**\n * Draw an image on a canvas\n */\nfunction renderImageDataToCanvas(image, canvas) {\n    canvas.width = image.width;\n    canvas.height = image.height;\n    var ctx = canvas.getContext('2d');\n    ctx.putImageData(image, 0, 0);\n}\nfunction renderImageDataToOffScreenCanvas(image, canvasName) {\n    var canvas = ensureOffscreenCanvasCreated(canvasName);\n    renderImageDataToCanvas(image, canvas);\n    return canvas;\n}\n/**\n * Given the output from estimating multi-person segmentation, generates an\n * image with foreground and background color at each pixel determined by the\n * corresponding binary segmentation value at the pixel from the output.  In\n * other words, pixels where there is a person will be colored with foreground\n * color and where there is not a person will be colored with background color.\n *\n * @param personOrPartSegmentation The output from\n * `segmentPerson`, `segmentMultiPerson`,\n * `segmentPersonParts` or `segmentMultiPersonParts`. They can\n * be SemanticPersonSegmentation object, an array of PersonSegmentation object,\n * SemanticPartSegmentation object, or an array of PartSegmentation object.\n *\n * @param foreground Default to {r:0, g:0, b:0, a: 0}. The foreground color\n * (r,g,b,a) for visualizing pixels that belong to people.\n *\n * @param background Default to {r:0, g:0, b:0, a: 255}. The background color\n * (r,g,b,a) for visualizing pixels that don't belong to people.\n *\n * @param drawContour Default to false. Whether to draw the contour around each\n * person's segmentation mask or body part mask.\n *\n * @param foregroundIds Default to [1]. The integer values that represent\n * foreground. For person segmentation, 1 is the foreground. For body part\n * segmentation, it can be a subset of all body parts ids.\n *\n * @returns An ImageData with the same width and height of\n * all the PersonSegmentation in multiPersonSegmentation, with opacity and\n * transparency at each pixel determined by the corresponding binary\n * segmentation value at the pixel from the output.\n */\nfunction toMask(personOrPartSegmentation, foreground, background, drawContour, foregroundIds) {\n    if (foreground === void 0) { foreground = {\n        r: 0,\n        g: 0,\n        b: 0,\n        a: 0\n    }; }\n    if (background === void 0) { background = {\n        r: 0,\n        g: 0,\n        b: 0,\n        a: 255\n    }; }\n    if (drawContour === void 0) { drawContour = false; }\n    if (foregroundIds === void 0) { foregroundIds = [1]; }\n    if (Array.isArray(personOrPartSegmentation) &&\n        personOrPartSegmentation.length === 0) {\n        return null;\n    }\n    var multiPersonOrPartSegmentation;\n    if (!Array.isArray(personOrPartSegmentation)) {\n        multiPersonOrPartSegmentation = [personOrPartSegmentation];\n    }\n    else {\n        multiPersonOrPartSegmentation = personOrPartSegmentation;\n    }\n    var _a = multiPersonOrPartSegmentation[0], width = _a.width, height = _a.height;\n    var bytes = new Uint8ClampedArray(width * height * 4);\n    function drawStroke(bytes, row, column, width, radius, color) {\n        if (color === void 0) { color = { r: 0, g: 255, b: 255, a: 255 }; }\n        for (var i = -radius; i <= radius; i++) {\n            for (var j = -radius; j <= radius; j++) {\n                if (i !== 0 && j !== 0) {\n                    var n = (row + i) * width + (column + j);\n                    bytes[4 * n + 0] = color.r;\n                    bytes[4 * n + 1] = color.g;\n                    bytes[4 * n + 2] = color.b;\n                    bytes[4 * n + 3] = color.a;\n                }\n            }\n        }\n    }\n    function isSegmentationBoundary(segmentationData, row, column, width, foregroundIds, radius) {\n        if (foregroundIds === void 0) { foregroundIds = [1]; }\n        if (radius === void 0) { radius = 1; }\n        var numberBackgroundPixels = 0;\n        for (var i = -radius; i <= radius; i++) {\n            var _loop_2 = function (j) {\n                if (i !== 0 && j !== 0) {\n                    var n_1 = (row + i) * width + (column + j);\n                    if (!foregroundIds.some(function (id) { return id === segmentationData[n_1]; })) {\n                        numberBackgroundPixels += 1;\n                    }\n                }\n            };\n            for (var j = -radius; j <= radius; j++) {\n                _loop_2(j);\n            }\n        }\n        return numberBackgroundPixels > 0;\n    }\n    for (var i = 0; i < height; i += 1) {\n        var _loop_1 = function (j) {\n            var n = i * width + j;\n            bytes[4 * n + 0] = background.r;\n            bytes[4 * n + 1] = background.g;\n            bytes[4 * n + 2] = background.b;\n            bytes[4 * n + 3] = background.a;\n            var _loop_3 = function (k) {\n                if (foregroundIds.some(function (id) { return id === multiPersonOrPartSegmentation[k].data[n]; })) {\n                    bytes[4 * n] = foreground.r;\n                    bytes[4 * n + 1] = foreground.g;\n                    bytes[4 * n + 2] = foreground.b;\n                    bytes[4 * n + 3] = foreground.a;\n                    var isBoundary = isSegmentationBoundary(multiPersonOrPartSegmentation[k].data, i, j, width, foregroundIds);\n                    if (drawContour && i - 1 >= 0 && i + 1 < height && j - 1 >= 0 &&\n                        j + 1 < width && isBoundary) {\n                        drawStroke(bytes, i, j, width, 1);\n                    }\n                }\n            };\n            for (var k = 0; k < multiPersonOrPartSegmentation.length; k++) {\n                _loop_3(k);\n            }\n        };\n        for (var j = 0; j < width; j += 1) {\n            _loop_1(j);\n        }\n    }\n    return new ImageData(bytes, width, height);\n}\nvar RAINBOW_PART_COLORS = [\n    [110, 64, 170], [143, 61, 178], [178, 60, 178], [210, 62, 167],\n    [238, 67, 149], [255, 78, 125], [255, 94, 99], [255, 115, 75],\n    [255, 140, 56], [239, 167, 47], [217, 194, 49], [194, 219, 64],\n    [175, 240, 91], [135, 245, 87], [96, 247, 96], [64, 243, 115],\n    [40, 234, 141], [28, 219, 169], [26, 199, 194], [33, 176, 213],\n    [47, 150, 224], [65, 125, 224], [84, 101, 214], [99, 81, 195]\n];\n/**\n * Given the output from person body part segmentation (or multi-person\n * instance body part segmentation) and an array of colors indexed by part id,\n * generates an image with the corresponding color for each part at each pixel,\n * and white pixels where there is no part.\n *\n * @param partSegmentation The output from segmentPersonParts\n * or segmentMultiPersonParts. The former is a SemanticPartSegmentation\n * object and later is an array of PartSegmentation object.\n *\n * @param partColors A multi-dimensional array of rgb colors indexed by\n * part id.  Must have 24 colors, one for every part.\n *\n * @returns An ImageData with the same width and height of all the element in\n * multiPersonPartSegmentation, with the corresponding color for each part at\n * each pixel, and black pixels where there is no part.\n */\nfunction toColoredPartMask(partSegmentation, partColors) {\n    if (partColors === void 0) { partColors = RAINBOW_PART_COLORS; }\n    if (Array.isArray(partSegmentation) && partSegmentation.length === 0) {\n        return null;\n    }\n    var multiPersonPartSegmentation;\n    if (!Array.isArray(partSegmentation)) {\n        multiPersonPartSegmentation = [partSegmentation];\n    }\n    else {\n        multiPersonPartSegmentation = partSegmentation;\n    }\n    var _a = multiPersonPartSegmentation[0], width = _a.width, height = _a.height;\n    var bytes = new Uint8ClampedArray(width * height * 4);\n    for (var i = 0; i < height * width; ++i) {\n        // invert mask.  Invert the segmentation mask.\n        var j = i * 4;\n        bytes[j + 0] = 255;\n        bytes[j + 1] = 255;\n        bytes[j + 2] = 255;\n        bytes[j + 3] = 255;\n        for (var k = 0; k < multiPersonPartSegmentation.length; k++) {\n            var partId = multiPersonPartSegmentation[k].data[i];\n            if (partId !== -1) {\n                var color = partColors[partId];\n                if (!color) {\n                    throw new Error(\"No color could be found for part id \".concat(partId));\n                }\n                bytes[j + 0] = color[0];\n                bytes[j + 1] = color[1];\n                bytes[j + 2] = color[2];\n                bytes[j + 3] = 255;\n            }\n        }\n    }\n    return new ImageData(bytes, width, height);\n}\nvar CANVAS_NAMES = {\n    blurred: 'blurred',\n    blurredMask: 'blurred-mask',\n    mask: 'mask',\n    lowresPartMask: 'lowres-part-mask',\n};\n/**\n * Given an image and a maskImage of type ImageData, draws the image with the\n * mask on top of it onto a canvas.\n *\n * @param canvas The canvas to be drawn onto.\n *\n * @param image The original image to apply the mask to.\n *\n * @param maskImage An ImageData containing the mask.  Ideally this should be\n * generated by toMask or toColoredPartMask.\n *\n * @param maskOpacity The opacity of the mask when drawing it on top of the\n * image. Defaults to 0.7. Should be a float between 0 and 1.\n *\n * @param maskBlurAmount How many pixels to blur the mask by. Defaults to 0.\n * Should be an integer between 0 and 20.\n *\n * @param flipHorizontal If the result should be flipped horizontally.  Defaults\n * to false.\n */\nfunction drawMask(canvas, image, maskImage, maskOpacity, maskBlurAmount, flipHorizontal) {\n    if (maskOpacity === void 0) { maskOpacity = 0.7; }\n    if (maskBlurAmount === void 0) { maskBlurAmount = 0; }\n    if (flipHorizontal === void 0) { flipHorizontal = false; }\n    var _a = getInputSize(image), height = _a[0], width = _a[1];\n    canvas.width = width;\n    canvas.height = height;\n    var ctx = canvas.getContext('2d');\n    ctx.save();\n    if (flipHorizontal) {\n        flipCanvasHorizontal(canvas);\n    }\n    ctx.drawImage(image, 0, 0);\n    ctx.globalAlpha = maskOpacity;\n    if (maskImage) {\n        assertSameDimensions({ width: width, height: height }, maskImage, 'image', 'mask');\n        var mask = renderImageDataToOffScreenCanvas(maskImage, CANVAS_NAMES.mask);\n        var blurredMask = drawAndBlurImageOnOffScreenCanvas(mask, maskBlurAmount, CANVAS_NAMES.blurredMask);\n        ctx.drawImage(blurredMask, 0, 0, width, height);\n    }\n    ctx.restore();\n}\n/**\n * Given an image and a maskImage of type ImageData, draws the image with the\n * pixelated mask on top of it onto a canvas.\n *\n * @param canvas The canvas to be drawn onto.\n *\n * @param image The original image to apply the mask to.\n *\n * @param maskImage An ImageData containing the mask.  Ideally this should be\n * generated by toColoredPartMask.\n *\n * @param maskOpacity The opacity of the mask when drawing it on top of the\n * image. Defaults to 0.7. Should be a float between 0 and 1.\n *\n * @param maskBlurAmount How many pixels to blur the mask by. Defaults to 0.\n * Should be an integer between 0 and 20.\n *\n * @param flipHorizontal If the result should be flipped horizontally.  Defaults\n * to false.\n *\n * @param pixelCellWidth The width of each pixel cell. Default to 10 px.\n */\nfunction drawPixelatedMask(canvas, image, maskImage, maskOpacity, maskBlurAmount, flipHorizontal, pixelCellWidth) {\n    if (maskOpacity === void 0) { maskOpacity = 0.7; }\n    if (maskBlurAmount === void 0) { maskBlurAmount = 0; }\n    if (flipHorizontal === void 0) { flipHorizontal = false; }\n    if (pixelCellWidth === void 0) { pixelCellWidth = 10.0; }\n    var _a = getInputSize(image), height = _a[0], width = _a[1];\n    assertSameDimensions({ width: width, height: height }, maskImage, 'image', 'mask');\n    var mask = renderImageDataToOffScreenCanvas(maskImage, CANVAS_NAMES.mask);\n    var blurredMask = drawAndBlurImageOnOffScreenCanvas(mask, maskBlurAmount, CANVAS_NAMES.blurredMask);\n    canvas.width = blurredMask.width;\n    canvas.height = blurredMask.height;\n    var ctx = canvas.getContext('2d');\n    ctx.save();\n    if (flipHorizontal) {\n        flipCanvasHorizontal(canvas);\n    }\n    var offscreenCanvas = ensureOffscreenCanvasCreated(CANVAS_NAMES.lowresPartMask);\n    var offscreenCanvasCtx = offscreenCanvas\n        .getContext('2d');\n    offscreenCanvas.width = blurredMask.width * (1.0 / pixelCellWidth);\n    offscreenCanvas.height = blurredMask.height * (1.0 / pixelCellWidth);\n    offscreenCanvasCtx.drawImage(blurredMask, 0, 0, blurredMask.width, blurredMask.height, 0, 0, offscreenCanvas.width, offscreenCanvas.height);\n    ctx.imageSmoothingEnabled = false;\n    ctx.drawImage(offscreenCanvas, 0, 0, offscreenCanvas.width, offscreenCanvas.height, 0, 0, canvas.width, canvas.height);\n    // Draws vertical grid lines that are `pixelCellWidth` apart from each other.\n    for (var i = 0; i < offscreenCanvas.width; i++) {\n        ctx.beginPath();\n        ctx.strokeStyle = '#ffffff';\n        ctx.moveTo(pixelCellWidth * i, 0);\n        ctx.lineTo(pixelCellWidth * i, canvas.height);\n        ctx.stroke();\n    }\n    // Draws horizontal grid lines that are `pixelCellWidth` apart from each\n    // other.\n    for (var i = 0; i < offscreenCanvas.height; i++) {\n        ctx.beginPath();\n        ctx.strokeStyle = '#ffffff';\n        ctx.moveTo(0, pixelCellWidth * i);\n        ctx.lineTo(canvas.width, pixelCellWidth * i);\n        ctx.stroke();\n    }\n    ctx.globalAlpha = 1.0 - maskOpacity;\n    ctx.drawImage(image, 0, 0, blurredMask.width, blurredMask.height);\n    ctx.restore();\n}\nfunction createPersonMask(multiPersonSegmentation, edgeBlurAmount) {\n    var backgroundMaskImage = toMask(multiPersonSegmentation, { r: 0, g: 0, b: 0, a: 255 }, { r: 0, g: 0, b: 0, a: 0 });\n    var backgroundMask = renderImageDataToOffScreenCanvas(backgroundMaskImage, CANVAS_NAMES.mask);\n    if (edgeBlurAmount === 0) {\n        return backgroundMask;\n    }\n    else {\n        return drawAndBlurImageOnOffScreenCanvas(backgroundMask, edgeBlurAmount, CANVAS_NAMES.blurredMask);\n    }\n}\n/**\n * Given a personSegmentation and an image, draws the image with its background\n * blurred onto the canvas.\n *\n * @param canvas The canvas to draw the background-blurred image onto.\n *\n * @param image The image to blur the background of and draw.\n *\n * @param personSegmentation A SemanticPersonSegmentation or an array of\n * PersonSegmentation object.\n *\n * @param backgroundBlurAmount How many pixels in the background blend into each\n * other.  Defaults to 3. Should be an integer between 1 and 20.\n *\n * @param edgeBlurAmount How many pixels to blur on the edge between the person\n * and the background by.  Defaults to 3. Should be an integer between 0 and 20.\n *\n * @param flipHorizontal If the output should be flipped horizontally.  Defaults\n * to false.\n */\nfunction drawBokehEffect(canvas, image, multiPersonSegmentation, backgroundBlurAmount, edgeBlurAmount, flipHorizontal) {\n    if (backgroundBlurAmount === void 0) { backgroundBlurAmount = 3; }\n    if (edgeBlurAmount === void 0) { edgeBlurAmount = 3; }\n    if (flipHorizontal === void 0) { flipHorizontal = false; }\n    var blurredImage = drawAndBlurImageOnOffScreenCanvas(image, backgroundBlurAmount, CANVAS_NAMES.blurred);\n    canvas.width = blurredImage.width;\n    canvas.height = blurredImage.height;\n    var ctx = canvas.getContext('2d');\n    if (Array.isArray(multiPersonSegmentation) &&\n        multiPersonSegmentation.length === 0) {\n        ctx.drawImage(blurredImage, 0, 0);\n        return;\n    }\n    var personMask = createPersonMask(multiPersonSegmentation, edgeBlurAmount);\n    ctx.save();\n    if (flipHorizontal) {\n        flipCanvasHorizontal(canvas);\n    }\n    // draw the original image on the final canvas\n    var _a = getInputSize(image), height = _a[0], width = _a[1];\n    ctx.drawImage(image, 0, 0, width, height);\n    // \"destination-in\" - \"The existing canvas content is kept where both the\n    // new shape and existing canvas content overlap. Everything else is made\n    // transparent.\"\n    // crop what's not the person using the mask from the original image\n    drawWithCompositing(ctx, personMask, 'destination-in');\n    // \"destination-over\" - \"The existing canvas content is kept where both the\n    // new shape and existing canvas content overlap. Everything else is made\n    // transparent.\"\n    // draw the blurred background on top of the original image where it doesn't\n    // overlap.\n    drawWithCompositing(ctx, blurredImage, 'destination-over');\n    ctx.restore();\n}\nfunction createBodyPartMask(multiPersonPartSegmentation, bodyPartIdsToMask, edgeBlurAmount) {\n    var backgroundMaskImage = toMask(multiPersonPartSegmentation, { r: 0, g: 0, b: 0, a: 0 }, { r: 0, g: 0, b: 0, a: 255 }, true, bodyPartIdsToMask);\n    var backgroundMask = renderImageDataToOffScreenCanvas(backgroundMaskImage, CANVAS_NAMES.mask);\n    if (edgeBlurAmount === 0) {\n        return backgroundMask;\n    }\n    else {\n        return drawAndBlurImageOnOffScreenCanvas(backgroundMask, edgeBlurAmount, CANVAS_NAMES.blurredMask);\n    }\n}\n/**\n * Given a personSegmentation and an image, draws the image with its background\n * blurred onto the canvas.\n *\n * @param canvas The canvas to draw the background-blurred image onto.\n *\n * @param image The image to blur the background of and draw.\n *\n * @param partSegmentation A SemanticPartSegmentation or an array of\n * PartSegmentation object.\n *\n * @param bodyPartIdsToBlur Default to [0, 1] (left-face and right-face). An\n * array of body part ids to blur. Each must be one of the 24 body part ids.\n *\n * @param backgroundBlurAmount How many pixels in the background blend into each\n * other.  Defaults to 3. Should be an integer between 1 and 20.\n *\n * @param edgeBlurAmount How many pixels to blur on the edge between the person\n * and the background by.  Defaults to 3. Should be an integer between 0 and 20.\n *\n * @param flipHorizontal If the output should be flipped horizontally.  Defaults\n * to false.\n */\nfunction blurBodyPart(canvas, image, partSegmentation, bodyPartIdsToBlur, backgroundBlurAmount, edgeBlurAmount, flipHorizontal) {\n    if (bodyPartIdsToBlur === void 0) { bodyPartIdsToBlur = [0, 1]; }\n    if (backgroundBlurAmount === void 0) { backgroundBlurAmount = 3; }\n    if (edgeBlurAmount === void 0) { edgeBlurAmount = 3; }\n    if (flipHorizontal === void 0) { flipHorizontal = false; }\n    var blurredImage = drawAndBlurImageOnOffScreenCanvas(image, backgroundBlurAmount, CANVAS_NAMES.blurred);\n    canvas.width = blurredImage.width;\n    canvas.height = blurredImage.height;\n    var ctx = canvas.getContext('2d');\n    if (Array.isArray(partSegmentation) && partSegmentation.length === 0) {\n        ctx.drawImage(blurredImage, 0, 0);\n        return;\n    }\n    var bodyPartMask = createBodyPartMask(partSegmentation, bodyPartIdsToBlur, edgeBlurAmount);\n    ctx.save();\n    if (flipHorizontal) {\n        flipCanvasHorizontal(canvas);\n    }\n    // draw the original image on the final canvas\n    var _a = getInputSize(image), height = _a[0], width = _a[1];\n    ctx.drawImage(image, 0, 0, width, height);\n    // \"destination-in\" - \"The existing canvas content is kept where both the\n    // new shape and existing canvas content overlap. Everything else is made\n    // transparent.\"\n    // crop what's not the person using the mask from the original image\n    drawWithCompositing(ctx, bodyPartMask, 'destination-in');\n    // \"destination-over\" - \"The existing canvas content is kept where both the\n    // new shape and existing canvas content overlap. Everything else is made\n    // transparent.\"\n    // draw the blurred background on top of the original image where it doesn't\n    // overlap.\n    drawWithCompositing(ctx, blurredImage, 'destination-over');\n    ctx.restore();\n}\n\n/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nvar PART_CHANNELS = [\n    'left_face',\n    'right_face',\n    'left_upper_arm_front',\n    'left_upper_arm_back',\n    'right_upper_arm_front',\n    'right_upper_arm_back',\n    'left_lower_arm_front',\n    'left_lower_arm_back',\n    'right_lower_arm_front',\n    'right_lower_arm_back',\n    'left_hand',\n    'right_hand',\n    'torso_front',\n    'torso_back',\n    'left_upper_leg_front',\n    'left_upper_leg_back',\n    'right_upper_leg_front',\n    'right_upper_leg_back',\n    'left_lower_leg_front',\n    'left_lower_leg_back',\n    'right_lower_leg_front',\n    'right_lower_leg_back',\n    'left_feet',\n    'right_feet'\n];\n\n/** @license See the LICENSE file. */\n// This code is auto-generated, do not modify this file!\nvar version = '2.2.1';\n\nexport { BodyPix, PART_CHANNELS, blurBodyPart, drawBokehEffect, drawMask, drawPixelatedMask, flipPoseHorizontal, load, resizeAndPadTo, scaleAndCropToInputTensorShape, toColoredPartMask, toMask, version };\n//# sourceMappingURL=body-pix.esm.js.map\n"],"names":["extendStatics","d","b","Object","setPrototypeOf","__proto__","Array","p","hasOwnProperty","__extends","__","this","constructor","prototype","create","__assign","assign","t","s","i","n","arguments","length","call","apply","__awaiter","thisArg","_arguments","P","generator","Promise","resolve","reject","fulfilled","value","step","next","e","rejected","result","done","then","__generator","body","f","y","g","_","label","sent","trys","ops","verb","Symbol","iterator","v","op","TypeError","pop","push","toFlattenedOneHotPartMap","partHeatmapScores","numParts","shape","partMapLocations","partMapFlattened","toMaskTensor","segmentScores","threshold","decodePartSegmentation","segmentationMask","_a","partMapHeight","partMapWidth","image","mask","flattenedMap","partNumbers","partMap","partMapShiftedUpForClipping","BaseModel","model","outputStride","inputShape","inputs","concat","predict","input","_this","asFloat","preprocessInput","asBatch","results3d","map","namedResults","nameOutputResults","heatmapScores","heatmap","offsets","displacementFwd","displacementBwd","segmentation","partHeatmaps","longOffsets","partOffsets","dispose","MobileNet","_super","results","PART_NAMES","NUM_KEYPOINTS","PART_IDS","reduce","jointName","getScale","_b","padding","height","width","inputResolutionY","inputResolutionX","padT","top","padB","bottom","left","right","getOffsetPoint","x","keypoint","get","getImageCoords","part","heatmapY","heatmapX","id","clamp","a","min","max","addVectors","computeDistance","embedding","pose","minPartScore","distance","numKpt","keypoints","score","Math","pow","position","Infinity","getEmbedding","location","keypointIndex","convertToPosition","outputResolutionX","refineSteps","newLocation","nn","dy","dx","newPos","nn_1","matchEmbeddingToInstance","poses","numKptForMatching","_c","stride","padL","scaleX","scaleY","embed","pair","round","convertToPositionInOuput","keypointsIndex","kMin","kMinDist","k","dist","getOutputResolution","decodeMultipleMasksWebGl","posesAboveScore","minKptScore","maxNumPeople","inHeight","inWidth","origHeight","origWidth","slice","outHeight","outWidth","shapedLongOffsets","poseVals","Float32Array","fill","poseOffset","kp","offset","_d","posesTensor","program","variableNames","outputShape","userCode","compileAndRun","isWebGlBackend","getBackend","decodePersonInstanceMasks","minPoseScore","minKeypointScore","personSegmentationsData","personSegmentations","segmentationsData","longOffsetsData","filter","masksTensorInfo","masksTensor","makeTensorFromDataId","dataId","dtype","toPersonKSegmentation","all","data","forEach","dataArrays","Uint8Array","j","decodeMultipleMasksCPU","decodePersonInstancePartMasks","partSegmentation","partSegmentationsByPersonData","partSegmentations","partSegmentaionData","bodyParts","toPersonKPartSegmentation","partSegmentaion","Int32Array","decodeMultiplePartMasksCPU","half","floor","jointNameA","jointNameB","MaxHeap","maxSize","getElementValue","priorityQueue","numberOfElements","enqueue","swim","dequeue","exchange","sink","empty","size","less","getValueAt","scoreIsMaximumInLocalWindow","keypointId","localMaximumRadius","scores","localMaximum","yStart","yEnd","yCurrent","xStart","xEnd","xCurrent","parentChildrenTuples","parentJoinName","childJoinName","parentToChildEdges","childToParentEdges","getStridedIndexNearPoint","point","traverseToTargetKeypoint","edgeId","sourceKeypoint","targetKeypointId","scoresBuffer","displacements","offsetRefineStep","displacement","numEdges","getDisplacement","targetKeypoint","targetKeypointIndices","offsetPoint","targetKeyPointIndices","decodePose","root","displacementsFwd","displacementsBwd","instanceKeypoints","rootPart","rootScore","rootPoint","edge","sourceKeypointId","withinNmsRadiusOfCorrespondingPoint","squaredNmsRadius","some","correspondingKeypoint","y1","x1","y2","x2","squaredDistance","getInstanceScore","existingPoses","notOverlappedKeypointScores","decodeMultiplePoses","offsetsBuffer","displacementsFwdBuffer","displacementsBwdBuffer","maxPoseDetections","scoreThreshold","nmsRadius","queue","numKeypoints","buildPartWithScoreQueue","imageNetMean","ResNet","RESNET50_BASE_URL","MOBILENET_BASE_URL","getInputSize","HTMLCanvasElement","OffscreenCanvas","HTMLImageElement","offsetHeight","offsetWidth","Error","getSizeFromImageLikeElement","ImageData","HTMLVideoElement","hasAttribute","videoHeight","videoWidth","getSizeFromVideoElement","toValidInputResolution","inputResolution","resolution","isValidInputResolution","INTERNAL_RESOLUTION_STRING_OPTIONS","low","medium","high","full","INTERNAL_RESOLUTION_PERCENTAGES","toInputResolutionHeightAndWidth","internalResolution","inputHeight","inputWidth","internalResolutionPercentage","values","join","toInternalResolutionPercentage","scaleAndCropToInputTensorShape","tensor","applySigmoidActivation","inputTensorHeight","inputTensorWidth","resizedAndPaddedHeight","resizedAndPaddedWidth","_e","padR","inResizedAndPadded","resizeBilinear","resizedAndPadded","originalHeight","originalWidth","batchedImage","cropAndResize","removePaddingAndResizeBack","padAndResizeTo","targetH","targetW","targetAspect","resized","imageTensor","toInputTensor","toTensorBuffers3D","tensors","buffer","scaleAndFlipPoses","flipHorizontal","inputResolutionHeight","inputResolutionWidth","scaledPoses","offsetY","offsetX","scalePose","scalePoses","imageWidth","flipPoseHorizontal","flipPosesHorizontal","APPLY_SIGMOID_ACTIVATION","FLIP_POSES_AFTER_SCALING","MOBILENET_V1_CONFIG","architecture","quantBytes","multiplier","VALID_ARCHITECTURE","VALID_STRIDE","VALID_MULTIPLIER","VALID_QUANT_BYTES","PERSON_INFERENCE_CONFIG","segmentationThreshold","maxDetections","MULTI_PERSON_INSTANCE_INFERENCE_CONFIG","validatePersonInferenceConfig","config","validateMultiPersonInstanceInferenceConfig","BodyPix","net","baseModel","predictForPersonSegmentation","segmentLogits","predictForPersonSegmentationAndPart","partHeatmapLogits","predictForMultiPersonInstanceSegmentationAndPart","segmentPersonActivation","internalResolutionHeightAndWidth","resizedHeight","resizedWidth","scaledSegmentScores","segmentPerson","tensorBuffers","scoresBuf","offsetsBuf","displacementsFwdBuf","displacementsBwdBuf","allPoses","segmentMultiPerson","heatmapScoresRaw","offsetsRaw","displacementFwdRaw","displacementBwdRaw","instanceMasks","scaledLongOffsets","segmentPersonPartsActivation","scaledPartHeatmapScore","segmentPersonParts","segmentMultiPersonParts","scaledPartSegmentationScores","decodeOnlyPartSegmentation","loadMobileNet","url","graphModel","mobilenet","toStr","graphJson","mobileNetSavedModel","modelUrl","loadResNet","resnet","resNet50SavedModel","load","indexOf","validateModelConfig"],"sourceRoot":""}