{"version":3,"file":"stylist-vendors-bef946b4.bdd19c1a9e73af24821d.js","mappings":"uNAmBA,UAYA,MAAMA,EAAY,CACdC,OAAM,IACNC,KAAI,IACJC,MAAK,IACLC,MAAK,MAET,QAAaJ,E,gJCnBb,MAAMK,EAA4B,YAQ3B,MAAMC,EAET,WAAAC,CAAYC,GACRC,KAAKD,OAASA,EACdC,KAAKC,MAAQ,CAAC,EACdD,KAAKE,aAAe,CAAC,EACrBF,KAAKG,SAAW,CAAC,EAEjBH,KAAKI,eAAiBA,EACtBJ,KAAKK,kBACT,CACA,WAAAC,CAAYC,EAAcC,GAClBR,KAAKQ,SAITR,KAAKO,aAAeA,EACpBP,KAAKQ,SAAWA,CACpB,CACA,YAAAC,CAAaC,EAAUC,EAAcC,GAIjC,GAHAZ,KAAKE,aAAaQ,GAAY,CAAEC,eAAcC,WAGf,MAA3BZ,KAAKG,SAASO,GAAmB,CACjC,MAAMG,EAAYb,KAAKG,SAASO,GAEhCV,KAAKc,IAAIJ,EAAUG,EACvB,CACJ,CACA,cAAME,CAASL,GACX,OAAIA,KAAYV,KAAKC,QAGrBD,KAAKC,MAAMS,SAAkBV,KAAKgB,aAAaN,IAFpCV,KAAKC,MAAMS,EAI1B,CACA,GAAAO,CAAIP,GACA,GAAIA,KAAYV,KAAKC,MACjB,OAAOD,KAAKC,MAAMS,GAEtB,MAAMG,EAAYb,KAAKgB,aAAaN,GACpC,IAAI,QAAUG,GACV,MAAM,IAAIK,MAAM,QAAQR,uEAI5B,OADAV,KAAKC,MAAMS,GAAYG,EAChBb,KAAKC,MAAMS,EACtB,CACA,SAAAS,CAAUT,GACN,OAAOV,KAAKiB,IAAIP,EACpB,CACA,OAAAU,CAAQV,GACJ,OAAOV,KAAKiB,IAAIP,EACpB,CACA,QAAAW,GACI,OAAOrB,KAAKC,KAChB,CAEA,YAAIqB,GACA,OAAOtB,KAAKC,KAChB,CACA,GAAAa,CAAIJ,EAAUa,GACV,GAAmC,MAA/BvB,KAAKE,aAAaQ,GAClB,MAAM,IAAIQ,MAAM,mBAAmBR,oCAEvCV,KAAKC,MAAMS,GAAYa,EACoB,MAAvCvB,KAAKE,aAAaQ,GAAUE,SAC5BZ,KAAKE,aAAaQ,GAAUE,QAAQW,EAE5C,CACA,YAAAP,CAAaN,GACT,GAAmC,MAA/BV,KAAKE,aAAaQ,GAClB,MAAM,IAAIQ,MAAM,yBAAyBR,qCAE7C,OAAOV,KAAKE,aAAaQ,GAAUC,cACvC,CACA,QAAAa,CAASvB,GACLD,KAAKC,MAAQwB,OAAOC,OAAO,CAAC,EAAGzB,EACnC,CACA,KAAA0B,GACI3B,KAAKC,MAAQ,CAAC,EACdD,KAAKG,SAAW,CAAC,EACjBH,KAAKK,kBACT,CACA,gBAAAA,GACI,GAA2B,qBAAhBL,KAAKD,QACoB,qBAAzBC,KAAKD,OAAO6B,UACoB,qBAAhC5B,KAAKD,OAAO6B,SAASC,OAC5B,OAEJ,MAAMC,EAAY9B,KAAKI,eAAeJ,KAAKD,OAAO6B,SAASC,QAC3D,GAAIjC,KAA6BkC,EAAW,CACtBA,EAAUlC,GAA2BmC,MAAM,KACnDC,SAAQC,IACd,MAAOC,EAAKX,GAASU,EAASF,MAAM,KACpC/B,KAAKG,SAAS+B,GAgB9B,SAAoBxB,EAAUa,GAE1B,GAAc,UADdA,EAAQA,EAAMY,gBACoB,UAAVZ,EACpB,MAAiB,SAAVA,EAEN,GAAI,KAAIA,IAAYA,EACrB,OAAQA,EAEZ,MAAM,IAAIL,MAAM,oCAAoCK,cAAkBb,KAC1E,CAzBqC0B,CAAWF,EAAKX,EAAM,GAEnD,CACJ,EAEG,SAASnB,EAAeiC,GAC3B,MAAMC,EAAS,CAAC,EAKhB,OAJAD,EAAYE,QAAQ,+BAA+B,CAACC,KAAMC,KAM9D,SAAqBH,EAAQI,EAAMnB,GAC/Be,EAAOK,mBAAmBD,IAASC,mBAAmBpB,GAAS,GACnE,CAPQqB,CAAYN,EAAQG,EAAE,GAAIA,EAAE,IACrBA,EAAEI,KAAK,QAEXP,CACX,CAsBO,SAASQ,IACZ,OAAOC,CACX,CACO,IAAIA,EAAM,KACV,SAASC,EAAqBC,GACjCF,EAAME,CACV,C,sEC9IA,MAAMF,GAAM,UAKZA,EAAItC,aAAa,SAAS,KAAM,IAAOyC,IAKnC,IAGJH,EAAItC,aAAa,cAAc,IAAM,gBAErCsC,EAAItC,aAAa,WAAW,IAA0B,qBAAZ0C,GACT,qBAArBA,EAAQC,UACkB,qBAA1BD,EAAQC,SAASC,OAE7BN,EAAItC,aAAa,aAAa,IAA2B,qBAAd6C,WAA0C,MAAbA,WAC7C,MAAvBA,UAAUC,WAAqB,SAASC,KAAKF,UAAUC,YACvD,aAAaC,KAAKF,UAAUG,UAKhCV,EAAItC,aAAa,QAAQ,KAAM,IAK/BsC,EAAItC,aAAa,sCAAsC,IAAMsC,EAAI3B,QAAQ,WAEzE2B,EAAItC,aAAa,gCAAgC,KAAM,IAEvDsC,EAAItC,aAAa,WAAW,KAAM,IAElCsC,EAAItC,aAAa,gCAAgC,KAAM,IAEvDsC,EAAItC,aAAa,uBAAuB,KAAM,G,8MC/B9C,SAASiD,EAA6BC,GAClC,OAAsC,MAA/BA,EAAiBC,UAC5B,CACA,MAAMC,EACF,WAAA/D,GAEIE,KAAK8D,oBAAsB,CAAC,EAC5B9D,KAAK+D,eAAiB,EACtB/D,KAAKgE,SAAW,EAChBhE,KAAKiE,WAAa,EAClBjE,KAAKkE,iBAAmB,EACxBlE,KAAKmE,eAAiB,EAItBnE,KAAKoE,cAAgB,EAGrBpE,KAAKqE,YAAc,EACnBrE,KAAKsE,WAAa,GAKlBtE,KAAKuE,kBAAoB,GACzBvE,KAAKwE,YAAc,EACnBxE,KAAKyE,WAAa,IAAIC,QACtB1E,KAAK2E,WAAY,EACjB3E,KAAK4E,cAAgB,CACjBC,SAAU,EACVC,WAAY,EACZC,UAAW,EACXC,QAAS,GACTC,OAAQ,KACR,eAAIC,GACA,OAAOC,MAAMC,KAAK,IAAIC,IAAIrF,KAAKgF,QAAQM,KAAIC,GAAKA,EAAE7C,QACtD,EAER,CACA,OAAA8C,GACI,IAAK,MAAMC,KAAgBzF,KAAK8D,oBAC5B9D,KAAK8D,oBAAoB2B,GAAcD,SAE/C,EAEG,MAAME,EACT,WAAA5F,CAAYiD,GACR/C,KAAK+C,IAAMA,EACX/C,KAAK2F,SAAW,CAAC,EACjB3F,KAAK4F,gBAAkB,CAAC,EACxB5F,KAAK6F,qBAAuB,EAC5B7F,KAAK8F,MAAQ,IAAIjC,CACrB,CACA,WAAMkC,GACF,GAA+B,MAA3B/F,KAAKgG,mBACL,OAAOhG,KAAKgG,mBAAmBC,MAAK,SAExC,GAA4B,MAAxBjG,KAAKkG,gBACL,OAEJ,MAAMC,EAAiBnG,KAAKoG,oBAC5B,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAeG,OAAQD,IAAK,CAC5C,MAAME,EAAcJ,EAAeE,GAEnC,SADsBrG,KAAKwG,kBAAkBD,GAAaE,QAGtD,kBADMzG,KAAK0G,WAAWH,EAG9B,CACA,MAAM,IAAIrF,MAAM,yEAEpB,CACA,WAAIyF,GACA,GAA+B,MAA3B3G,KAAKgG,mBACL,MAAM,IAAI9E,MAAM,YAAYlB,KAAKuG,kIAIrC,GAA4B,MAAxBvG,KAAKkG,gBAAyB,CAC9B,MAAM,KAAExD,EAAI,UAAEkE,GAAc5G,KAAK6G,kCACjC,GAAID,EACA,MAAM,IAAI1F,MAAM,iCAAiCwB,wHAIrD1C,KAAK0G,WAAWhE,EACpB,CACA,OAAO1C,KAAKkG,eAChB,CACA,YAAAY,GACI,OAAOrF,OAAOsF,KAAK/G,KAAK4F,gBAC5B,CACA,WAAAoB,CAAYT,GACR,KAAMA,KAAevG,KAAK2F,UAAW,CAGjC,KAAIY,KAAevG,KAAK4F,iBAQpB,OAAO,KAR8B,CACrC,MAAM,UAAEgB,GAAc5G,KAAKwG,kBAAkBD,GAC7C,GAAIK,EAEA,OAAO,IAEf,CAIJ,CACA,OAAO5G,KAAK2F,SAASY,EACzB,CACA,kBAAAU,CAAmBV,GACf,OAAMA,KAAevG,KAAK4F,gBAGnB5F,KAAK4F,gBAAgBW,GAAaW,QAF9B,IAGf,CACA,eAAAC,CAAgBZ,EAAaW,EAASE,EAAW,GAC7C,QAAIb,KAAevG,KAAK4F,mBAKxB5F,KAAK4F,gBAAgBW,GAAe,CAAEW,UAASE,aACxC,EACX,CACA,gBAAMV,CAAWH,GACb,GAAyC,MAArCvG,KAAK4F,gBAAgBW,GACrB,MAAM,IAAIrF,MAAM,iBAAiBqF,4BAGrC,GADAvG,KAAKuG,YAAcA,EACe,MAA9BvG,KAAK2F,SAASY,GAAsB,CACpCvG,KAAKkG,gBAAkB,KACvB,MAAM,QAAEO,EAAO,UAAEG,GAAc5G,KAAKwG,kBAAkBD,GAEtD,KADeK,QAAkBH,EAAUA,GAEvC,OAAO,CAEf,CAKA,OAJAzG,KAAKkG,gBAAkBlG,KAAK2F,SAASY,GACrCvG,KAAKqH,yBAELrH,KAAKsH,SAAW,IAAI,KAAStH,KAAKkG,kBAC3B,CACX,CACA,sBAAAmB,IACoB,QAAqBrH,KAAKuG,aAClCvE,SAAQuF,IACY,MAApBA,EAAOC,WACPD,EAAOC,UAAUxH,KAAKkG,gBAC1B,GAER,CACA,wBAAAuB,CAAyBlB,IACL,QAAqBA,GAC7BvE,SAAQuF,IACc,MAAtBA,EAAOG,aACPH,EAAOG,YAAY1H,KAAK2F,SAASY,GACrC,GAER,CAOA,iBAAAC,CAAkBD,GACd,MAAMoB,EAAuB3H,KAAK4F,gBAAgBW,GAClD,GAA4B,MAAxBoB,EACA,MAAM,IAAIzG,MAAM,6BAA6BqF,6BAEjD,IACI,MAAMI,EAAUgB,EAAqBT,UAMrC,IAAIP,GAAaA,aAAmB,MACR,oBAAjBA,EAAQV,KA2Bf,OADAjG,KAAK2F,SAASY,GAAeI,EACtB,CAAEF,SAAS,EAAMG,WAAW,GA3BC,CACpC,MAAMgB,IAAc5H,KAAK6F,qBACnBY,EAAUE,EACXV,MAAKC,KAEF0B,EAAY5H,KAAK6F,wBAGrB7F,KAAK2F,SAASY,GAAeL,EAC7BlG,KAAKgG,mBAAqB,MACnB,KAEN6B,OAAMC,IAEHF,EAAY5H,KAAK6F,uBAGrB7F,KAAKgG,mBAAqB,OAFf,KAQf,OADAhG,KAAKgG,mBAAqBS,EACnB,CAAEA,UAASG,WAAW,EACjC,CAKJ,CACA,MAAOkB,GAGH,MAAO,CAAErB,SAAS,EAAOG,WAAW,EACxC,CACJ,CACA,aAAAmB,CAAcxB,GACV,KAAMA,KAAevG,KAAK4F,iBACtB,MAAM,IAAI1E,MAAM,GAAGqF,mCAEnBvG,KAAKuG,cAAgBA,GAA0C,MAA3BvG,KAAKgG,oBAGzChG,KAAK6F,uBAELU,KAAevG,KAAK2F,WACpB3F,KAAKyH,yBAAyBlB,GAC9BvG,KAAK2F,SAASY,GAAaf,iBACpBxF,KAAK2F,SAASY,WAElBvG,KAAK4F,gBAAgBW,GAExBvG,KAAKuG,cAAgBA,IACrBvG,KAAKgG,mBAAqB,KAC1BhG,KAAKuG,YAAc,KACnBvG,KAAKkG,gBAAkB,KAE/B,CACA,iBAAAE,GACI,GAAiD,IAA7C3E,OAAOsF,KAAK/G,KAAK4F,iBAAiBU,OAClC,MAAM,IAAIpF,MAAM,iCAEpB,OAAOO,OAAOsF,KAAK/G,KAAK4F,iBAAiBoC,MAAK,CAACC,EAAGC,IAEvClI,KAAK4F,gBAAgBsC,GAAGd,SAC3BpH,KAAK4F,gBAAgBqC,GAAGb,UAEpC,CACA,+BAAAP,GACI,MAAMV,EAAiBnG,KAAKoG,oBAC5B,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAeG,OAAQD,IAAK,CAC5C,MAAME,EAAcJ,EAAeE,IAC7B,QAAEI,EAAO,UAAEG,GAAc5G,KAAKwG,kBAAkBD,GACtD,GAAIK,GAAaH,EACb,MAAO,CAAE/D,KAAM6D,EAAaK,YAEpC,CACA,MAAM,IAAI1F,MAAM,yEAEpB,CACA,QAAAiH,CAASxB,EAASyB,GACd,MAAMC,EAAOrI,KAAK8F,MAAMrB,WAAWxD,IAAImH,GACjCE,EAAaD,EAAK1B,QAClB4B,EAASvI,KAAKwI,SAASJ,GACvBK,EAAWH,EAAWG,SAASL,GAGrCE,EAAWI,YAAYN,GAAQ,GAC/BC,EAAK1B,QAAUA,EACfA,EAAQgC,KAAKP,EAAQG,EAAQF,EAAKO,MAAOP,EAAKQ,MAAOJ,GACjDzI,KAAK8I,0BAGL9I,KAAK8F,MAAMvB,kBAAkBvE,KAAK8F,MAAMvB,kBAAkB+B,OAAS,IAE3E,CACA,IAAAyC,CAAKC,EAAUC,GACX,IAsBIhE,EAtBAvC,EAAO,KACX,GAAU,MAANuG,EAAY,CAEZ,GAAwB,oBAAbD,EACP,MAAM,IAAI9H,MAAM,uCAEpB+H,EAAKD,CACT,KACK,CAED,GAAwB,kBAAbA,KAA2BA,aAAoBE,QACtD,MAAM,IAAIhI,MAAM,kFAGpB,GAAkB,oBAAP+H,EACP,MAAM,IAAI/H,MAAM,kFAGpBwB,EAAOsG,CAGX,CAEA,OAAOhJ,KAAKmJ,WAAU,IAAMnJ,KAAKoJ,WAAW1G,KAAO,IAAM1C,KAAKqJ,SAASpE,KAAS,KAC5EA,EAASgE,IAIFhE,IAEf,CACA,SAAAkE,CAAUG,EAAOC,EAAKC,GAClBF,IACA,IACI,MAAMG,EAAMD,IAEZ,OADAD,IACOE,CACX,CACA,MAAOC,GAEH,MADAH,IACMG,CACV,CACJ,CACA,YAAAC,GACI,OAAOjE,EAAOiE,cAClB,CACA,cAAAC,GACI,OAAOlE,EAAOkE,gBAClB,CAOA,KAAAlK,CAAMmK,GACF,MAAMC,EAAIC,EAAOC,UAAU,KAAU,CAAEH,MACjCI,EAAS,CAAEJ,KAajB,OADA7J,KAAKkK,YAAYlK,KAAK8F,MAAMqE,YAAYzH,KAAMuH,EAAQ,CAACH,IAXzCM,IAAO,CACjBP,EAAG,KACC,MACMQ,EAAa,CAAER,EAAGO,GAClBE,EAAQ,CAAEzB,MAFF,WAGd,OAAOkB,EAAOC,UAAU,KAAMK,EAE9BC,EAAM,KAGA,GAC0D,CAAC,GAClER,CACX,CAcA,SAAAE,CAAUpG,EAAYqG,EAAQK,GAE1B,KAD6D,OAA3C,QAAU1G,EAAY5D,KAAKuG,cAEzC,MAAM,IAAIrF,MAAM,WAAW0C,kCAA2C5D,KAAKuG,gBAE/E,OAAOvG,KAAKuK,cAAc,CAAE3G,aAAYqG,SAAQK,SACpD,CACA,sBAAAxB,GACI,OAAO9I,KAAK+C,IAAI3B,QAAQ,UAC5B,CACA,qBAAAoJ,CAAsB5G,EAAY6G,EAAkBC,GAChD,MAAMC,EAAkB3K,KAAK2G,QAAQiE,aAErC,IAAIC,EAAmB,EACvBH,EAAS1I,SAAQqG,IAGbwC,GAAoC,cAAfxC,EAAKQ,MAAwB,EAAI,CAAE,IAO5D,MAAMiC,EAAW9K,KAAK8F,MAAMvB,kBAAkBvE,KAAK8F,MAAMvB,kBAAkB+B,OAAS,GAC9EyE,EAAgBJ,EAAkBF,EAAmBI,EAAmBC,EAC9E,GAAIC,EAAgB,EAChB,MAAM,IAAI7J,MAAM,YAAYlB,KAAKuG,6CACzBwE,8BAA0CnH,KAE1D,CAMA,aAAA2G,CAAcS,GACV,IAAIC,EACAC,EAAQ,GACZ,MAAMC,EAAWnL,KAAKmL,WAChBC,EAAoBpL,KAAK8F,MAAM9B,SAC/BqH,EAAqBrL,KAAK8F,MAAM7B,WAItC,IAAIqH,EASAC,EAZAvL,KAAK8I,0BACL9I,KAAK8F,MAAMvB,kBAAkBiH,KAAK,GAGd,MAApBxL,KAAKuG,aAMLvG,KAAK2G,QAGT,MAAM8E,EAAoB/H,EAA6BsH,GACnDA,EAAapH,WACa,MAA1B5D,KAAK8F,MAAMqE,YAAsBnK,KAAK8F,MAAMqE,YAAYzH,KAAO,GAInE,GAAIgB,EAA6BsH,GAAe,CAC5C,MAAM,WAAEpH,EAAU,OAAEqG,EAAM,MAAEK,GAAUU,EACd,MAApBhL,KAAKuG,aAMLvG,KAAK2G,QAET,MAAMY,GAAS,QAAU3D,EAAY5D,KAAKuG,aAC1C,KAAsB,MAAVgB,GAAgB,IAAM,kCAAkC3D,mBAA4B5D,KAAKuG,iBACrG+E,EAAa,KACT,MAAMb,EAAmBzK,KAAK2G,QAAQiE,aACtCW,EAAMhE,EAAO+D,WAAW,CAAErB,SAAQK,QAAO3D,QAAS3G,KAAK2G,UACvD,MAAM+D,EAAWvF,MAAMuG,QAAQH,GAAOA,EAAM,CAACA,GACzCvL,KAAK8I,0BACL9I,KAAKwK,sBAAsB5G,EAAY6G,EAAkBC,GAE7D,MAAMiB,EAAajB,EAASpF,KAAKsG,IAI7B,GAAoB,MAAhBA,EAAQC,KACR,OAAOD,EAEX,MAAM,OAAExD,EAAM,MAAEQ,EAAK,MAAEC,GAAU+C,EACjC,OAAO5L,KAAK8L,qBAAqB1D,EAAQQ,EAAOC,EAAM,IAM1D,GAAIsC,EAAU,CACV,MAAMY,EAAgB/L,KAAKgM,sBAAsBpI,EAAYqG,EAAQ0B,GACrET,EAAQlL,KAAKiM,2BAA2BF,EAC5C,CACA,OAAOJ,CAAU,CAEzB,KACK,CACD,MAAM,YAAEO,GAAgBlB,EAElBmB,EAAYC,IAITjB,IAGLD,EAAQkB,EAAQ9G,KAAI+G,GAAUrM,KAAKsM,KAAKtM,KAAKN,MAAM2M,MAAS,EAEhEf,EAAa,KACT,MAAMb,EAAmBzK,KAAK2G,QAAQiE,aACtCW,EAAMvL,KAAK+I,MAAK,IAAMmD,EAAYlM,KAAK2G,QAASwF,KAChD,MAAMI,EAAQpH,MAAMuG,QAAQH,GAAOA,EAAM,CAACA,GAK1C,OAJIvL,KAAK8I,0BAEL9I,KAAKwK,sBAAsBiB,EAAmBhB,EAAkB8B,GAE7DA,CAAI,CAEnB,CAIA,MAAM,OAAEtC,EAAM,MAAEK,GAAUU,EACpBwB,EAAgB9I,EAA6BsH,GAC/C,KACAA,EAAawB,cACjB,IAAIC,EA+BJ,OA9BAzM,KAAKmJ,WAEL,IAAMnJ,KAAK8F,MAAMzB,gBAAe,IAAMrE,KAAK8F,MAAMzB,gBAAe,KACvDrE,KAAK+C,IAAI3B,QAAQ,UAAapB,KAAK8F,MAAMnB,WAI1C8H,EAAgBzM,KAAKsH,SAASoF,cAAcjB,EAAmBxB,GAAQ,IAAMqB,MACzEtL,KAAK+C,IAAI3B,QAAQ,UACjBpB,KAAKsH,SAASqF,iBAAiBF,GAEnCxB,EAAUwB,EAAcxB,SAPxBA,EAAUK,GAQd,IAEAH,GACAnL,KAAKkK,YAAYuB,EAAmBxB,EAAQgB,EAASuB,EAAetB,EAAOZ,GAE3EtK,KAAK8F,MAAMnB,WACX3E,KAAK8F,MAAMlB,cAAcI,QAAQwG,KAAK,CAClC9I,KAAM+I,EACNmB,WAAY5M,KAAK8F,MAAM9B,SAAWoH,EAClCyB,mBAAoB7M,KAAK8F,MAAM9B,SAC/B8I,aAAc9M,KAAK8F,MAAM7B,WAAaoH,EACtC0B,qBAAsB/M,KAAK8F,MAAM7B,WACjC+I,YAAavL,OAAOsF,KAAKkD,GAAQ3E,KAAIpD,GAAsB,MAAf+H,EAAO/H,GAAe+H,EAAO/H,GAAK0G,MAAQ,OACtFqE,aAAchC,EAAQ3F,KAAI4H,GAAQA,EAAKtE,QACvCuE,aAAcV,EAAcW,OAC5BC,UAAWZ,EAAcY,YAGzBlI,MAAMuG,QAAQH,GAAON,EAAUA,EAAQ,EACnD,CAMA,0BAAAgB,CAA2BG,GAEvB,OADcA,EAAQ9G,KAAI+G,GAAUrM,KAAKsM,KAAKtM,KAAKN,MAAM2M,KAE7D,CAQA,qBAAAL,CAAsBpI,EAAYqG,EAAQgB,GACtC,MAAMqC,GAAa,QAAY1J,GAC/B,GAAkB,MAAd0J,EAAoB,CACpB,MAAMC,EAAeD,EAAWC,cAAgB,GAC1CC,EAAgBF,EAAWE,eAAiB,GAGlD,IAAIC,EACAH,EAAWI,eACX,KAAYvI,MAAMuG,QAAQzB,IAAS,IAAM,2DACzCwD,EAAqBhM,OAAOsF,KAAKkD,GAAQ3E,KAAKpD,GAAQ+H,EAAO/H,MAG7DuL,EAAqBF,EAAajI,KAAKqI,GAAc1D,EAAO0D,KAEhE,MAAMC,EAAsB3C,EAAQ4C,QAAO,CAACC,EAAGzH,IAAMmH,EAAcnH,KACnE,OAAOoH,EAAmBM,OAAOH,EACrC,CAOA,MAAO,EACX,CAMA,UAAAI,CAAWzF,EAAQK,EAAOC,EAAOlC,GAC7B,GAAc,MAAV4B,EACA,MAAM,IAAIrH,MAAM,iDAEpB2H,EAAQA,GAAS,UACjBlC,EAAUA,GAAW3G,KAAK2G,QAC1B,IAAIsH,EAAc1F,EACJ,WAAVM,GAAsB,KAAcN,EAAO,MAC3C0F,EAAc1F,EAAOjD,KAAI4I,GAAK,eAAkBA,MAEpD,MAAM9F,EAASzB,EAAQwH,MAAMF,EAAarF,EAAOC,GAC3CpG,EAAI,IAAI,KAAOmG,EAAOC,EAAOT,EAAQpI,KAAK2J,gBAGhD,GAFA3J,KAAKoO,YAAY3L,EAAGkE,GAEN,WAAVkC,EAAoB,CACpB,MAAMR,EAAOrI,KAAK8F,MAAMrB,WAAWxD,IAAImH,GACjCvD,GAAW,QAAqBoJ,GACtCjO,KAAK8F,MAAM9B,UAAYa,EAAWwD,EAAKgG,MACvChG,EAAKgG,MAAQxJ,CACjB,CACA,OAAOpC,CACX,CAMA,oBAAAqJ,CAAqB1D,EAAQQ,EAAOC,EAAOlC,GACvCkC,EAAQA,GAAS,UACjB,MAAMpG,EAAI,IAAI,KAAOmG,EAAOC,EAAOT,EAAQpI,KAAK2J,gBAEhD,OADA3J,KAAKoO,YAAY3L,EAAGkE,GACblE,CACX,CACA,YAAA6L,CAAaC,EAAcC,GAAY,EAAM9L,EAAMmG,GAC/CnG,EAAOA,GAAQ1C,KAAK4J,iBAAiB6E,WACxB,MAAT5F,GAAiBA,IAAU0F,EAAa1F,QACxC0F,EAAeA,EAAa9O,KAAKoJ,IAErC,MAAM6F,EAAI,IAAI,KAASH,EAAcC,EAAW9L,EAAM1C,KAAK2J,gBAC3D,GAA8C,MAA1C3J,KAAK8F,MAAMhC,oBAAoB4K,EAAEhM,MACjC,MAAM,IAAIxB,MAAM,sBAAsBwN,EAAEhM,+BAI5C,OAFA1C,KAAK8F,MAAMhC,oBAAoB4K,EAAEhM,MAAQgM,EACzC1O,KAAK2O,OAAOD,EAAG1O,KAAK2G,SACb+H,CACX,CACA,WAAAN,CAAYnG,EAAGtB,GACX3G,KAAK8F,MAAM7B,aACK,WAAZgE,EAAEY,OACF7I,KAAK8F,MAAM5B,mBAIf,IAAImK,EAAQ,EACI,cAAZpG,EAAEY,OAAqC,WAAZZ,EAAEY,QAC7BwF,EAAQpG,EAAE2G,KAAO,KAAqB3G,EAAEY,QAE5C7I,KAAK8F,MAAM9B,UAAYqK,EAClBrO,KAAK8F,MAAMrB,WAAWoK,IAAI5G,EAAEG,UAC7BpI,KAAK8F,MAAM3B,iBACXnE,KAAK8F,MAAMrB,WAAW3D,IAAImH,EAAEG,OAAQ,CAChCzB,QAASA,GAAW3G,KAAK2G,QACzBkC,MAAOZ,EAAEY,MACTD,MAAOX,EAAEW,MACTyF,WAGFpG,aAAa,MACfjI,KAAK8O,MAAM7G,EAEnB,CAMA,MAAA0G,CAAO1G,EAAGtB,GACN3G,KAAKoO,YAAYnG,EAAGtB,GACpB3G,KAAK2G,QAAQgI,OAAO1G,EAAEG,OAC1B,CACA,YAAA2G,CAAa3G,EAAQzB,GACb3G,KAAK8F,MAAMrB,WAAWoK,IAAIzG,IAC1BpI,KAAK8F,MAAMrB,WAAWxD,IAAImH,GAAQzB,UAAYA,IAC9C3G,KAAK8F,MAAMrB,WAAWuK,OAAO5G,GAC7BpI,KAAK8F,MAAM3B,iBAEnB,CACA,aAAA8K,CAAchH,GACV,IAAKjI,KAAK8F,MAAMrB,WAAWoK,IAAI5G,EAAEG,QAC7B,OAEJ,MAAMC,EAAOrI,KAAK8F,MAAMrB,WAAWxD,IAAIgH,EAAEG,QAQzC,GAPApI,KAAK8F,MAAM7B,aACK,WAAZgE,EAAEY,QACF7I,KAAK8F,MAAM5B,mBACXlE,KAAK8F,MAAM9B,UAAYqE,EAAKgG,OAIhB,cAAZpG,EAAEY,OAAqC,WAAZZ,EAAEY,MAAoB,CACjD,MAAMwF,EAAQpG,EAAE2G,KAAO,KAAqB3G,EAAEY,OAC9C7I,KAAK8F,MAAM9B,UAAYqK,CAC3B,CAEIhG,EAAK1B,QAAQ+B,YAAYT,EAAEG,SAC3BpI,KAAK+O,aAAa9G,EAAEG,OAAQC,EAAK1B,QAKzC,CACA,gBAAAuI,GACI,IAAK,MAAMC,KAAWnP,KAAK8F,MAAMhC,oBAAqB,CAClD,MAAM4K,EAAI1O,KAAK8F,MAAMhC,oBAAoBqL,GACzCnP,KAAKoP,gBAAgBV,EACzB,CACJ,CACA,eAAAU,CAAgBV,GACZ1O,KAAKiP,cAAcP,GAC2B,MAA1C1O,KAAK8F,MAAMhC,oBAAoB4K,EAAEhM,cAC1B1C,KAAK8F,MAAMhC,oBAAoB4K,EAAEhM,KAEhD,CACA,MAAA2M,GACI,MAAMhH,EAAOrI,KAAK2G,QAAQ0I,SAY1B,OAXAhH,EAAKpE,WAAajE,KAAK8F,MAAM7B,WAC7BoE,EAAKlE,eAAiBnE,KAAK8F,MAAM3B,eACjCkE,EAAKrE,SAAWhE,KAAK8F,MAAM9B,SACvBhE,KAAK8F,MAAM5B,iBAAmB,IAC9BmE,EAAKiH,YAAa,EACE,MAAhBjH,EAAKkH,UACLlH,EAAKkH,QAAU,IAEnBlH,EAAKkH,QAAQ/D,KAAK,0EAGfnD,CACX,CACA,aAAMmH,CAAQC,GACVzP,KAAK8F,MAAMnB,WAAY,EACvB,MAAM+K,EAAa1P,KAAK8F,MAAM9B,SACxB2L,EAAkB3P,KAAK8F,MAAM7B,WACnCjE,KAAK8F,MAAMlB,cAAcI,QAAU,GACnChF,KAAK8F,MAAMlB,cAAcK,aAAewK,IACxCzP,KAAK8F,MAAMnB,WAAY,EACvB3E,KAAK8F,MAAMlB,cAAcG,UAAY6K,KAAKC,OAAO7P,KAAK8F,MAAMlB,cAAcI,QAAQM,KAAI4I,GAAKA,EAAErB,sBAC7F7M,KAAK8F,MAAMlB,cAAcC,SAAW7E,KAAK8F,MAAM9B,SAAW0L,EAC1D1P,KAAK8F,MAAMlB,cAAcE,WACrB9E,KAAK8F,MAAM7B,WAAa0L,EAC5B,IAAK,MAAMpI,KAAUvH,KAAK8F,MAAMlB,cAAcI,QAC1CuC,EAAO4F,mBAAqB5F,EAAO4F,aACnC5F,EAAO8F,gBAAkB9F,EAAO8F,UAEpC,OAAOrN,KAAK8F,MAAMlB,aACtB,CACA,QAAAuG,GACI,OAAOnL,KAAK8F,MAAM1B,cAAgB,GAAgC,IAA3BpE,KAAK8F,MAAMzB,WACtD,CACA,WAAA6F,CAAYtG,EAAYqG,EAAQgB,EAAS6E,EAAe5E,EAAOZ,GAC3D,MAAMyF,EAAW,CAAEC,GAAIhQ,KAAK8F,MAAM/B,iBAAkBH,aAAYqG,SAAQgB,UAASC,SAC3EoC,GAAa,QAAY1J,GACb,MAAd0J,IACAwC,EAAgBxC,EAAW2C,UAEV,MAAjBH,IACAC,EAASG,SAAYC,IAGjBA,EAAMA,EAAI7K,KAAI,CAAC8E,EAAI/D,KACf,GAAU,MAAN+D,EAAY,CACZ,MAAMgG,EAASnF,EAAQ5E,GACjBgK,EAAO,KAAyBD,EAAOxB,KAAMwB,EAAOvH,OAC1D,OAAO7I,KAAKgO,WAAWqC,EAAMD,EAAOxH,MAAOwH,EAAOvH,MACtD,CACA,OAAOuB,CAAE,IAIN0F,EAAcK,EAAI7J,OAAS,EAAI6J,EAAMA,EAAI,GAAIjF,EAAOZ,KAGnEtK,KAAK8F,MAAMwK,WAAW9E,KAAKuE,EAC/B,CACA,IAAAzD,CAAKrH,GAED,OADAA,EAAOsL,MAAO,EACPtL,CACX,CACA,SAAAuL,GACqC,IAA7BxQ,KAAK8F,MAAM1B,gBACXpE,KAAK8F,MAAMwK,WAAa,IAE5BtQ,KAAK8F,MAAM1B,eACf,CACA,OAAAqM,GACIzQ,KAAK8F,MAAM1B,eACf,CAKA,UAAAgF,CAAW1G,GACP,MAAMgO,EAAY,CACd5B,MAAO,GACPpM,KAAM,gBACNsN,GAAIhQ,KAAK8F,MAAMtB,eAEf9B,IACAgO,EAAUhO,KAAOA,GAErB1C,KAAK8F,MAAMxB,WAAWkH,KAAKkF,GAC3B1Q,KAAK8F,MAAMqE,YAAcuG,CAC7B,CAKA,QAAArH,CAASpE,GACL,MAAM0L,GAAyB,IAAAC,uBAAsB3L,GAC/C4L,EAA4B,IAAIxL,IAAIsL,EAAuBrL,KAAI7C,GAAKA,EAAEuN,MAE5E,IAAK,IAAI3J,EAAI,EAAGA,EAAIrG,KAAK8F,MAAMqE,YAAY2E,MAAMxI,OAAQD,IAAK,CAC1D,MAAMgG,EAASrM,KAAK8F,MAAMqE,YAAY2E,MAAMzI,GACvCgG,EAAOkE,MAASM,EAA0BhC,IAAIxC,EAAO2D,KACtD3D,EAAO7G,SAEf,CACA,MAAMsL,EAAW9Q,KAAK8F,MAAMxB,WAAWyM,MACvC/Q,KAAK8F,MAAMqE,YAA+C,IAAjCnK,KAAK8F,MAAMxB,WAAWgC,OAC3C,KACAtG,KAAK8F,MAAMxB,WAAWtE,KAAK8F,MAAMxB,WAAWgC,OAAS,GAEzDqK,EAAuB3O,SAAQqK,IAGtBA,EAAOkE,MAAQlE,EAAO2E,UAAYF,EAASd,IAC5ChQ,KAAK8O,MAAMzC,EACf,GAER,CAOA,SAAA4E,CAAUzH,EAAG0H,EAAI9G,EAAI+G,GAAmB,GAEpC,GADA,KAAYD,EAAG5K,OAAS,GAAG,IAAM,8CACvB,MAAN8D,GAA2B,YAAbA,EAAGvB,MACjB,MAAM,IAAI3H,MAAM,0CAA0CkJ,EAAGvB,UAEjE,MAAMiB,EAAI9J,KAAKmJ,WAAU,IAAMnJ,KAAKwQ,cAAa,IAAMxQ,KAAKyQ,YAAW,IAAMzQ,KAAK+I,KAAK,UAAWS,KAClG,KAAYM,aAAa,MAAQ,IAAM,mDAEvC,MAAMsH,GAAe,OAAqBpR,KAAK8F,MAAMwK,WAAYY,EAAIpH,GACrE,IAAKqH,GAA4C,IAAxBC,EAAa9K,QAAgB4K,EAAG5K,OAAS,EAC9D,MAAM,IAAIpF,MAAM,uIAIpB,OAAOlB,KAAK+I,KAAK,YAAY,KACzB,MAAMsI,EAAyB,CAAC,EAChCA,EAAuBvH,EAAEkG,IAAa,MAAN5F,EAmH5C,SAAcxB,GACV,MAAML,GAAS,SAAmB,QAAcK,GAAQ,WACxD,OAAOmB,EAAOiE,WAAWzF,EAAQK,EAAO,UAC5C,CAtH0D0I,CAAKxH,EAAElB,OAASwB,GAE9D,OAAuBiH,EAAwBD,GAE/C5H,GAAKxJ,KAAK+I,KAAKS,IAEf+H,GACA,MAAMC,EAAQN,EAAG5L,KAAIuE,GAAKwH,EAAuBxH,EAAEmG,MAWnD,OAViC,IAA7BhQ,KAAK8F,MAAM1B,gBAGXpE,KAAK8F,MAAMwK,WAAWtO,SAAQqB,IAC1B,IAAK,MAAMgJ,KAAUhJ,EAAK6H,MACtBmB,EAAO7G,SACX,IAEJxF,KAAK8F,MAAMwK,WAAa,MAErB,CAAE/O,MAAOuI,EAAG0H,QAAO,GAElC,CACA,UAAAC,CAAWjI,GAEP,OADA,KAAY,KAAgBA,IAAI,IAAM,sDAC/B,IAAIS,KAGP,IAAIR,EAFJ,KAAYQ,EAAOyH,OAAMjP,GAAKA,aAAa,QAAS,IAAM,qEAG1D,MAAMkP,EAAW,CAAC,EAClB1H,EAAOjI,SAAQ,CAAC4P,EAAOvL,KACnBsL,EAAStL,GAAKuL,CAAK,IAyBvB,OAAO5R,KAAKuK,cAAc,CACtB2B,YAxBgB,CAAC4B,EAAG+D,KACpBpI,EAAMD,KAASS,EAAQ4H,GACvB,KAAYpI,EAAIlI,iBAAiB,MAAQ,IAAM,+FAE/C,KAAY,KAAgBkI,EAAIwG,WAAW,IAAM,qGAE1CxG,EAAIlI,OAmBXiL,cAjBkB,CAACpC,EAAIc,KACvB,MAAM4G,EAAUrI,EAAIwG,SAAS7F,EAAIc,GAC3BsG,EAAQrM,MAAMuG,QAAQoG,GAAWA,EAAU,CAACA,GAClD,KAAYN,EAAMlL,SAAW2D,EAAO3D,QAAQ,IAAM,wKAGlD,KAAYkL,EAAME,OAAMjP,GAAKA,aAAa,QAAS,IAAM,yIAGzD,MAAMsP,EAAU,CAAC,EAIjB,OAHAP,EAAMxP,SAAQ,CAACgQ,EAAM3L,KACjB0L,EAAQ1L,GAAK,IAAM2L,CAAI,IAEpBD,CAAO,EAKd9H,OAAQ0H,GACV,CAEV,CACA,QAAAnJ,CAASJ,GAGL,OADapI,KAAK8F,MAAMrB,WAAWxD,IAAImH,GAC3BzB,QAAQ6B,SAASJ,EACjC,CACA,IAAA6J,CAAK7J,GAGD,OADapI,KAAK8F,MAAMrB,WAAWxD,IAAImH,GAC3BzB,QAAQsL,KAAK7J,EAC7B,CACA,UAAM8J,CAAKzC,GACP,MAAMnG,GAAQ,IAAA6I,OACRC,QAAmBpS,KAAK2G,QAAQuL,KAAKzC,GAE3C,OADA2C,EAAWC,QAAS,IAAAF,OAAQ7I,EACrB8I,CACX,CAOA,KAAAtD,CAAM7J,GAKF,OAJ8B,MAA1BjF,KAAK8F,MAAMqE,cACXlF,EAAO+L,QAAUhR,KAAK8F,MAAMqE,YAAY6F,GACxChQ,KAAK8F,MAAMqE,YAAY2E,MAAMtD,KAAKvG,IAE/BA,CACX,CACA,uBAAInB,GACA,OAAO9D,KAAK8F,MAAMhC,mBACtB,CAKA,KAAAnC,GAEI3B,KAAK6F,uBACL7F,KAAK8F,MAAMN,UACXxF,KAAK+C,IAAIpB,QACT3B,KAAK8F,MAAQ,IAAIjC,EACjB,IAAK,MAAM0C,KAAevG,KAAK2F,SAC3B3F,KAAKyH,yBAAyBlB,GAC9BvG,KAAK2F,SAASY,GAAaf,iBACpBxF,KAAK2F,SAASY,GAEzBvG,KAAKuG,YAAc,KACnBvG,KAAKkG,gBAAkB,KACvBlG,KAAKgG,mBAAqB,IAC9B,EAQG,SAASsM,IACZ,MAAMC,GAAK,SACX,GAAoB,MAAhBA,EAAGC,UAAmB,CACtB,MAAMvP,EAAc,IAAI,KAAYsP,GACpCA,EAAGC,UAAY,IAAI9M,EAAOzC,EAC9B,CAKA,OAJA,QAAqBsP,EAAGC,UAAUzP,MAGlC,SAAiB,IAAMwP,EAAGC,YACnBD,EAAGC,SACd,CAjBA9M,EAAOiE,aAAe,EACtBjE,EAAOkE,eAAiB,EAiBjB,MAAMG,EAASuI,IAOf,SAASf,EAAItJ,EAAGC,GAEnB,MAAM+B,EAAS,CAAEhC,IAAGC,KACpB,OAAO6B,EAAOC,UAAU,KAAKC,EACjC,C,wBCr9BO,SAASwI,EAASC,GACrB,GAAIA,GAHwB,qBAAdpP,WAA0C,MAAbA,UAGT,CAI9B,GAHKoP,IACDA,EAAMpP,WAEU,gBAAhBoP,EAAIC,QACJ,OAAO,EAGX,MAAM1K,EAAIyK,EAAInP,WAAamP,EAAIjP,QAAUmP,OAAOC,MAEhD,MAAO,2TACFrP,KAAKyE,IAEN,0kDACKzE,KAAKyE,EAAE6K,OAAO,EAAG,GAC9B,CACA,OAAO,CACX,CACO,SAASC,IACZ,MAA0B,qBAAXH,QAA6C,MAAnBA,OAAOI,UAEd,qBAAtBC,iBAChB,C,k6YC3BA,MAAMC,EACmC,qBAA1BC,sBACAA,sBAEsB,qBAAjBC,aACLA,aAEH5J,GAAMA,IAYlB,SAAS6J,IACL,OAAO,IAAIC,SAAQC,GAAWL,GAAc,IAAMK,OACtD,C","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/environment.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/flags.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/engine.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/device_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/browser_util.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Required side effectful code for tfjs-core\n// Set up Engine and ENV\nimport { getOrMakeEngine } from './engine';\ngetOrMakeEngine();\n// Register backend-agnostic flags.\nimport './flags';\n// Register platforms\nimport './platforms/platform_browser';\nimport './platforms/platform_node';\n// Set up OpHandler\nimport { buffer } from './ops/buffer';\nimport { cast } from './ops/cast';\nimport { clone } from './ops/clone';\nimport { print } from './ops/print';\nimport { setOpHandler } from './tensor';\nconst opHandler = {\n    buffer,\n    cast,\n    clone,\n    print\n};\nsetOpHandler(opHandler);\n//# sourceMappingURL=base_side_effects.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { isPromise } from './util_base';\n// Expects flags from URL in the format ?tfjsflags=FLAG1:1,FLAG2:true.\nconst TENSORFLOWJS_FLAGS_PREFIX = 'tfjsflags';\n/**\n * The environment contains evaluated flags as well as the registered platform.\n * This is always used as a global singleton and can be retrieved with\n * `tf.env()`.\n *\n * @doc {heading: 'Environment'}\n */\nexport class Environment {\n    // tslint:disable-next-line: no-any\n    constructor(global) {\n        this.global = global;\n        this.flags = {};\n        this.flagRegistry = {};\n        this.urlFlags = {};\n        // Jasmine spies on this in 'environment_test.ts'\n        this.getQueryParams = getQueryParams;\n        this.populateURLFlags();\n    }\n    setPlatform(platformName, platform) {\n        if (this.platform != null) {\n            console.warn(`Platform ${this.platformName} has already been set. ` +\n                `Overwriting the platform with ${platform}.`);\n        }\n        this.platformName = platformName;\n        this.platform = platform;\n    }\n    registerFlag(flagName, evaluationFn, setHook) {\n        this.flagRegistry[flagName] = { evaluationFn, setHook };\n        // Override the flag value from the URL. This has to happen here because the\n        // environment is initialized before flags get registered.\n        if (this.urlFlags[flagName] != null) {\n            const flagValue = this.urlFlags[flagName];\n            console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);\n            this.set(flagName, flagValue);\n        }\n    }\n    async getAsync(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        this.flags[flagName] = await this.evaluateFlag(flagName);\n        return this.flags[flagName];\n    }\n    get(flagName) {\n        if (flagName in this.flags) {\n            return this.flags[flagName];\n        }\n        const flagValue = this.evaluateFlag(flagName);\n        if (isPromise(flagValue)) {\n            throw new Error(`Flag ${flagName} cannot be synchronously evaluated. ` +\n                `Please use getAsync() instead.`);\n        }\n        this.flags[flagName] = flagValue;\n        return this.flags[flagName];\n    }\n    getNumber(flagName) {\n        return this.get(flagName);\n    }\n    getBool(flagName) {\n        return this.get(flagName);\n    }\n    getFlags() {\n        return this.flags;\n    }\n    // For backwards compatibility.\n    get features() {\n        return this.flags;\n    }\n    set(flagName, value) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);\n        }\n        this.flags[flagName] = value;\n        if (this.flagRegistry[flagName].setHook != null) {\n            this.flagRegistry[flagName].setHook(value);\n        }\n    }\n    evaluateFlag(flagName) {\n        if (this.flagRegistry[flagName] == null) {\n            throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);\n        }\n        return this.flagRegistry[flagName].evaluationFn();\n    }\n    setFlags(flags) {\n        this.flags = Object.assign({}, flags);\n    }\n    reset() {\n        this.flags = {};\n        this.urlFlags = {};\n        this.populateURLFlags();\n    }\n    populateURLFlags() {\n        if (typeof this.global === 'undefined' ||\n            typeof this.global.location === 'undefined' ||\n            typeof this.global.location.search === 'undefined') {\n            return;\n        }\n        const urlParams = this.getQueryParams(this.global.location.search);\n        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {\n            const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(',');\n            keyValues.forEach(keyValue => {\n                const [key, value] = keyValue.split(':');\n                this.urlFlags[key] = parseValue(key, value);\n            });\n        }\n    }\n}\nexport function getQueryParams(queryString) {\n    const params = {};\n    queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {\n        decodeParam(params, t[0], t[1]);\n        return t.join('=');\n    });\n    return params;\n}\nfunction decodeParam(params, name, value) {\n    params[decodeURIComponent(name)] = decodeURIComponent(value || '');\n}\nfunction parseValue(flagName, value) {\n    value = value.toLowerCase();\n    if (value === 'true' || value === 'false') {\n        return value === 'true';\n    }\n    else if (`${+value}` === value) {\n        return +value;\n    }\n    throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);\n}\n/**\n * Returns the current environment (a global singleton).\n *\n * The environment object contains the evaluated feature values as well as the\n * active platform.\n *\n * @doc {heading: 'Environment'}\n */\nexport function env() {\n    return ENV;\n}\nexport let ENV = null;\nexport function setEnvironmentGlobal(environment) {\n    ENV = environment;\n}\n//# sourceMappingURL=environment.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport './engine';\nimport * as device_util from './device_util';\nimport { env } from './environment';\nconst ENV = env();\n/**\n * This file contains environment-related flag registrations.\n */\n/** Whether to enable debug mode. */\nENV.registerFlag('DEBUG', () => false, debugValue => {\n    if (debugValue) {\n        console.warn('Debugging mode is ON. The output of every math call will ' +\n            'be downloaded to CPU and checked for NaNs. ' +\n            'This significantly impacts performance.');\n    }\n});\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_BROWSER', () => device_util.isBrowser());\n/** Whether we are in a browser (as versus, say, node.js) environment. */\nENV.registerFlag('IS_NODE', () => (typeof process !== 'undefined') &&\n    (typeof process.versions !== 'undefined') &&\n    (typeof process.versions.node !== 'undefined'));\n/** Whether this browser is Chrome. */\nENV.registerFlag('IS_CHROME', () => typeof navigator !== 'undefined' && navigator != null &&\n    navigator.userAgent != null && /Chrome/.test(navigator.userAgent) &&\n    /Google Inc/.test(navigator.vendor));\n/**\n * True when the environment is \"production\" where we disable safety checks\n * to gain performance.\n */\nENV.registerFlag('PROD', () => false);\n/**\n * Whether to do sanity checks when inferring a shape from user-provided\n * values, used when creating a new tensor.\n */\nENV.registerFlag('TENSORLIKE_CHECK_SHAPE_CONSISTENCY', () => ENV.getBool('DEBUG'));\n/** Whether deprecation warnings are enabled. */\nENV.registerFlag('DEPRECATION_WARNINGS_ENABLED', () => true);\n/** True if running unit tests. */\nENV.registerFlag('IS_TEST', () => false);\n/** Whether to check computation result for errors. */\nENV.registerFlag('CHECK_COMPUTATION_FOR_ERRORS', () => true);\n/** Whether the backend needs to wrap input to imageBitmap. */\nENV.registerFlag('WRAP_TO_IMAGEBITMAP', () => false);\n//# sourceMappingURL=flags.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { KernelBackend } from './backends/backend';\nimport { Environment, setEnvironmentGlobal } from './environment';\nimport { getGlobalNamespace } from './global_util';\nimport { Add, Cast, Identity } from './kernel_names';\nimport { getGradient, getKernel, getKernelsForBackend } from './kernel_registry';\nimport { Profiler } from './profiler';\nimport { backpropagateGradients, getFilteredNodesXToY } from './tape';\nimport { setTensorTracker, Tensor, Variable } from './tensor';\nimport { getTensorsInContainer } from './tensor_util';\nimport * as util from './util';\nimport { bytesFromStringArray, makeOnesTypedArray, now, sizeFromShape } from './util';\nfunction isRegisteredKernelInvocation(kernelInvocation) {\n    return kernelInvocation.kernelName != null;\n}\nclass EngineState {\n    constructor() {\n        // Public since optimizers will use it.\n        this.registeredVariables = {};\n        this.nextTapeNodeId = 0;\n        this.numBytes = 0;\n        this.numTensors = 0;\n        this.numStringTensors = 0;\n        this.numDataBuffers = 0;\n        // Number of nested tf.grad() statements when computing higher-order\n        // gradients. E.g. `1` for first-order gradients and `2` for second-order\n        // gradients. Used to track if the tape should be removed after a backprop.\n        this.gradientDepth = 0;\n        // Number of nested kernel calls. When kernel depth is greater than 1, we turn\n        // off the tape.\n        this.kernelDepth = 0;\n        this.scopeStack = [];\n        /**\n         * Keeps track of the number of data moves during a kernel execution. We\n         * maintain a stack since kernels can call other kernels, recursively.\n         */\n        this.numDataMovesStack = [];\n        this.nextScopeId = 0;\n        this.tensorInfo = new WeakMap();\n        this.profiling = false;\n        this.activeProfile = {\n            newBytes: 0,\n            newTensors: 0,\n            peakBytes: 0,\n            kernels: [],\n            result: null,\n            get kernelNames() {\n                return Array.from(new Set(this.kernels.map(k => k.name)));\n            }\n        };\n    }\n    dispose() {\n        for (const variableName in this.registeredVariables) {\n            this.registeredVariables[variableName].dispose();\n        }\n    }\n}\nexport class Engine {\n    constructor(ENV) {\n        this.ENV = ENV;\n        this.registry = {};\n        this.registryFactory = {};\n        this.pendingBackendInitId = 0;\n        this.state = new EngineState();\n    }\n    async ready() {\n        if (this.pendingBackendInit != null) {\n            return this.pendingBackendInit.then(() => { });\n        }\n        if (this.backendInstance != null) {\n            return;\n        }\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const success = await this.initializeBackend(backendName).success;\n            if (success) {\n                await this.setBackend(backendName);\n                return;\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    get backend() {\n        if (this.pendingBackendInit != null) {\n            throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make ` +\n                `sure to await tf.ready() or await tf.setBackend() before calling ` +\n                `other methods`);\n        }\n        if (this.backendInstance == null) {\n            const { name, asyncInit } = this.initializeBackendsAndReturnBest();\n            if (asyncInit) {\n                throw new Error(`The highest priority backend '${name}' has not yet been ` +\n                    `initialized. Make sure to await tf.ready() or ` +\n                    `await tf.setBackend() before calling other methods`);\n            }\n            this.setBackend(name);\n        }\n        return this.backendInstance;\n    }\n    backendNames() {\n        return Object.keys(this.registryFactory);\n    }\n    findBackend(backendName) {\n        if (!(backendName in this.registry)) {\n            // If the backend hasn't been initialized but we have a registry entry for\n            // it, initialize it and return it.\n            if (backendName in this.registryFactory) {\n                const { asyncInit } = this.initializeBackend(backendName);\n                if (asyncInit) {\n                    // Backend is not ready yet.\n                    return null;\n                }\n            }\n            else {\n                return null;\n            }\n        }\n        return this.registry[backendName];\n    }\n    findBackendFactory(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            return null;\n        }\n        return this.registryFactory[backendName].factory;\n    }\n    registerBackend(backendName, factory, priority = 1) {\n        if (backendName in this.registryFactory) {\n            console.warn(`${backendName} backend was already registered. ` +\n                `Reusing existing backend factory.`);\n            return false;\n        }\n        this.registryFactory[backendName] = { factory, priority };\n        return true;\n    }\n    async setBackend(backendName) {\n        if (this.registryFactory[backendName] == null) {\n            throw new Error(`Backend name '${backendName}' not found in registry`);\n        }\n        this.backendName = backendName;\n        if (this.registry[backendName] == null) {\n            this.backendInstance = null;\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            const result = asyncInit ? await success : success;\n            if (!result) {\n                return false;\n            }\n        }\n        this.backendInstance = this.registry[backendName];\n        this.setupRegisteredKernels();\n        // Reset the profiler.\n        this.profiler = new Profiler(this.backendInstance);\n        return true;\n    }\n    setupRegisteredKernels() {\n        const kernels = getKernelsForBackend(this.backendName);\n        kernels.forEach(kernel => {\n            if (kernel.setupFunc != null) {\n                kernel.setupFunc(this.backendInstance);\n            }\n        });\n    }\n    disposeRegisteredKernels(backendName) {\n        const kernels = getKernelsForBackend(backendName);\n        kernels.forEach(kernel => {\n            if (kernel.disposeFunc != null) {\n                kernel.disposeFunc(this.registry[backendName]);\n            }\n        });\n    }\n    /**\n     * Initializes a backend by looking up the backend name in the factory\n     * registry and calling the factory method. Returns a boolean representing\n     * whether the initialization of the backend suceeded. Throws an error if\n     * there is no backend in the factory registry.\n     */\n    initializeBackend(backendName) {\n        const registryFactoryEntry = this.registryFactory[backendName];\n        if (registryFactoryEntry == null) {\n            throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);\n        }\n        try {\n            const backend = registryFactoryEntry.factory();\n            /* Test if the factory returns a promise.\n            Done in a more liberal way than\n            previous 'Promise.resolve(backend)===backend'\n            as we needed to account for custom Promise\n            implementations (e.g. Angular) */\n            if (backend && !(backend instanceof KernelBackend) &&\n                typeof backend.then === 'function') {\n                const promiseId = ++this.pendingBackendInitId;\n                const success = backend\n                    .then(backendInstance => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.registry[backendName] = backendInstance;\n                    this.pendingBackendInit = null;\n                    return true;\n                })\n                    .catch(err => {\n                    // Outdated promise. Another backend was set in the meantime.\n                    if (promiseId < this.pendingBackendInitId) {\n                        return false;\n                    }\n                    this.pendingBackendInit = null;\n                    console.warn(`Initialization of backend ${backendName} failed`);\n                    console.warn(err.stack || err.message);\n                    return false;\n                });\n                this.pendingBackendInit = success;\n                return { success, asyncInit: true };\n            }\n            else {\n                this.registry[backendName] = backend;\n                return { success: true, asyncInit: false };\n            }\n        }\n        catch (err) {\n            console.warn(`Initialization of backend ${backendName} failed`);\n            console.warn(err.stack || err.message);\n            return { success: false, asyncInit: false };\n        }\n    }\n    removeBackend(backendName) {\n        if (!(backendName in this.registryFactory)) {\n            throw new Error(`${backendName} backend not found in registry`);\n        }\n        if (this.backendName === backendName && this.pendingBackendInit != null) {\n            // There is a pending promise of the backend we want to remove. Make it\n            // obsolete.\n            this.pendingBackendInitId++;\n        }\n        if (backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        delete this.registryFactory[backendName];\n        // Unset the backend if it is active.\n        if (this.backendName === backendName) {\n            this.pendingBackendInit = null;\n            this.backendName = null;\n            this.backendInstance = null;\n        }\n    }\n    getSortedBackends() {\n        if (Object.keys(this.registryFactory).length === 0) {\n            throw new Error('No backend found in registry.');\n        }\n        return Object.keys(this.registryFactory).sort((a, b) => {\n            // Highest priority comes first.\n            return this.registryFactory[b].priority -\n                this.registryFactory[a].priority;\n        });\n    }\n    initializeBackendsAndReturnBest() {\n        const sortedBackends = this.getSortedBackends();\n        for (let i = 0; i < sortedBackends.length; i++) {\n            const backendName = sortedBackends[i];\n            const { success, asyncInit } = this.initializeBackend(backendName);\n            if (asyncInit || success) {\n                return { name: backendName, asyncInit };\n            }\n        }\n        throw new Error(`Could not initialize any backends, all backend initializations ` +\n            `failed.`);\n    }\n    moveData(backend, dataId) {\n        const info = this.state.tensorInfo.get(dataId);\n        const srcBackend = info.backend;\n        const values = this.readSync(dataId);\n        const refCount = srcBackend.refCount(dataId);\n        // Delete the tensor from the old backend and move it to the new\n        // backend.\n        srcBackend.disposeData(dataId, true);\n        info.backend = backend;\n        backend.move(dataId, values, info.shape, info.dtype, refCount);\n        if (this.shouldCheckForMemLeaks()) {\n            // Track the number of moves during a kernel execution to correctly\n            // detect memory leaks.\n            this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;\n        }\n    }\n    tidy(nameOrFn, fn) {\n        let name = null;\n        if (fn == null) {\n            // Called with only 1 argument.\n            if (typeof nameOrFn !== 'function') {\n                throw new Error('Please provide a function to tidy()');\n            }\n            fn = nameOrFn;\n        }\n        else {\n            // Called with 2 arguments.\n            if (typeof nameOrFn !== 'string' && !(nameOrFn instanceof String)) {\n                throw new Error('When calling with two arguments, the first argument ' +\n                    'to tidy() must be a string');\n            }\n            if (typeof fn !== 'function') {\n                throw new Error('When calling with two arguments, the 2nd argument ' +\n                    'to tidy() must be a function');\n            }\n            name = nameOrFn;\n            // TODO(nsthorat,smilkov): Do operation logging and performance\n            // profiling.\n        }\n        let result;\n        return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {\n            result = fn();\n            if (result instanceof Promise) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            return result;\n        });\n    }\n    scopedRun(start, end, f) {\n        start();\n        try {\n            const res = f();\n            end();\n            return res;\n        }\n        catch (ex) {\n            end();\n            throw ex;\n        }\n    }\n    nextTensorId() {\n        return Engine.nextTensorId++;\n    }\n    nextVariableId() {\n        return Engine.nextVariableId++;\n    }\n    /**\n     * This method is called instead of the public-facing tensor.clone() when\n     * saving a tensor for backwards pass. It makes sure to add the clone\n     * operation to the tape regardless of being called inside a kernel\n     * execution.\n     */\n    clone(x) {\n        const y = ENGINE.runKernel(Identity, { x });\n        const inputs = { x };\n        const grad = (dy) => ({\n            x: () => {\n                const dtype = 'float32';\n                const gradInputs = { x: dy };\n                const attrs = { dtype };\n                return ENGINE.runKernel(Cast, gradInputs, \n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                attrs);\n            }\n        });\n        const saved = [];\n        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});\n        return y;\n    }\n    /**\n     * Execute a kernel with the given name and return the output tensor.\n     *\n     * @param kernelName The name of the kernel to execute.\n     * @param inputs A map of input names to tensors.\n     * @param attrs A map of attribute names to their values. An attribute is a\n     *     primitive (non-tensor) input to the kernel.\n     * @param inputsToSave A list of tensors, inputs to save for the backprop\n     *     computation.\n     * @param outputsToSave A list of booleans, specifying which output to save\n     *     for the backprop computation. These are booleans since the output\n     * tensors are not visible to the user.\n     */\n    runKernel(kernelName, inputs, attrs) {\n        const hasKernel = getKernel(kernelName, this.backendName) != null;\n        if (!hasKernel) {\n            throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);\n        }\n        return this.runKernelFunc({ kernelName, inputs, attrs });\n    }\n    shouldCheckForMemLeaks() {\n        return this.ENV.getBool('IS_TEST');\n    }\n    checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {\n        const numDataIdsAfter = this.backend.numDataIds();\n        // Count the number of data ids associated with the result of the kernel.\n        let numOutputDataIds = 0;\n        outInfos.forEach(info => {\n            // Complex numbers allocate 3 data ids, one for 'real', one for\n            // 'imaginary', and one for the container that holds the former two.\n            numOutputDataIds += (info.dtype === 'complex64' ? 3 : 1);\n        });\n        // Account for the number of moves during kernel execution. A \"data move\"\n        // can happen in the middle of a kernel execution, placing a new (key,value)\n        // pair in the data storage. Since data moves have net zero effect (we\n        // always remove the data from the old backend), we have to cancel them out\n        // when detecting memory leaks.\n        const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];\n        const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;\n        if (dataIdsLeaked > 0) {\n            throw new Error(`Backend '${this.backendName}' has an internal memory leak ` +\n                `(${dataIdsLeaked} data ids) after running '${kernelName}'`);\n        }\n    }\n    /**\n     * Internal helper method to execute a kernel Func\n     *\n     * Use `runKernel` to execute kernels from outside of engine.\n     */\n    runKernelFunc(kernelParams) {\n        let outputs;\n        let saved = [];\n        const isTapeOn = this.isTapeOn();\n        const startingBytecount = this.state.numBytes;\n        const startingNumTensors = this.state.numTensors;\n        if (this.shouldCheckForMemLeaks()) {\n            this.state.numDataMovesStack.push(0);\n        }\n        let kernelFunc;\n        if (this.backendName == null) {\n            // backend has not been initialized yet (backend initialization is lazy\n            // can be deferred until an op/ kernel is run).\n            // The below getter has side effects that will try to initialize the\n            // backend and set properties like this.backendName\n            // tslint:disable-next-line: no-unused-expression\n            this.backend;\n        }\n        let out;\n        const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ?\n            kernelParams.kernelName :\n            this.state.activeScope != null ? this.state.activeScope.name : '';\n        // Create the kernelFunc from either a registered kernel OR passed in\n        // forward/backward functions (used by custom grad). In this context a\n        // kernelFunc wraps a kernel implementation with some bookkeeping.\n        if (isRegisteredKernelInvocation(kernelParams)) {\n            const { kernelName, inputs, attrs } = kernelParams;\n            if (this.backendName == null) {\n                // backend has not been initialized yet (backend initialization is lazy\n                // can be deferred until an op/ kernel is run).\n                // The below getter has side effects that will try to initialize the\n                // backend and set properties like this.backendName\n                // tslint:disable-next-line: no-unused-expression\n                this.backend;\n            }\n            const kernel = getKernel(kernelName, this.backendName);\n            util.assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = kernel.kernelFunc({ inputs, attrs, backend: this.backend });\n                const outInfos = Array.isArray(out) ? out : [out];\n                if (this.shouldCheckForMemLeaks()) {\n                    this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);\n                }\n                const outTensors = outInfos.map((outInfo) => {\n                    // todo (yassogba) remove this option (Tensor) when node backend\n                    // methods have been modularized and they all return tensorInfo.\n                    // TensorInfos do not have a rank attribute.\n                    if (outInfo.rank != null) {\n                        return outInfo;\n                    }\n                    const { dataId, shape, dtype } = outInfo;\n                    return this.makeTensorFromDataId(dataId, shape, dtype);\n                });\n                // Save any required inputs and outputs.\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since there would be no backprop for these tensors\n                // (which would otherwise dispose them).\n                if (isTapeOn) {\n                    const tensorsToSave = this.getTensorsForGradient(kernelName, inputs, outTensors);\n                    saved = this.saveTensorsForBackwardMode(tensorsToSave);\n                }\n                return outTensors;\n            };\n        }\n        else {\n            const { forwardFunc } = kernelParams;\n            // Running a customGrad op.\n            const saveFunc = (tensors) => {\n                // Do not save unless we are recording to the tape. Otherwise it would\n                // cause a mem leak since we would never run backprop, which disposes\n                // the kept tensors.\n                if (!isTapeOn) {\n                    return;\n                }\n                saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n            };\n            kernelFunc = () => {\n                const numDataIdsBefore = this.backend.numDataIds();\n                out = this.tidy(() => forwardFunc(this.backend, saveFunc));\n                const outs = (Array.isArray(out) ? out : [out]);\n                if (this.shouldCheckForMemLeaks()) {\n                    // Scope name is used to print a more helpful error message if needed.\n                    this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);\n                }\n                return outs;\n            };\n        }\n        //\n        // Run the kernelFunc. Optionally profiling it.\n        //\n        const { inputs, attrs } = kernelParams;\n        const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ?\n            null :\n            kernelParams.backwardsFunc;\n        let kernelProfile;\n        this.scopedRun(\n        // Stop recording to a tape when running a kernel.\n        () => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {\n            if (!this.ENV.getBool('DEBUG') && !this.state.profiling) {\n                outputs = kernelFunc();\n            }\n            else {\n                kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc());\n                if (this.ENV.getBool('DEBUG')) {\n                    this.profiler.logKernelProfile(kernelProfile);\n                }\n                outputs = kernelProfile.outputs;\n            }\n        });\n        if (isTapeOn) {\n            this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);\n        }\n        if (this.state.profiling) {\n            this.state.activeProfile.kernels.push({\n                name: kernelOrScopeName,\n                bytesAdded: this.state.numBytes - startingBytecount,\n                totalBytesSnapshot: this.state.numBytes,\n                tensorsAdded: this.state.numTensors - startingNumTensors,\n                totalTensorsSnapshot: this.state.numTensors,\n                inputShapes: Object.keys(inputs).map(key => inputs[key] != null ? inputs[key].shape : null),\n                outputShapes: outputs.map(item => item.shape),\n                kernelTimeMs: kernelProfile.timeMs,\n                extraInfo: kernelProfile.extraInfo\n            });\n        }\n        return (Array.isArray(out) ? outputs : outputs[0]);\n    }\n    /**\n     * Saves tensors used in forward mode for use in backward mode.\n     *\n     * @param tensors the list of tensors to save.\n     */\n    saveTensorsForBackwardMode(tensors) {\n        const saved = tensors.map(tensor => this.keep(this.clone(tensor)));\n        return saved;\n    }\n    /**\n     * Returns a list of tensors to save for a given gradient calculation.\n     *\n     * @param kernelName name of kernel to look up gradient for.\n     * @param inputs a map of input tensors.\n     * @param outputs an array of output tensors from forward mode of kernel.\n     */\n    getTensorsForGradient(kernelName, inputs, outputs) {\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            const inputsToSave = gradConfig.inputsToSave || [];\n            const outputsToSave = gradConfig.outputsToSave || [];\n            // If saveAllInputs is true, all inputs will be saved. Otherwise, inputs\n            // specified in inputsToSave will be saved.\n            let inputTensorsToSave;\n            if (gradConfig.saveAllInputs) {\n                util.assert(Array.isArray(inputs), () => 'saveAllInputs is true, expected inputs to be an array.');\n                inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);\n            }\n            else {\n                inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);\n            }\n            const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);\n            return inputTensorsToSave.concat(outputTensorsToSave);\n        }\n        // We return an empty list rather than throw an error because the kernel we\n        // are looking up may not actually be relevant to backproping through the\n        // overall function\n        //\n        // See 'does not error if irrelevant (pruned) ops are missing grads' test\n        // in gradients_test.ts for an example.\n        return [];\n    }\n    /**\n     * Internal method used by public APIs for tensor creation. Makes a new\n     * tensor with the provided shape, dtype and values. It always\n     * creates a new data id and writes the values to the underlying backend.\n     */\n    makeTensor(values, shape, dtype, backend) {\n        if (values == null) {\n            throw new Error('Values passed to engine.makeTensor() are null');\n        }\n        dtype = dtype || 'float32';\n        backend = backend || this.backend;\n        let backendVals = values;\n        if (dtype === 'string' && util.isString(values[0])) {\n            backendVals = values.map(d => util.encodeString(d));\n        }\n        const dataId = backend.write(backendVals, shape, dtype);\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.trackTensor(t, backend);\n        // Count bytes for string tensors.\n        if (dtype === 'string') {\n            const info = this.state.tensorInfo.get(dataId);\n            const newBytes = bytesFromStringArray(backendVals);\n            this.state.numBytes += newBytes - info.bytes;\n            info.bytes = newBytes;\n        }\n        return t;\n    }\n    /**\n     * Internal method used by backends. Makes a new tensor\n     * that is a wrapper around an existing data id. It doesn't create\n     * a new data id, only increments the ref count used in memory tracking.\n     */\n    makeTensorFromDataId(dataId, shape, dtype, backend) {\n        dtype = dtype || 'float32';\n        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());\n        this.trackTensor(t, backend);\n        return t;\n    }\n    makeVariable(initialValue, trainable = true, name, dtype) {\n        name = name || this.nextVariableId().toString();\n        if (dtype != null && dtype !== initialValue.dtype) {\n            initialValue = initialValue.cast(dtype);\n        }\n        const v = new Variable(initialValue, trainable, name, this.nextTensorId());\n        if (this.state.registeredVariables[v.name] != null) {\n            throw new Error(`Variable with name ${v.name} was already registered`);\n        }\n        this.state.registeredVariables[v.name] = v;\n        this.incRef(v, this.backend);\n        return v;\n    }\n    trackTensor(a, backend) {\n        this.state.numTensors++;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors++;\n        }\n        // Bytes for complex numbers are counted by their components. Bytes for\n        // string tensors are counted when writing values.\n        let bytes = 0;\n        if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n            bytes = a.size * util.bytesPerElement(a.dtype);\n        }\n        this.state.numBytes += bytes;\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            this.state.numDataBuffers++;\n            this.state.tensorInfo.set(a.dataId, {\n                backend: backend || this.backend,\n                dtype: a.dtype,\n                shape: a.shape,\n                bytes\n            });\n        }\n        if (!(a instanceof Variable)) {\n            this.track(a);\n        }\n    }\n    // Track the tensor by dataId and increase the refCount for the dataId in the\n    // backend.\n    // TODO(pyu10055): This is currently used by makeVariable method, to increase\n    // refCount on the backend for the dataId. It can potentially be replaced with\n    // Identity op indead of calling backend directly.\n    incRef(a, backend) {\n        this.trackTensor(a, backend);\n        this.backend.incRef(a.dataId);\n    }\n    removeDataId(dataId, backend) {\n        if (this.state.tensorInfo.has(dataId) &&\n            this.state.tensorInfo.get(dataId).backend === backend) {\n            this.state.tensorInfo.delete(dataId);\n            this.state.numDataBuffers--;\n        }\n    }\n    disposeTensor(a) {\n        if (!this.state.tensorInfo.has(a.dataId)) {\n            return;\n        }\n        const info = this.state.tensorInfo.get(a.dataId);\n        this.state.numTensors--;\n        if (a.dtype === 'string') {\n            this.state.numStringTensors--;\n            this.state.numBytes -= info.bytes;\n        }\n        // Don't count bytes for complex numbers as they are counted by their\n        // components.\n        if (a.dtype !== 'complex64' && a.dtype !== 'string') {\n            const bytes = a.size * util.bytesPerElement(a.dtype);\n            this.state.numBytes -= bytes;\n        }\n        // Remove the reference to dataId if backend dispose the data successfully\n        if (info.backend.disposeData(a.dataId)) {\n            this.removeDataId(a.dataId, info.backend);\n        }\n        // TODO(nsthorat): Construct an error and save the stack trace for\n        // debugging when in debug mode. Creating a stack trace is too expensive\n        // to do unconditionally.\n    }\n    disposeVariables() {\n        for (const varName in this.state.registeredVariables) {\n            const v = this.state.registeredVariables[varName];\n            this.disposeVariable(v);\n        }\n    }\n    disposeVariable(v) {\n        this.disposeTensor(v);\n        if (this.state.registeredVariables[v.name] != null) {\n            delete this.state.registeredVariables[v.name];\n        }\n    }\n    memory() {\n        const info = this.backend.memory();\n        info.numTensors = this.state.numTensors;\n        info.numDataBuffers = this.state.numDataBuffers;\n        info.numBytes = this.state.numBytes;\n        if (this.state.numStringTensors > 0) {\n            info.unreliable = true;\n            if (info.reasons == null) {\n                info.reasons = [];\n            }\n            info.reasons.push('Memory usage by string tensors is approximate ' +\n                '(2 bytes per character)');\n        }\n        return info;\n    }\n    async profile(query) {\n        this.state.profiling = true;\n        const startBytes = this.state.numBytes;\n        const startNumTensors = this.state.numTensors;\n        this.state.activeProfile.kernels = [];\n        this.state.activeProfile.result = await query();\n        this.state.profiling = false;\n        this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map(d => d.totalBytesSnapshot));\n        this.state.activeProfile.newBytes = this.state.numBytes - startBytes;\n        this.state.activeProfile.newTensors =\n            this.state.numTensors - startNumTensors;\n        for (const kernel of this.state.activeProfile.kernels) {\n            kernel.kernelTimeMs = await kernel.kernelTimeMs;\n            kernel.extraInfo = await kernel.extraInfo;\n        }\n        return this.state.activeProfile;\n    }\n    isTapeOn() {\n        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;\n    }\n    addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {\n        const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };\n        const gradConfig = getGradient(kernelName);\n        if (gradConfig != null) {\n            gradientsFunc = gradConfig.gradFunc;\n        }\n        if (gradientsFunc != null) {\n            tapeNode.gradient = (dys) => {\n                // TODO(smilkov): To optimize back-prop, pass dys that are not used in\n                // the backprop graph to the user as null instead of zeros\n                dys = dys.map((dy, i) => {\n                    if (dy == null) {\n                        const output = outputs[i];\n                        const vals = util.makeZerosTypedArray(output.size, output.dtype);\n                        return this.makeTensor(vals, output.shape, output.dtype);\n                    }\n                    return dy;\n                });\n                // Grad functions of ops with single outputs expect a dy, while ops\n                // with multiple outputs expect dys (array of dy).\n                return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);\n            };\n        }\n        this.state.activeTape.push(tapeNode);\n    }\n    keep(result) {\n        result.kept = true;\n        return result;\n    }\n    startTape() {\n        if (this.state.gradientDepth === 0) {\n            this.state.activeTape = [];\n        }\n        this.state.gradientDepth++;\n    }\n    endTape() {\n        this.state.gradientDepth--;\n    }\n    /**\n     * Start a scope. Use this with endScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    startScope(name) {\n        const scopeInfo = {\n            track: [],\n            name: 'unnamed scope',\n            id: this.state.nextScopeId++\n        };\n        if (name) {\n            scopeInfo.name = name;\n        }\n        this.state.scopeStack.push(scopeInfo);\n        this.state.activeScope = scopeInfo;\n    }\n    /**\n     * End a scope. Use this with startScope() to achieve the same functionality\n     * as scope() without the need for a function closure.\n     */\n    endScope(result) {\n        const tensorsToTrackInParent = getTensorsInContainer(result);\n        const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map(t => t.id));\n        // Dispose the arrays tracked in this scope.\n        for (let i = 0; i < this.state.activeScope.track.length; i++) {\n            const tensor = this.state.activeScope.track[i];\n            if (!tensor.kept && !tensorsToTrackInParentSet.has(tensor.id)) {\n                tensor.dispose();\n            }\n        }\n        const oldScope = this.state.scopeStack.pop();\n        this.state.activeScope = this.state.scopeStack.length === 0 ?\n            null :\n            this.state.scopeStack[this.state.scopeStack.length - 1];\n        // Track the current result in the parent scope.\n        tensorsToTrackInParent.forEach(tensor => {\n            // Only track the tensor if was allocated in the inner scope and is not\n            // globally kept.\n            if (!tensor.kept && tensor.scopeId === oldScope.id) {\n                this.track(tensor);\n            }\n        });\n    }\n    /**\n     * Returns gradients of `f` with respect to each of the `xs`. The gradients\n     * returned are of the same length as `xs`, but some might be null if `f`\n     * was not a function of that `x`. It also takes optional dy to multiply the\n     * gradient, which defaults to `1`.\n     */\n    gradients(f, xs, dy, allowNoGradients = false) {\n        util.assert(xs.length > 0, () => 'gradients() received an empty list of xs.');\n        if (dy != null && dy.dtype !== 'float32') {\n            throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);\n        }\n        const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy('forward', f));\n        util.assert(y instanceof Tensor, () => 'The result y returned by f() must be a tensor.');\n        // Filter out the nodes that don't connect x => y.\n        const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);\n        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {\n            throw new Error('Cannot compute gradient of y=f(x) with respect to x. Make sure ' +\n                'that the f you passed encloses all operations that lead from x ' +\n                'to y.');\n        }\n        return this.tidy('backward', () => {\n            const accumulatedGradientMap = {};\n            accumulatedGradientMap[y.id] = (dy == null) ? ones(y.shape) : dy;\n            // Backprop gradients through the filtered nodes.\n            backpropagateGradients(accumulatedGradientMap, filteredTape, \n            // Pass the tidy function to avoid circular dep with `tape.ts`.\n            f => this.tidy(f), \n            // Pass an add function to avoide a circular dep with `tape.ts`.\n            add);\n            const grads = xs.map(x => accumulatedGradientMap[x.id]);\n            if (this.state.gradientDepth === 0) {\n                // This means that we are not computing higher-order gradients\n                // and can clean up the tape.\n                this.state.activeTape.forEach(node => {\n                    for (const tensor of node.saved) {\n                        tensor.dispose();\n                    }\n                });\n                this.state.activeTape = null;\n            }\n            return { value: y, grads };\n        });\n    }\n    customGrad(f) {\n        util.assert(util.isFunction(f), () => 'The f passed in customGrad(f) must be a function.');\n        return (...inputs) => {\n            util.assert(inputs.every(t => t instanceof Tensor), () => 'The args passed in customGrad(f)(x1, x2,...) must all be ' +\n                'tensors');\n            let res;\n            const inputMap = {};\n            inputs.forEach((input, i) => {\n                inputMap[i] = input;\n            });\n            const forwardFunc = (_, save) => {\n                res = f(...[...inputs, save]);\n                util.assert(res.value instanceof Tensor, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.value` is a tensor');\n                util.assert(util.isFunction(res.gradFunc), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function.');\n                return res.value;\n            };\n            const backwardsFunc = (dy, saved) => {\n                const gradRes = res.gradFunc(dy, saved);\n                const grads = Array.isArray(gradRes) ? gradRes : [gradRes];\n                util.assert(grads.length === inputs.length, () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'the same number of tensors as inputs passed to f(...).');\n                util.assert(grads.every(t => t instanceof Tensor), () => 'The function f passed in customGrad(f) must return an ' +\n                    'object where `obj.gradFunc` is a function that returns ' +\n                    'a list of only tensors.');\n                const gradMap = {};\n                grads.forEach((grad, i) => {\n                    gradMap[i] = () => grad;\n                });\n                return gradMap;\n            };\n            return this.runKernelFunc({\n                forwardFunc,\n                backwardsFunc,\n                inputs: inputMap,\n            });\n        };\n    }\n    readSync(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.readSync(dataId);\n    }\n    read(dataId) {\n        // Route the read to the correct backend.\n        const info = this.state.tensorInfo.get(dataId);\n        return info.backend.read(dataId);\n    }\n    async time(query) {\n        const start = now();\n        const timingInfo = await this.backend.time(query);\n        timingInfo.wallMs = now() - start;\n        return timingInfo;\n    }\n    /**\n     * Tracks a Tensor in the current scope to be automatically cleaned up\n     * when the current scope ends, and returns the value.\n     *\n     * @param result The Tensor to track in the current scope.\n     */\n    track(result) {\n        if (this.state.activeScope != null) {\n            result.scopeId = this.state.activeScope.id;\n            this.state.activeScope.track.push(result);\n        }\n        return result;\n    }\n    get registeredVariables() {\n        return this.state.registeredVariables;\n    }\n    /**\n     * Resets the engine state. Removes all backends but does not remove\n     * registered backend factories.\n     */\n    reset() {\n        // Make any pending promise obsolete.\n        this.pendingBackendInitId++;\n        this.state.dispose();\n        this.ENV.reset();\n        this.state = new EngineState();\n        for (const backendName in this.registry) {\n            this.disposeRegisteredKernels(backendName);\n            this.registry[backendName].dispose();\n            delete this.registry[backendName];\n        }\n        this.backendName = null;\n        this.backendInstance = null;\n        this.pendingBackendInit = null;\n    }\n}\nEngine.nextTensorId = 0;\nEngine.nextVariableId = 0;\nfunction ones(shape) {\n    const values = makeOnesTypedArray(sizeFromShape(shape), 'float32');\n    return ENGINE.makeTensor(values, shape, 'float32');\n}\nexport function getOrMakeEngine() {\n    const ns = getGlobalNamespace();\n    if (ns._tfengine == null) {\n        const environment = new Environment(ns);\n        ns._tfengine = new Engine(environment);\n    }\n    setEnvironmentGlobal(ns._tfengine.ENV);\n    // Tell the current tensor interface that the global engine is responsible\n    // for tracking.\n    setTensorTracker(() => ns._tfengine);\n    return ns._tfengine;\n}\nexport const ENGINE = getOrMakeEngine();\n/**\n * A implementation of the add op for use within engine and tape.\n *\n * This allows us to avoid a circular dependency between add.ts and engine.\n * It is exported to be available in tape tests.\n */\nexport function add(a, b) {\n    // We duplicate Add here to avoid a circular dependency with add.ts.\n    const inputs = { a, b };\n    return ENGINE.runKernel(Add, inputs);\n}\n//# sourceMappingURL=engine.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// tslint:disable-next-line:no-any\nfunction _isNavigatorDefined() {\n    return typeof navigator !== 'undefined' && navigator != null;\n}\nexport function isMobile(nav) {\n    if (nav || _isNavigatorDefined()) {\n        if (!nav) {\n            nav = navigator;\n        }\n        if (nav.product === 'ReactNative') {\n            return true;\n        }\n        // tslint:disable-next-line:no-any\n        const a = nav.userAgent || nav.vendor || window.opera;\n        // tslint:disable-next-line:max-line-length\n        return /(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i\n            .test(a) ||\n            // tslint:disable-next-line:max-line-length\n            /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i\n                .test(a.substr(0, 4));\n    }\n    return false;\n}\nexport function isBrowser() {\n    return (typeof window !== 'undefined' && window.document != null) ||\n        //@ts-ignore\n        (typeof WorkerGlobalScope !== 'undefined');\n}\n//# sourceMappingURL=device_util.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nconst delayCallback = (() => {\n    if (typeof requestAnimationFrame !== 'undefined') {\n        return requestAnimationFrame;\n    }\n    else if (typeof setImmediate !== 'undefined') {\n        return setImmediate;\n    }\n    return (f) => f(); // no delays\n})();\n/**\n * Returns a promise that resolve when a requestAnimationFrame has completed.\n *\n * On Node.js this uses setImmediate instead of requestAnimationFrame.\n *\n * This is simply a sugar method so that users can do the following:\n * `await tf.nextFrame();`\n *\n * @doc {heading: 'Performance', subheading: 'Timing'}\n */\nfunction nextFrame() {\n    return new Promise(resolve => delayCallback(() => resolve()));\n}\nexport { nextFrame };\n//# sourceMappingURL=browser_util.js.map"],"names":["opHandler","buffer","cast","clone","print","TENSORFLOWJS_FLAGS_PREFIX","Environment","constructor","global","this","flags","flagRegistry","urlFlags","getQueryParams","populateURLFlags","setPlatform","platformName","platform","registerFlag","flagName","evaluationFn","setHook","flagValue","set","getAsync","evaluateFlag","get","Error","getNumber","getBool","getFlags","features","value","setFlags","Object","assign","reset","location","search","urlParams","split","forEach","keyValue","key","toLowerCase","parseValue","queryString","params","replace","s","t","name","decodeURIComponent","decodeParam","join","env","ENV","setEnvironmentGlobal","environment","debugValue","process","versions","node","navigator","userAgent","test","vendor","isRegisteredKernelInvocation","kernelInvocation","kernelName","EngineState","registeredVariables","nextTapeNodeId","numBytes","numTensors","numStringTensors","numDataBuffers","gradientDepth","kernelDepth","scopeStack","numDataMovesStack","nextScopeId","tensorInfo","WeakMap","profiling","activeProfile","newBytes","newTensors","peakBytes","kernels","result","kernelNames","Array","from","Set","map","k","dispose","variableName","Engine","registry","registryFactory","pendingBackendInitId","state","ready","pendingBackendInit","then","backendInstance","sortedBackends","getSortedBackends","i","length","backendName","initializeBackend","success","setBackend","backend","asyncInit","initializeBackendsAndReturnBest","backendNames","keys","findBackend","findBackendFactory","factory","registerBackend","priority","setupRegisteredKernels","profiler","kernel","setupFunc","disposeRegisteredKernels","disposeFunc","registryFactoryEntry","promiseId","catch","err","removeBackend","sort","a","b","moveData","dataId","info","srcBackend","values","readSync","refCount","disposeData","move","shape","dtype","shouldCheckForMemLeaks","tidy","nameOrFn","fn","String","scopedRun","startScope","endScope","start","end","f","res","ex","nextTensorId","nextVariableId","x","y","ENGINE","runKernel","inputs","addTapeNode","activeScope","dy","gradInputs","attrs","runKernelFunc","checkKernelForMemLeak","numDataIdsBefore","outInfos","numDataIdsAfter","numDataIds","numOutputDataIds","numMoves","dataIdsLeaked","kernelParams","outputs","saved","isTapeOn","startingBytecount","startingNumTensors","kernelFunc","out","push","kernelOrScopeName","isArray","outTensors","outInfo","rank","makeTensorFromDataId","tensorsToSave","getTensorsForGradient","saveTensorsForBackwardMode","forwardFunc","saveFunc","tensors","tensor","keep","outs","backwardsFunc","kernelProfile","profileKernel","logKernelProfile","bytesAdded","totalBytesSnapshot","tensorsAdded","totalTensorsSnapshot","inputShapes","outputShapes","item","kernelTimeMs","timeMs","extraInfo","gradConfig","inputsToSave","outputsToSave","inputTensorsToSave","saveAllInputs","inputName","outputTensorsToSave","filter","_","concat","makeTensor","backendVals","d","write","trackTensor","bytes","makeVariable","initialValue","trainable","toString","v","incRef","size","has","track","removeDataId","delete","disposeTensor","disposeVariables","varName","disposeVariable","memory","unreliable","reasons","profile","query","startBytes","startNumTensors","Math","max","gradientsFunc","tapeNode","id","gradFunc","gradient","dys","output","vals","activeTape","kept","startTape","endTape","scopeInfo","tensorsToTrackInParent","getTensorsInContainer","tensorsToTrackInParentSet","oldScope","pop","scopeId","gradients","xs","allowNoGradients","filteredTape","accumulatedGradientMap","ones","add","grads","customGrad","every","inputMap","input","save","gradRes","gradMap","grad","read","time","now","timingInfo","wallMs","getOrMakeEngine","ns","_tfengine","isMobile","nav","product","window","opera","substr","isBrowser","document","WorkerGlobalScope","delayCallback","requestAnimationFrame","setImmediate","nextFrame","Promise","resolve"],"sourceRoot":""}