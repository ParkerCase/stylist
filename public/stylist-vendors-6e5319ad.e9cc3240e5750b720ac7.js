"use strict";(self.webpackChunkStylistWidget=self.webpackChunkStylistWidget||[]).push([[5151],{12629:function(t,e,i){var s=i(9495),n=i(47661),r=i(87504),a=i(79730),l=i(15841),o=i(59351),u=i(84379),h=i(44813),c=i(63057);class p extends a.Wd{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==t.batchInputShape&&null==t.inputShape){let e=null;null!=t.batchSize&&(e=t.batchSize),null==t.inputLength?this.batchInputShape=[e,null]:this.batchInputShape=[e].concat(h.st(t.inputLength))}this.inputDim=t.inputDim,h.oo(this.inputDim,"inputDim"),this.outputDim=t.outputDim,h.oo(this.outputDim,"outputDim"),this.embeddingsInitializer=(0,o.Fe)(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=(0,u.Bm)(t.embeddingsRegularizer),this.activityRegularizer=(0,u.Bm)(t.activityRegularizer),this.embeddingsConstraint=(0,r.YZ)(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return(0,s.tidy)((()=>this.maskZero?(t=(0,c.un)(t),(0,s.notEqual)(t,(0,s.zerosLike)(t))):null))}computeOutputShape(t){if(t=(0,c.U$)(t),null==this.inputLength)return[...t,this.outputDim];const e=h.st(this.inputLength);if(e.length!==t.length-1)throw new l.Qp(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);{let i=0;for(let s=0;s<e.length;++s){const n=e[s],r=t[s+1];if(null!=n&&null!=r&&n!==r)throw new l.Qp(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);null==n&&(e[i]=r),i++}}return[t[0],...e,this.outputDim]}call(t,e){return(0,s.tidy)((()=>{this.invokeCallHook(t,e);let i=(0,c.un)(t);"int32"!==i.dtype&&(i=n.wg(i,"int32"));return n.kg(this.embeddings.read(),i.as1D()).reshape((0,c.U$)(this.computeOutputShape(i.shape)))}))}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:(0,o.zo)(this.embeddingsInitializer),embeddingsRegularizer:(0,u.R9)(this.embeddingsRegularizer),activityRegularizer:(0,u.R9)(this.activityRegularizer),embeddingsConstraint:(0,r.uH)(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}p.className="Embedding",s.serialization.registerClass(p)},28098:function(t,e,i){var s=i(9495),n=i(87504),r=i(79730),a=i(15841),l=i(59351),o=i(84379),u=i(44813),h=i(73072),c=i(63057);function p(t,e,i,n,r,l=.001){let o;if(2===t.rank)o=s.batchNorm2d(t,e,i,n,r,l);else if(3===t.rank)o=s.batchNorm3d(t,e,i,n,r,l);else{if(4!==t.rank)throw new a.EH(`batchNormalization is not implemented for array of rank ${t.rank} yet`);o=s.batchNorm4d(t,e,i,n,r,l)}return o}function g(t,e,i,n,r=.001){return s.util.arraysEqual(n.slice().sort(),h.y1(0,t.rank-1))?function(t,e,i,n,r=.001){return(0,s.tidy)((()=>{const a=s.moments(t,n),l=a.mean,o=a.variance;return[p(t,l,o,i,e,r),l,o]}))}(t,e,i,n,r):function(t,e,i,n,r=.001){return(0,s.tidy)((()=>{const a=s.moments(t,n),l=a.mean,o=a.variance,u=[];for(const e of h.y1(0,t.rank))-1!==n.indexOf(e)?u.push(1):u.push(t.shape[e]);const c=l.reshape(u),g=o.reshape(u),d=null==e?null:e.reshape(u),m=null==i?null:i.reshape(u);return[p(t,c,g,m,d,r),l,o]}))}(t,e,i,n,r)}class d extends r.Wd{constructor(t){null==t&&(t={}),super(t),this.supportsMasking=!0,this.axis=null==t.axis?-1:t.axis,this.momentum=null==t.momentum?.99:t.momentum,this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=(0,l.Fe)(t.betaInitializer||"zeros"),this.gammaInitializer=(0,l.Fe)(t.gammaInitializer||"ones"),this.movingMeanInitializer=(0,l.Fe)(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=(0,l.Fe)(t.movingVarianceInitializer||"ones"),this.betaConstraint=(0,n.YZ)(t.betaConstraint),this.gammaConstraint=(0,n.YZ)(t.gammaConstraint),this.betaRegularizer=(0,o.Bm)(t.betaRegularizer),this.gammaRegularizer=(0,o.Bm)(t.gammaRegularizer)}build(t){t=(0,c.U$)(t);const e=this.axis>=0?this.axis:this.axis+t.length,i=t[e];if(null==i)throw new a.Qp(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);this.inputSpec=[new r.eO({ndim:t.length,axes:{[e]:i}})];const s=[i];this.scale&&(this.gamma=this.addWeight("gamma",s,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",s,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",s,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",s,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return(0,s.tidy)((()=>{const i=null!=e.training&&e.training,n=(0,c.un)(t),r=n.shape,a=r.length,l=h.y1(0,a),o=this.axis>=0?this.axis:this.axis+a;l.splice(o,1);const d=u.fD(1,a);d[o]=r[o];const m=l.slice();m.sort();const f=!s.util.arraysEqual(m,h.y1(0,a).slice(0,a-1));if(!i)return(()=>{if(f){const t=this.movingMean.read().reshape(d),e=this.movingVariance.read().reshape(d),i=this.center?this.beta.read().reshape(d):null,s=this.scale?this.gamma.read().reshape(d):null;return p(n,t,e,i,s,this.epsilon)}return p(n,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[z,b,y]=g(n,this.gamma.read(),this.beta.read(),l,this.epsilon),S=(t,e,i)=>{s.tidy((()=>{const s=1-i,n=t.read(),r=n.sub(e).mul(s);t.write(n.sub(r))}))};return(()=>{S(this.movingMean,b,this.momentum),S(this.movingVariance,y,this.momentum)})(),z}))}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:(0,l.zo)(this.betaInitializer),gammaInitializer:(0,l.zo)(this.gammaInitializer),movingMeanInitializer:(0,l.zo)(this.movingMeanInitializer),movingVarianceInitializer:(0,l.zo)(this.movingVarianceInitializer),betaRegularizer:(0,o.R9)(this.betaRegularizer),gammaRegularizer:(0,o.R9)(this.gammaRegularizer),betaConstraint:(0,n.uH)(this.betaConstraint),gammaConstraint:(0,n.uH)(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}d.className="BatchNormalization",s.serialization.registerClass(d);class m extends r.Wd{constructor(t){if(null==t&&(t={}),super(t),this.axis=null==t.axis?-1:t.axis,"number"===typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const t of this.axis)if(!Number.isInteger(t))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=(0,l.Fe)(t.betaInitializer||"zeros"),this.gammaInitializer=(0,l.Fe)(t.gammaInitializer||"ones"),this.betaRegularizer=(0,o.Bm)(t.betaRegularizer),this.gammaRegularizer=(0,o.Bm)(t.gammaRegularizer),this.supportsMasking=!0}build(t){const e=(t=(0,c.U$)(t)).length;"number"===typeof this.axis&&(this.axis=[this.axis]);for(let n=0;n<this.axis.length;++n)this.axis[n]<0&&(this.axis[n]+=e);for(const n of this.axis)if(n<0||n>=e)throw new Error(`Invalid axis: ${n}`);if(this.axis.length!==u.Am(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const i=this.axis.map((e=>t[e])),s=!0;this.scale?this.gamma=this.addWeight("gamma",i,"float32",this.gammaInitializer,this.gammaRegularizer,s):this.gamma=null,this.center?this.beta=this.addWeight("beta",i,"float32",this.betaInitializer,this.betaRegularizer,s):this.beta=null,this.built=!0}call(t,e){const i=(0,c.un)(t),n=i.shape,r=n.length;return(0,s.tidy)((()=>{let{mean:t,variance:e}=(0,s.moments)(i,this.axis,!0);const a=u.fD(1,r);for(const i of this.axis)a[i]=n[i];const l=t=>null!=t&&t.shape.length!==r&&this.axis!==[r-1]?t.reshape(a):t;let o=l(this.gamma.read()),h=l(this.beta.read());const c=[],g=[];for(let i=0;i<r;++i)-1!==this.axis.indexOf(i)?(c.push(n[i]),g.push(1)):(c.push(1),g.push(n[i]));return t=t.tile(c),e=e.tile(c),o=o.tile(g),h=h.tile(g),p(i,t,e,h,o,this.epsilon)}))}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:(0,l.zo)(this.betaInitializer),gammaInitializer:(0,l.zo)(this.gammaInitializer),betaRegularizer:(0,o.R9)(this.betaRegularizer),gammaRegularizer:(0,o.R9)(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}m.className="LayerNormalization",s.serialization.registerClass(m)},36165:function(t,e,i){var s=i(9495),n=i(47661),r=i(79730),a=i(63057);class l extends r.Wd{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return(0,s.tidy)((()=>{this.invokeCallHook(t,e);const i=(0,a.un)(t);return n.Ls((()=>n.FE(i.shape,0,this.stddev).add(i)),(()=>i),e.training||!1)}))}}l.className="GaussianNoise",s.serialization.registerClass(l);class o extends r.Wd{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return(0,s.tidy)((()=>{this.invokeCallHook(t,e);const i=(0,a.un)(t);if(this.rate>0&&this.rate<1){const t=()=>{const t=Math.sqrt(this.rate/(1-this.rate));return i.mul(n.FE(i.shape,1,t))};return n.Ls(t,(()=>i),e.training||!1)}return i}))}}o.className="GaussianDropout",s.serialization.registerClass(o);class u extends r.Wd{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||(0,a.un)(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return(0,s.tidy)((()=>{if(this.rate<1&&this.rate>0){const i=this._getNoiseShape(t),r=()=>{const e=(0,a.un)(t),r=-1.7580993408473766;let l=(0,s.greaterEqual)((0,s.randomUniform)(i),this.rate);l=n.wg(l,"float32");const o=((1-this.rate)*(1+this.rate*r**2))**-.5,u=-o*r*this.rate;return e.mul(l).add(l.add(-1).mul(r)).mul(o).add(u)};return n.Ls(r,(()=>(0,a.un)(t)),e.training||!1)}return t}))}}u.className="AlphaDropout",s.serialization.registerClass(u)},47477:function(t,e,i){var s=i(9495),n=i(6090),r=i(47661),a=i(39459),l=i(79730),o=i(15841),u=i(69184),h=i(44813),c=i(63057),p=i(9548);function g(t,e,i,r,l,o){return(0,s.tidy)((()=>{let u;(0,a.uM)(l),(0,a.Kx)(o),(0,a.tB)(r),null==i&&(i=[1,1]),null==r&&(r="valid"),null==l&&(l=(0,n.VI)()),null==o&&(o="max"),t=(0,p.RK)(t,l);const h="same"===r?"same":"valid";return u="max"===o?s.maxPool(t,e,i,h):s.avgPool(t,e,i,h),"channelsFirst"===l&&(u=s.transpose(u,[0,3,1,2])),u}))}function d(t,e,i,r,l,o){return(0,s.tidy)((()=>{let u;(0,a.uM)(l),(0,a.Kx)(o),(0,a.tB)(r),null==i&&(i=[1,1,1]),null==r&&(r="valid"),null==l&&(l=(0,n.VI)()),null==o&&(o="max"),t=(0,p.al)(t,l);const h="same"===r?"same":"valid";return u="max"===o?s.maxPool3d(t,e,i,h):s.avgPool3d(t,e,i,h),"channelsFirst"===l&&(u=s.transpose(u,[0,4,1,2,3])),u}))}class m extends l.Wd{constructor(t){if(null==t.poolSize&&(t.poolSize=2),super(t),"number"===typeof t.poolSize)this.poolSize=[t.poolSize];else{if(!Array.isArray(t.poolSize)||1!==t.poolSize.length||"number"!==typeof t.poolSize[0])throw new o.Qp(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);this.poolSize=t.poolSize}if((0,h.oo)(this.poolSize,"poolSize"),null==t.strides)this.strides=this.poolSize;else if("number"===typeof t.strides)this.strides=[t.strides];else{if(!Array.isArray(t.strides)||1!==t.strides.length||"number"!==typeof t.strides[0])throw new o.Qp(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);this.strides=t.strides}(0,h.oo)(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,(0,a.tB)(this.padding),this.inputSpec=[new l.eO({ndim:3})]}computeOutputShape(t){t=(0,c.U$)(t);const e=(0,u.Ol)(t[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return(0,s.tidy)((()=>{this.invokeCallHook(t,e),t=r.UG((0,c.un)(t),2);const i=this.poolingFunction((0,c.un)(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return s.squeeze(i,[2])}))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides},e=super.getConfig();return Object.assign(t,e),t}}class f extends m{constructor(t){super(t)}poolingFunction(t,e,i,s,n){return(0,a.uM)(n),(0,a.tB)(s),g(t,e,i,s,n,"max")}}f.className="MaxPooling1D",s.serialization.registerClass(f);class z extends m{constructor(t){super(t)}poolingFunction(t,e,i,s,n){return(0,a.uM)(n),(0,a.tB)(s),g(t,e,i,s,n,"avg")}}z.className="AveragePooling1D",s.serialization.registerClass(z);class b extends l.Wd{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(2!==t.strides.length)throw new o.Qp(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides];(0,h.oo)(this.poolSize,"poolSize"),(0,h.oo)(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,a.uM)(this.dataFormat),(0,a.tB)(this.padding),this.inputSpec=[new l.eO({ndim:4})]}computeOutputShape(t){t=(0,c.U$)(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],i="channelsFirst"===this.dataFormat?t[3]:t[2];return e=(0,u.Ol)(e,this.poolSize[0],this.padding,this.strides[0]),i=(0,u.Ol)(i,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,i]:[t[0],e,i,t[3]]}call(t,e){return(0,s.tidy)((()=>(this.invokeCallHook(t,e),this.poolingFunction((0,c.un)(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class y extends b{constructor(t){super(t)}poolingFunction(t,e,i,s,n){return(0,a.uM)(n),(0,a.tB)(s),g(t,e,i,s,n,"max")}}y.className="MaxPooling2D",s.serialization.registerClass(y);class S extends b{constructor(t){super(t)}poolingFunction(t,e,i,s,n){return(0,a.uM)(n),(0,a.tB)(s),g(t,e,i,s,n,"avg")}}S.className="AveragePooling2D",s.serialization.registerClass(S);class A extends l.Wd{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(3!==t.strides.length)throw new o.Qp(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];(0,h.oo)(this.poolSize,"poolSize"),(0,h.oo)(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,a.uM)(this.dataFormat),(0,a.tB)(this.padding),this.inputSpec=[new l.eO({ndim:5})]}computeOutputShape(t){t=(0,c.U$)(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],i="channelsFirst"===this.dataFormat?t[3]:t[2],s="channelsFirst"===this.dataFormat?t[4]:t[3];return e=(0,u.Ol)(e,this.poolSize[0],this.padding,this.strides[0]),i=(0,u.Ol)(i,this.poolSize[1],this.padding,this.strides[1]),s=(0,u.Ol)(s,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,i,s]:[t[0],e,i,s,t[4]]}call(t,e){return(0,s.tidy)((()=>(this.invokeCallHook(t,e),this.poolingFunction((0,c.un)(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class I extends A{constructor(t){super(t)}poolingFunction(t,e,i,s,n){return(0,a.uM)(n),(0,a.tB)(s),d(t,e,i,s,n,"max")}}I.className="MaxPooling3D",s.serialization.registerClass(I);class k extends A{constructor(t){super(t)}poolingFunction(t,e,i,s,n){return(0,a.uM)(n),(0,a.tB)(s),d(t,e,i,s,n,"avg")}}k.className="AveragePooling3D",s.serialization.registerClass(k);class C extends l.Wd{constructor(t){super(t),this.inputSpec=[new l.eO({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new o.EH}}class R extends C{constructor(t){super(t||{})}call(t,e){return(0,s.tidy)((()=>{const e=(0,c.un)(t);return s.mean(e,1)}))}}R.className="GlobalAveragePooling1D",s.serialization.registerClass(R);class w extends C{constructor(t){super(t||{})}call(t,e){return(0,s.tidy)((()=>{const e=(0,c.un)(t);return s.max(e,1)}))}}w.className="GlobalMaxPooling1D",s.serialization.registerClass(w);class x extends l.Wd{constructor(t){super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,a.uM)(this.dataFormat),this.inputSpec=[new l.eO({ndim:4})]}computeOutputShape(t){return"channelsLast"===this.dataFormat?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new o.EH}getConfig(){const t={dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class v extends x{call(t,e){return(0,s.tidy)((()=>{const e=(0,c.un)(t);return"channelsLast"===this.dataFormat?s.mean(e,[1,2]):s.mean(e,[2,3])}))}}v.className="GlobalAveragePooling2D",s.serialization.registerClass(v);class D extends x{call(t,e){return(0,s.tidy)((()=>{const e=(0,c.un)(t);return"channelsLast"===this.dataFormat?s.max(e,[1,2]):s.max(e,[2,3])}))}}D.className="GlobalMaxPooling2D",s.serialization.registerClass(D)},47483:function(t,e,i){var s=i(9495),n=i(47661),r=i(79730),a=i(15841),l=i(48981),o=i(44813),u=i(73072),h=i(63057);class c extends r.Wd{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new a.EH}computeElementwiseOpOutputShape(t,e){if(null==t||null==e)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(0===e.length)return t;const i=t.slice(0,t.length-e.length);for(let s=0;s<e.length;++s){const n=t[t.length-e.length+s],r=e[s];if(null==n||null==r||n<0||r<0)i.push(null);else if(1===n)i.push(r);else if(1===r)i.push(n);else{if(n!==r)throw new a.Qp("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));i.push(n)}}return i}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[(0,h.U$)(t)]),t.length<2)throw new a.Qp(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const n of t)null!=n&&null!==n[0]&&e.push(n[0]);if(e=o.Am(e),e.length>1)throw new a.Qp(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let i=null==t[0]?null:t[0].slice(1);for(let n=1;n<t.length;++n){const e=null==t[n]?null:t[n].slice(1);i=this.computeElementwiseOpOutputShape(i,e)}const s=t.map((t=>t.length));-1===t.indexOf(null)&&1===o.Am(s).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(t,e){return(0,s.tidy)((()=>{if(this.reshapeRequired){const e=[],i=t.map((t=>t.rank));if(-1===i.indexOf(null)){const s=u.T9(i);for(let i of t){const t=i.rank;for(let e=0;e<s-t;++e)i=n.UG(i,1);e.push(i)}return this.mergeFunction(e)}{let i=!1;for(const a of t){const t=a.rank;if(null==t){const t=a.shape,n=t[0],r=t.slice(1).concat([n]);let l=a.reshape([n].concat(u.no(t.slice(1))));l=s.transpose(l,[1,0]),l=l.reshape(r),e.push(l),i=!0}else if(t>1){const n=u.y1(1,t).concat([0]);e.push(s.transpose(a,n)),i=!0}else e.push(a)}let n=this.mergeFunction(e);const r=n.rank;if(i)if(null==r){const t=n.shape,e=t[t.length-1],i=[e].concat(t.slice(0,t.length-1));n=s.transpose(n.reshape([-1,e]),[1,0]).reshape(i)}else if(r>1){const t=[r-1].concat(u.y1(0,r-1));n=s.transpose(n,t)}return n}}return this.mergeFunction(t)}))}computeOutputShape(t){let e;e=null==t[0]?null:t[0].slice(1);for(let s=1;s<t.length;++s){const i=null==t[s]?null:t[s].slice(1);e=this.computeElementwiseOpOutputShape(e,i)}let i=[];for(const s of t)null!=s&&null!==s[0]&&i.push(s[0]);return i=o.Am(i),e=1===i.length?i.concat(e):[null].concat(e),e}computeMask(t,e){return s.tidy((()=>{if(null==e)return null;if(!Array.isArray(e))throw new a.Qp("`mask` should be an Array");if(!Array.isArray(t))throw new a.Qp("`inputs` should be an Array");if(e.length!==t.length)throw new a.Qp(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every((t=>null==t)))return null;let i=(e=e.map((t=>null==t?t:s.expandDims(t,0))))[0];for(let t=1;t<e.length-1;++t)i=s.logicalAnd(i,e[t]);return i}))}}class p extends c{constructor(t){super(t)}mergeFunction(t){return(0,s.tidy)((()=>{let e=t[0].clone();for(let i=1;i<t.length;++i)e=s.add(e,t[i]);return e}))}}p.className="Add",s.serialization.registerClass(p);class g extends c{constructor(t){super(t)}mergeFunction(t){return(0,s.tidy)((()=>{let e=t[0].clone();for(let i=1;i<t.length;++i)e=s.mul(e,t[i]);return e}))}}g.className="Multiply",s.serialization.registerClass(g);class d extends c{constructor(t){super(t)}mergeFunction(t){return(0,s.tidy)((()=>{let e=t[0].clone();for(let i=1;i<t.length;++i)e=s.add(e,t[i]);return s.mul(1/t.length,e)}))}}d.className="Average",s.serialization.registerClass(d);class m extends c{constructor(t){super(t)}mergeFunction(t){return(0,s.tidy)((()=>{let e=t[0];for(let i=1;i<t.length;++i)e=s.maximum(e,t[i]);return e}))}}m.className="Maximum",s.serialization.registerClass(m);class f extends c{constructor(t){super(t)}mergeFunction(t){return(0,s.tidy)((()=>{let e=t[0];for(let i=1;i<t.length;++i)e=s.minimum(e,t[i]);return e}))}}f.className="Minimum",s.serialization.registerClass(f);class z extends c{constructor(t){super(t),this.DEFAULT_AXIS=-1,null==t&&(t={}),this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new a.Qp("A `Concatenate` layer should be called on a list of at least 2 inputs");let e=!0;for(const s of t)if(null!=s){e=!1;break}if(e)return;const i=[];for(let n=0;n<t.length;++n){const e=t[n].slice();e.splice(this.axis,1);let r=!1;for(const t of i)if(s.util.arraysEqual(t,e)){r=!0;break}r||i.push(e)}if(i.length>1)throw new a.Qp("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return(0,s.tidy)((()=>n.u1(t,this.axis)))}computeOutputShape(t){if(!Array.isArray(t)||!Array.isArray(t[0]))throw new a.Qp("A `Concatenate` layer should be called on a list of inputs.");const e=t,i=e[0].slice(),s=this.axis<0?i.length+this.axis:this.axis;for(const n of e.slice(1)){if(null==i[s]||null==n[s]){i[s]=null;break}i[s]+=n[s]}return i}computeMask(t,e){if(null==e)return null;if(!Array.isArray(e))throw new a.Qp("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new a.Qp("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new a.Qp(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return s.tidy((()=>{let i=!0;if(e.forEach((t=>{null==t||(i=!1)})),i)return null;const n=[];for(let a=0;a<t.length;++a)null==e[a]?n.push(s.onesLike(t[a]).asType("bool")):e[a].rank<t[a].rank?n.push(s.expandDims(e[a],-1)):n.push(e[a]);const r=s.concat(n,this.axis);return s.all(r,-1,!1)}))}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function b(t,e){for(;t<0;)t+=e;return t}z.className="Concatenate",s.serialization.registerClass(z);class y extends c{constructor(t){super(t),this.axes=t.axes,this.normalize=null!=t.normalize&&t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){s.util.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0],i=t[1];if(e.length>3||i.length>3)throw new a.EH("Dot layer does not support tensors of 4D or higher rank yet.");const n=this.interpretAxes(e,i);if(e[n[0]]!==i[n[1]])throw new a.Qp(`Dimension incompatibility: ${e[n[0]]} !== ${i[n[1]]}`)}mergeFunction(t){if(2!==t.length)throw new a.Qp(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e,i=t[0],n=t[1];return e=Array.isArray(this.axes)?this.axes.map(((e,i)=>b(e,t[i].shape.length))):[b(this.axes,i.shape.length),b(this.axes,n.shape.length)],this.normalize&&(i=(0,l.Yq)(i,e[0]),n=(0,l.Yq)(n,e[1])),function(t,e,i){if(t.shape.length>3||e.shape.length>3)throw new a.EH("batchDot is not implemented for tensors of 4D or higher rank yet");if(s.util.assert(t.shape.length>=2,(()=>`batchDot requires the rank of x to be >= 2, but got ${t.shape.length}`)),s.util.assert(t.shape.length>=2,(()=>`batchDot requires the rank of y to be >= 2, but got ${e.shape.length}`)),"number"===typeof i&&(i=[i,i]),"complex64"===t.dtype||"complex64"===e.dtype)throw new a.EH("batchDot is not implemented for complex64-type Tensors yet.");const n=t.shape.length,r=e.shape.length;null==i&&(i=[n-1,r-2]);const l=i;return s.tidy((()=>{let i,s;if(n>r){i=n-r;const t=[];for(let e=0;e<i;++e)t.push(1);e=e.reshape(e.shape.concat(t))}else if(r>n){i=r-n;const e=[];for(let t=0;t<i;++t)e.push(1);t=t.reshape(t.shape.concat(e))}else i=0;if(2===t.shape.length&&2===e.shape.length)s=l[0]===l[1]?t.mul(e).sum(l[0]):t.transpose([1,0]).mul(e).sum(l[1]);else{const i=l[0]!==t.shape.length-1,n=l[1]===e.shape.length-1;s=t.matMul(e,i,n)}if(i>0){let t;t=n>r?n+r-3:n-1;const e=[];for(let s=t;s<t+i;++s)e.push(s);s=s.squeeze(e)}return 1===s.shape.length&&(s=s.expandDims(1)),s}))}(i,n,e)}interpretAxes(t,e){let i;return i=Array.isArray(this.axes)?this.axes:[b(this.axes,t.length),b(this.axes,e.length)],i}computeOutputShape(t){s.util.assert(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0].slice(),i=t[1].slice();if(e.length>3||i.length>3)throw new a.EH("Dot layer does not support tensors of 4D or higher rank yet.");const n=this.interpretAxes(e,i);e.splice(n[0],1),i.splice(n[1],1),i.splice(0,1);const r=e.concat(i);return 1===r.length&&r.push(1),r}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}y.className="Dot",s.serialization.registerClass(y)},55795:function(t,e,i){i.d(e,{i:function(){return r}});var s=i(9495),n=i(44813);function r(t,e={},i=!1){return(0,n.Xv)(t,s.serialization.SerializationMap.getMap().classNameMap,e,"layer",i)}},76481:function(t,e,i){i.d(e,{FW:function(){return v},L7:function(){return b},Tu:function(){return R},VS:function(){return y},tL:function(){return z}});var s=i(9495),n=i(59885),r=i(47661),a=i(39459),l=i(87504),o=i(79730),u=i(15841),h=i(59351),c=i(84379),p=i(44813),g=i(73072),d=i(63057),m=i(71765),f=i(55795);function z(t,e,i,s){if(Array.isArray(t)){if(null!=e||null!=i)throw new u.Qp("When inputs is an array, neither initialState or constants should be provided");null!=s&&(i=t.slice(t.length-s,t.length),t=t.slice(0,t.length-s)),t.length>1&&(e=t.slice(1,t.length)),t=t[0]}function n(t){return null==t||Array.isArray(t)?t:[t]}return{inputs:t,initialState:e=n(e),constants:i=n(i)}}function b(t,e,i,n=!1,r,a,l=!1,o=!1){return s.tidy((()=>{const l=e.shape.length;if(l<3)throw new u.Qp(`Input should be at least 3D, but is ${l}D.`);const h=[1,0].concat(g.y1(2,l));if(e=s.transpose(e,h),null!=a)throw new u.EH("The rnn() functoin of the deeplearn.js backend does not support constants yet.");null!=r&&((r=r.asType("bool").asType("float32")).rank===l-1&&(r=s.expandDims(r,-1)),r=s.transpose(r,h)),n&&(e=s.reverse(e,0),null!=r&&(r=s.reverse(r,0)));const c=[];let p,d=i;const m=e.shape[0],f=s.unstack(e);let z,b;null!=r&&(z=s.unstack(r));for(let e=0;e<m;++e){const i=f[e],n=s.tidy((()=>t(i,d)));if(null==r)p=n[0],d=n[1];else{const t=s.tidy((()=>{const t=z[e],i=s.onesLike(t).sub(t);return{output:n[0].mul(t).add(d[0].mul(i)),newStates:d.map(((e,s)=>n[1][s].mul(t).add(e.mul(i))))}}));p=t.output,d=t.newStates}o&&c.push(p)}if(o){const t=1;b=s.stack(c,t)}return[p,b,d]}))}class y extends o.Wd{constructor(t){let e;if(super(t),null==t.cell)throw new u.Qp("cell property is missing for the constructor of RNN.");if(e=Array.isArray(t.cell)?new x({cells:t.cell}):t.cell,null==e.stateSize)throw new u.Qp("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=null!=t.returnSequences&&t.returnSequences,this.returnState=null!=t.returnState&&t.returnState,this.goBackwards=null!=t.goBackwards&&t.goBackwards,this._stateful=null!=t.stateful&&t.stateful,this.unroll=null!=t.unroll&&t.unroll,this.supportsMasking=!0,this.inputSpec=[new o.eO({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;return g.y1(0,t).map((t=>null))}return this.states_}setStates(t){this.states_=t}computeOutputShape(t){(0,d.TT)(t)&&(t=t[0]);let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const i=e[0];let s;if(s=this.returnSequences?[t[0],t[1],i]:[t[0],i],this.returnState){const i=[];for(const s of e)i.push([t[0],s]);return[s].concat(i)}return s}computeMask(t,e){return s.tidy((()=>{Array.isArray(e)&&(e=e[0]);const t=this.returnSequences?e:null;if(this.returnState){const e=this.states.map((t=>null));return[t].concat(e)}return t}))}get states(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let i=0;i<t;++i)e.push(null);return e}return this.states_}set states(t){this.states_=t}build(t){if(null!=this.numConstants)throw new u.EH("Constants support is not implemented in RNN yet.");(0,d.TT)(t)&&(t=t[0]);const e=this.stateful?t[0]:null,i=t.slice(2);this.inputSpec[0]=new o.eO({shape:[e,null,...i]});const n=[t[0]].concat(t.slice(2));let r;if(this.cell.build(n),r=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!s.util.arraysEqual(this.stateSpec.map((t=>t.shape[t.shape.length-1])),r))throw new u.Qp(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=r.map((t=>new o.eO({shape:[null,t]})));this.stateful&&this.resetStates()}resetStates(t,e=!1){(0,s.tidy)((()=>{if(!this.stateful)throw new u.l7("Cannot call resetStates() on an RNN Layer that is not stateful.");const i=this.inputSpec[0].shape[0];if(null==i)throw new u.Qp("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>s.zeros([i,t]))):this.states_=[s.zeros([i,this.cell.stateSize])];else if(null==t)s.dispose(this.states_),null!=this.keptStates&&(s.dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>s.zeros([i,t]))):this.states_[0]=s.zeros([i,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new u.Qp(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);!0===e?this.keptStates.push(this.states_.slice()):s.dispose(this.states_);for(let e=0;e<this.states_.length;++e){const n=t[e],r=Array.isArray(this.cell.stateSize)?this.cell.stateSize[e]:this.cell.stateSize,a=[i,r];if(!s.util.arraysEqual(n.shape,a))throw new u.Qp(`State ${e} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${n.shape}`);this.states_[e]=n}}this.states_=this.states_.map((t=>s.keep(t.clone())))}))}apply(t,e){let i=null==e?null:e.initialState,s=null==e?null:e.constants;null==e&&(e={});const n=z(t,i,s,this.numConstants);t=n.inputs,i=n.initialState,s=n.constants;let r=[],a=[];if(null!=i){e.initialState=i,r=r.concat(i),this.stateSpec=[];for(const t of i)this.stateSpec.push(new o.eO({shape:t.shape}));a=a.concat(this.stateSpec)}null!=s&&(e.constants=s,r=r.concat(s),this.numConstants=s.length);if(r[0]instanceof o.Ar){const i=[t].concat(r),s=this.inputSpec.concat(a),n=this.inputSpec;this.inputSpec=s;const l=super.apply(i,e);return this.inputSpec=n,l}return super.apply(t,e)}call(t,e){return(0,s.tidy)((()=>{const i=null==e?null:e.mask,s=null==e?null:e.training;let n=null==e?null:e.initialState;t=(0,d.un)(t),null==n&&(n=this.stateful?this.states_:this.getInitialState(t));const r=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(n.length!==r)throw new u.Qp(`RNN Layer has ${r} state(s) but was passed ${n.length} initial state(s).`);this.unroll;const a={training:s},l=b(((t,e)=>{const i=this.cell.call([t].concat(e),a);return[i[0],i.slice(1)]}),t,n,this.goBackwards,i,null,this.unroll,this.returnSequences),o=l[0],h=l[1],c=l[2];this.stateful&&this.resetStates(c,s);const p=this.returnSequences?h:o;return this.returnState?[p].concat(c):p}))}getInitialState(t){return(0,s.tidy)((()=>{let e=s.zeros(t.shape);return e=s.sum(e,[1,2]),e=r.UG(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map((t=>t>1?r.Vs(e,[1,t]):e)):this.cell.stateSize>1?[r.Vs(e,[1,this.cell.stateSize])]:[e]}))}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(e.numConstants=this.numConstants);const i=this.cell.getConfig();return this.getClassName()===y.className&&(e.cell={className:this.cell.getClassName(),config:i}),Object.assign({},i,t,e)}static fromConfig(t,e,i={}){const s=e.cell,n=(0,f.i)(s,i);return new t(Object.assign(e,{cell:n}))}}y.className="RNN",s.serialization.registerClass(y);class S extends o.Wd{}class A extends S{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,(0,p.oo)(this.units,"units"),this.activation=(0,n.b_)(null==t.activation?this.DEFAULT_ACTIVATION:t.activation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=(0,h.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=(0,h.Fe)(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=(0,h.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=(0,c.Bm)(t.kernelRegularizer),this.recurrentRegularizer=(0,c.Bm)(t.recurrentRegularizer),this.biasRegularizer=(0,c.Bm)(t.biasRegularizer),this.kernelConstraint=(0,l.YZ)(t.kernelConstraint),this.recurrentConstraint=(0,l.YZ)(t.recurrentConstraint),this.biasConstraint=(0,l.YZ)(t.biasConstraint),this.dropout=g.jk([1,g.T9([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=g.jk([1,g.T9([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=(0,d.U$)(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return(0,s.tidy)((()=>{if(2!==t.length)throw new u.Qp(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let i=t[1];t=t[0];const n=null!=e.training&&e.training;let a;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=v({ones:()=>s.onesLike(t),rate:this.dropout,training:n})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=v({ones:()=>s.onesLike(i),rate:this.recurrentDropout,training:n}));const l=this.dropoutMask,o=this.recurrentDropoutMask;a=null!=l?r.Om(s.mul(t,l),this.kernel.read()):r.Om(t,this.kernel.read()),null!=this.bias&&(a=r.ni(a,this.bias.read())),null!=o&&(i=s.mul(i,o));let h=s.add(a,r.Om(i,this.recurrentKernel.read()));return null!=this.activation&&(h=this.activation.apply(h)),[h,h]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:(0,n.Bu)(this.activation),useBias:this.useBias,kernelInitializer:(0,h.zo)(this.kernelInitializer),recurrentInitializer:(0,h.zo)(this.recurrentInitializer),biasInitializer:(0,h.zo)(this.biasInitializer),kernelRegularizer:(0,c.R9)(this.kernelRegularizer),recurrentRegularizer:(0,c.R9)(this.recurrentRegularizer),biasRegularizer:(0,c.R9)(this.biasRegularizer),activityRegularizer:(0,c.R9)(this.activityRegularizer),kernelConstraint:(0,l.uH)(this.kernelConstraint),recurrentConstraint:(0,l.uH)(this.recurrentConstraint),biasConstraint:(0,l.uH)(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign({},t,e)}}A.className="SimpleRNNCell",s.serialization.registerClass(A);class I extends y{constructor(t){t.cell=new A(t),super(t)}call(t,e){return(0,s.tidy)((()=>{null!=this.cell.dropoutMask&&(s.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(s.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const i=null==e?null:e.mask,n=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:i,training:n,initialState:r})}))}static fromConfig(t,e){return new t(e)}}I.className="SimpleRNN",s.serialization.registerClass(I);class k extends S{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new u.Qp("GRUCell does not support reset_after parameter set to true.");this.units=t.units,(0,p.oo)(this.units,"units"),this.activation=(0,n.b_)(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=(0,n.b_)(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=(0,h.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=(0,h.Fe)(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=(0,h.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=(0,c.Bm)(t.kernelRegularizer),this.recurrentRegularizer=(0,c.Bm)(t.recurrentRegularizer),this.biasRegularizer=(0,c.Bm)(t.biasRegularizer),this.kernelConstraint=(0,l.YZ)(t.kernelConstraint),this.recurrentConstraint=(0,l.YZ)(t.recurrentConstraint),this.biasConstraint=(0,l.YZ)(t.biasConstraint),this.dropout=g.jk([1,g.T9([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=g.jk([1,g.T9([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){const e=(t=(0,d.U$)(t))[t.length-1];this.kernel=this.addWeight("kernel",[e,3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return(0,s.tidy)((()=>{if(2!==t.length)throw new u.Qp(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);const i=null!=e.training&&e.training;let n=t[1];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=v({ones:()=>s.onesLike(t),rate:this.dropout,training:i,count:3})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=v({ones:()=>s.onesLike(n),rate:this.recurrentDropout,training:i,count:3}));const a=this.dropoutMask,l=this.recurrentDropoutMask;let o,h,c;0<this.dropout&&this.dropout<1&&(t=s.mul(t,a[0]));let p=r.Om(t,this.kernel.read());this.useBias&&(p=r.ni(p,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(n=s.mul(n,l[0]));const g=this.recurrentKernel.read(),[d,m]=s.split(g,[2*this.units,this.units],g.rank-1),f=r.Om(n,d),[z,b,y]=s.split(p,3,p.rank-1),[S,A]=s.split(f,2,f.rank-1);o=this.recurrentActivation.apply(s.add(z,S)),h=this.recurrentActivation.apply(s.add(b,A));const I=r.Om(s.mul(h,n),m);c=this.activation.apply(s.add(y,I));const k=s.add(s.mul(o,n),s.mul(s.add(1,s.neg(o)),c));return[k,k]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:(0,n.Bu)(this.activation),recurrentActivation:(0,n.Bu)(this.recurrentActivation),useBias:this.useBias,kernelInitializer:(0,h.zo)(this.kernelInitializer),recurrentInitializer:(0,h.zo)(this.recurrentInitializer),biasInitializer:(0,h.zo)(this.biasInitializer),kernelRegularizer:(0,c.R9)(this.kernelRegularizer),recurrentRegularizer:(0,c.R9)(this.recurrentRegularizer),biasRegularizer:(0,c.R9)(this.biasRegularizer),activityRegularizer:(0,c.R9)(this.activityRegularizer),kernelConstraint:(0,l.uH)(this.kernelConstraint),recurrentConstraint:(0,l.uH)(this.recurrentConstraint),biasConstraint:(0,l.uH)(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign({},t,e)}}k.className="GRUCell",s.serialization.registerClass(k);class C extends y{constructor(t){t.implementation,t.cell=new k(t),super(t)}call(t,e){return(0,s.tidy)((()=>{null!=this.cell.dropoutMask&&(s.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(s.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const i=null==e?null:e.mask,n=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:i,training:n,initialState:r})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}C.className="GRU",s.serialization.registerClass(C);class R extends S{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,(0,p.oo)(this.units,"units"),this.activation=(0,n.b_)(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=(0,n.b_)(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=(0,h.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=(0,h.Fe)(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=(0,h.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=(0,c.Bm)(t.kernelRegularizer),this.recurrentRegularizer=(0,c.Bm)(t.recurrentRegularizer),this.biasRegularizer=(0,c.Bm)(t.biasRegularizer),this.kernelConstraint=(0,l.YZ)(t.kernelConstraint),this.recurrentConstraint=(0,l.YZ)(t.recurrentConstraint),this.biasConstraint=(0,l.YZ)(t.biasConstraint),this.dropout=g.jk([1,g.T9([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=g.jk([1,g.T9([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;const i=(t=(0,d.U$)(t))[t.length-1];let s;if(this.kernel=this.addWeight("kernel",[i,4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const t=this.biasInitializer,i=this.units;s=new((e=class extends h.H4{apply(e,s){const n=t.apply([i]),a=(new h.sN).apply([i]),l=t.apply([2*i]);return r.ly(r.ly(n,a),l)}}).className="CustomInit",e)}else s=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,s,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return(0,s.tidy)((()=>{const i=null!=e.training&&e.training;if(3!==t.length)throw new u.Qp(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);let n=t[1];const a=t[2];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=v({ones:()=>s.onesLike(t),rate:this.dropout,training:i,count:4})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=v({ones:()=>s.onesLike(n),rate:this.recurrentDropout,training:i,count:4}));const l=this.dropoutMask,o=this.recurrentDropoutMask;let h,c,p,g;0<this.dropout&&this.dropout<1&&(t=s.mul(t,l[0]));let d=r.Om(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(n=s.mul(n,o[0])),d=s.add(d,r.Om(n,this.recurrentKernel.read())),this.useBias&&(d=r.ni(d,this.bias.read()));const[m,f,z,b]=s.split(d,4,d.rank-1);h=this.recurrentActivation.apply(m),c=this.recurrentActivation.apply(f),p=s.add(s.mul(c,a),s.mul(h,this.activation.apply(z))),g=this.recurrentActivation.apply(b);const y=s.mul(g,this.activation.apply(p));return[y,y,p]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:(0,n.Bu)(this.activation),recurrentActivation:(0,n.Bu)(this.recurrentActivation),useBias:this.useBias,kernelInitializer:(0,h.zo)(this.kernelInitializer),recurrentInitializer:(0,h.zo)(this.recurrentInitializer),biasInitializer:(0,h.zo)(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:(0,c.R9)(this.kernelRegularizer),recurrentRegularizer:(0,c.R9)(this.recurrentRegularizer),biasRegularizer:(0,c.R9)(this.biasRegularizer),activityRegularizer:(0,c.R9)(this.activityRegularizer),kernelConstraint:(0,l.uH)(this.kernelConstraint),recurrentConstraint:(0,l.uH)(this.recurrentConstraint),biasConstraint:(0,l.uH)(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign({},t,e)}}R.className="LSTMCell",s.serialization.registerClass(R);class w extends y{constructor(t){t.implementation,t.cell=new R(t),super(t)}call(t,e){return(0,s.tidy)((()=>{null!=this.cell.dropoutMask&&(s.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(s.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const i=null==e?null:e.mask,n=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:i,training:n,initialState:r})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}w.className="LSTM",s.serialization.registerClass(w);class x extends S{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return(0,s.tidy)((()=>{let i=t.slice(1);const s=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?s.push(i.splice(0,t.stateSize.length)):s.push(i.splice(0,1));s.reverse();const n=[];let r;for(let a=0;a<this.cells.length;++a){const l=this.cells[a];i=s[a],r=0===a?[t[0]].concat(i):[r[0]].concat(i),r=l.call(r,e),n.push(r.slice(1))}i=[];for(const t of n.slice().reverse())i.push(...t);return[r[0]].concat(i)}))}build(t){let e;(0,d.TT)(t)&&(t=t[0]),this.cells.forEach(((i,s)=>{(0,a.IU)(`RNNCell_${s}`,(()=>{i.build(t),e=Array.isArray(i.stateSize)?i.stateSize[0]:i.stateSize,t=[t[0],e]}))})),this.built=!0}getConfig(){const t=super.getConfig(),e={cells:this.cells.map((t=>({className:t.getClassName(),config:t.getConfig()})))};return Object.assign({},t,e)}static fromConfig(t,e,i={}){const s=[];for(const n of e.cells)s.push((0,f.i)(n,i));return new t({cells:s})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return(0,m.ex)(t)}setWeights(t){const e=[];for(const i of this.cells){const s=i.weights.length,n=t.splice(s);for(let t=0;t<i.weights.length;++t)e.push([i.weights[t],n[t]])}(0,m.UM)(e)}}function v(t){const{ones:e,rate:i,training:n=!1,count:a=1}=t,l=()=>r.EZ(e(),i),o=()=>r.Ls(l,e,n);if(!a||a<=1)return s.keep(o().clone());return Array(a).fill(void 0).map(o).map((t=>s.keep(t.clone())))}x.className="StackedRNNCells",s.serialization.registerClass(x)},79710:function(t,e,i){var s=i(9495),n=i(6090),r=i(79730),a=i(15841),l=i(63057);class o extends r.Wd{constructor(t){if(null==t&&(t={}),super(t),this.dataFormat=null==t.dataFormat?(0,n.VI)():t.dataFormat,null==t.padding)this.padding=[[1,1],[1,1]];else if("number"===typeof t.padding)this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,2!==t.padding.length)throw new a.Qp(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,i;if("number"===typeof t.padding[0])e=[t.padding[0],t.padding[0]],i=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,2!==t.padding[0].length)throw new a.Qp(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],2!==t.padding[1].length)throw new a.Qp(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);i=t.padding[1]}this.padding=[e,i]}this.inputSpec=[new r.eO({ndim:4})]}computeOutputShape(t){let e,i;return t=(0,l.U$)(t),"channelsFirst"===this.dataFormat?(e=null!=t[2]&&t[2]>=0?t[2]+this.padding[0][0]+this.padding[0][1]:null,i=null!=t[3]&&t[3]>=0?t[3]+this.padding[1][0]+this.padding[1][1]:null,[t[0],t[1],e,i]):(e=null!=t[1]&&t[1]>=0?t[1]+this.padding[0][0]+this.padding[0][1]:null,i=null!=t[2]&&t[2]>=0?t[2]+this.padding[1][0]+this.padding[1][1]:null,[t[0],e,i,t[3]])}call(t,e){return(0,s.tidy)((()=>{return e=(0,l.un)(t),i=this.padding,r=this.dataFormat,(0,s.tidy)((()=>{if(4!==e.rank)throw new a.Qp(`temporalPadding expects input tensor to be 4-D, but received a ${e.rank}-D tensor.`);if(null==i&&(i=[[1,1],[1,1]]),2!==i.length||2!==i[0].length||2!==i[1].length)throw new a.Qp("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==r&&(r=(0,n.VI)()),"channelsLast"!==r&&"channelsFirst"!==r)throw new a.Qp(`Unknown data format: ${r}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let t;return t="channelsFirst"===r?[[0,0],[0,0],i[0],i[1]]:[[0,0],i[0],i[1],[0,0]],s.pad(e,t)}));var e,i,r}))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}o.className="ZeroPadding2D",s.serialization.registerClass(o)}}]);
//# sourceMappingURL=stylist-vendors-6e5319ad.e9cc3240e5750b720ac7.js.map