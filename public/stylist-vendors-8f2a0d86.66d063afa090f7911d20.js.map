{"version":3,"file":"stylist-vendors-8f2a0d86.66d063afa090f7911d20.js","mappings":"0LAgDO,MAAMA,GAAS,E,SAAAC,IAAG,CAAEC,QAT3B,SAAiBC,EAASC,EAAOC,EAAU,EAAGC,EAAW,GACrD,GAAIF,EAAQ,EACR,MAAM,IAAIG,MAAM,iDAAiDH,KAErE,MACMI,EAAS,CAAEL,SADA,QAAgBA,EAAS,UAAW,SAAU,UAEzDM,EAAQ,CAAEL,QAAOC,UAASC,YAChC,OAAO,KAAOI,UAAU,KAAQF,EAAQC,EAC5C,G,+JCiFO,MAAME,GAAO,IAAAV,IAAG,CAAEW,MA7EzB,SAAeC,EAAOC,EAAaC,EAAaC,EAAKC,EAAWC,GAC3C,MAAbD,IACAA,EAAY,CAAC,EAAG,IAEL,MAAXC,IACAA,EAAU,GAEF,IAARF,IACAA,EAAM,SAEV,MAAMG,GAAK,QAAgBN,EAAO,IAAK,WACvC,IAAIO,EAAMD,EACNE,GAAe,EACH,IAAZF,EAAGG,OACHD,GAAe,EACfD,GAAM,OAAQD,EAAI,CAAC,EAAGA,EAAGI,MAAM,GAAIJ,EAAGI,MAAM,GAAIJ,EAAGI,MAAM,MAE7D,KAAY,KAAyCL,EAASD,IAAY,IACtE,qEAAeC,oBAA0BD,OAC7C,MAAMO,EAAW,KAA4BJ,EAAIG,MAAOT,EAAaI,EAASD,EAAWD,GACnFS,EAAW,CAACD,EAASE,eAAgBF,EAASG,eAKpD,IAAIC,EAEAA,EADQ,SAARZ,EAoCR,SAAsCa,EAAaJ,GAG/C,MAAMK,EAAqBD,EAAYE,KAAI,CAACC,EAAGC,IACpCD,GAAKA,EAAI,IAAMP,EAASQ,GAAK,KAElCC,EAAgBJ,EAAmBC,KAAIC,GAAKA,EAAI,IAGhDG,EAAgBD,EAAcH,KAAIC,GAAKI,KAAKC,MAAML,EAAI,KACtDM,EAAcJ,EAAcH,KAAI,CAACC,EAAGC,IAAMD,EAAIG,EAAcF,KAClE,OAAOC,EAAcH,KAAI,CAACQ,EAAGN,IAClB,CAACE,EAAcF,GAAIK,EAAYL,KAE9C,CAjDsBO,CAA6B,CAAChB,EAASiB,aAAcjB,EAASkB,aAAcjB,GAG5E,CAAC,CAAC,EAAG,GAAI,CAAC,EAAG,IAE/B,MAAMkB,EAAgC,IAAhBlB,EAAS,IAA4B,IAAhBA,EAAS,IAC7CmB,EAAiBC,GAgB5B,SAAsCC,EAAYC,EAAYnB,GAC1D,MAAMoB,EAAWpB,EAAYG,KAAIkB,GAAKA,EAAE,KAClCC,EAAatB,EAAYG,KAAIkB,GAAKA,EAAE,KACpCE,EAAiBL,EAAWM,OAAOJ,EAAUE,GAC7CG,EAAcN,EAAWhB,KAAI,CAACkB,EAAGhB,KAAOgB,EAAIE,EAAelB,GAAKgB,GAAKA,IACrEK,EAASJ,EAAWnB,KAAI,CAACC,EAAGC,IAAMD,EAAIqB,EAAYpB,KAClDsB,EAAWR,EAAWhB,KAAI,CAACQ,EAAGN,IAAM,CAACe,EAASf,GAAIqB,EAAOrB,MACzDuB,EAAQT,EAAWhB,KAAI,CAACQ,EAAGN,IAAM,CAAC,EAAGoB,EAAYpB,MACvD,MAAO,CAACsB,EAAUC,EACtB,CAzB6CC,CAA6B,CAACjC,EAASkC,SAAUlC,EAASmC,SAAUlC,EAAUG,GACjHgC,EAAejB,EAAgB3B,EAAM,QACrC6C,EAAalB,EAAgBvB,GAAM,OAAeA,EAAKK,EAAUmB,GAIjEkB,GAH4B,QAAhB/C,EACd,KAAM,OAAQ8C,EAAY/C,EAAaI,EAAS0C,GAChD,KAAM,OAAQC,EAAY/C,EAAaI,EAAS0C,MAE9CG,EAAMpB,EAAgBmB,GAAI,OAAeA,EAAGrC,EAAUoB,GAC5D,OAAIxB,GACO,OAAQ0C,EAAK,CAACA,EAAIxC,MAAM,GAAIwC,EAAIxC,MAAM,GAAIwC,EAAIxC,MAAM,KAExDwC,CACX,G,+rNCpEO,MAAMC,IAAe,KAAA/D,IAAG,CAAEgE,cATjC,SAAuBC,EAAIC,GACvB,MAAMC,GAAM,SAAgBF,EAAI,KAAM,gBAChCG,GAAM,SAAgBF,EAAI,KAAM,gBACtC,MAAyB,IAAbC,EAAI9C,MAA2B,IAAb+C,EAAI/C,MAAY,IAC1C,+DAAG8C,EAAI9C,YAAY+C,EAAI/C,UAC3B,MAAMgD,GAAO,EAAAC,GAAA,GAAQH,EAAK,EAAE,EAAG,IACzBI,GAAO,EAAAD,GAAA,GAAQF,EAAK,CAAC,GAAI,IAC/B,OAAO,QAAOC,EAAME,EACxB,I,gBCjBO,MAAMC,IAAQ,KAAAxE,IAAG,CAAEyE,OAJ1B,SAAgBC,EAAGpB,EAAUqB,EAAgB,GAEzC,OADA,SAA2B,IAApBrB,EAASsB,QAAc,IAAM,sDAC7B,EAAA7D,GAAA,GAAI2D,EAAG,CAACpB,GAAWqB,EAC9B,ICEO,MAAME,IAAQ,KAAA7E,IAAG,CAAE8E,OAL1B,SAAgBJ,EAAGpB,EAAUqB,EAAgB,GAGzC,OAFA,SAA2B,IAApBrB,EAASsB,QAAuC,IAAvBtB,EAAS,GAAGsB,QACjB,IAAvBtB,EAAS,GAAGsB,QAAc,IAAM,2DAC7B,EAAA7D,GAAA,GAAI2D,EAAGpB,EAAUqB,EAC5B,ICCO,MAAMI,IAAQ,KAAA/E,IAAG,CAAEgF,OAL1B,SAAgBN,EAAGpB,EAAUqB,EAAgB,GAGzC,OAFA,SAA2B,IAApBrB,EAASsB,QAAuC,IAAvBtB,EAAS,GAAGsB,QACjB,IAAvBtB,EAAS,GAAGsB,QAAuC,IAAvBtB,EAAS,GAAGsB,QAAc,IAAM,2DACzD,EAAA7D,GAAA,GAAI2D,EAAGpB,EAAUqB,EAC5B,ICEO,MAAMM,IAAQ,KAAAjF,IAAG,CAAEkF,OAN1B,SAAgBR,EAAGpB,EAAUqB,EAAgB,GAIzC,OAHA,SAA2B,IAApBrB,EAASsB,QAAuC,IAAvBtB,EAAS,GAAGsB,QACjB,IAAvBtB,EAAS,GAAGsB,QAAuC,IAAvBtB,EAAS,GAAGsB,QACjB,IAAvBtB,EAAS,GAAGsB,QAAc,IAAM,2DAC7B,EAAA7D,GAAA,GAAI2D,EAAGpB,EAAUqB,EAC5B,I,o0CC2MA,MAAMQ,GAAW,CACbC,IAAG,KACHC,KAAI,KACJC,KAAI,KACJC,MAAK,MAOHC,GAAS,CACXC,cAAa,KACbC,WAAU,KACVC,MAAK,KACLC,KAAI,MAgBF,GAAQ,CACVC,cAAa,KACbC,sBAAqB,KACrBC,eAAc,KACdC,iBAAgB,KAChBC,cAAa,KACbC,kBAAiB,KACjBC,uBAAsB,KACtBC,2BAA0B,KAC1BC,gCAA+B,KAC/BC,wBAAuB,KACvBC,6BAA4B,KAC5BC,UAAS,KACTC,UAAS,MAMPC,GAAS,CACXC,SAAQ,KACRC,YAAW,KACXC,GAAE,OAYAC,GAAS,CACXC,mBAAkB,KAClBC,oBAAmB,KACnBC,eAAc,KACdC,UAAS,KACTC,UAAS,KACTC,QAAO,KACPC,iBAAgB,KAChBC,oBAAmB,KACnBC,oBAAmB,MAIjBC,GAAS,CACXC,oBAAmB,KACnBC,cAAa,K,mHC1PV,MAAMC,GAAW,E,SAAA3H,IAAG,CAAE4H,UAR7B,SAAmBC,EAAG7E,GAClB,IAAI8E,GAAK,QAAgBD,EAAG,IAAK,YAC7BE,GAAK,QAAgB/E,EAAG,IAAK,aAChC8E,EAAIC,IAAM,IAAAC,gBAAeF,EAAIC,IAC9B,QAA2BD,EAAGxG,MAAOyG,EAAGzG,OACxC,MAAMf,EAAS,CAAEsH,EAAGC,EAAI9E,EAAG+E,GAC3B,OAAO,KAAOtH,UAAU,KAAUF,EACtC,G,wGCVO,SAAS0H,EAAK3G,EAAO4G,EAAQ,WAChC,GAAc,cAAVA,EAAuB,CACvB,MAAMC,EAAOF,EAAK3G,EAAO,WACnB8G,GAAO,OAAM9G,EAAO,WAC1B,OAAO,OAAQ6G,EAAMC,EACzB,CACA,MAAMC,GAAS,SAAmB,QAAc/G,GAAQ4G,GACxD,OAAO,KAAOI,WAAWD,EAAQ/G,EAAO4G,EAC5C,C,6FCaO,MAAMnH,GAAM,E,SAAAf,IAAG,CAAEuI,KATxB,SAAc7D,EAAGpB,EAAUqB,EAAgB,GACvC,MAAMzD,GAAK,QAAgBwD,EAAG,IAAK,OACnC,GAAgB,IAAZxD,EAAGG,KACH,MAAM,IAAIf,MAAM,sDAEpB,MAAME,EAAQ,CAAE8C,WAAUqB,iBACpBpE,EAAS,CAAEmE,EAAGxD,GACpB,OAAO,KAAOT,UAAU,KAAOF,EAAQC,EAC3C,G,uECpCA,SAASgI,EAAsBC,EAAOC,EAAQC,EAAeC,EAAcC,EAAgBC,GACnE,MAAhBF,IACAA,EAAe,IAEG,MAAlBC,IACAA,EAAiBE,OAAOC,mBAER,MAAhBF,IACAA,EAAe,GAEnB,MAAMG,EAAWR,EAAMnH,MAAM,GAS7B,OARAqH,EAAgBxG,KAAK+G,IAAIP,EAAeM,GACxC,KAAY,GAAKL,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OACtG,KAA2B,IAAfH,EAAMpH,MAAY,IAAM,+CAA+CoH,EAAMpH,UACzF,KAA+B,IAAnBoH,EAAMnH,MAAM,IAAU,IAAM,oDAAoDmH,EAAMnH,MAAM,OACxG,KAA4B,IAAhBoH,EAAOrH,MAAY,IAAM,+BACrC,KAAYqH,EAAOpH,MAAM,KAAO2H,GAAU,IAAM,sDAAsDA,cACvFP,EAAOpH,MAAM,OAC5B,KAAY,GAAKwH,GAAgBA,GAAgB,GAAG,IAAM,4CAA4CA,OAC/F,CAAEH,gBAAeC,eAAcC,iBAAgBC,eAC1D,C,6FCAO,MAAMK,GAAW,E,SAAAnJ,IAAG,CAAEoJ,UAL7B,SAAmB1E,GACf,MACMnE,EAAS,CAAEmE,GADN,QAAgBA,EAAG,IAAK,aAEnC,OAAO,KAAOjE,UAAU,KAAUF,EACtC,G,0GClBO,MAAM8I,EAAkB,OAMxB,SAASrJ,EAAGsJ,GACf,MAAMC,EAAOC,OAAOD,KAAKD,GACzB,GAAoB,IAAhBC,EAAK3E,OACL,MAAM,IAAItE,MAEN,yGAAGiJ,EAAK3E,gBAEhB,IAAI6E,EAASF,EAAK,GAClB,MAAMG,EAAKJ,EAAEG,GAETA,EAAOE,SAAS,OAChBF,EAASA,EAAOG,UAAU,EAAGH,EAAO7E,OAAS,IAGjD6E,GAAkBJ,EAElB,MAAMQ,EAAK,IAAIC,KACX,KAAOC,WAAWN,GAClB,IACI,MAAMO,EAASN,KAAMI,GAKrB,OAJI,QAAUE,GAGd,KAAOC,SAASD,GACTA,CACX,CACA,MAAOE,GAEH,MADA,KAAOD,SAAS,MACVC,CACV,GAIJ,OAFAV,OAAOW,eAAeN,EAAI,OAAQ,CAAEO,MAAOX,EAAQY,cAAc,IAE1DR,CACX,C,0MCmBA,SAASS,EAAS5F,EAAG6F,EAAGC,EAAO,MAC3B,GAAe,IAAX9F,EAAErD,KACF,OAAO,OAAIqD,GAGf,GAAe,IAAXA,EAAErD,MAAuB,OAATmJ,EAChB,OAAOF,GAAS,OAAQ5F,EAAG,EAAE,IAAK6F,EAAGC,GAGzC,GAAe,IAAX9F,EAAErD,MAA8B,kBAATmJ,GACvBC,MAAMC,QAAQF,IAAyB,IAAhBA,EAAK5F,OAAc,CAC1C,GAAU,IAAN2F,EACA,OAAO,QAAI,OAAI7F,GAAI8F,GAEvB,GAAID,IAAMI,IACN,OAAO,QAAI,OAAIjG,GAAI8F,GAEvB,GAAID,KAAOI,IACP,OAAO,QAAI,OAAIjG,GAAI8F,GAEvB,GAAU,cAAND,GAA2B,IAANA,EAErB,OAAO,QAAK,QAAI,QAAI,OAAI7F,IAAI,OAAO,EAAG,UAAW8F,IAErD,MAAM,IAAIlK,MAAM,qCAAqCiK,IACzD,CAEA,GAAIE,MAAMC,QAAQF,IAAyB,IAAhBA,EAAK5F,OAAc,CAC1C,GAAU,IAAN2F,EACA,OAAO,QAAI,QAAI,OAAI7F,GAAI8F,EAAK,IAAKA,EAAK,GAAK,GAE/C,GAAID,IAAMI,IACN,OAAO,QAAI,QAAI,OAAIjG,GAAI8F,EAAK,IAAKA,EAAK,IAE1C,GAAID,KAAOI,IACP,OAAO,QAAI,QAAI,OAAIjG,GAAI8F,EAAK,IAAKA,EAAK,IAE1C,GAAU,QAAND,GAAqB,cAANA,EAEf,OAAO,QAAK,QAAI,OAAO7F,GAAI8F,IAE/B,MAAM,IAAIlK,MAAM,qCAAqCiK,IACzD,CACA,MAAM,IAAIjK,MAAM,gCAAgCkK,IACpD,CACO,MAAMI,GAAO,IAAA5K,IAAG,CAAE6K,MAvDzB,SAAenG,EAAGoG,EAAM,YAAaN,EAAO,KAAMO,GAAW,GAEzD,MAAMH,EAAON,EADb5F,GAAI,QAAgBA,EAAG,IAAK,QACHoG,EAAKN,GAC9B,IAAIQ,EAAgBJ,EAAKtJ,MACzB,GAAIyJ,EAAU,CACV,MAAME,GAAO,QAAeT,EAAM9F,EAAEpD,OACpC0J,EAAgB,KAA+BJ,EAAKtJ,MAAO2J,EAC/D,CACA,OAAO,OAAQL,EAAMI,EACzB,G,wGCpBO,MAAME,GAAM,E,SAAAlL,IAAG,CAAEmL,KAPxB,SAAcC,EAAMC,GAChB,IAAIC,GAAQ,QAAgBF,EAAM,OAAQ,OACtCG,GAAO,QAAgBF,EAAK,MAAO,QACtCC,EAAOC,IAAQ,IAAAvD,gBAAesD,EAAOC,GACtC,MAAMhL,EAAS,CAAEsH,EAAGyD,EAAOtI,EAAGuI,GAC9B,OAAO,KAAO9K,UAAU,KAAKF,EACjC,G","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pool.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/outer_product.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pad1d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pad2d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pad3d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pad4d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/ops.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/ones.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/operation.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/norm.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/pow.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { OneHot } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a one-hot `tf.Tensor`. The locations represented by `indices` take\n * value `onValue` (defaults to 1), while all other locations take value\n * `offValue` (defaults to 0). If `indices` is rank `R`, the output has rank\n * `R+1` with the last axis of size `depth`.\n *\n * ```js\n * tf.oneHot(tf.tensor1d([0, 1], 'int32'), 3).print();\n * ```\n *\n * @param indices `tf.Tensor` of indices with dtype `int32`.\n * @param depth The depth of the one hot dimension.\n * @param onValue A number used to fill in the output when the index matches\n * the location.\n * @param offValue A number used to fill in the output when the index does\n *     not match the location.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction oneHot_(indices, depth, onValue = 1, offValue = 0) {\n    if (depth < 2) {\n        throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);\n    }\n    const $indices = convertToTensor(indices, 'indices', 'oneHot', 'int32');\n    const inputs = { indices: $indices };\n    const attrs = { depth, onValue, offValue };\n    return ENGINE.runKernel(OneHot, inputs, attrs);\n}\nexport const oneHot = op({ oneHot_ });\n//# sourceMappingURL=one_hot.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { avgPool } from './avg_pool';\nimport { batchToSpaceND } from './batch_to_space_nd';\nimport * as conv_util from './conv_util';\nimport { maxPool } from './max_pool';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { spaceToBatchND } from './space_to_batch_nd';\n/**\n * Performs an N-D pooling operation\n *\n * @param input The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param windowShape The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param poolingType The type of pooling, either 'max' or 'avg'.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in dilated pooling. Defaults to `[1, 1]`. If `dilationRate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction pool_(input, windowShape, poolingType, pad, dilations, strides) {\n    if (dilations == null) {\n        dilations = [1, 1];\n    }\n    if (strides == null) {\n        strides = 1;\n    }\n    if (pad === 0) {\n        pad = 'valid';\n    }\n    const $x = convertToTensor(input, 'x', 'maxPool');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in pool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const convInfo = conv_util.computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad);\n    const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];\n    // The following implementation does batchToSpace(pool(spaceToBatch(x)))\n    // whenever dilation > 1 since the TF kernels do not support dilation > 1.\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L1037\n    let basePadding;\n    if (pad === 'same') {\n        basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);\n    }\n    else {\n        basePadding = [[0, 0], [0, 0]];\n    }\n    const isDilationOne = dilation[0] === 1 && dilation[1] === 1;\n    const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);\n    const convertedPad = isDilationOne ? pad : 'valid';\n    const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);\n    const forwardOp = poolingType === 'avg' ?\n        () => avgPool(convertedX, windowShape, strides, convertedPad) :\n        () => maxPool(convertedX, windowShape, strides, convertedPad);\n    const y = forwardOp();\n    const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\n// Helper function to compute crops and paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/array_ops.py#L2184\nfunction requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {\n    const padStart = basePadding.map(b => b[0]);\n    const origPadEnd = basePadding.map(b => b[1]);\n    const fullInputShape = inputShape.concat(padStart, origPadEnd);\n    const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);\n    const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);\n    const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);\n    const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);\n    return [paddings, crops];\n}\n// Helper function to compute base paddings for pool with dilation > 1.\n// tslint:disable-next-line:max-line-length\n// https://github.com/tensorflow/tensorflow/blob/50f6bb67dc98c9b74630b6047aae7a4f8a40fd02/tensorflow/python/ops/nn_ops.py#L524\nfunction withSpaceToBatchBasePaddings(filterShape, dilation) {\n    // Spatial dimensions of the filters and the upsampled filters in which we\n    // introduce (rate - 1) zeros between consecutive filter values.\n    const dilatedFilterShape = filterShape.map((s, i) => {\n        return s + (s - 1) * (dilation[i] - 1);\n    });\n    const padExtraShape = dilatedFilterShape.map(s => s - 1);\n    // When padding is odd, we pad more at end, following the same\n    // convention as conv2d.\n    const padExtraStart = padExtraShape.map(s => Math.floor(s / 2));\n    const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);\n    return padExtraShape.map((_, i) => {\n        return [padExtraStart[i], padExtraEnd[i]];\n    });\n}\nexport const pool = op({ pool_ });\n//# sourceMappingURL=pool.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { matMul } from './mat_mul';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the outer product of two vectors, `v1` and `v2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([3, 4, 5]);\n *\n * tf.outerProduct(a, b).print();\n * ```\n * @param v1 The first vector in the outer product operation.\n * @param v2 The second vector in the outer product operation.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction outerProduct_(v1, v2) {\n    const $v1 = convertToTensor(v1, 'v1', 'outerProduct');\n    const $v2 = convertToTensor(v2, 'v2', 'outerProduct');\n    util.assert($v1.rank === 1 && $v2.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ` +\n        `${$v1.rank} and ${$v2.rank}.`);\n    const v12D = reshape($v1, [-1, 1]);\n    const v22D = reshape($v2, [1, -1]);\n    return matMul(v12D, v22D);\n}\nexport const outerProduct = op({ outerProduct_ });\n//# sourceMappingURL=outer_product.js.map","import { assert } from '../util';\nimport { op } from './operation';\nimport { pad } from './pad';\n/**\n * Pads a `tf.Tensor1D` with a given value and paddings. See `pad` for details.\n */\nfunction pad1d_(x, paddings, constantValue = 0) {\n    assert(paddings.length === 2, () => 'Invalid number of paddings. Must be length of 2.');\n    return pad(x, [paddings], constantValue);\n}\nexport const pad1d = op({ pad1d_ });\n//# sourceMappingURL=pad1d.js.map","import { assert } from '../util';\nimport { op } from './operation';\nimport { pad } from './pad';\n/**\n * Pads a `tf.Tensor2D` with a given value and paddings. See `pad` for details.\n */\nfunction pad2d_(x, paddings, constantValue = 0) {\n    assert(paddings.length === 2 && paddings[0].length === 2 &&\n        paddings[1].length === 2, () => 'Invalid number of paddings. Must be length of 2 each.');\n    return pad(x, paddings, constantValue);\n}\nexport const pad2d = op({ pad2d_ });\n//# sourceMappingURL=pad2d.js.map","import { assert } from '../util';\nimport { op } from './operation';\nimport { pad } from './pad';\n/**\n * Pads a `tf.Tensor3D` with a given value and paddings. See `pad` for details.\n */\nfunction pad3d_(x, paddings, constantValue = 0) {\n    assert(paddings.length === 3 && paddings[0].length === 2 &&\n        paddings[1].length === 2 && paddings[2].length === 2, () => 'Invalid number of paddings. Must be length of 2 each.');\n    return pad(x, paddings, constantValue);\n}\nexport const pad3d = op({ pad3d_ });\n//# sourceMappingURL=pad3d.js.map","import { assert } from '../util';\nimport { op } from './operation';\nimport { pad } from './pad';\n/**\n * Pads a `tf.Tensor4D` with a given value and paddings. See `pad` for details.\n */\nfunction pad4d_(x, paddings, constantValue = 0) {\n    assert(paddings.length === 4 && paddings[0].length === 2 &&\n        paddings[1].length === 2 && paddings[2].length === 2 &&\n        paddings[3].length === 2, () => 'Invalid number of paddings. Must be length of 2 each.');\n    return pad(x, paddings, constantValue);\n}\nexport const pad4d = op({ pad4d_ });\n//# sourceMappingURL=pad4d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Modularized ops.\nexport { abs } from './abs';\nexport { acos } from './acos';\nexport { acosh } from './acosh';\nexport { add } from './add';\nexport { addN } from './add_n';\nexport { all } from './all';\nexport { any } from './any';\nexport { argMax } from './arg_max';\nexport { argMin } from './arg_min';\nexport { asin } from './asin';\nexport { asinh } from './asinh';\nexport { atan } from './atan';\nexport { atan2 } from './atan2';\nexport { atanh } from './atanh';\nexport { avgPool } from './avg_pool';\nexport { avgPool3d } from './avg_pool_3d';\nexport { basicLSTMCell } from './basic_lstm_cell';\nexport { batchToSpaceND } from './batch_to_space_nd';\nexport { batchNorm } from './batchnorm';\nexport { batchNorm2d } from './batchnorm2d';\nexport { batchNorm3d } from './batchnorm3d';\nexport { batchNorm4d } from './batchnorm4d';\nexport { bincount } from './bincount';\nexport { broadcastTo } from './broadcast_to';\nexport { buffer } from './buffer';\nexport { cast } from './cast';\nexport { ceil } from './ceil';\nexport { clipByValue } from './clip_by_value';\nexport { clone } from './clone';\nexport { complex } from './complex';\nexport { concat } from './concat';\nexport { concat1d } from './concat_1d';\nexport { concat2d } from './concat_2d';\nexport { concat3d } from './concat_3d';\nexport { concat4d } from './concat_4d';\nexport { conv1d } from './conv1d';\nexport { conv2d } from './conv2d';\nexport { conv2dTranspose } from './conv2d_transpose';\nexport { conv3d } from './conv3d';\nexport { conv3dTranspose } from './conv3d_transpose';\nexport { cos } from './cos';\nexport { cosh } from './cosh';\nexport { cumsum } from './cumsum';\nexport { denseBincount } from './dense_bincount';\nexport { depthToSpace } from './depth_to_space';\nexport { depthwiseConv2d } from './depthwise_conv2d';\nexport { diag } from './diag';\nexport { dilation2d } from './dilation2d';\nexport { div } from './div';\nexport { divNoNan } from './div_no_nan';\nexport { dot } from './dot';\nexport { einsum } from './einsum';\nexport { elu } from './elu';\nexport { equal } from './equal';\nexport { erf } from './erf';\nexport { exp } from './exp';\nexport { expandDims } from './expand_dims';\nexport { expm1 } from './expm1';\nexport { eye } from './eye';\nexport { fill } from './fill';\nexport { floor } from './floor';\nexport { floorDiv } from './floorDiv';\nexport { gather } from './gather';\nexport { greater } from './greater';\nexport { greaterEqual } from './greater_equal';\nexport { imag } from './imag';\nexport { isFinite } from './is_finite';\nexport { isInf } from './is_inf';\nexport { isNaN } from './is_nan';\nexport { leakyRelu } from './leaky_relu';\nexport { less } from './less';\nexport { lessEqual } from './less_equal';\nexport { linspace } from './linspace';\nexport { localResponseNormalization } from './local_response_normalization';\nexport { log } from './log';\nexport { log1p } from './log1p';\nexport { logSigmoid } from './log_sigmoid';\nexport { logSoftmax } from './log_softmax';\nexport { logSumExp } from './log_sum_exp';\nexport { logicalAnd } from './logical_and';\nexport { logicalNot } from './logical_not';\nexport { logicalOr } from './logical_or';\nexport { logicalXor } from './logical_xor';\nexport { matMul } from './mat_mul';\nexport { max } from './max';\nexport { maxPool } from './max_pool';\nexport { maxPool3d } from './max_pool_3d';\nexport { maxPoolWithArgmax } from './max_pool_with_argmax';\nexport { maximum } from './maximum';\nexport { mean } from './mean';\nexport { meshgrid } from './meshgrid';\nexport { min } from './min';\nexport { minimum } from './minimum';\nexport { mirrorPad } from './mirror_pad';\nexport { mod } from './mod';\nexport { moments } from './moments';\nexport { mul } from './mul';\nexport { multiRNNCell } from './multi_rnn_cell';\nexport { multinomial } from './multinomial';\nexport { neg } from './neg';\nexport { notEqual } from './not_equal';\nexport { oneHot } from './one_hot';\nexport { ones } from './ones';\nexport { onesLike } from './ones_like';\nexport { outerProduct } from './outer_product';\nexport { pad } from './pad';\nexport { pad1d } from './pad1d';\nexport { pad2d } from './pad2d';\nexport { pad3d } from './pad3d';\nexport { pad4d } from './pad4d';\nexport { pool } from './pool';\nexport { pow } from './pow';\nexport { prelu } from './prelu';\nexport { print } from './print';\nexport { prod } from './prod';\nexport { rand } from './rand';\nexport { randomGamma } from './random_gamma';\nexport { randomNormal } from './random_normal';\nexport { randomUniform } from './random_uniform';\nexport { range } from './range';\nexport { real } from './real';\nexport { reciprocal } from './reciprocal';\nexport { relu } from './relu';\nexport { relu6 } from './relu6';\nexport { reshape } from './reshape';\nexport { reverse } from './reverse';\nexport { reverse1d } from './reverse_1d';\nexport { reverse2d } from './reverse_2d';\nexport { reverse3d } from './reverse_3d';\nexport { reverse4d } from './reverse_4d';\nexport { round } from './round';\nexport { rsqrt } from './rsqrt';\nexport { scalar } from './scalar';\nexport { selu } from './selu';\nexport { separableConv2d } from './separable_conv2d';\nexport { setdiff1dAsync } from './setdiff1d_async';\nexport { sigmoid } from './sigmoid';\nexport { sign } from './sign';\nexport { sin } from './sin';\nexport { sinh } from './sinh';\nexport { slice } from './slice';\nexport { slice1d } from './slice1d';\nexport { slice2d } from './slice2d';\nexport { slice3d } from './slice3d';\nexport { slice4d } from './slice4d';\nexport { softmax } from './softmax';\nexport { softplus } from './softplus';\nexport { spaceToBatchND } from './space_to_batch_nd';\nexport { fft } from './spectral/fft';\nexport { ifft } from './spectral/ifft';\nexport { irfft } from './spectral/irfft';\nexport { rfft } from './spectral/rfft';\nexport { split } from './split';\nexport { sqrt } from './sqrt';\nexport { square } from './square';\nexport { squaredDifference } from './squared_difference';\nexport { squeeze } from './squeeze';\nexport { stack } from './stack';\nexport { step } from './step';\nexport { stridedSlice } from './strided_slice';\nexport { sub } from './sub';\nexport { sum } from './sum';\nexport { tan } from './tan';\nexport { tanh } from './tanh';\nexport { tensor } from './tensor';\nexport { tensor1d } from './tensor1d';\nexport { tensor2d } from './tensor2d';\nexport { tensor3d } from './tensor3d';\nexport { tensor4d } from './tensor4d';\nexport { tensor5d } from './tensor5d';\nexport { tensor6d } from './tensor6d';\nexport { tile } from './tile';\nexport { topk } from './topk';\nexport { truncatedNormal } from './truncated_normal';\nexport { unique } from './unique';\nexport { unsortedSegmentSum } from './unsorted_segment_sum';\nexport { unstack } from './unstack';\nexport { variable } from './variable';\nexport { where } from './where';\nexport { whereAsync } from './where_async';\nexport { zeros } from './zeros';\nexport { zerosLike } from './zeros_like';\nexport * from './boolean_mask';\nexport * from './transpose';\nexport * from './norm';\nexport * from './moving_average';\nexport * from './scatter_nd';\nexport * from './sparse_to_dense';\nexport * from './gather_nd';\nexport * from './dropout';\nexport * from './signal_ops_util';\nexport * from './in_top_k';\nexport { op, OP_SCOPE_SUFFIX } from './operation';\nimport { rfft } from './spectral/rfft';\nimport { fft } from './spectral/fft';\nimport { ifft } from './spectral/ifft';\nimport { irfft } from './spectral/irfft';\nconst spectral = {\n    fft,\n    ifft,\n    rfft,\n    irfft\n};\nimport * as fused from './fused_ops';\nimport { hammingWindow } from './signal/hamming_window';\nimport { hannWindow } from './signal/hann_window';\nimport { frame } from './signal/frame';\nimport { stft } from './signal/stft';\nconst signal = {\n    hammingWindow,\n    hannWindow,\n    frame,\n    stft,\n};\n// Image Ops namespace\nimport { cropAndResize } from './image/crop_and_resize';\nimport { flipLeftRight } from './image/flip_left_right';\nimport { rotateWithOffset } from './image/rotate_with_offset';\nimport { nonMaxSuppression } from './image/non_max_suppression';\nimport { nonMaxSuppressionAsync } from './image/non_max_suppression_async';\nimport { nonMaxSuppressionWithScore } from './image/non_max_suppression_with_score';\nimport { nonMaxSuppressionWithScoreAsync } from './image/non_max_suppression_with_score_async';\nimport { nonMaxSuppressionPadded } from './image/non_max_suppression_padded';\nimport { nonMaxSuppressionPaddedAsync } from './image/non_max_suppression_padded_async';\nimport { resizeBilinear } from './image/resize_bilinear';\nimport { resizeNearestNeighbor } from './image/resize_nearest_neighbor';\nimport { threshold } from './image/threshold';\nimport { transform } from './image/transform';\nconst image = {\n    flipLeftRight,\n    resizeNearestNeighbor,\n    resizeBilinear,\n    rotateWithOffset,\n    cropAndResize,\n    nonMaxSuppression,\n    nonMaxSuppressionAsync,\n    nonMaxSuppressionWithScore,\n    nonMaxSuppressionWithScoreAsync,\n    nonMaxSuppressionPadded,\n    nonMaxSuppressionPaddedAsync,\n    threshold,\n    transform\n};\n// linalg namespace\nimport { bandPart } from './linalg/band_part';\nimport { gramSchmidt } from './linalg/gram_schmidt';\nimport { qr } from './linalg/qr';\nconst linalg = {\n    bandPart,\n    gramSchmidt,\n    qr\n};\n// losses namespace;\nimport { absoluteDifference } from './losses/absolute_difference';\nimport { computeWeightedLoss } from './losses/compute_weighted_loss';\nimport { cosineDistance } from './losses/cosine_distance';\nimport { hingeLoss } from './losses/hinge_loss';\nimport { huberLoss } from './losses/huber_loss';\nimport { logLoss } from './losses/log_loss';\nimport { meanSquaredError } from './losses/mean_squared_error';\nimport { sigmoidCrossEntropy } from './losses/sigmoid_cross_entropy';\nimport { softmaxCrossEntropy } from './losses/softmax_cross_entropy';\nconst losses = {\n    absoluteDifference,\n    computeWeightedLoss,\n    cosineDistance,\n    hingeLoss,\n    huberLoss,\n    logLoss,\n    meanSquaredError,\n    sigmoidCrossEntropy,\n    softmaxCrossEntropy\n};\nimport { sparseFillEmptyRows } from './sparse/sparse_fill_empty_rows';\nimport { sparseReshape } from './sparse/sparse_reshape';\nconst sparse = {\n    sparseFillEmptyRows,\n    sparseReshape\n};\n// Second level exports.\nexport { image, linalg, losses, spectral, fused, signal, sparse };\n//# sourceMappingURL=ops.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { NotEqual } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a != b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([0, 2, 3]);\n *\n * a.notEqual(b).print();\n * ```\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction notEqual_(a, b) {\n    let $a = convertToTensor(a, 'a', 'notEqual');\n    let $b = convertToTensor(b, 'b', 'notEqual');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(NotEqual, inputs);\n}\nexport const notEqual = op({ notEqual_ });\n//# sourceMappingURL=not_equal.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { makeOnesTypedArray, sizeFromShape } from '../util';\nimport { complex } from './complex';\nimport { zeros } from './zeros';\n/**\n * Creates a `tf.Tensor` with all elements set to 1.\n *\n * ```js\n * tf.ones([2, 2]).print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The type of an element in the resulting tensor. Defaults to\n *     'float'.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function ones(shape, dtype = 'float32') {\n    if (dtype === 'complex64') {\n        const real = ones(shape, 'float32');\n        const imag = zeros(shape, 'float32');\n        return complex(real, imag);\n    }\n    const values = makeOnesTypedArray(sizeFromShape(shape), dtype);\n    return ENGINE.makeTensor(values, shape, dtype);\n}\n//# sourceMappingURL=ones.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { PadV2 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Pads a `tf.Tensor` with a given value and paddings.\n *\n * This operation implements `CONSTANT` mode. For `REFLECT` and `SYMMETRIC`,\n * refer to `tf.mirrorPad`\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that `paddings` is of given length.\n *   - `tf.pad1d`\n *   - `tf.pad2d`\n *   - `tf.pad3d`\n *   - `tf.pad4d`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * x.pad([[1, 2]]).print();\n * ```\n * @param x The tensor to pad.\n * @param paddings An array of length `R` (the rank of the tensor), where\n * each element is a length-2 tuple of ints `[padBefore, padAfter]`,\n * specifying how much to pad along each dimension of the tensor.\n * @param constantValue The pad value to use. Defaults to 0.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction pad_(x, paddings, constantValue = 0) {\n    const $x = convertToTensor(x, 'x', 'pad');\n    if ($x.rank === 0) {\n        throw new Error('pad(scalar) is not defined. Pass non-scalar to pad');\n    }\n    const attrs = { paddings, constantValue };\n    const inputs = { x: $x };\n    return ENGINE.runKernel(PadV2, inputs, attrs);\n}\nexport const pad = op({ pad_ });\n//# sourceMappingURL=pad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nfunction nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {\n    if (iouThreshold == null) {\n        iouThreshold = 0.5;\n    }\n    if (scoreThreshold == null) {\n        scoreThreshold = Number.NEGATIVE_INFINITY;\n    }\n    if (softNmsSigma == null) {\n        softNmsSigma = 0.0;\n    }\n    const numBoxes = boxes.shape[0];\n    maxOutputSize = Math.min(maxOutputSize, numBoxes);\n    util.assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);\n    util.assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);\n    util.assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);\n    util.assert(scores.rank === 1, () => 'scores must be a 1D tensor');\n    util.assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, ` +\n        `but was ${scores.shape[0]}`);\n    util.assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);\n    return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };\n}\nexport { nonMaxSuppSanityCheck };\n//# sourceMappingURL=nonmax_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { OnesLike } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a `tf.Tensor` with all elements set to 1 with the same shape as the\n * given tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n * tf.onesLike(x).print();\n * ```\n * @param x A tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction onesLike_(x) {\n    const $x = convertToTensor(x, 'x', 'onesLike');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(OnesLike, inputs);\n}\nexport const onesLike = op({ onesLike_ });\n//# sourceMappingURL=ones_like.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { isPromise } from '../util';\nexport const OP_SCOPE_SUFFIX = '__op';\n/**\n * Used for wrapping functions that perform math operations on\n * Tensors. The function will be wrapped in a named scope that cleans all\n * memory usage after the function is done.\n */\nexport function op(f) {\n    const keys = Object.keys(f);\n    if (keys.length !== 1) {\n        throw new Error(`Please provide an object with a single key ` +\n            `(operation name) mapping to a function. Got an object with ` +\n            `${keys.length} keys.`);\n    }\n    let opName = keys[0];\n    const fn = f[opName];\n    // Strip the underscore from the end of the function name.\n    if (opName.endsWith('_')) {\n        opName = opName.substring(0, opName.length - 1);\n    }\n    // add an __op suffix to distinguish ops from kernels in tf.profile\n    opName = opName + OP_SCOPE_SUFFIX;\n    // tslint:disable-next-line:no-any\n    const f2 = (...args) => {\n        ENGINE.startScope(opName);\n        try {\n            const result = fn(...args);\n            if (isPromise(result)) {\n                console.error('Cannot return a Promise inside of tidy.');\n            }\n            ENGINE.endScope(result);\n            return result;\n        }\n        catch (ex) {\n            ENGINE.endScope(null);\n            throw ex;\n        }\n    };\n    Object.defineProperty(f2, 'name', { value: opName, configurable: true });\n    // tslint:disable-next-line:no-any\n    return f2;\n}\n//# sourceMappingURL=operation.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { parseAxisParam } from '../util';\nimport { abs } from './abs';\nimport * as axis_util from './axis_util';\nimport { max } from './max';\nimport { min } from './min';\nimport { op } from './operation';\nimport { pow } from './pow';\nimport { reshape } from './reshape';\nimport { scalar } from './scalar';\nimport { sqrt } from './sqrt';\nimport { square } from './square';\nimport { sum } from './sum';\n/**\n * Computes the norm of scalar, vectors, and matrices.\n * This function can compute several different vector norms (the 1-norm, the\n * Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0)\n * and matrix norms (Frobenius, 1-norm, and inf-norm).\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * x.norm().print();  // or tf.norm(x)\n * ```\n *\n * @param x The input array.\n * @param ord Optional. Order of the norm. Supported norm types are\n * following:\n *\n *  | ord        | norm for matrices         | norm for vectors\n *  |------------|---------------------------|---------------------\n *  |'euclidean' |Frobenius norm             |2-norm\n *  |'fro'       |Frobenius norm\t           |\n *  |Infinity    |max(sum(abs(x), axis=1))   |max(abs(x))\n *  |-Infinity   |min(sum(abs(x), axis=1))   |min(abs(x))\n *  |1           |max(sum(abs(x), axis=0))   |sum(abs(x))\n *  |2           |                           |sum(abs(x)^2)^1/2*\n *\n * @param axis Optional. If axis is null (the default), the input is\n * considered a vector and a single vector norm is computed over the entire\n * set of values in the Tensor, i.e. norm(x, ord) is equivalent\n * to norm(x.reshape([-1]), ord). If axis is a integer, the input\n * is considered a batch of vectors, and axis determines the axis in x\n * over which to compute vector norms. If axis is a 2-tuple of integer it is\n * considered a batch of matrices and axis determines the axes in NDArray\n * over which to compute a matrix norm.\n * @param keepDims Optional. If true, the norm have the same dimensionality\n * as the input.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction norm_(x, ord = 'euclidean', axis = null, keepDims = false) {\n    x = convertToTensor(x, 'x', 'norm');\n    const norm = normImpl(x, ord, axis);\n    let keepDimsShape = norm.shape;\n    if (keepDims) {\n        const axes = parseAxisParam(axis, x.shape);\n        keepDimsShape = axis_util.expandShapeToKeepDim(norm.shape, axes);\n    }\n    return reshape(norm, keepDimsShape);\n}\nfunction normImpl(x, p, axis = null) {\n    if (x.rank === 0) {\n        return abs(x);\n    }\n    // consider vector when no axis is specified\n    if (x.rank !== 1 && axis === null) {\n        return normImpl(reshape(x, [-1]), p, axis);\n    }\n    // vector\n    if (x.rank === 1 || typeof axis === 'number' ||\n        Array.isArray(axis) && axis.length === 1) {\n        if (p === 1) {\n            return sum(abs(x), axis);\n        }\n        if (p === Infinity) {\n            return max(abs(x), axis);\n        }\n        if (p === -Infinity) {\n            return min(abs(x), axis);\n        }\n        if (p === 'euclidean' || p === 2) {\n            // norm(x, 2) = sum(abs(xi) ^ 2) ^ 1/2\n            return sqrt(sum(pow(abs(x), scalar(2, 'int32')), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    // matrix (assumption axis[0] < axis[1])\n    if (Array.isArray(axis) && axis.length === 2) {\n        if (p === 1) {\n            return max(sum(abs(x), axis[0]), axis[1] - 1);\n        }\n        if (p === Infinity) {\n            return max(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === -Infinity) {\n            return min(sum(abs(x), axis[1]), axis[0]);\n        }\n        if (p === 'fro' || p === 'euclidean') {\n            // norm(x) = sqrt(sum(pow(x, 2)))\n            return sqrt(sum(square(x), axis));\n        }\n        throw new Error(`Error in norm: invalid ord value: ${p}`);\n    }\n    throw new Error(`Error in norm: invalid axis: ${axis}`);\n}\nexport const norm = op({ norm_ });\n//# sourceMappingURL=norm.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Pow } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the power of one `tf.Tensor` to another. Supports broadcasting.\n *\n * Given a `tf.Tensor` x and a `tf.Tensor` y, this operation computes x^y for\n * corresponding elements in x and y. The result's dtype will be the upcasted\n * type of the `base` and `exp` dtypes.\n *\n * ```js\n * const a = tf.tensor([[2, 3], [4, 5]])\n * const b = tf.tensor([[1, 2], [3, 0]]).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n *\n * ```js\n * const a = tf.tensor([[1, 2], [3, 4]])\n * const b = tf.tensor(2).toInt();\n *\n * a.pow(b).print();  // or tf.pow(a, b)\n * ```\n * We also expose `powStrict` which has the same signature as this op and\n * asserts that `base` and `exp` are the same shape (does not broadcast).\n *\n * @param base The base `tf.Tensor` to pow element-wise.\n * @param exp The exponent `tf.Tensor` to pow element-wise.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction pow_(base, exp) {\n    let $base = convertToTensor(base, 'base', 'pow');\n    let $exp = convertToTensor(exp, 'exp', 'pow');\n    [$base, $exp] = makeTypesMatch($base, $exp);\n    const inputs = { a: $base, b: $exp };\n    return ENGINE.runKernel(Pow, inputs);\n}\nexport const pow = op({ pow_ });\n//# sourceMappingURL=pow.js.map"],"names":["oneHot","op","oneHot_","indices","depth","onValue","offValue","Error","inputs","attrs","runKernel","pool","pool_","input","windowShape","poolingType","pad","dilations","strides","$x","x4D","reshapedTo4D","rank","shape","convInfo","dilation","dilationHeight","dilationWidth","basePadding","filterShape","dilatedFilterShape","map","s","i","padExtraShape","padExtraStart","Math","floor","padExtraEnd","_","withSpaceToBatchBasePaddings","filterHeight","filterWidth","isDilationOne","adjustedPadding","adjustedCrops","inputShape","blockShape","padStart","b","origPadEnd","fullInputShape","concat","padEndExtra","padEnd","paddings","crops","requiredSpaceToBatchPaddings","inHeight","inWidth","convertedPad","convertedX","y","res","outerProduct","outerProduct_","v1","v2","$v1","$v2","v12D","reshape","v22D","pad1d","pad1d_","x","constantValue","length","pad2d","pad2d_","pad3d","pad3d_","pad4d","pad4d_","spectral","fft","ifft","rfft","irfft","signal","hammingWindow","hannWindow","frame","stft","flipLeftRight","resizeNearestNeighbor","resizeBilinear","rotateWithOffset","cropAndResize","nonMaxSuppression","nonMaxSuppressionAsync","nonMaxSuppressionWithScore","nonMaxSuppressionWithScoreAsync","nonMaxSuppressionPadded","nonMaxSuppressionPaddedAsync","threshold","transform","linalg","bandPart","gramSchmidt","qr","losses","absoluteDifference","computeWeightedLoss","cosineDistance","hingeLoss","huberLoss","logLoss","meanSquaredError","sigmoidCrossEntropy","softmaxCrossEntropy","sparse","sparseFillEmptyRows","sparseReshape","notEqual","notEqual_","a","$a","$b","makeTypesMatch","ones","dtype","real","imag","values","makeTensor","pad_","nonMaxSuppSanityCheck","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","softNmsSigma","Number","NEGATIVE_INFINITY","numBoxes","min","onesLike","onesLike_","OP_SCOPE_SUFFIX","f","keys","Object","opName","fn","endsWith","substring","f2","args","startScope","result","endScope","ex","defineProperty","value","configurable","normImpl","p","axis","Array","isArray","Infinity","norm","norm_","ord","keepDims","keepDimsShape","axes","pow","pow_","base","exp","$base","$exp"],"sourceRoot":""}