{"version":3,"file":"stylist-vendors-92835348.be3ac1dfac7b752312a9.js","mappings":"qJAoBO,MAAMA,EAAuB,CAChC,QAAW,EACX,QAAW,EACX,MAAS,EACT,OAAU,EACV,MAAS,EACT,KAAQ,EACR,UAAa,E,uECFV,SAASC,EAAwBC,EAAUC,EAAYC,EAAeC,IAgBzE,SAAuBH,IACnB,QAAmB,MAAZA,GAAoBI,MAAMC,QAAQL,IAAaA,EAASM,OAAS,GAAG,IAAM,uCACrF,CAjBAC,CAAcP,GAkBd,SAAuBE,EAAeC,IAClC,QAAOD,GAAiB,GAAKA,GAAiB,GAAG,IAC7C,oEAAqBA,OACzB,QAAOC,GAAe,GAAKA,GAAe,GAAG,IACzC,kEAAmBA,OACvB,QAAOA,GAAeD,GAAe,IACjC,yEAAqBA,qBAClBC,KACX,CAvBAK,CAFAN,EAAiC,MAAjBA,EAAwB,EAAIA,EAC5CC,EAA6B,MAAfA,EAAsB,EAAIA,GAExC,IAAIM,EAAkB,EAuBtB,OAAOC,QAAQC,IAAIX,EAASY,KAtBHC,IACrBA,EAAQC,MAAKC,IACT,MAAMC,EAAWd,KACXO,EAAkBT,EAASM,QAAUH,EAAcD,GAGzD,OADAD,EAAWe,GACJD,CAAK,IAETF,KAef,C,q2BC3BA,SAASI,EAAMC,GACX,OAAO,IAAIR,SAAQS,GAAWC,WAAWD,KAAUL,KAAKI,EAC5D,CACO,MAAMG,EACT,WAAAC,CAAYC,GACR,KAAK,UAAMC,QAAQ,cAGf,MAAM,IAAIC,MAAM,uFAGhBF,EAAeG,WAAWL,EAAiBM,cAC3CJ,EAAiBA,EAAeK,MAAMP,EAAiBM,WAAWrB,SAEhD,MAAlBiB,GAAoD,IAA1BA,EAAejB,SACzCiB,EAlBqB,SAoBzBM,KAAKC,sBAAwBP,EAnBD,QAoB5BM,KAAKE,mBACDR,EApB+B,cAqBvC,CACA,UAAMS,CAAKC,GACP,GAA0B,qBAAf,SACP,MAAM,IAAIR,MAAM,2FAGpB,MAAMS,EAAaC,OAAOC,IAAIC,gBAAgB,IAAIC,KAAK,CAACL,EAAeM,YAAa,CAAEC,KAAM,8BAC5F,GAAIP,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,yFAGf,CACD,MAAMkB,EAAkB,CAAC,CACjBC,MAAO,CAAC,KAAOf,KAAKE,oBACpBc,QAASZ,EAAea,cAE1BC,EAAiC,CACnCN,cAAeR,EAAeQ,cAC9BO,OAAQf,EAAee,OACvBC,YAAahB,EAAegB,YAC5BC,YAAajB,EAAeiB,YAC5BP,mBAE4B,MAA5BV,EAAekB,YACfJ,EAA+BI,UAAYlB,EAAekB,WAEpB,MAAtClB,EAAemB,sBACfL,EAA+BK,oBAC3BnB,EAAemB,qBAEgB,MAAnCnB,EAAeoB,mBACfN,EAA+BM,iBAC3BpB,EAAeoB,kBAEvB,MAAMC,EAAoCnB,OAAOC,IAAIC,gBAAgB,IAAIC,KAAK,CAACiB,KAAKC,UAAUT,IAAkC,CAAEP,KAAM,sBAGlIiB,EAAgC,MAAnB5B,KAAK4B,WAAqBC,SAASC,cAAc,KAChE9B,KAAK4B,WAOT,GANAA,EAAWG,SAAW/B,KAAKC,sBAC3B2B,EAAWI,KAAOP,QAIZrC,GAAM,IAAMwC,EAAWK,cAAc,IAAIC,WAAW,YACzB,MAA7B9B,EAAeM,WAAoB,CACnC,MAAMyB,EAA4C,MAAzBnC,KAAKmC,iBAC1BN,SAASC,cAAc,KACvB9B,KAAKmC,iBACTA,EAAiBJ,SAAW/B,KAAKE,mBACjCiC,EAAiBH,KAAO3B,QAClBjB,GAAM,IAAM+C,EAAiBF,cAAc,IAAIC,WAAW,WACpE,CACA,MAAO,CAAEE,oBAAoB,QAA6BhC,GAC9D,CACJ,EAEJZ,EAAiBM,WAAa,eAC9B,MAAMuC,EACF,WAAA5C,CAAY6C,GACR,GAAa,MAATA,GAAiBA,EAAM7D,OAAS,EAChC,MAAM,IAAImB,MACN,wEAAgB0C,KAExBtC,KAAKsC,MAAQA,CACjB,CACA,UAAMC,GACF,MAAMC,EAAWxC,KAAKsC,MAAM,GACtBG,EAAczC,KAAKsC,MAAMvC,MAAM,GACrC,OAAO,IAAIlB,SAAQ,CAACS,EAASoD,KACzB,MAAMC,EAAa,IAAIC,WACvBD,EAAWE,OAAUC,IAEjB,MAAMC,EAAYrB,KAAKsB,MAAMF,EAAMG,OAAOC,QACpCtC,EAAgBmC,EAAUnC,cAChC,GAAqB,MAAjBA,EAEA,YADA8B,EAAO,IAAI9C,MAAM,4CAA4C4C,EAASW,SAG/C,IAAvBV,EAAYhE,QACZa,EAAQ,CAAEsB,kBAEd,MAAME,EAAkBiC,EAAUjC,gBAClC,GAAuB,MAAnBA,EAEA,YADA4B,EAAO,IAAI9C,MAAM,6CAA6C4C,EAASW,SAG3E,IAAIC,EACJ,IACIA,EACIpD,KAAKqD,4BAA4BvC,EAAiB2B,EAC1D,CACA,MAAOa,GAEH,YADAZ,EAAOY,EAEX,CACA,MAAMrC,EAAc,GACdF,EAAQ,GACRwC,EAAiB,GACvBzC,EAAgB0C,SAAQC,IACpBA,EAAa1C,MAAMyC,SAAQE,IACvB3C,EAAM4C,KAAKD,GACXH,EAAeI,KAAK,KAAK,IAE7B1C,EAAY0C,QAAQF,EAAazC,QAAQ,IAE7CF,EAAgB0C,SAAQC,IACpBA,EAAa1C,MAAMyC,SAAQE,IACvB,MAAME,EAAmB,IAAIhB,WAC7BgB,EAAiBf,OAAUC,IAEvB,MAAMpC,EAAaoC,EAAMG,OAAOC,OAC1BW,EAAQ9C,EAAM+C,QAAQJ,GAE5B,GADAH,EAAeM,GAASnD,GACc,IAAlC6C,EAAeO,QAAQ,MAAc,CACrC,MAAMZ,EAAS,CACXtC,gBACAK,cACAP,YAAY,QAAwB6C,GACpCpC,OAAQ4B,EAAU5B,OAClBC,YAAa2B,EAAU3B,YACvBC,YAAa0B,EAAU1B,aAEA,MAAvB0B,EAAUzB,YACV4B,EAAO5B,UAAYyB,EAAUzB,WAEI,MAAjCyB,EAAUxB,sBACV2B,EAAO3B,oBAAsBwB,EAAUxB,qBAET,MAA9BwB,EAAUvB,mBACV0B,EAAO1B,iBAAmBuB,EAAUvB,kBAExClC,EAAQ4D,EACZ,GAEJU,EAAiBG,QAAUC,GAAStB,EAAO,6CAA6CgB,OACxFE,EAAiBK,kBAAkBb,EAAWM,GAAM,GACtD,GACJ,EAENf,EAAWoB,QAAUC,GAAStB,EAC1B,sEAAcF,EAASW,6EAE3BR,EAAWuB,WAAW1B,EAAS,GAEvC,CAIA,2BAAAa,CAA4Bc,EAAU7B,GAClC,MAAM8B,EAAY,GACZC,EAAY/B,EAAMvD,KAAIuF,IAAQ,QAASA,EAAKnB,QAC5CC,EAAa,CAAC,EACpB,IAAK,MAAMmB,KAASJ,EAChBI,EAAMxD,MAAMyC,SAAQE,IAChB,MAAMc,GAAe,QAASd,GAC9B,IAAyC,IAArCU,EAAUN,QAAQU,GAClB,MAAM,IAAI5E,MACN,uDAAI4E,MAGZ,GADAJ,EAAUT,KAAKa,IAC0B,IAArCH,EAAUP,QAAQU,GAClB,MAAM,IAAI5E,MAAM,8BAA8B4E,uBAG9CpB,EAAWM,GAAQpB,EAAM+B,EAAUP,QAAQU,GAC/C,IAGR,GAAIJ,EAAU3F,SAAW6D,EAAM7D,OAC3B,MAAM,IAAImB,MACN,wDAAIwE,EAAU3F,oDACV6D,EAAM7D,YAElB,OAAO2E,CACX,EAkGG,SAASqB,EAAanC,GACzB,OAAO,IAAID,EAAaC,EAC5B,CArFA,KAAiBoC,oBAbsBC,IAC9B,UAAMhF,QAAQ,gBAIVpB,MAAMC,QAAQmG,IAAQA,EAAI9E,WAAWL,EAAiBM,YAgD5D,SAA0BJ,EAAiB,SAC9C,OAAO,IAAIF,EAAiBE,EAChC,CAjDmBkF,CAAiBD,EAAI5E,MAAMP,EAAiBM,WAAWrB,SAJ3D,O,0BCtMR,MAAMoG,EACT,WAAApF,CAAYiE,EAAMoB,GAwBd,GAvBA9E,KAAK+E,eAAiB,OACH,MAAfD,IACAA,EAAc,CAAC,GAEnB9E,KAAKgF,iBAAmBF,EAAYE,iBACpChF,KAAK5B,WAAa0G,EAAY1G,WAC9B4B,KAAKiF,mBAAqBH,EAAYG,mBACT,MAAzBH,EAAYI,YACZ,QAAwC,oBAA1BJ,EAAYI,WAA0B,IAAM,gIAG1DlF,KAAKmF,MAAQL,EAAYI,WAGzBlF,KAAKmF,OAAQ,UAAMC,SAASD,OAEhC,QAAe,MAARzB,GAAgBA,EAAKjF,OAAS,GAAG,IAAM,4DAE1CF,MAAMC,QAAQkF,KACd,QAAuB,IAAhBA,EAAKjF,QAAc,IACtB,iEAAqBiF,EAAKjF,aAElCuB,KAAK0D,KAAOA,EACmB,MAA3BoB,EAAYO,aACoB,MAAhCP,EAAYO,YAAYC,KACxB,MAAM,IAAI1F,MAAM,sEAEpBI,KAAKqF,YAAcP,EAAYO,aAAe,CAAC,CACnD,CACA,UAAMlF,CAAKC,GACP,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,2FAGpB,MAAM2F,EAAOC,OAAOC,OAAO,CAAEC,OAAQ1F,KAAK+E,gBAAkB/E,KAAKqF,aACjEE,EAAKD,KAAO,IAAIK,SAChB,MAAM7E,EAAkB,CAAC,CACjBC,MAAO,CAAC,uBACRC,QAASZ,EAAea,cAE1BC,EAAiC,CACnCN,cAAeR,EAAeQ,cAC9BO,OAAQf,EAAee,OACvBC,YAAahB,EAAegB,YAC5BC,YAAajB,EAAeiB,YAC5BP,mBAE4B,MAA5BV,EAAekB,YACfJ,EAA+BI,UAAYlB,EAAekB,WAEpB,MAAtClB,EAAemB,sBACfL,EAA+BK,oBAC3BnB,EAAemB,qBAEgB,MAAnCnB,EAAeoB,mBACfN,EAA+BM,iBAC3BpB,EAAeoB,kBAEvB+D,EAAKD,KAAKM,OAAO,aAAc,IAAInF,KAAK,CAACiB,KAAKC,UAAUT,IAAkC,CAAEP,KA7DlF,qBA6DsG,cAC/E,MAA7BP,EAAeM,YACf6E,EAAKD,KAAKM,OAAO,oBAAqB,IAAInF,KAAK,CAACL,EAAeM,YAAa,CAAEC,KAhE3D,6BAgE4F,qBAEnH,MAAMkF,QAAiB7F,KAAKmF,MAAMnF,KAAK0D,KAAM6B,GAC7C,GAAIM,EAASC,GACT,MAAO,CACH1D,oBAAoB,QAA6BhC,GACjD2F,UAAW,CAACF,IAIhB,MAAM,IAAIjG,MACN,gEAAGiG,EAASG,UAExB,CASA,UAAMzD,GACF,MAAM0D,QAA2BjG,KAAKmF,MAAMnF,KAAK0D,KAAM1D,KAAKqF,aAC5D,IAAKY,EAAmBH,GACpB,MAAM,IAAIlG,MAAM,cAAcI,KAAK0D,gCAC5BuC,EAAmBD,iFAG9B,IAAIE,EACJ,IACIA,QAAoBD,EAAmBE,MAC3C,CACA,MAAOC,GACH,IAAIC,EAAU,+CAA+CrG,KAAK0D,QAelE,MAZI1D,KAAK0D,KAAK4C,SAAS,OACnBD,GAAW,+UAQXA,GAAW,uEAGT,IAAIzG,MAAMyG,EACpB,CACA,MAAMzF,EAAgBsF,EAAYtF,cAC5BE,EAAkBoF,EAAYpF,gBAC9BM,EAAc8E,EAAY9E,YAC1BC,EAAc6E,EAAY7E,YAC1BF,EAAS+E,EAAY/E,OACrBG,EAAY4E,EAAY5E,UACxBC,EAAsB2E,EAAY3E,oBAExC,GAAqB,MAAjBX,GAA4C,MAAnBE,EACzB,MAAM,IAAIlB,MAAM,2BAA2BI,KAAK0D,iEAGpD,IAAIzC,EACAP,EACJ,GAAuB,MAAnBI,EAAyB,CACzB,MAAMyF,QAAgBvG,KAAKwG,YAAY1F,IACtCG,EAAaP,GAAc6F,CAChC,CACA,MAAME,EAAY,CACd7F,gBACAK,cACAP,aACAU,cACAC,cACAF,UAEa,MAAbG,IACAmF,EAAUnF,UAAYA,GAEC,MAAvBC,IACAkF,EAAUlF,oBAAsBA,GAEpC,MAAMmF,EAAcR,EAAY1E,iBAIhC,OAHIkF,IACAD,EAAUjF,iBAAmBkF,GAE1BD,CACX,CACA,iBAAMD,CAAY1F,GACd,MAAM6F,EAAapI,MAAMC,QAAQwB,KAAK0D,MAAQ1D,KAAK0D,KAAK,GAAK1D,KAAK0D,MAC3DkD,EAAQC,GAyChB,SAAkBlC,GACrB,MAAMmC,EAAYnC,EAAIoC,YAAY,KAC5BC,EAAkBrC,EAAIoC,YAAY,KAClCH,EAASjC,EAAIsC,UAAU,EAAGH,GAC1BD,EAASG,EAAkBF,EAAYnC,EAAIsC,UAAUD,GAAmB,GAC9E,MAAO,CAACJ,EAAS,IAAKC,EAC1B,CA/CiCK,CAASP,GAC5BQ,EAAanH,KAAKgF,kBAAoB4B,EACtC3F,EAAc,GACpB,IAAK,MAAMmG,KAAStG,EAChBG,EAAY0C,QAAQyD,EAAMpG,SAE9B,MAAMqG,EAAY,GACZC,EAAc,GACpB,IAAK,MAAM7D,KAAgB3C,EACvB,IAAK,MAAM4C,KAAQD,EAAa1C,MACG,MAA3Bf,KAAKiF,mBACLqC,EAAY3D,KAAK3D,KAAKiF,mBAAmBvB,IAGzC2D,EAAU1D,KAAKwD,EAAazD,EAAOmD,GAI3C7G,KAAKiF,oBACLoC,EAAU1D,cAAc9E,QAAQC,IAAIwI,IAExC,MAAMC,QAAgB,QAAyBF,EAAW,CACtDhC,YAAarF,KAAKqF,YAClBH,UAAWlF,KAAKmF,MAChB/G,WAAY4B,KAAK5B,aAErB,MAAO,CAAC6C,GAAa,QAAwBsG,GACjD,EAqBG,SAASC,EAAa7C,GACzB,OAAkD,MAA3CA,EAAI8C,MAAM5C,EAAY6C,iBACjC,CArBA7C,EAAY6C,iBAAmB,eAsBxB,MAAMC,EAAa,CAAChD,EAAKG,KAC5B,GAAqB,qBAAVK,QACS,MAAfL,GAAgD,MAAzBA,EAAYI,WAIpC,OAAO,KAEN,CACD,IAAI0C,GAAS,EAOb,GALIA,EADArJ,MAAMC,QAAQmG,GACLA,EAAIkD,OAAMC,GAAWN,EAAaM,KAGlCN,EAAa7C,GAEtBiD,EACA,OAAOG,EAAKpD,EAAKG,EAEzB,CACA,OAAO,IAAI,EA0ER,SAASiD,EAAKrE,EAAMoB,GACvB,OAAO,IAAID,EAAYnB,EAAMoB,EACjC,CAMO,SAASkD,EAAmBtE,EAAMoB,GACrC,OAAOiD,EAAKrE,EAAMoB,EACtB,CAlFA,KAAiBJ,mBAAmBiD,GACpC,KAAiBM,mBAAmBN,GC/OpC,MAAMO,EACF,WAAAzI,CAAYW,GACRJ,KAAKI,eAAiBA,CAC1B,CACA,UAAMmC,GACF,OAAOvC,KAAKI,cAChB,EAEJ,MAAM+H,EACF,WAAA1I,CAAY2I,GACRpI,KAAKoI,YAAcA,CACvB,CACA,UAAMjI,CAAKC,GACP,OAAOJ,KAAKoI,YAAYhI,EAC5B,EAuBG,SAASiI,EAAWjI,EAAgBa,EAAaP,EAAY4H,GAChE,GAAyB,IAArBC,UAAU9J,OAAc,CACxB,MAAM+J,EAAmD,MAAhCpI,EAAeQ,eACN,MAA9BR,EAAea,YACnB,OACW,IAAIiH,EADXM,EAC6BpI,EASA,CAAEQ,cAAeR,GAEtD,CAQI,OAAO,IAAI8H,EAAkB,CACzBtH,cAAeR,EACfa,cACAP,aACA4H,kBAGZ,CAgBO,SAASG,EAAgBL,GAC5B,OAAO,IAAID,EAAiBC,EAChC,C,6IClFA,MAAMM,EAAgB,eAKhBC,EAAmB,eAInBC,EAAkB,mBAYxB,SAASC,IACL,KAAK,UAAMlJ,QAAQ,cAIf,MAAM,IAAIC,MAAM,2FAIpB,MAAMkJ,EAA8B,qBAAXxI,OAAyByI,KAAOzI,OACnD0I,EAAUF,EAAUG,WAAaH,EAAUI,cAC7CJ,EAAUK,iBAAmBL,EAAUM,aACvCN,EAAUO,cACd,GAAe,MAAXL,EACA,MAAM,IAAIpJ,MAAM,6DAEpB,OAAOoJ,CACX,CACA,SAASM,EAAcC,GACnB,MAAMC,EAAKD,EAAYrG,OACvBsG,EAAGC,kBAAkBd,EAAkB,CAAEe,QAAS,cAClDF,EAAGC,kBAAkBb,EAAiB,CAAEc,QAAS,aACrD,CAMO,MAAMC,EACT,WAAAlK,CAAYmK,GAER,GADA5J,KAAKiJ,UAAYJ,IACA,MAAbe,IAAsBA,EACtB,MAAM,IAAIhK,MAAM,kEAEpBI,KAAK4J,UAAYA,CACrB,CACA,UAAMzJ,CAAKC,GAEP,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,4FAGpB,OAAOI,KAAK6J,eAAe7J,KAAK4J,UAAWxJ,EAC/C,CACA,UAAMmC,GACF,OAAOvC,KAAK6J,eAAe7J,KAAK4J,UACpC,CAeA,cAAAC,CAAeD,EAAWxJ,GACtB,OAAO,IAAIvB,SAAQ,CAACS,EAASoD,KACzB,MAAM6G,EAAcvJ,KAAKiJ,UAAUa,KAAKpB,EAnF3B,GAoFba,EAAYQ,gBAAkB,IAAMT,EAAcC,GAClDA,EAAYS,UAAY,KACpB,MAAMR,EAAKD,EAAYrG,OACvB,GAAsB,MAAlB9C,EAAwB,CAExB,MAAM6J,EAAUT,EAAGU,YAAYvB,EAAkB,YAE3CwB,EADaF,EAAQG,YAAYzB,GACT0B,IAAIrK,KAAK4J,WACvCO,EAAWH,UAAY,KACnB,GAAyB,MAArBG,EAAWjH,OAEX,OADAsG,EAAGc,QACI5H,EAAO,IAAI9C,MAAM,gCAAgCI,KAAK4J,6BAI7DtK,EAAQ6K,EAAWjH,OAAO9C,eAC9B,EAEJ+J,EAAWpG,QAAUC,IACjBwF,EAAGc,QACI5H,EAAOyH,EAAWnG,QAE7BiG,EAAQM,WAAa,IAAMf,EAAGc,OAClC,KACK,CAED,MAAMlI,GAAqB,QAA6BhC,GAElDoK,EAAShB,EAAGU,YAAYtB,EAAiB,aAC/C,IAAI6B,EAAYD,EAAOJ,YAAYxB,GACnC,MAAM8B,EAAiBD,EAAUE,IAAI,CAAEf,UAAW5J,KAAK4J,UAAWxH,uBAClE,IAAI6H,EACJS,EAAeV,UAAY,KAEvBC,EAAUT,EAAGU,YAAYvB,EAAkB,aAC3C,MACMiC,EADaX,EAAQG,YAAYzB,GACJgC,IAAI,CACnCf,UAAW5J,KAAK4J,UAChBxJ,iBACAgC,uBAEJwI,EAAgBZ,UAAY,IAAM1K,EAAQ,CAAE8C,uBAC5CwI,EAAgB7G,QAAUC,IAGtByG,EAAYD,EAAOJ,YAAYxB,GAC/B,MAAMiC,EAAoBJ,EAAUK,OAAO9K,KAAK4J,WAChDiB,EAAkBb,UAAY,KAC1BR,EAAGc,QACI5H,EAAOkI,EAAgB5G,QAElC6G,EAAkB9G,QAAUC,IACxBwF,EAAGc,QACI5H,EAAOkI,EAAgB5G,OACjC,CACJ,EAEL0G,EAAe3G,QAAUC,IACrBwF,EAAGc,QACI5H,EAAOgI,EAAe1G,QAEjCwG,EAAOD,WAAa,KACD,MAAXN,EACAT,EAAGc,QAGHL,EAAQM,WAAa,IAAMf,EAAGc,OAClC,CAER,GAEJf,EAAYxF,QAAUC,GAAStB,EAAO6G,EAAYvF,MAAM,GAEhE,EAEJ2F,EAAiB7J,WAAa,eACvB,MAAMiL,EAAmBpG,IAC5B,OAAK,UAAMhF,QAAQ,gBAIVpB,MAAMC,QAAQmG,IAAQA,EAAI9E,WAAW8J,EAAiB7J,aA2BlC8J,EA1BGjF,EAAI5E,MAAM4J,EAAiB7J,WAAWrB,QA2B/D,IAAIkL,EAAiBC,IA/BjB,KA8BR,IAA0BA,CArB7B,EAEJ,KAAiBlF,mBAAmBqG,GACpC,KAAiB9C,mBAAmB8C,GA0B7B,MAAMC,EACT,WAAAvL,GACIO,KAAKiJ,UAAYJ,GACrB,CACA,gBAAMoC,GACF,OAAO,IAAIpM,SAAQ,CAACS,EAASoD,KACzB,MAAM6G,EAAcvJ,KAAKiJ,UAAUa,KAAKpB,EA9M3B,GA+Mba,EAAYQ,gBAAkB,IAAMT,EAAcC,GAClDA,EAAYS,UAAY,KACpB,MAAMR,EAAKD,EAAYrG,OACjBgI,EAAK1B,EAAGU,YAAYtB,EAAiB,YAUrCuC,EATQD,EAAGd,YAAYxB,GASGwC,SAChCD,EAAkBnB,UAAY,KAC1B,MAAMqB,EAAM,CAAC,EACb,IAAK,MAAMC,KAAQH,EAAkBjI,OACjCmI,EAAIC,EAAK1B,WAAa0B,EAAKlJ,mBAE/B9C,EAAQ+L,EAAI,EAEhBF,EAAkBpH,QAAUC,IACxBwF,EAAGc,QACI5H,EAAOyI,EAAkBnH,QAEpCkH,EAAGX,WAAa,IAAMf,EAAGc,OAAO,EAEpCf,EAAYxF,QAAUC,GAAStB,EAAO6G,EAAYvF,MAAM,GAEhE,CACA,iBAAMuH,CAAY7H,GA1CtB,IAA0B8H,EA4ClB,OADA9H,GA3CkB8H,EA2CM9H,GA1CjB7D,WAAW8J,EAAiB7J,YACnC0L,EAAIzL,MAAM4J,EAAiB7J,WAAWrB,QACtC+M,EAyCO,IAAI3M,SAAQ,CAACS,EAASoD,KACzB,MAAM6G,EAAcvJ,KAAKiJ,UAAUa,KAAKpB,EAhP3B,GAiPba,EAAYQ,gBAAkB,IAAMT,EAAcC,GAClDA,EAAYS,UAAY,KACpB,MAAMR,EAAKD,EAAYrG,OACjBsH,EAAShB,EAAGU,YAAYtB,EAAiB,aACzC6B,EAAYD,EAAOJ,YAAYxB,GAC/B6C,EAAiBhB,EAAUJ,IAAI3G,GACrC,IAAIuG,EACJwB,EAAezB,UAAY,KACvB,GAA6B,MAAzByB,EAAevI,OAEf,OADAsG,EAAGc,QACI5H,EAAO,IAAI9C,MAAM,gCAAgC8D,qBAGvD,CAED,MAAMmH,EAAoBJ,EAAUK,OAAOpH,GACrCgI,EAAkB,KAEpBzB,EAAUT,EAAGU,YAAYvB,EAAkB,aAC3C,MACMgD,EADa1B,EAAQG,YAAYzB,GACDmC,OAAOpH,GAC7CiI,EAAmB3B,UAAY,IAAM1K,EAAQmM,EAAevI,OAAOd,oBACnEuJ,EAAmB5H,QAAUC,GAAStB,EAAO+I,EAAezH,MAAM,EAItE6G,EAAkBb,UAAY0B,EAC9Bb,EAAkB9G,QAAUC,IACxB0H,IACAlC,EAAGc,QACI5H,EAAO+I,EAAezH,OAErC,GAEJyH,EAAe1H,QAAUC,IACrBwF,EAAGc,QACI5H,EAAO+I,EAAezH,QAEjCwG,EAAOD,WAAa,KACD,MAAXN,EACAT,EAAGc,QAGHL,EAAQM,WAAa,IAAMf,EAAGc,OAClC,CACH,EAELf,EAAYxF,QAAUC,GAAStB,EAAO6G,EAAYvF,MAAM,GAEhE,E,yJCvSG,MAAM4H,EACT,WAAAnM,GACIO,KAAK6L,YAAc,GACnB7L,KAAK8L,YAAc,EACvB,CACA,kBAAOC,GAIH,OAHiC,MAA7BH,EAAiBI,WACjBJ,EAAiBI,SAAW,IAAIJ,GAE7BA,EAAiBI,QAC5B,CAOA,yBAAOtH,CAAmBuH,GACtBL,EAAiBG,cAAcF,YAAYlI,KAAKsI,EACpD,CAOA,yBAAOhE,CAAmBiE,GACtBN,EAAiBG,cAAcD,YAAYnI,KAAKuI,EACpD,CASA,sBAAOC,CAAgBxH,GACnB,OAAOiH,EAAiBQ,YAAYzH,EAAK,OAC7C,CASA,sBAAO0H,CAAgB1H,EAAKG,GACxB,OAAO8G,EAAiBQ,YAAYzH,EAAK,OAAQG,EACrD,CACA,kBAAOsH,CAAYzH,EAAK2H,EAAaxH,GACjC,MAAMyH,EAAgB,GAUtB,OATgC,SAAhBD,EACZV,EAAiBG,cAAcD,YAC/BF,EAAiBG,cAAcF,aAC3BrI,SAAQgJ,IACZ,MAAMC,EAAUD,EAAO7H,EAAKG,GACZ,OAAZ2H,GACAF,EAAc5I,KAAK8I,EACvB,IAEGF,CACX,EAEG,MAAM7H,EAAsBgI,GAAed,EAAiBlH,mBAAmBgI,GACzEzE,EAAsByE,GAAed,EAAiB3D,mBAAmByE,GACzEP,EAAmBxH,GAAQiH,EAAiBO,gBAAgBxH,GAC5D0H,EAAkB,CAAC1H,EAAKG,IAAgB8G,EAAiBS,gBAAgB1H,EAAKG,E,kLCxD3F,MAAM6H,EAAoB,MACnB,MAAMC,EACT,WAAAnN,GACIO,KAAK6M,SAAW,CAAC,CACrB,CACA,kBAAOd,GAIH,OAH0C,MAAtCa,EAA0BZ,WAC1BY,EAA0BZ,SAAW,IAAIY,GAEtCA,EAA0BZ,QACrC,CAOA,sBAAOc,CAAgBC,EAAQC,IAC3B,QAAiB,MAAVD,GAAgB,IAAM,0CACzBA,EAAOzG,SAASqG,KAChBI,EAASA,EAAOhN,MAAM,EAAGgN,EAAOjJ,QAAQ6I,MAE5C,QAAOI,EAAOtO,OAAS,GAAG,IAAM,wCAChC,MAAMwO,EAAWL,EAA0Bb,eAC3C,QAAoC,MAA7BkB,EAASJ,SAASE,IAAiB,IAAM,2DAA2DA,QAC3GE,EAASJ,SAASE,GAAUC,CAChC,CACA,iBAAOE,CAAWH,GACd,MAAMC,EAAUhN,KAAK+L,cAAcc,SAASE,GAC5C,GAAe,MAAXC,EACA,MAAM,IAAIpN,MAAM,yCAAyCmN,MAE7D,OAAOC,CACX,CACA,iBAAOG,GACH,OAAO3H,OAAO4H,KAAKpN,KAAK+L,cAAcc,SAC1C,EAUJ,SAASQ,EAAS1I,GACd,IAAwC,IAApCA,EAAIb,QAAQ6I,GACZ,MAAM,IAAI/M,MAEN,6EAAGgN,EAA0BO,aAAaG,KAAK,QAEvD,MAAO,CACHP,OAAQpI,EAAI4I,MAAMZ,GAAmB,GACrCjJ,KAAMiB,EAAI4I,MAAMZ,GAAmB,GAE3C,CACAa,eAAeC,EAAmBC,EAAWC,EAASC,GAAe,IACjE,QAAOF,IAAcC,GAAS,IAAM,wCAAwCD,OAC5E,MAAMG,EAAe,KAAiBxB,gBAAgBqB,IACtD,QAAOG,EAAapP,OAAS,GAAG,IAAM,kEAAkEiP,QACxG,QAAOG,EAAapP,OAAS,GAAG,IAAM,yCAAyCoP,EAAapP,wCACxDiP,OACpC,MAAMI,EAAcD,EAAa,GAC3BE,EAAe,KAAiB5B,gBAAgBwB,IACtD,QAAOI,EAAatP,OAAS,GAAG,IAC5B,uEAAOkP,QACX,QAAOI,EAAatP,OAAS,GAAG,IAAM,yCAAyCoP,EAAapP,6CACnDkP,OACzC,MAAMvF,EAAc2F,EAAa,GAC3BC,EAAeX,EAASK,GAAWX,OACnCkB,EAAaZ,EAASK,GAAWhK,KACjCwK,EAAaF,IAAiBX,EAASK,GAAWX,OAClD3M,QAAuB0N,EAAYvL,OAIrCqL,GAAgBM,SACVtB,EAA0BM,WAAWc,GACtCzC,YAAY0C,GAErB,MAAME,QAAmB/F,EAAYjI,KAAKC,GAQ1C,OAJIwN,IAAiBM,SACXtB,EAA0BM,WAAWc,GACtCzC,YAAY0C,GAEdE,EAAW/L,kBACtB,CAoCAoL,eAAevC,IACX,MAAMmD,EAAUxB,EAA0BO,aACpC9B,EAAM,CAAC,EACb,IAAK,MAAM0B,KAAUqB,EAAS,CAC1B,MAAMC,QAAkBzB,EAA0BM,WAAWH,GAAQ9B,aACrE,IAAK,MAAMvH,KAAQ2K,EAAW,CAE1BhD,EADY0B,EAASJ,EAAoBjJ,GAC9B2K,EAAU3K,EACzB,CACJ,CACA,OAAO2H,CACX,CAkCAmC,eAAejC,EAAY5G,GACvB,MAAM2J,EAAgBjB,EAAS1I,GAE/B,OADgBiI,EAA0BM,WAAWoB,EAAcvB,QACpDxB,YAAY+C,EAAc5K,KAC7C,CAgDA8J,eAAee,EAAUb,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB,EAEzB,CA+CAH,eAAegB,EAAUd,EAAWC,GAEhC,OAAOF,EAAmBC,EAAWC,GADhB,EAEzB,C,0IC3RA,MAAMc,EAAiB,IACjBC,EAAc,sBACdC,EAAc,OACdC,EAAwB,iBACxBC,EAAsB,eACtBC,EAAqB,cACrBC,EAAwB,iBA2B9B,SAASC,EAAatL,GAClB,MAAO,CACHuL,KAAM,CAACP,EAAahL,EAAMiL,GAAarB,KAAKmB,GAC5CS,SAAU,CAACR,EAAahL,EAAMkL,GAAuBtB,KAAKmB,GAC1DxN,YAAa,CAACyN,EAAahL,EAAMmL,GAAqBvB,KAAKmB,GAC3D/N,WAAY,CAACgO,EAAahL,EAAMoL,GAAoBxB,KAAKmB,GACzDU,cAAe,CAACT,EAAahL,EAAMqL,GAAuBzB,KAAKmB,GAEvE,CAQA,SAASW,EAAoB5D,GACzB,MAAM6D,EAAQ7D,EAAI+B,MAAMkB,GACxB,GAAIY,EAAM5Q,OAAS,EACf,MAAM,IAAImB,MAAM,uBAAuB4L,KAE3C,OAAO6D,EAAMtP,MAAM,EAAGsP,EAAM5Q,OAAS,GAAG6O,KAAKmB,EACjD,CAWO,MAAMa,EACT,WAAA7P,CAAYmK,GACR,KAAK,UAAMjK,QAAQ,eAAmC,qBAAXW,QACR,qBAAxBA,OAAOiP,aAKd,MAAM,IAAI3P,MAAM,2DAGpB,GADAI,KAAKwP,GAAKlP,OAAOiP,aACA,MAAb3F,IAAsBA,EACtB,MAAM,IAAIhK,MAAM,sEAEpBI,KAAK4J,UAAYA,EACjB5J,KAAKoN,KAAO4B,EAAahP,KAAK4J,UAClC,CAUA,UAAMzJ,CAAKC,GACP,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,4FAGf,CACD,MAAMsP,EAAWxN,KAAKC,UAAUvB,EAAeQ,eACzCK,EAAcS,KAAKC,UAAUvB,EAAea,aAC5CmB,GAAqB,QAA6BhC,GACxD,IACIJ,KAAKwP,GAAGC,QAAQzP,KAAKoN,KAAK6B,KAAMvN,KAAKC,UAAUS,IAC/CpC,KAAKwP,GAAGC,QAAQzP,KAAKoN,KAAK8B,SAAUA,GACpClP,KAAKwP,GAAGC,QAAQzP,KAAKoN,KAAKnM,YAAaA,GACvCjB,KAAKwP,GAAGC,QAAQzP,KAAKoN,KAAK1M,YAAY,QAA0BN,EAAeM,aAC/E,MAAMwC,EAAS,CACX/B,OAAQf,EAAee,OACvBC,YAAahB,EAAegB,YAC5BC,YAAajB,EAAeiB,aAYhC,OAVgC,MAA5BjB,EAAekB,YACf4B,EAAO5B,UAAYlB,EAAekB,WAEI,MAAtClB,EAAemB,sBACf2B,EAAO3B,oBAAsBnB,EAAemB,qBAET,MAAnCnB,EAAeoB,mBACf0B,EAAO1B,iBAAmBpB,EAAeoB,kBAE7CxB,KAAKwP,GAAGC,QAAQzP,KAAKoN,KAAK+B,cAAezN,KAAKC,UAAUuB,IACjD,CAAEd,qBACb,CACA,MAAOkB,GAOH,MALAtD,KAAKwP,GAAGE,WAAW1P,KAAKoN,KAAK6B,MAC7BjP,KAAKwP,GAAGE,WAAW1P,KAAKoN,KAAK8B,UAC7BlP,KAAKwP,GAAGE,WAAW1P,KAAKoN,KAAKnM,aAC7BjB,KAAKwP,GAAGE,WAAW1P,KAAKoN,KAAK1M,YAC7BV,KAAKwP,GAAGE,WAAW1P,KAAKoN,KAAK+B,eACvB,IAAIvP,MAAM,yBAAyBI,KAAK4J,kHAEpBxH,EAAmBuN,wCACrBvN,EAAmBwN,qCACpBxN,EAAmByN,mBAC9C,CACJ,CACJ,CASA,UAAMtN,GACF,MAAM0M,EAAOvN,KAAKsB,MAAMhD,KAAKwP,GAAGM,QAAQ9P,KAAKoN,KAAK6B,OAClD,GAAY,MAARA,EACA,MAAM,IAAIrP,MAAM,kDAAkDI,KAAK4J,cAE3E,GAA+B,SAA3BqF,EAAKc,kBACL,MAAM,IAAInQ,MAAM,6EAGpB,MAAMyL,EAAM,CAAC,EAEP6D,EAAWxN,KAAKsB,MAAMhD,KAAKwP,GAAGM,QAAQ9P,KAAKoN,KAAK8B,WACtD,GAAgB,MAAZA,EACA,MAAM,IAAItP,MAAM,4CAA4CI,KAAK4J,0BAGrEyB,EAAIzK,cAAgBsO,EAEpB,MAAMjO,EAAcS,KAAKsB,MAAMhD,KAAKwP,GAAGM,QAAQ9P,KAAKoN,KAAKnM,cACzD,GAAmB,MAAfA,EACA,MAAM,IAAIrB,MAAM,gDAAgDI,KAAK4J,2BAGzEyB,EAAIpK,YAAcA,EAElB,MAAM+O,EAAiBhQ,KAAKwP,GAAGM,QAAQ9P,KAAKoN,KAAK+B,eACjD,GAAsB,MAAlBa,EAAwB,CACxB,MAAMC,EAAWvO,KAAKsB,MAAMgN,GAC5B3E,EAAIlK,OAAS8O,EAAiB,OAC9B5E,EAAIjK,YAAc6O,EAAsB,YACxC5E,EAAIhK,YAAc4O,EAAsB,YACX,MAAzBA,EAAoB,YACpB5E,EAAI/J,UAAY2O,EAAoB,WAED,MAAnCA,EAA8B,sBAC9B5E,EAAI9J,oBAAsB0O,EAA8B,qBAExB,MAAhCA,EAA2B,mBAC3B5E,EAAI7J,iBAAmByO,EAA2B,iBAE1D,CAEA,MAAMC,EAAmBlQ,KAAKwP,GAAGM,QAAQ9P,KAAKoN,KAAK1M,YACnD,GAAwB,MAApBwP,EACA,MAAM,IAAItQ,MACN,wDAAII,KAAK4J,2BAGjB,OADAyB,EAAI3K,YAAa,QAA0BwP,GACpC7E,CACX,EAEJiE,EAAoBxP,WAAa,kBAC1B,MAAMqQ,EAAsBxL,IAC/B,OAAK,UAAMhF,QAAQ,gBAIVpB,MAAMC,QAAQmG,IAAQA,EAAI9E,WAAWyP,EAAoBxP,aAkClC8J,EAjCGjF,EAAI5E,MAAMuP,EAAoBxP,WAAWrB,QAkCrE,IAAI6Q,EAAoB1F,IAtCpB,KAqCR,IAA6BA,CA5BhC,EAEJ,KAAiBlF,mBAAmByL,GACpC,KAAiBlI,mBAAmBkI,GA4B7B,MAAMC,EACT,WAAA3Q,IACI,SAAO,UAAME,QAAQ,eAAe,IAAM,8CAC1C,QAAyB,qBAAXW,QACqB,qBAAxBA,OAAOiP,cAA8B,IAAM,4DACtDvP,KAAKwP,GAAKlP,OAAOiP,YACrB,CACA,gBAAMtE,GACF,MAAMI,EAAM,CAAC,EACPzE,EAAS8H,EAAcD,EACvB5H,EAAS4H,EAAiBE,EAChC,IAAK,IAAI0B,EAAI,EAAGA,EAAIrQ,KAAKwP,GAAG/Q,SAAU4R,EAAG,CACrC,MAAM7E,EAAMxL,KAAKwP,GAAGhE,IAAI6E,GACxB,GAAI7E,EAAI3L,WAAW+G,IAAW4E,EAAIlF,SAASO,GAAS,CAEhDwE,EADkB+D,EAAoB5D,IACrB9J,KAAKsB,MAAMhD,KAAKwP,GAAGM,QAAQtE,GAChD,CACJ,CACA,OAAOH,CACX,CACA,iBAAME,CAAY7H,GA5MtB,IAA0B8H,EA8MlB,MAAM4B,EAAO4B,EADbtL,GA7MkB8H,EA6MM9H,GA5MjB7D,WAAWyP,EAAoBxP,YACtC0L,EAAIzL,MAAMuP,EAAoBxP,WAAWrB,QACzC+M,GA4MA,GAAkC,MAA9BxL,KAAKwP,GAAGM,QAAQ1C,EAAK6B,MACrB,MAAM,IAAIrP,MAAM,8BAA8B8D,MAElD,MAAMuL,EAAOvN,KAAKsB,MAAMhD,KAAKwP,GAAGM,QAAQ1C,EAAK6B,OAK7C,OAJAjP,KAAKwP,GAAGE,WAAWtC,EAAK6B,MACxBjP,KAAKwP,GAAGE,WAAWtC,EAAK8B,UACxBlP,KAAKwP,GAAGE,WAAWtC,EAAKnM,aACxBjB,KAAKwP,GAAGE,WAAWtC,EAAK1M,YACjBuO,CACX,E,uQChRJ,MAAMqB,EAA0B,EAkBzB9C,eAAe+C,EAAcC,EAASjM,GAEzC,MAAMkM,EAAQ,GACRC,EAAe,GACfC,EAAQpS,MAAMC,QAAQgS,GACxBA,EAAQzR,KAAI6R,GAAUA,EAAOzN,OAC7BqC,OAAO4H,KAAKoD,GAChB,IAAK,IAAIH,EAAI,EAAGA,EAAIM,EAAMlS,SAAU4R,EAAG,CACnC,MAAMlN,EAAOwN,EAAMN,GACbQ,EAAItS,MAAMC,QAAQgS,GAAWA,EAAQH,GAAGO,OAASJ,EAAQrN,GAC/D,GAAgB,YAAZ0N,EAAEC,OAAmC,UAAZD,EAAEC,OAAiC,SAAZD,EAAEC,OACtC,WAAZD,EAAEC,OAAkC,cAAZD,EAAEC,MAC1B,MAAM,IAAIlR,MAAM,gCAAgCuD,OAAU0N,EAAEC,SAEhE,MAAMC,EAAO,CAAE5N,OAAM6N,MAAOH,EAAEG,MAAOF,MAAOD,EAAEC,OAC9C,GAAgB,WAAZD,EAAEC,MAAoB,CACtB,MAAMG,EAAY,IAAIpS,SAAQ2O,MAAOlO,IACjC,MAAM4R,QAAaL,EAAEM,QACfC,EAAgBF,EAAKG,QAAO,CAACC,EAAGC,IAAMD,EAAIC,EAAE9S,QAAQ,GACtD6R,EAA0BY,EAAKzS,OAC7B0S,EAAQ,IAAIK,WAAWJ,GAC7B,IAAIK,EAAS,EACb,IAAK,IAAIpB,EAAI,EAAGA,EAAIa,EAAKzS,OAAQ4R,IAAK,CAClC,MAAMqB,EAAMR,EAAKb,GACXsB,EAAgB,IAAIH,WAAW,IAAII,YAAY,CAACF,EAAIjT,SAASoT,QACnEV,EAAMW,IAAIH,EAAeF,GACzBA,GAAUnB,EACVa,EAAMW,IAAIJ,EAAKD,GACfA,GAAUC,EAAIjT,MAClB,CACAa,EAAQ6R,EAAM,IAElBT,EAAa/M,KAAKsN,EACtB,MAEIP,EAAa/M,KAAKkN,EAAEkB,QAEX,MAATxN,IACAwM,EAAKxM,MAAQA,GAEjBkM,EAAM9M,KAAKoN,EACf,CAEA,MAAO,CAAEgB,KAAMC,QADYnT,QAAQC,IAAI4R,IACcD,QACzD,CAgBO,SAASwB,EAAcJ,EAAQpB,GAElC,MAAMpF,EAAM,CAAC,EACb,IAAI6G,EACAT,EAAS,EACb,IAAK,MAAMV,KAAQN,EAAO,CACtB,MAAMtN,EAAO4N,EAAK5N,KACZ2N,EAAQC,EAAKD,MACbE,EAAQD,EAAKC,MACbmB,GAAO,QAAcnB,GAC3B,IAAIoB,EACJ,GAAI,iBAAkBrB,EAAM,CACxB,MAAMsB,EAAetB,EAAKsB,aAC1B,GAA2B,UAAvBA,EAAavB,OAA4C,WAAvBuB,EAAavB,OAC/C,KAAM,QAASuB,MAAgB,UAAWA,GACtC,MAAM,IAAIzS,MAAM,UAAUmR,EAAK5N,0BAA0BkP,EAAavB,gEAIzE,IAA2B,YAAvBuB,EAAavB,MAOlB,MAAM,IAAIlR,MAAM,UAAUmR,EAAK5N,uCACLkP,EAAavB,+EAPvC,GAAc,YAAVA,EACA,MAAM,IAAIlR,MAAM,UAAUmR,EAAK5N,0BAA0BkP,EAAavB,yDACfA,KAQ/D,CACA,MAAMwB,EAAyB,IAAqBD,EAAavB,OAC3DyB,EAAaV,EAAO9R,MAAM0R,EAAQA,EAASU,EAAOG,GAClDE,EAAyC,UAAvBH,EAAavB,MACjC,IAAIU,WAAWe,GACf,IAAIE,YAAYF,GACpB,GAAc,YAAVzB,EACA,GAA2B,UAAvBuB,EAAavB,OAA4C,WAAvBuB,EAAavB,MAAoB,CACnEsB,EAAS,IAAIM,aAAaF,EAAe/T,QACzC,IAAK,IAAI4R,EAAI,EAAGA,EAAImC,EAAe/T,OAAQ4R,IAAK,CAC5C,MAAMsC,EAAIH,EAAenC,GACzB+B,EAAO/B,GAAKsC,EAAIN,EAAaO,MAAQP,EAAaQ,GACtD,CACJ,KACK,IAA2B,YAAvBR,EAAavB,MAOlB,MAAM,IAAIlR,MAAM,iCAAiCyS,EAAavB,uCANxCgC,IAAlBZ,IACAA,EAAgBa,KAEpBX,EAASF,EAAcM,EAK3B,KAEC,IAAc,UAAV1B,EAYL,MAAM,IAAIlR,MAAM,gCAAgCuD,OAAU2N,KAX1D,GAA2B,UAAvBuB,EAAavB,OAA4C,WAAvBuB,EAAavB,MAC/C,MAAM,IAAIlR,MAAM,iCAAiCyS,EAAavB,gCAGlEsB,EAAS,IAAIY,WAAWR,EAAe/T,QACvC,IAAK,IAAI4R,EAAI,EAAGA,EAAImC,EAAe/T,OAAQ4R,IAAK,CAC5C,MAAMsC,EAAIH,EAAenC,GACzB+B,EAAO/B,GAAK4C,KAAKC,MAAMP,EAAIN,EAAaO,MAAQP,EAAaQ,IACjE,CAIJ,CACApB,GAAUU,EAAOG,CACrB,MACK,GAAc,WAAVxB,EAAoB,CACzB,MAAMqB,GAAO,QAAcpB,EAAKC,OAChCoB,EAAS,GACT,IAAK,IAAI/B,EAAI,EAAGA,EAAI8B,EAAM9B,IAAK,CAC3B,MAAM8C,EAAa,IAAIvB,YAAYC,EAAO9R,MAAM0R,EAAQA,EAASnB,IAA0B,GAC3FmB,GAAUnB,EACV,MAAMa,EAAQ,IAAIK,WAAWK,EAAO9R,MAAM0R,EAAQA,EAAS0B,IAC3Df,EAAOzO,KAAKwN,GACZM,GAAU0B,CACd,CACJ,KACK,CACD,MAAMC,EAAc,IAAqBtC,GACnCyB,EAAaV,EAAO9R,MAAM0R,EAAQA,EAASU,EAAOiB,GACxD,GAAc,YAAVtC,EACAsB,EAAS,IAAIM,aAAaH,QAEzB,GAAc,UAAVzB,EACLsB,EAAS,IAAIY,WAAWT,QAEvB,GAAc,SAAVzB,EACLsB,EAAS,IAAIZ,WAAWe,OAEvB,IAAc,cAAVzB,EAeL,MAAM,IAAIlR,MAAM,gCAAgCuD,OAAU2N,KAf9B,CAC5BsB,EAAS,IAAIM,aAAaH,GAC1B,MAAMc,EAAO,IAAIX,aAAaN,EAAO3T,OAAS,GACxC6U,EAAQ,IAAIZ,aAAaN,EAAO3T,OAAS,GAC/C,IAAK,IAAI4R,EAAI,EAAGA,EAAIgD,EAAK5U,OAAQ4R,IAC7BgD,EAAKhD,GAAK+B,EAAW,EAAJ/B,GACjBiD,EAAMjD,GAAK+B,EAAW,EAAJ/B,EAAQ,GAE9B,MAAMkD,GAAa,OAAOF,EAAMrC,EAAO,WACjCwC,GAAc,OAAOF,EAAOtC,EAAO,WACzC3F,EAAIlI,IAAQ,OAAQoQ,EAAYC,GAChCD,EAAWE,UACXD,EAAYC,SAChB,CAGA,CACAhC,GAAUU,EAAOiB,CACrB,CACc,cAAVtC,IACAzF,EAAIlI,IAAQ,OAAOiP,EAAQpB,EAAOF,GAE1C,CACA,OAAOzF,CACX,CAIO,SAAS2G,EAAuB0B,GAEnC,GAAW,OAAPA,EACA,MAAM,IAAI9T,MAAM,wBAAwB8B,KAAKC,UAAU+R,MAE3D,IAAIC,EAAkB,EAQtB,MAAMC,EAAe,GACrBF,EAAGlQ,SAASqQ,IAKR,GAJAF,GAAmBE,EAAEV,WAErBS,EAAajQ,KAAKkQ,EAAEV,aAAeU,EAAEhC,OAAOsB,WAAaU,EACrD,IAAIA,EAAEpU,YAAYoU,MAChBA,aAAanB,cAAgBmB,aAAab,YAC5Ca,aAAarC,YACb,MAAM,IAAI5R,MAAM,mCAAmCiU,EAAEpU,YAAY0D,OACrE,IAGJ,MAAM2Q,EAAI,IAAItC,WAAWmC,GACzB,IAAIlC,EAAS,EAKb,OAJAmC,EAAapQ,SAASqQ,IAClBC,EAAEhC,IAAI,IAAIN,WAAWqC,EAAEhC,QAASJ,GAChCA,GAAUoC,EAAEV,UAAU,IAEnBW,EAAEjC,MACb,CAEA,MAAMkC,EAAkC,qBAAXC,IACR,qBAATvT,MAAwC,qBAATwT,MACnB,qBAATC,MAUR,SAASC,EAAiBC,GAC7B,OAAIL,EACOC,EAAOb,WAAWiB,GAEtB,IAAI3T,KAAK,CAAC2T,IAAMjC,IAC3B,CAOO,SAASkC,EAA0BxC,GACtC,GAAIkC,EACA,OAAOC,EAAOM,KAAKzC,GAAQ0C,SAAS,UAExC,MAAMC,EAAM,IAAIhD,WAAWK,GAC3B,IAAI4C,EAAI,GACR,IAAK,IAAIpE,EAAI,EAAGqE,EAAIF,EAAI/V,OAAQ4R,EAAIqE,EAAGrE,IACnCoE,GAAKE,OAAOC,aAAaJ,EAAInE,IAEjC,OAAO6D,KAAKO,EAChB,CAOO,SAASI,EAA0BT,GACtC,GAAIL,EAAe,CACf,MAAMS,EAAMR,EAAOM,KAAKF,EAAK,UAC7B,OAAOI,EAAI3C,OAAO9R,MAAMyU,EAAIM,WAAYN,EAAIM,WAAaN,EAAIrB,WACjE,CACA,MAAMsB,EAAIR,KAAKG,GACTvC,EAAS,IAAIL,WAAWiD,EAAEhW,QAChC,IAAK,IAAI4R,EAAI,EAAGA,EAAIoE,EAAEhW,SAAU4R,EAC5BwB,EAAOC,IAAI,CAAC2C,EAAEM,WAAW1E,IAAKA,GAElC,OAAOwB,EAAOA,MAClB,CAOO,SAASmD,EAAwBzN,GACpC,GAAuB,IAAnBA,EAAQ9I,OACR,OAAO8I,EAAQ,GAEnB,IAAIoM,EAAkB,EACtBpM,EAAQ/D,SAASqO,IACb8B,GAAmB9B,EAAOsB,UAAU,IAExC,MAAM8B,EAAO,IAAIzD,WAAWmC,GAC5B,IAAIlC,EAAS,EAKb,OAJAlK,EAAQ/D,SAASqO,IACboD,EAAKnD,IAAI,IAAIN,WAAWK,GAASJ,GACjCA,GAAUI,EAAOsB,UAAU,IAExB8B,EAAKpD,MAChB,CAQO,SAASqD,EAASxR,GAGrB,IADAA,EAAOA,EAAKyR,OACLzR,EAAK4C,SAFM,MAGd5C,EAAOA,EAAK3D,MAAM,EAAG2D,EAAKjF,OAAS,GAEvC,MAAM4Q,EAAQ3L,EAAK6J,MALD,KAMlB,OAAO8B,EAAMA,EAAM5Q,OAAS,EAChC,CAMO,SAAS2W,EAA6BhV,GACzC,GAAIA,EAAeQ,yBAAyBC,YACxC,MAAM,IAAIjB,MAAM,uDAEpB,MAAO,CACHyV,UAAW,IAAIC,KACfvF,kBAAmB,OACnBJ,mBAAoD,MAAhCvP,EAAeQ,cAC/B,EACAuT,EAAiBzS,KAAKC,UAAUvB,EAAeQ,gBACnDgP,iBAAgD,MAA9BxP,EAAea,YAC7B,EACAkT,EAAiBzS,KAAKC,UAAUvB,EAAea,cACnD4O,gBAA8C,MAA7BzP,EAAeM,WAC5B,EACAN,EAAeM,WAAWyS,WAEtC,CAsEO,SAASJ,IAIZ,MAAMwC,EAnEV,WACI,MAAMC,EAAmBnF,IACrB,IAAIoF,EAAIpF,GAAK,GACTjK,EAAI,EACR,KAA4B,KAAhB,QAAJqP,IACJrP,GAAK,QACLqP,IAAM,EAIV,OAFAA,IAAK,QACLrP,GAAK,UACEqP,EAAIrP,CAAC,EAEVmP,EAAe,IAAI3D,YAAY,MACrC2D,EAAa,GAAK,EAClB,IAAK,IAAIlF,EAAI,EAAGA,EAAI,KAAMA,IACtBkF,EAAalF,GAAKmF,EAAgBnF,GAEtC,IAAK,IAAIA,EAAI,KAAMA,EAAI,KAAMA,IACzBkF,EAAalF,GAAK,WAAeA,EAAI,MAAS,IAElD,OAAOkF,CACX,CA8CyBG,GACfC,EAxCV,WACI,MAAMA,EAAgB,IAAI/D,YAAY,IACtC+D,EAAc,GAAK,EACnBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpBA,EAAc,IAAM,WACpB,IAAK,IAAItF,EAAI,EAAGA,EAAI,GAAIA,IACpBsF,EAActF,GAAKA,GAAK,GAE5B,IAAK,IAAIA,EAAI,GAAIA,EAAI,GAAIA,IACrBsF,EAActF,GAAK,YAAeA,EAAI,IAAO,IAEjD,OAAOsF,CACX,CA2B0BC,GAChBC,EArBV,WACI,MAAMA,EAAc,IAAIjE,YAAY,IACpC,IAAK,IAAIvB,EAAI,EAAGA,EAAI,GAAIA,IACpBwF,EAAYxF,GAAK,KAGrB,OADAwF,EAAY,GAAKA,EAAY,IAAM,EAC5BA,CACX,CAcwBC,GACpB,OAAQtD,IACJ,MAAMX,EAAS,IAAIhR,YAAY,EAAI2R,EAAe/T,QAC5CsX,EAAmB,IAAInE,YAAYC,GACzC,IAAK,IAAIhO,EAAQ,EAAGA,EAAQ2O,EAAe/T,OAAQoF,IAAS,CACxD,MAAMmS,EAAcxD,EAAe3O,GAC7BoS,EAAcV,EAAaM,EAAYG,GAAe,KAAqB,KAAdA,IAC/DL,EAAcK,GAAe,IACjCD,EAAiBlS,GAASoS,CAC9B,CACA,OAAO,IAAIvD,aAAab,EAAO,CAEvC,C","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/types.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/progress.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/http.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/model_management.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/* Type definitions for exporting and importing of models. */\n/**\n * A map from Tensor dtype to number of bytes per element of the Tensor.\n */\nexport const DTYPE_VALUE_SIZE_MAP = {\n    'float32': 4,\n    'float16': 2,\n    'int32': 4,\n    'uint16': 2,\n    'uint8': 1,\n    'bool': 1,\n    'complex64': 8\n};\n//# sourceMappingURL=types.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { assert } from '../util';\n/**\n * Monitor Promise.all progress, fire onProgress callback function.\n *\n * @param promises Promise list going to be monitored\n * @param onProgress Callback function. Fired when a promise resolved.\n * @param startFraction Optional fraction start. Default to 0.\n * @param endFraction Optional fraction end. Default to 1.\n */\nexport function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {\n    checkPromises(promises);\n    startFraction = startFraction == null ? 0 : startFraction;\n    endFraction = endFraction == null ? 1 : endFraction;\n    checkFraction(startFraction, endFraction);\n    let resolvedPromise = 0;\n    const registerMonitor = (promise) => {\n        promise.then(value => {\n            const fraction = startFraction +\n                ++resolvedPromise / promises.length * (endFraction - startFraction);\n            // pass fraction as parameter to callback function.\n            onProgress(fraction);\n            return value;\n        });\n        return promise;\n    };\n    function checkPromises(promises) {\n        assert(promises != null && Array.isArray(promises) && promises.length > 0, () => 'promises must be a none empty array');\n    }\n    function checkFraction(startFraction, endFraction) {\n        assert(startFraction >= 0 && startFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got startFraction ${startFraction}`);\n        assert(endFraction >= 0 && endFraction <= 1, () => `Progress fraction must be in range [0, 1], but ` +\n            `got endFraction ${endFraction}`);\n        assert(endFraction >= startFraction, () => `startFraction must be no more than endFraction, but ` +\n            `got startFraction ${startFraction} and endFraction ` +\n            `${endFraction}`);\n    }\n    return Promise.all(promises.map(registerMonitor));\n}\n//# sourceMappingURL=progress.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandlers related to files, such as browser-triggered file downloads,\n * user-selected files in browser.\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { basename, concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DEFAULT_FILE_NAME_PREFIX = 'model';\nconst DEFAULT_JSON_EXTENSION_NAME = '.json';\nconst DEFAULT_WEIGHT_DATA_EXTENSION_NAME = '.weights.bin';\nfunction defer(f) {\n    return new Promise(resolve => setTimeout(resolve)).then(f);\n}\nexport class BrowserDownloads {\n    constructor(fileNamePrefix) {\n        if (!env().getBool('IS_BROWSER')) {\n            // TODO(cais): Provide info on what IOHandlers are available under the\n            //   current environment.\n            throw new Error('browserDownloads() cannot proceed because the current environment ' +\n                'is not a browser.');\n        }\n        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {\n            fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);\n        }\n        if (fileNamePrefix == null || fileNamePrefix.length === 0) {\n            fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;\n        }\n        this.modelTopologyFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;\n        this.weightDataFileName =\n            fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;\n    }\n    async save(modelArtifacts) {\n        if (typeof (document) === 'undefined') {\n            throw new Error('Browser downloads are not supported in ' +\n                'this environment since `document` is not present');\n        }\n        const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: 'application/octet-stream' }));\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserDownloads.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const weightsManifest = [{\n                    paths: ['./' + this.weightDataFileName],\n                    weights: modelArtifacts.weightSpecs\n                }];\n            const modelTopologyAndWeightManifest = {\n                modelTopology: modelArtifacts.modelTopology,\n                format: modelArtifacts.format,\n                generatedBy: modelArtifacts.generatedBy,\n                convertedBy: modelArtifacts.convertedBy,\n                weightsManifest\n            };\n            if (modelArtifacts.signature != null) {\n                modelTopologyAndWeightManifest.signature = modelArtifacts.signature;\n            }\n            if (modelArtifacts.userDefinedMetadata != null) {\n                modelTopologyAndWeightManifest.userDefinedMetadata =\n                    modelArtifacts.userDefinedMetadata;\n            }\n            if (modelArtifacts.modelInitializer != null) {\n                modelTopologyAndWeightManifest.modelInitializer =\n                    modelArtifacts.modelInitializer;\n            }\n            const modelTopologyAndWeightManifestURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: 'application/json' }));\n            // If anchor elements are not provided, create them without attaching them\n            // to parents, so that the downloaded file names can be controlled.\n            const jsonAnchor = this.jsonAnchor == null ? document.createElement('a') :\n                this.jsonAnchor;\n            jsonAnchor.download = this.modelTopologyFileName;\n            jsonAnchor.href = modelTopologyAndWeightManifestURL;\n            // Trigger downloads by evoking a click event on the download anchors.\n            // When multiple downloads are started synchronously, Firefox will only\n            // save the last one.\n            await defer(() => jsonAnchor.dispatchEvent(new MouseEvent('click')));\n            if (modelArtifacts.weightData != null) {\n                const weightDataAnchor = this.weightDataAnchor == null ?\n                    document.createElement('a') :\n                    this.weightDataAnchor;\n                weightDataAnchor.download = this.weightDataFileName;\n                weightDataAnchor.href = weightsURL;\n                await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent('click')));\n            }\n            return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };\n        }\n    }\n}\nBrowserDownloads.URL_SCHEME = 'downloads://';\nclass BrowserFiles {\n    constructor(files) {\n        if (files == null || files.length < 1) {\n            throw new Error(`When calling browserFiles, at least 1 file is required, ` +\n                `but received ${files}`);\n        }\n        this.files = files;\n    }\n    async load() {\n        const jsonFile = this.files[0];\n        const weightFiles = this.files.slice(1);\n        return new Promise((resolve, reject) => {\n            const jsonReader = new FileReader();\n            jsonReader.onload = (event) => {\n                // tslint:disable-next-line:no-any\n                const modelJSON = JSON.parse(event.target.result);\n                const modelTopology = modelJSON.modelTopology;\n                if (modelTopology == null) {\n                    reject(new Error(`modelTopology field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                if (weightFiles.length === 0) {\n                    resolve({ modelTopology });\n                }\n                const weightsManifest = modelJSON.weightsManifest;\n                if (weightsManifest == null) {\n                    reject(new Error(`weightManifest field is missing from file ${jsonFile.name}`));\n                    return;\n                }\n                let pathToFile;\n                try {\n                    pathToFile =\n                        this.checkManifestAndWeightFiles(weightsManifest, weightFiles);\n                }\n                catch (err) {\n                    reject(err);\n                    return;\n                }\n                const weightSpecs = [];\n                const paths = [];\n                const perFileBuffers = [];\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        paths.push(path);\n                        perFileBuffers.push(null);\n                    });\n                    weightSpecs.push(...weightsGroup.weights);\n                });\n                weightsManifest.forEach(weightsGroup => {\n                    weightsGroup.paths.forEach(path => {\n                        const weightFileReader = new FileReader();\n                        weightFileReader.onload = (event) => {\n                            // tslint:disable-next-line:no-any\n                            const weightData = event.target.result;\n                            const index = paths.indexOf(path);\n                            perFileBuffers[index] = weightData;\n                            if (perFileBuffers.indexOf(null) === -1) {\n                                const result = {\n                                    modelTopology,\n                                    weightSpecs,\n                                    weightData: concatenateArrayBuffers(perFileBuffers),\n                                    format: modelJSON.format,\n                                    generatedBy: modelJSON.generatedBy,\n                                    convertedBy: modelJSON.convertedBy\n                                };\n                                if (modelJSON.signature != null) {\n                                    result.signature = modelJSON.signature;\n                                }\n                                if (modelJSON.userDefinedMetadata != null) {\n                                    result.userDefinedMetadata = modelJSON.userDefinedMetadata;\n                                }\n                                if (modelJSON.modelInitializer != null) {\n                                    result.modelInitializer = modelJSON.modelInitializer;\n                                }\n                                resolve(result);\n                            }\n                        };\n                        weightFileReader.onerror = error => reject(`Failed to weights data from file of path '${path}'.`);\n                        weightFileReader.readAsArrayBuffer(pathToFile[path]);\n                    });\n                });\n            };\n            jsonReader.onerror = error => reject(`Failed to read model topology and weights manifest JSON ` +\n                `from file '${jsonFile.name}'. BrowserFiles supports loading ` +\n                `Keras-style tf.Model artifacts only.`);\n            jsonReader.readAsText(jsonFile);\n        });\n    }\n    /**\n     * Check the compatibility between weights manifest and weight files.\n     */\n    checkManifestAndWeightFiles(manifest, files) {\n        const basenames = [];\n        const fileNames = files.map(file => basename(file.name));\n        const pathToFile = {};\n        for (const group of manifest) {\n            group.paths.forEach(path => {\n                const pathBasename = basename(path);\n                if (basenames.indexOf(pathBasename) !== -1) {\n                    throw new Error(`Duplicate file basename found in weights manifest: ` +\n                        `'${pathBasename}'`);\n                }\n                basenames.push(pathBasename);\n                if (fileNames.indexOf(pathBasename) === -1) {\n                    throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);\n                }\n                else {\n                    pathToFile[path] = files[fileNames.indexOf(pathBasename)];\n                }\n            });\n        }\n        if (basenames.length !== files.length) {\n            throw new Error(`Mismatch in the number of files in weights manifest ` +\n                `(${basenames.length}) and the number of weight files provided ` +\n                `(${files.length}).`);\n        }\n        return pathToFile;\n    }\n}\nexport const browserDownloadsRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {\n            return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(browserDownloadsRouter);\n/**\n * Creates an IOHandler that triggers file downloads from the browser.\n *\n * The returned `IOHandler` instance can be used as model exporting methods such\n * as `tf.Model.save` and supports only saving.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * const saveResult = await model.save('downloads://mymodel');\n * // This will trigger downloading of two files:\n * //   'mymodel.json' and 'mymodel.weights.bin'.\n * console.log(saveResult);\n * ```\n *\n * @param fileNamePrefix Prefix name of the files to be downloaded. For use with\n *   `tf.Model`, `fileNamePrefix` should follow either of the following two\n *   formats:\n *   1. `null` or `undefined`, in which case the default file\n *      names will be used:\n *      - 'model.json' for the JSON file containing the model topology and\n *        weights manifest.\n *      - 'model.weights.bin' for the binary file containing the binary weight\n *        values.\n *   2. A single string or an Array of a single string, as the file name prefix.\n *      For example, if `'foo'` is provided, the downloaded JSON\n *      file and binary weights file will be named 'foo.json' and\n *      'foo.weights.bin', respectively.\n * @param config Additional configuration for triggering downloads.\n * @returns An instance of `BrowserDownloads` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserDownloads(fileNamePrefix = 'model') {\n    return new BrowserDownloads(fileNamePrefix);\n}\n/**\n * Creates an IOHandler that loads model artifacts from user-selected files.\n *\n * This method can be used for loading from files such as user-selected files\n * in the browser.\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * // Note: This code snippet won't run properly without the actual file input\n * //   elements in the HTML DOM.\n *\n * // Suppose there are two HTML file input (`<input type=\"file\" ...>`)\n * // elements.\n * const uploadJSONInput = document.getElementById('upload-json');\n * const uploadWeightsInput = document.getElementById('upload-weights');\n * const model = await tf.loadLayersModel(tf.io.browserFiles(\n *     [uploadJSONInput.files[0], uploadWeightsInput.files[0]]));\n * ```\n *\n * @param files `File`s to load from. Currently, this function supports only\n *   loading from files that contain Keras-style models (i.e., `tf.Model`s), for\n *   which an `Array` of `File`s is expected (in that order):\n *   - A JSON file containing the model topology and weight manifest.\n *   - Optionally, One or more binary files containing the binary weights.\n *     These files must have names that match the paths in the `weightsManifest`\n *     contained by the aforementioned JSON file, or errors will be thrown\n *     during loading. These weights files have the same format as the ones\n *     generated by `tensorflowjs_converter` that comes with the `tensorflowjs`\n *     Python PIP package. If no weights files are provided, only the model\n *     topology will be loaded from the JSON file above.\n * @returns An instance of `Files` `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function browserFiles(files) {\n    return new BrowserFiles(files);\n}\n//# sourceMappingURL=browser_files.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * IOHandler implementations based on HTTP requests in the web browser.\n *\n * Uses [`fetch`](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n */\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { concatenateArrayBuffers, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nimport { loadWeightsAsArrayBuffer } from './weights_loader';\nconst OCTET_STREAM_MIME_TYPE = 'application/octet-stream';\nconst JSON_TYPE = 'application/json';\nexport class HTTPRequest {\n    constructor(path, loadOptions) {\n        this.DEFAULT_METHOD = 'POST';\n        if (loadOptions == null) {\n            loadOptions = {};\n        }\n        this.weightPathPrefix = loadOptions.weightPathPrefix;\n        this.onProgress = loadOptions.onProgress;\n        this.weightUrlConverter = loadOptions.weightUrlConverter;\n        if (loadOptions.fetchFunc != null) {\n            assert(typeof loadOptions.fetchFunc === 'function', () => 'Must pass a function that matches the signature of ' +\n                '`fetch` (see ' +\n                'https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)');\n            this.fetch = loadOptions.fetchFunc;\n        }\n        else {\n            this.fetch = env().platform.fetch;\n        }\n        assert(path != null && path.length > 0, () => 'URL path for http must not be null, undefined or ' +\n            'empty.');\n        if (Array.isArray(path)) {\n            assert(path.length === 2, () => 'URL paths for http must have a length of 2, ' +\n                `(actual length is ${path.length}).`);\n        }\n        this.path = path;\n        if (loadOptions.requestInit != null &&\n            loadOptions.requestInit.body != null) {\n            throw new Error('requestInit is expected to have no pre-existing body, but has one.');\n        }\n        this.requestInit = loadOptions.requestInit || {};\n    }\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserHTTPRequest.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);\n        init.body = new FormData();\n        const weightsManifest = [{\n                paths: ['./model.weights.bin'],\n                weights: modelArtifacts.weightSpecs,\n            }];\n        const modelTopologyAndWeightManifest = {\n            modelTopology: modelArtifacts.modelTopology,\n            format: modelArtifacts.format,\n            generatedBy: modelArtifacts.generatedBy,\n            convertedBy: modelArtifacts.convertedBy,\n            weightsManifest\n        };\n        if (modelArtifacts.signature != null) {\n            modelTopologyAndWeightManifest.signature = modelArtifacts.signature;\n        }\n        if (modelArtifacts.userDefinedMetadata != null) {\n            modelTopologyAndWeightManifest.userDefinedMetadata =\n                modelArtifacts.userDefinedMetadata;\n        }\n        if (modelArtifacts.modelInitializer != null) {\n            modelTopologyAndWeightManifest.modelInitializer =\n                modelArtifacts.modelInitializer;\n        }\n        init.body.append('model.json', new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), 'model.json');\n        if (modelArtifacts.weightData != null) {\n            init.body.append('model.weights.bin', new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), 'model.weights.bin');\n        }\n        const response = await this.fetch(this.path, init);\n        if (response.ok) {\n            return {\n                modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),\n                responses: [response],\n            };\n        }\n        else {\n            throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ` +\n                `${response.status}.`);\n        }\n    }\n    /**\n     * Load model artifacts via HTTP request(s).\n     *\n     * See the documentation to `tf.io.http` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model artifacts (if loading succeeds).\n     */\n    async load() {\n        const modelConfigRequest = await this.fetch(this.path, this.requestInit);\n        if (!modelConfigRequest.ok) {\n            throw new Error(`Request to ${this.path} failed with status code ` +\n                `${modelConfigRequest.status}. Please verify this URL points to ` +\n                `the model JSON of the model to load.`);\n        }\n        let modelConfig;\n        try {\n            modelConfig = await modelConfigRequest.json();\n        }\n        catch (e) {\n            let message = `Failed to parse model JSON of response from ${this.path}.`;\n            // TODO(nsthorat): Remove this after some time when we're comfortable that\n            // .pb files are mostly gone.\n            if (this.path.endsWith('.pb')) {\n                message += ' Your path contains a .pb file extension. ' +\n                    'Support for .pb models have been removed in TensorFlow.js 1.0 ' +\n                    'in favor of .json models. You can re-convert your Python ' +\n                    'TensorFlow model using the TensorFlow.js 1.0 conversion scripts ' +\n                    'or you can convert your.pb models with the \\'pb2json\\'' +\n                    'NPM script in the tensorflow/tfjs-converter repository.';\n            }\n            else {\n                message += ' Please make sure the server is serving valid ' +\n                    'JSON for this request.';\n            }\n            throw new Error(message);\n        }\n        const modelTopology = modelConfig.modelTopology;\n        const weightsManifest = modelConfig.weightsManifest;\n        const generatedBy = modelConfig.generatedBy;\n        const convertedBy = modelConfig.convertedBy;\n        const format = modelConfig.format;\n        const signature = modelConfig.signature;\n        const userDefinedMetadata = modelConfig.userDefinedMetadata;\n        // We do not allow both modelTopology and weightsManifest to be missing.\n        if (modelTopology == null && weightsManifest == null) {\n            throw new Error(`The JSON from HTTP path ${this.path} contains neither model ` +\n                `topology or manifest for weights.`);\n        }\n        let weightSpecs;\n        let weightData;\n        if (weightsManifest != null) {\n            const results = await this.loadWeights(weightsManifest);\n            [weightSpecs, weightData] = results;\n        }\n        const artifacts = {\n            modelTopology,\n            weightSpecs,\n            weightData,\n            generatedBy,\n            convertedBy,\n            format\n        };\n        if (signature != null) {\n            artifacts.signature = signature;\n        }\n        if (userDefinedMetadata != null) {\n            artifacts.userDefinedMetadata = userDefinedMetadata;\n        }\n        const initializer = modelConfig.modelInitializer;\n        if (initializer) {\n            artifacts.modelInitializer = initializer;\n        }\n        return artifacts;\n    }\n    async loadWeights(weightsManifest) {\n        const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;\n        const [prefix, suffix] = parseUrl(weightPath);\n        const pathPrefix = this.weightPathPrefix || prefix;\n        const weightSpecs = [];\n        for (const entry of weightsManifest) {\n            weightSpecs.push(...entry.weights);\n        }\n        const fetchURLs = [];\n        const urlPromises = [];\n        for (const weightsGroup of weightsManifest) {\n            for (const path of weightsGroup.paths) {\n                if (this.weightUrlConverter != null) {\n                    urlPromises.push(this.weightUrlConverter(path));\n                }\n                else {\n                    fetchURLs.push(pathPrefix + path + suffix);\n                }\n            }\n        }\n        if (this.weightUrlConverter) {\n            fetchURLs.push(...await Promise.all(urlPromises));\n        }\n        const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {\n            requestInit: this.requestInit,\n            fetchFunc: this.fetch,\n            onProgress: this.onProgress\n        });\n        return [weightSpecs, concatenateArrayBuffers(buffers)];\n    }\n}\nHTTPRequest.URL_SCHEME_REGEX = /^https?:\\/\\//;\n/**\n * Extract the prefix and suffix of the url, where the prefix is the path before\n * the last file, and suffix is the search params after the last file.\n * ```\n * const url = 'http://tfhub.dev/model/1/tensorflowjs_model.pb?tfjs-format=file'\n * [prefix, suffix] = parseUrl(url)\n * // prefix = 'http://tfhub.dev/model/1/'\n * // suffix = '?tfjs-format=file'\n * ```\n * @param url the model url to be parsed.\n */\nexport function parseUrl(url) {\n    const lastSlash = url.lastIndexOf('/');\n    const lastSearchParam = url.lastIndexOf('?');\n    const prefix = url.substring(0, lastSlash);\n    const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : '';\n    return [prefix + '/', suffix];\n}\nexport function isHTTPScheme(url) {\n    return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;\n}\nexport const httpRouter = (url, loadOptions) => {\n    if (typeof fetch === 'undefined' &&\n        (loadOptions == null || loadOptions.fetchFunc == null)) {\n        // `http` uses `fetch` or `node-fetch`, if one wants to use it in\n        // an environment that is not the browser or node they have to setup a\n        // global fetch polyfill.\n        return null;\n    }\n    else {\n        let isHTTP = true;\n        if (Array.isArray(url)) {\n            isHTTP = url.every(urlItem => isHTTPScheme(urlItem));\n        }\n        else {\n            isHTTP = isHTTPScheme(url);\n        }\n        if (isHTTP) {\n            return http(url, loadOptions);\n        }\n    }\n    return null;\n};\nIORouterRegistry.registerSaveRouter(httpRouter);\nIORouterRegistry.registerLoadRouter(httpRouter);\n/**\n * Creates an IOHandler subtype that sends model artifacts to HTTP server.\n *\n * An HTTP request of the `multipart/form-data` mime type will be sent to the\n * `path` URL. The form data includes artifacts that represent the topology\n * and/or weights of the model. In the case of Keras-style `tf.Model`, two\n * blobs (files) exist in form-data:\n *   - A JSON file consisting of `modelTopology` and `weightsManifest`.\n *   - A binary weights file consisting of the concatenated weight values.\n * These files are in the same format as the one generated by\n * [tfjs_converter](https://js.tensorflow.org/tutorials/import-keras.html).\n *\n * The following code snippet exemplifies the client-side code that uses this\n * function:\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save(tf.io.http(\n *     'http://model-server:5000/upload', {requestInit: {method: 'PUT'}}));\n * console.log(saveResult);\n * ```\n *\n * If the default `POST` method is to be used, without any custom parameters\n * such as headers, you can simply pass an HTTP or HTTPS URL to `model.save`:\n *\n * ```js\n * const saveResult = await model.save('http://model-server:5000/upload');\n * ```\n *\n * The following GitHub Gist\n * https://gist.github.com/dsmilkov/1b6046fd6132d7408d5257b0976f7864\n * implements a server based on [flask](https://github.com/pallets/flask) that\n * can receive the request. Upon receiving the model artifacts via the requst,\n * this particular server reconsistutes instances of [Keras\n * Models](https://keras.io/models/model/) in memory.\n *\n *\n * @param path A URL path to the model.\n *   Can be an absolute HTTP path (e.g.,\n *   'http://localhost:8000/model-upload)') or a relative path (e.g.,\n *   './model-upload').\n * @param requestInit Request configurations to be used when sending\n *    HTTP request to server using `fetch`. It can contain fields such as\n *    `method`, `credentials`, `headers`, `mode`, etc. See\n *    https://developer.mozilla.org/en-US/docs/Web/API/Request/Request\n *    for more information. `requestInit` must not have a body, because the\n * body will be set by TensorFlow.js. File blobs representing the model\n * topology (filename: 'model.json') and the weights of the model (filename:\n * 'model.weights.bin') will be appended to the body. If `requestInit` has a\n * `body`, an Error will be thrown.\n * @param loadOptions Optional configuration for the loading. It includes the\n *   following fields:\n *   - weightPathPrefix Optional, this specifies the path prefix for weight\n *     files, by default this is calculated from the path param.\n *   - fetchFunc Optional, custom `fetch` function. E.g., in Node.js,\n *     the `fetch` from node-fetch can be used here.\n *   - onProgress Optional, progress callback function, fired periodically\n *     before the load is completed.\n * @returns An instance of `IOHandler`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Loading',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nexport function http(path, loadOptions) {\n    return new HTTPRequest(path, loadOptions);\n}\n/**\n * Deprecated. Use `tf.io.http`.\n * @param path\n * @param loadOptions\n */\nexport function browserHTTPRequest(path, loadOptions) {\n    return http(path, loadOptions);\n}\n//# sourceMappingURL=http.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nclass PassthroughLoader {\n    constructor(modelArtifacts) {\n        this.modelArtifacts = modelArtifacts;\n    }\n    async load() {\n        return this.modelArtifacts;\n    }\n}\nclass PassthroughSaver {\n    constructor(saveHandler) {\n        this.saveHandler = saveHandler;\n    }\n    async save(modelArtifacts) {\n        return this.saveHandler(modelArtifacts);\n    }\n}\n/**\n * Creates an IOHandler that loads model artifacts from memory.\n *\n * When used in conjunction with `tf.loadLayersModel`, an instance of\n * `tf.LayersModel` (Keras-style) can be constructed from the loaded artifacts.\n *\n * ```js\n * const model = await tf.loadLayersModel(tf.io.fromMemory(\n *     modelTopology, weightSpecs, weightData));\n * ```\n *\n * @param modelArtifacts a object containing model topology (i.e., parsed from\n *   the JSON format).\n * @param weightSpecs An array of `WeightsManifestEntry` objects describing the\n *   names, shapes, types, and quantization of the weight data.\n * @param weightData A single `ArrayBuffer` containing the weight data,\n *   concatenated in the order described by the weightSpecs.\n * @param trainingConfig Model training configuration. Optional.\n *\n * @returns A passthrough `IOHandler` that simply loads the provided data.\n */\nexport function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {\n    if (arguments.length === 1) {\n        const isModelArtifacts = modelArtifacts.modelTopology != null ||\n            modelArtifacts.weightSpecs != null;\n        if (isModelArtifacts) {\n            return new PassthroughLoader(modelArtifacts);\n        }\n        else {\n            // Legacy support: with only modelTopology.\n            // TODO(cais): Remove this deprecated API.\n            console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n                'The argument should be of type ModelArtifacts. ' +\n                'The multi-argument signature of tf.io.fromMemory() has been ' +\n                'deprecated and will be removed in a future release.');\n            return new PassthroughLoader({ modelTopology: modelArtifacts });\n        }\n    }\n    else {\n        // Legacy support.\n        // TODO(cais): Remove this deprecated API.\n        console.warn('Please call tf.io.fromMemory() with only one argument. ' +\n            'The argument should be of type ModelArtifacts. ' +\n            'The multi-argument signature of tf.io.fromMemory() has been ' +\n            'deprecated and will be removed in a future release.');\n        return new PassthroughLoader({\n            modelTopology: modelArtifacts,\n            weightSpecs,\n            weightData,\n            trainingConfig\n        });\n    }\n}\n/**\n * Creates an IOHandler that passes saved model artifacts to a callback.\n *\n * ```js\n * function handleSave(artifacts) {\n *   // ... do something with the artifacts ...\n *   return {modelArtifactsInfo: {...}, ...};\n * }\n *\n * const saveResult = model.save(tf.io.withSaveHandler(handleSave));\n * ```\n *\n * @param saveHandler A function that accepts a `ModelArtifacts` and returns a\n *     `SaveResult`.\n */\nexport function withSaveHandler(saveHandler) {\n    return new PassthroughSaver(saveHandler);\n}\n//# sourceMappingURL=passthrough.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst DATABASE_NAME = 'tensorflowjs';\nconst DATABASE_VERSION = 1;\n// Model data and ModelArtifactsInfo (metadata) are stored in two separate\n// stores for efficient access of the list of stored models and their metadata.\n// 1. The object store for model data: topology, weights and weight manifests.\nconst MODEL_STORE_NAME = 'models_store';\n// 2. The object store for ModelArtifactsInfo, including meta-information such\n//    as the type of topology (JSON vs binary), byte size of the topology, byte\n//    size of the weights, etc.\nconst INFO_STORE_NAME = 'model_info_store';\n/**\n * Delete the entire database for tensorflow.js, including the models store.\n */\nexport async function deleteDatabase() {\n    const idbFactory = getIndexedDBFactory();\n    return new Promise((resolve, reject) => {\n        const deleteRequest = idbFactory.deleteDatabase(DATABASE_NAME);\n        deleteRequest.onsuccess = () => resolve();\n        deleteRequest.onerror = error => reject(error);\n    });\n}\nfunction getIndexedDBFactory() {\n    if (!env().getBool('IS_BROWSER')) {\n        // TODO(cais): Add more info about what IOHandler subtypes are available.\n        //   Maybe point to a doc page on the web and/or automatically determine\n        //   the available IOHandlers and print them in the error message.\n        throw new Error('Failed to obtain IndexedDB factory because the current environment' +\n            'is not a web browser.');\n    }\n    // tslint:disable-next-line:no-any\n    const theWindow = typeof window === 'undefined' ? self : window;\n    const factory = theWindow.indexedDB || theWindow.mozIndexedDB ||\n        theWindow.webkitIndexedDB || theWindow.msIndexedDB ||\n        theWindow.shimIndexedDB;\n    if (factory == null) {\n        throw new Error('The current browser does not appear to support IndexedDB.');\n    }\n    return factory;\n}\nfunction setUpDatabase(openRequest) {\n    const db = openRequest.result;\n    db.createObjectStore(MODEL_STORE_NAME, { keyPath: 'modelPath' });\n    db.createObjectStore(INFO_STORE_NAME, { keyPath: 'modelPath' });\n}\n/**\n * IOHandler subclass: Browser IndexedDB.\n *\n * See the doc string of `browserIndexedDB` for more details.\n */\nexport class BrowserIndexedDB {\n    constructor(modelPath) {\n        this.indexedDB = getIndexedDBFactory();\n        if (modelPath == null || !modelPath) {\n            throw new Error('For IndexedDB, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n    }\n    async save(modelArtifacts) {\n        // TODO(cais): Support saving GraphDef models.\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        return this.databaseAction(this.modelPath, modelArtifacts);\n    }\n    async load() {\n        return this.databaseAction(this.modelPath);\n    }\n    /**\n     * Perform database action to put model artifacts into or read model artifacts\n     * from IndexedDB object store.\n     *\n     * Whether the action is put or get depends on whether `modelArtifacts` is\n     * specified. If it is specified, the action will be put; otherwise the action\n     * will be get.\n     *\n     * @param modelPath A unique string path for the model.\n     * @param modelArtifacts If specified, it will be the model artifacts to be\n     *   stored in IndexedDB.\n     * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`\n     *   of `ModelArtifacts`, if the action is get.\n     */\n    databaseAction(modelPath, modelArtifacts) {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                if (modelArtifacts == null) {\n                    // Read model out from object store.\n                    const modelTx = db.transaction(MODEL_STORE_NAME, 'readonly');\n                    const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                    const getRequest = modelStore.get(this.modelPath);\n                    getRequest.onsuccess = () => {\n                        if (getRequest.result == null) {\n                            db.close();\n                            return reject(new Error(`Cannot find model with path '${this.modelPath}' ` +\n                                `in IndexedDB.`));\n                        }\n                        else {\n                            resolve(getRequest.result.modelArtifacts);\n                        }\n                    };\n                    getRequest.onerror = error => {\n                        db.close();\n                        return reject(getRequest.error);\n                    };\n                    modelTx.oncomplete = () => db.close();\n                }\n                else {\n                    // Put model into object store.\n                    const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n                    // First, put ModelArtifactsInfo into info store.\n                    const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                    let infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                    const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });\n                    let modelTx;\n                    putInfoRequest.onsuccess = () => {\n                        // Second, put model data into model store.\n                        modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                        const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                        const putModelRequest = modelStore.put({\n                            modelPath: this.modelPath,\n                            modelArtifacts,\n                            modelArtifactsInfo\n                        });\n                        putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });\n                        putModelRequest.onerror = error => {\n                            // If the put-model request fails, roll back the info entry as\n                            // well.\n                            infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                            const deleteInfoRequest = infoStore.delete(this.modelPath);\n                            deleteInfoRequest.onsuccess = () => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                            deleteInfoRequest.onerror = error => {\n                                db.close();\n                                return reject(putModelRequest.error);\n                            };\n                        };\n                    };\n                    putInfoRequest.onerror = error => {\n                        db.close();\n                        return reject(putInfoRequest.error);\n                    };\n                    infoTx.oncomplete = () => {\n                        if (modelTx == null) {\n                            db.close();\n                        }\n                        else {\n                            modelTx.oncomplete = () => db.close();\n                        }\n                    };\n                }\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\nBrowserIndexedDB.URL_SCHEME = 'indexeddb://';\nexport const indexedDBRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {\n            return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(indexedDBRouter);\nIORouterRegistry.registerLoadRouter(indexedDBRouter);\n/**\n * Creates a browser IndexedDB IOHandler for saving and loading models.\n *\n * ```js\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 1, inputShape: [100], activation: 'sigmoid'}));\n *\n * const saveResult = await model.save('indexeddb://MyModel'));\n * console.log(saveResult);\n * ```\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `BrowserIndexedDB` (sublcass of `IOHandler`),\n *   which can be used with, e.g., `tf.Model.save`.\n */\nexport function browserIndexedDB(modelPath) {\n    return new BrowserIndexedDB(modelPath);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserIndexedDB.URL_SCHEME) ?\n        key.slice(BrowserIndexedDB.URL_SCHEME.length) :\n        key;\n}\nexport class BrowserIndexedDBManager {\n    constructor() {\n        this.indexedDB = getIndexedDBFactory();\n    }\n    async listModels() {\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const tx = db.transaction(INFO_STORE_NAME, 'readonly');\n                const store = tx.objectStore(INFO_STORE_NAME);\n                // tslint:disable:max-line-length\n                // Need to cast `store` as `any` here because TypeScript's DOM\n                // library does not have the `getAll()` method even though the\n                // method is supported in the latest version of most mainstream\n                // browsers:\n                // https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/getAll\n                // tslint:enable:max-line-length\n                // tslint:disable-next-line:no-any\n                const getAllInfoRequest = store.getAll();\n                getAllInfoRequest.onsuccess = () => {\n                    const out = {};\n                    for (const item of getAllInfoRequest.result) {\n                        out[item.modelPath] = item.modelArtifactsInfo;\n                    }\n                    resolve(out);\n                };\n                getAllInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getAllInfoRequest.error);\n                };\n                tx.oncomplete = () => db.close();\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        return new Promise((resolve, reject) => {\n            const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);\n            openRequest.onupgradeneeded = () => setUpDatabase(openRequest);\n            openRequest.onsuccess = () => {\n                const db = openRequest.result;\n                const infoTx = db.transaction(INFO_STORE_NAME, 'readwrite');\n                const infoStore = infoTx.objectStore(INFO_STORE_NAME);\n                const getInfoRequest = infoStore.get(path);\n                let modelTx;\n                getInfoRequest.onsuccess = () => {\n                    if (getInfoRequest.result == null) {\n                        db.close();\n                        return reject(new Error(`Cannot find model with path '${path}' ` +\n                            `in IndexedDB.`));\n                    }\n                    else {\n                        // First, delete the entry in the info store.\n                        const deleteInfoRequest = infoStore.delete(path);\n                        const deleteModelData = () => {\n                            // Second, delete the entry in the model store.\n                            modelTx = db.transaction(MODEL_STORE_NAME, 'readwrite');\n                            const modelStore = modelTx.objectStore(MODEL_STORE_NAME);\n                            const deleteModelRequest = modelStore.delete(path);\n                            deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);\n                            deleteModelRequest.onerror = error => reject(getInfoRequest.error);\n                        };\n                        // Proceed with deleting model data regardless of whether deletion\n                        // of info data succeeds or not.\n                        deleteInfoRequest.onsuccess = deleteModelData;\n                        deleteInfoRequest.onerror = error => {\n                            deleteModelData();\n                            db.close();\n                            return reject(getInfoRequest.error);\n                        };\n                    }\n                };\n                getInfoRequest.onerror = error => {\n                    db.close();\n                    return reject(getInfoRequest.error);\n                };\n                infoTx.oncomplete = () => {\n                    if (modelTx == null) {\n                        db.close();\n                    }\n                    else {\n                        modelTx.oncomplete = () => db.close();\n                    }\n                };\n            };\n            openRequest.onerror = error => reject(openRequest.error);\n        });\n    }\n}\n//# sourceMappingURL=indexed_db.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport class IORouterRegistry {\n    constructor() {\n        this.saveRouters = [];\n        this.loadRouters = [];\n    }\n    static getInstance() {\n        if (IORouterRegistry.instance == null) {\n            IORouterRegistry.instance = new IORouterRegistry();\n        }\n        return IORouterRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerSaveRouter(saveRouter) {\n        IORouterRegistry.getInstance().saveRouters.push(saveRouter);\n    }\n    /**\n     * Register a load-handler router.\n     *\n     * @param loadRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `load` method defined or `null`.\n     */\n    static registerLoadRouter(loadRouter) {\n        IORouterRegistry.getInstance().loadRouters.push(loadRouter);\n    }\n    /**\n     * Look up IOHandler for saving, given a URL-like string.\n     *\n     * @param url\n     * @returns If only one match is found, an instance of IOHandler with the\n     * `save` method defined. If no match is found, `null`.\n     * @throws Error, if more than one match is found.\n     */\n    static getSaveHandlers(url) {\n        return IORouterRegistry.getHandlers(url, 'save');\n    }\n    /**\n     * Look up IOHandler for loading, given a URL-like string.\n     *\n     * @param url\n     * @param loadOptions Optional, custom load options.\n     * @returns All valid handlers for `url`, given the currently registered\n     *   handler routers.\n     */\n    static getLoadHandlers(url, loadOptions) {\n        return IORouterRegistry.getHandlers(url, 'load', loadOptions);\n    }\n    static getHandlers(url, handlerType, loadOptions) {\n        const validHandlers = [];\n        const routers = handlerType === 'load' ?\n            IORouterRegistry.getInstance().loadRouters :\n            IORouterRegistry.getInstance().saveRouters;\n        routers.forEach(router => {\n            const handler = router(url, loadOptions);\n            if (handler !== null) {\n                validHandlers.push(handler);\n            }\n        });\n        return validHandlers;\n    }\n}\nexport const registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);\nexport const registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);\nexport const getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);\nexport const getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);\n//# sourceMappingURL=router_registry.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Classes and functions for model management across multiple storage mediums.\n *\n * Supported client actions:\n * - Listing models on all registered storage mediums.\n * - Remove model by URL from any registered storage mediums, by using URL\n *   string.\n * - Moving or copying model from one path to another in the same medium or from\n *   one medium to another, by using URL strings.\n */\nimport { assert } from '../util';\nimport { IORouterRegistry } from './router_registry';\nconst URL_SCHEME_SUFFIX = '://';\nexport class ModelStoreManagerRegistry {\n    constructor() {\n        this.managers = {};\n    }\n    static getInstance() {\n        if (ModelStoreManagerRegistry.instance == null) {\n            ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();\n        }\n        return ModelStoreManagerRegistry.instance;\n    }\n    /**\n     * Register a save-handler router.\n     *\n     * @param saveRouter A function that maps a URL-like string onto an instance\n     * of `IOHandler` with the `save` method defined or `null`.\n     */\n    static registerManager(scheme, manager) {\n        assert(scheme != null, () => 'scheme must not be undefined or null.');\n        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {\n            scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));\n        }\n        assert(scheme.length > 0, () => 'scheme must not be an empty string.');\n        const registry = ModelStoreManagerRegistry.getInstance();\n        assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);\n        registry.managers[scheme] = manager;\n    }\n    static getManager(scheme) {\n        const manager = this.getInstance().managers[scheme];\n        if (manager == null) {\n            throw new Error(`Cannot find model manager for scheme '${scheme}'`);\n        }\n        return manager;\n    }\n    static getSchemes() {\n        return Object.keys(this.getInstance().managers);\n    }\n}\n/**\n * Helper method for parsing a URL string into a scheme and a path.\n *\n * @param url E.g., 'localstorage://my-model'\n * @returns A dictionary with two fields: scheme and path.\n *   Scheme: e.g., 'localstorage' in the example above.\n *   Path: e.g., 'my-model' in the example above.\n */\nfunction parseURL(url) {\n    if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {\n        throw new Error(`The url string provided does not contain a scheme. ` +\n            `Supported schemes are: ` +\n            `${ModelStoreManagerRegistry.getSchemes().join(',')}`);\n    }\n    return {\n        scheme: url.split(URL_SCHEME_SUFFIX)[0],\n        path: url.split(URL_SCHEME_SUFFIX)[1],\n    };\n}\nasync function cloneModelInternal(sourceURL, destURL, deleteSource = false) {\n    assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);\n    const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);\n    assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);\n    assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `load handlers for source URL ${sourceURL}.`);\n    const loadHandler = loadHandlers[0];\n    const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);\n    assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination ` +\n        `URL ${destURL}.`);\n    assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) ` +\n        `save handlers for destination URL ${destURL}.`);\n    const saveHandler = saveHandlers[0];\n    const sourceScheme = parseURL(sourceURL).scheme;\n    const sourcePath = parseURL(sourceURL).path;\n    const sameMedium = sourceScheme === parseURL(sourceURL).scheme;\n    const modelArtifacts = await loadHandler.load();\n    // If moving within the same storage medium, remove the old model as soon as\n    // the loading is done. Without doing this, it is possible that the combined\n    // size of the two models will cause the cloning to fail.\n    if (deleteSource && sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    const saveResult = await saveHandler.save(modelArtifacts);\n    // If moving between mediums, the deletion is done after the save succeeds.\n    // This guards against the case in which saving to the destination medium\n    // fails.\n    if (deleteSource && !sameMedium) {\n        await ModelStoreManagerRegistry.getManager(sourceScheme)\n            .removeModel(sourcePath);\n    }\n    return saveResult.modelArtifactsInfo;\n}\n/**\n * List all models stored in registered storage mediums.\n *\n * For a web browser environment, the registered mediums are Local Storage and\n * IndexedDB.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @returns A `Promise` of a dictionary mapping URLs of existing models to\n * their model artifacts info. URLs include medium-specific schemes, e.g.,\n *   'indexeddb://my/model/1'. Model artifacts info include type of the\n * model's topology, byte sizes of the topology, weights, etc.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function listModels() {\n    const schemes = ModelStoreManagerRegistry.getSchemes();\n    const out = {};\n    for (const scheme of schemes) {\n        const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();\n        for (const path in schemeOut) {\n            const url = scheme + URL_SCHEME_SUFFIX + path;\n            out[url] = schemeOut[path];\n        }\n    }\n    return out;\n}\n/**\n * Remove a model specified by URL from a reigstered storage medium.\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Delete the model.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n * ```\n *\n * @param url A URL to a stored model, with a scheme prefix, e.g.,\n *   'localstorage://my-model-1', 'indexeddb://my/model/2'.\n * @returns ModelArtifactsInfo of the deleted model (if and only if deletion\n *   is successful).\n * @throws Error if deletion fails, e.g., if no model exists at `path`.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function removeModel(url) {\n    const schemeAndPath = parseURL(url);\n    const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);\n    return manager.removeModel(schemeAndPath.path);\n}\n/**\n * Copy a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Copying within a storage medium, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Copying between two storage mediums, e.g.,\n *    `tf.io.copyModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Copy the model, from Local Storage to IndexedDB.\n * await tf.io.copyModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove both models.\n * await tf.io.removeModel('localstorage://demo/management/model1');\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of copying.\n * @param destURL Destination URL of copying.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if copying fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function copyModel(sourceURL, destURL) {\n    const deleteSource = false;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\n/**\n * Move a model from one URL to another.\n *\n * This function supports:\n *\n * 1. Moving within a storage medium, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'localstorage://model-2')`\n * 2. Moving between two storage mediums, e.g.,\n *    `tf.io.moveModel('localstorage://model-1', 'indexeddb://model-1')`\n *\n * ```js\n * // First create and save a model.\n * const model = tf.sequential();\n * model.add(tf.layers.dense(\n *     {units: 1, inputShape: [10], activation: 'sigmoid'}));\n * await model.save('localstorage://demo/management/model1');\n *\n * // Then list existing models.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Move the model, from Local Storage to IndexedDB.\n * await tf.io.moveModel(\n *     'localstorage://demo/management/model1',\n *     'indexeddb://demo/management/model1');\n *\n * // List models again.\n * console.log(JSON.stringify(await tf.io.listModels()));\n *\n * // Remove the moved model.\n * await tf.io.removeModel('indexeddb://demo/management/model1');\n * ```\n *\n * @param sourceURL Source URL of moving.\n * @param destURL Destination URL of moving.\n * @returns ModelArtifactsInfo of the copied model (if and only if copying\n *   is successful).\n * @throws Error if moving fails, e.g., if no model exists at `sourceURL`, or\n *   if `oldPath` and `newPath` are identical.\n *\n * @doc {\n *   heading: 'Models',\n *   subheading: 'Management',\n *   namespace: 'io',\n *   ignoreCI: true\n * }\n */\nasync function moveModel(sourceURL, destURL) {\n    const deleteSource = true;\n    return cloneModelInternal(sourceURL, destURL, deleteSource);\n}\nexport { moveModel, copyModel, removeModel, listModels };\n//# sourceMappingURL=model_management.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '../flags';\nimport { env } from '../environment';\nimport { assert } from '../util';\nimport { arrayBufferToBase64String, base64StringToArrayBuffer, getModelArtifactsInfoForJSON } from './io_utils';\nimport { IORouterRegistry } from './router_registry';\nconst PATH_SEPARATOR = '/';\nconst PATH_PREFIX = 'tensorflowjs_models';\nconst INFO_SUFFIX = 'info';\nconst MODEL_TOPOLOGY_SUFFIX = 'model_topology';\nconst WEIGHT_SPECS_SUFFIX = 'weight_specs';\nconst WEIGHT_DATA_SUFFIX = 'weight_data';\nconst MODEL_METADATA_SUFFIX = 'model_metadata';\n/**\n * Purge all tensorflow.js-saved model artifacts from local storage.\n *\n * @returns Paths of the models purged.\n */\nexport function purgeLocalStorageArtifacts() {\n    if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n        typeof window.localStorage === 'undefined') {\n        throw new Error('purgeLocalStorageModels() cannot proceed because local storage is ' +\n            'unavailable in the current environment.');\n    }\n    const LS = window.localStorage;\n    const purgedModelPaths = [];\n    for (let i = 0; i < LS.length; ++i) {\n        const key = LS.key(i);\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        if (key.startsWith(prefix) && key.length > prefix.length) {\n            LS.removeItem(key);\n            const modelName = getModelPathFromKey(key);\n            if (purgedModelPaths.indexOf(modelName) === -1) {\n                purgedModelPaths.push(modelName);\n            }\n        }\n    }\n    return purgedModelPaths;\n}\nfunction getModelKeys(path) {\n    return {\n        info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),\n        topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),\n        weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),\n        weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),\n        modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)\n    };\n}\n/**\n * Get model path from a local-storage key.\n *\n * E.g., 'tensorflowjs_models/my/model/1/info' --> 'my/model/1'\n *\n * @param key\n */\nfunction getModelPathFromKey(key) {\n    const items = key.split(PATH_SEPARATOR);\n    if (items.length < 3) {\n        throw new Error(`Invalid key format: ${key}`);\n    }\n    return items.slice(1, items.length - 1).join(PATH_SEPARATOR);\n}\nfunction maybeStripScheme(key) {\n    return key.startsWith(BrowserLocalStorage.URL_SCHEME) ?\n        key.slice(BrowserLocalStorage.URL_SCHEME.length) :\n        key;\n}\n/**\n * IOHandler subclass: Browser Local Storage.\n *\n * See the doc string to `browserLocalStorage` for more details.\n */\nexport class BrowserLocalStorage {\n    constructor(modelPath) {\n        if (!env().getBool('IS_BROWSER') || typeof window === 'undefined' ||\n            typeof window.localStorage === 'undefined') {\n            // TODO(cais): Add more info about what IOHandler subtypes are\n            // available.\n            //   Maybe point to a doc page on the web and/or automatically determine\n            //   the available IOHandlers and print them in the error message.\n            throw new Error('The current environment does not support local storage.');\n        }\n        this.LS = window.localStorage;\n        if (modelPath == null || !modelPath) {\n            throw new Error('For local storage, modelPath must not be null, undefined or empty.');\n        }\n        this.modelPath = modelPath;\n        this.keys = getModelKeys(this.modelPath);\n    }\n    /**\n     * Save model artifacts to browser local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @param modelArtifacts The model artifacts to be stored.\n     * @returns An instance of SaveResult.\n     */\n    async save(modelArtifacts) {\n        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n            throw new Error('BrowserLocalStorage.save() does not support saving model topology ' +\n                'in binary formats yet.');\n        }\n        else {\n            const topology = JSON.stringify(modelArtifacts.modelTopology);\n            const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);\n            const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);\n            try {\n                this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));\n                this.LS.setItem(this.keys.topology, topology);\n                this.LS.setItem(this.keys.weightSpecs, weightSpecs);\n                this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));\n                const result = {\n                    format: modelArtifacts.format,\n                    generatedBy: modelArtifacts.generatedBy,\n                    convertedBy: modelArtifacts.convertedBy\n                };\n                if (modelArtifacts.signature != null) {\n                    result.signature = modelArtifacts.signature;\n                }\n                if (modelArtifacts.userDefinedMetadata != null) {\n                    result.userDefinedMetadata = modelArtifacts.userDefinedMetadata;\n                }\n                if (modelArtifacts.modelInitializer != null) {\n                    result.modelInitializer = modelArtifacts.modelInitializer;\n                }\n                this.LS.setItem(this.keys.modelMetadata, JSON.stringify(result));\n                return { modelArtifactsInfo };\n            }\n            catch (err) {\n                // If saving failed, clean up all items saved so far.\n                this.LS.removeItem(this.keys.info);\n                this.LS.removeItem(this.keys.topology);\n                this.LS.removeItem(this.keys.weightSpecs);\n                this.LS.removeItem(this.keys.weightData);\n                this.LS.removeItem(this.keys.modelMetadata);\n                throw new Error(`Failed to save model '${this.modelPath}' to local storage: ` +\n                    `size quota being exceeded is a possible cause of this failure: ` +\n                    `modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, ` +\n                    `weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, ` +\n                    `weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);\n            }\n        }\n    }\n    /**\n     * Load a model from local storage.\n     *\n     * See the documentation to `browserLocalStorage` for details on the saved\n     * artifacts.\n     *\n     * @returns The loaded model (if loading succeeds).\n     */\n    async load() {\n        const info = JSON.parse(this.LS.getItem(this.keys.info));\n        if (info == null) {\n            throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);\n        }\n        if (info.modelTopologyType !== 'JSON') {\n            throw new Error('BrowserLocalStorage does not support loading non-JSON model ' +\n                'topology yet.');\n        }\n        const out = {};\n        // Load topology.\n        const topology = JSON.parse(this.LS.getItem(this.keys.topology));\n        if (topology == null) {\n            throw new Error(`In local storage, the topology of model '${this.modelPath}' ` +\n                `is missing.`);\n        }\n        out.modelTopology = topology;\n        // Load weight specs.\n        const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));\n        if (weightSpecs == null) {\n            throw new Error(`In local storage, the weight specs of model '${this.modelPath}' ` +\n                `are missing.`);\n        }\n        out.weightSpecs = weightSpecs;\n        // Load meta-data fields.\n        const metadataString = this.LS.getItem(this.keys.modelMetadata);\n        if (metadataString != null) {\n            const metadata = JSON.parse(metadataString);\n            out.format = metadata['format'];\n            out.generatedBy = metadata['generatedBy'];\n            out.convertedBy = metadata['convertedBy'];\n            if (metadata['signature'] != null) {\n                out.signature = metadata['signature'];\n            }\n            if (metadata['userDefinedMetadata'] != null) {\n                out.userDefinedMetadata = metadata['userDefinedMetadata'];\n            }\n            if (metadata['modelInitializer'] != null) {\n                out.modelInitializer = metadata['modelInitializer'];\n            }\n        }\n        // Load weight data.\n        const weightDataBase64 = this.LS.getItem(this.keys.weightData);\n        if (weightDataBase64 == null) {\n            throw new Error(`In local storage, the binary weight values of model ` +\n                `'${this.modelPath}' are missing.`);\n        }\n        out.weightData = base64StringToArrayBuffer(weightDataBase64);\n        return out;\n    }\n}\nBrowserLocalStorage.URL_SCHEME = 'localstorage://';\nexport const localStorageRouter = (url) => {\n    if (!env().getBool('IS_BROWSER')) {\n        return null;\n    }\n    else {\n        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {\n            return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));\n        }\n        else {\n            return null;\n        }\n    }\n};\nIORouterRegistry.registerSaveRouter(localStorageRouter);\nIORouterRegistry.registerLoadRouter(localStorageRouter);\n/**\n * Factory function for local storage IOHandler.\n *\n * This `IOHandler` supports both `save` and `load`.\n *\n * For each model's saved artifacts, four items are saved to local storage.\n *   - `${PATH_SEPARATOR}/${modelPath}/info`: Contains meta-info about the\n *     model, such as date saved, type of the topology, size in bytes, etc.\n *   - `${PATH_SEPARATOR}/${modelPath}/topology`: Model topology. For Keras-\n *     style models, this is a stringized JSON.\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_specs`: Weight specs of the\n *     model, can be used to decode the saved binary weight values (see\n *     item below).\n *   - `${PATH_SEPARATOR}/${modelPath}/weight_data`: Concatenated binary\n *     weight values, stored as a base64-encoded string.\n *\n * Saving may throw an `Error` if the total size of the artifacts exceed the\n * browser-specific quota.\n *\n * @param modelPath A unique identifier for the model to be saved. Must be a\n *   non-empty string.\n * @returns An instance of `IOHandler`, which can be used with, e.g.,\n *   `tf.Model.save`.\n */\nexport function browserLocalStorage(modelPath) {\n    return new BrowserLocalStorage(modelPath);\n}\nexport class BrowserLocalStorageManager {\n    constructor() {\n        assert(env().getBool('IS_BROWSER'), () => 'Current environment is not a web browser');\n        assert(typeof window === 'undefined' ||\n            typeof window.localStorage !== 'undefined', () => 'Current browser does not appear to support localStorage');\n        this.LS = window.localStorage;\n    }\n    async listModels() {\n        const out = {};\n        const prefix = PATH_PREFIX + PATH_SEPARATOR;\n        const suffix = PATH_SEPARATOR + INFO_SUFFIX;\n        for (let i = 0; i < this.LS.length; ++i) {\n            const key = this.LS.key(i);\n            if (key.startsWith(prefix) && key.endsWith(suffix)) {\n                const modelPath = getModelPathFromKey(key);\n                out[modelPath] = JSON.parse(this.LS.getItem(key));\n            }\n        }\n        return out;\n    }\n    async removeModel(path) {\n        path = maybeStripScheme(path);\n        const keys = getModelKeys(path);\n        if (this.LS.getItem(keys.info) == null) {\n            throw new Error(`Cannot find model at path '${path}'`);\n        }\n        const info = JSON.parse(this.LS.getItem(keys.info));\n        this.LS.removeItem(keys.info);\n        this.LS.removeItem(keys.topology);\n        this.LS.removeItem(keys.weightSpecs);\n        this.LS.removeItem(keys.weightData);\n        return info;\n    }\n}\n//# sourceMappingURL=local_storage.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../ops/complex';\nimport { tensor } from '../ops/tensor';\nimport { sizeFromShape } from '../util';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/** Number of bytes reserved for the length of the string. (32bit integer). */\nconst NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\nexport async function encodeWeights(tensors, group) {\n    // TODO(adarob, cais): Support quantization.\n    const specs = [];\n    const dataPromises = [];\n    const names = Array.isArray(tensors) ?\n        tensors.map(tensor => tensor.name) :\n        Object.keys(tensors);\n    for (let i = 0; i < names.length; ++i) {\n        const name = names[i];\n        const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n        if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' &&\n            t.dtype !== 'string' && t.dtype !== 'complex64') {\n            throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);\n        }\n        const spec = { name, shape: t.shape, dtype: t.dtype };\n        if (t.dtype === 'string') {\n            const utf8bytes = new Promise(async (resolve) => {\n                const vals = await t.bytes();\n                const totalNumBytes = vals.reduce((p, c) => p + c.length, 0) +\n                    NUM_BYTES_STRING_LENGTH * vals.length;\n                const bytes = new Uint8Array(totalNumBytes);\n                let offset = 0;\n                for (let i = 0; i < vals.length; i++) {\n                    const val = vals[i];\n                    const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n                    bytes.set(bytesOfLength, offset);\n                    offset += NUM_BYTES_STRING_LENGTH;\n                    bytes.set(val, offset);\n                    offset += val.length;\n                }\n                resolve(bytes);\n            });\n            dataPromises.push(utf8bytes);\n        }\n        else {\n            dataPromises.push(t.data());\n        }\n        if (group != null) {\n            spec.group = group;\n        }\n        specs.push(spec);\n    }\n    const tensorValues = await Promise.all(dataPromises);\n    return { data: concatenateTypedArrays(tensorValues), specs };\n}\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\nexport function decodeWeights(buffer, specs) {\n    // TODO(adarob, cais): Support quantization.\n    const out = {};\n    let float16Decode;\n    let offset = 0;\n    for (const spec of specs) {\n        const name = spec.name;\n        const dtype = spec.dtype;\n        const shape = spec.shape;\n        const size = sizeFromShape(shape);\n        let values;\n        if ('quantization' in spec) {\n            const quantization = spec.quantization;\n            if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                if (!('min' in quantization && 'scale' in quantization)) {\n                    throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} ` +\n                        `doesn't have corresponding metadata min and scale.`);\n                }\n            }\n            else if (quantization.dtype === 'float16') {\n                if (dtype !== 'float32') {\n                    throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} ` +\n                        `which only supports weights of type float32 not ${dtype}.`);\n                }\n            }\n            else {\n                throw new Error(`Weight ${spec.name} has unknown ` +\n                    `quantization dtype ${quantization.dtype}. ` +\n                    `Supported quantization dtypes are: ` +\n                    `'uint8', 'uint16', and 'float16'.`);\n            }\n            const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n            const quantizedArray = (quantization.dtype === 'uint8') ?\n                new Uint8Array(byteBuffer) :\n                new Uint16Array(byteBuffer);\n            if (dtype === 'float32') {\n                if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n                    values = new Float32Array(quantizedArray.length);\n                    for (let i = 0; i < quantizedArray.length; i++) {\n                        const v = quantizedArray[i];\n                        values[i] = v * quantization.scale + quantization.min;\n                    }\n                }\n                else if (quantization.dtype === 'float16') {\n                    if (float16Decode === undefined) {\n                        float16Decode = getFloat16Decoder();\n                    }\n                    values = float16Decode(quantizedArray);\n                }\n                else {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type float32.`);\n                }\n            }\n            else if (dtype === 'int32') {\n                if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n                    throw new Error(`Unsupported quantization type ${quantization.dtype} ` +\n                        `for weight type int32.`);\n                }\n                values = new Int32Array(quantizedArray.length);\n                for (let i = 0; i < quantizedArray.length; i++) {\n                    const v = quantizedArray[i];\n                    values[i] = Math.round(v * quantization.scale + quantization.min);\n                }\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * quantizationSizeFactor;\n        }\n        else if (dtype === 'string') {\n            const size = sizeFromShape(spec.shape);\n            values = [];\n            for (let i = 0; i < size; i++) {\n                const byteLength = new Uint32Array(buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n                offset += NUM_BYTES_STRING_LENGTH;\n                const bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n                values.push(bytes);\n                offset += byteLength;\n            }\n        }\n        else {\n            const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n            const byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n            if (dtype === 'float32') {\n                values = new Float32Array(byteBuffer);\n            }\n            else if (dtype === 'int32') {\n                values = new Int32Array(byteBuffer);\n            }\n            else if (dtype === 'bool') {\n                values = new Uint8Array(byteBuffer);\n            }\n            else if (dtype === 'complex64') {\n                values = new Float32Array(byteBuffer);\n                const real = new Float32Array(values.length / 2);\n                const image = new Float32Array(values.length / 2);\n                for (let i = 0; i < real.length; i++) {\n                    real[i] = values[i * 2];\n                    image[i] = values[i * 2 + 1];\n                }\n                const realTensor = tensor(real, shape, 'float32');\n                const imageTensor = tensor(image, shape, 'float32');\n                out[name] = complex(realTensor, imageTensor);\n                realTensor.dispose();\n                imageTensor.dispose();\n            }\n            else {\n                throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);\n            }\n            offset += size * dtypeFactor;\n        }\n        if (dtype !== 'complex64') {\n            out[name] = tensor(values, shape, dtype);\n        }\n    }\n    return out;\n}\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\nexport function concatenateTypedArrays(xs) {\n    // TODO(adarob, cais): Support quantization.\n    if (xs === null) {\n        throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);\n    }\n    let totalByteLength = 0;\n    // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n    // can have a different byte length from that of the `TypedArray` itself,\n    // for example, when the `TypedArray` is created from an offset in an\n    // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n    // the `TypedArray` in byte length. If an element of `xs` does not show\n    // this property, a new `TypedArray` that satisfy this property will be\n    // constructed and pushed into `normalizedXs`.\n    const normalizedXs = [];\n    xs.forEach((x) => {\n        totalByteLength += x.byteLength;\n        // tslint:disable:no-any\n        normalizedXs.push(x.byteLength === x.buffer.byteLength ? x :\n            new x.constructor(x));\n        if (!(x instanceof Float32Array || x instanceof Int32Array ||\n            x instanceof Uint8Array)) {\n            throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);\n        }\n        // tslint:enable:no-any\n    });\n    const y = new Uint8Array(totalByteLength);\n    let offset = 0;\n    normalizedXs.forEach((x) => {\n        y.set(new Uint8Array(x.buffer), offset);\n        offset += x.byteLength;\n    });\n    return y.buffer;\n}\n// Use Buffer on Node.js instead of Blob/atob/btoa\nconst useNodeBuffer = typeof Buffer !== 'undefined' &&\n    (typeof Blob === 'undefined' || typeof atob === 'undefined' ||\n        typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\nexport function stringByteLength(str) {\n    if (useNodeBuffer) {\n        return Buffer.byteLength(str);\n    }\n    return new Blob([str]).size;\n}\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\nexport function arrayBufferToBase64String(buffer) {\n    if (useNodeBuffer) {\n        return Buffer.from(buffer).toString('base64');\n    }\n    const buf = new Uint8Array(buffer);\n    let s = '';\n    for (let i = 0, l = buf.length; i < l; i++) {\n        s += String.fromCharCode(buf[i]);\n    }\n    return btoa(s);\n}\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\nexport function base64StringToArrayBuffer(str) {\n    if (useNodeBuffer) {\n        const buf = Buffer.from(str, 'base64');\n        return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n    }\n    const s = atob(str);\n    const buffer = new Uint8Array(s.length);\n    for (let i = 0; i < s.length; ++i) {\n        buffer.set([s.charCodeAt(i)], i);\n    }\n    return buffer.buffer;\n}\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\nexport function concatenateArrayBuffers(buffers) {\n    if (buffers.length === 1) {\n        return buffers[0];\n    }\n    let totalByteLength = 0;\n    buffers.forEach((buffer) => {\n        totalByteLength += buffer.byteLength;\n    });\n    const temp = new Uint8Array(totalByteLength);\n    let offset = 0;\n    buffers.forEach((buffer) => {\n        temp.set(new Uint8Array(buffer), offset);\n        offset += buffer.byteLength;\n    });\n    return temp.buffer;\n}\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\nexport function basename(path) {\n    const SEPARATOR = '/';\n    path = path.trim();\n    while (path.endsWith(SEPARATOR)) {\n        path = path.slice(0, path.length - 1);\n    }\n    const items = path.split(SEPARATOR);\n    return items[items.length - 1];\n}\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\nexport function getModelArtifactsInfoForJSON(modelArtifacts) {\n    if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n        throw new Error('Expected JSON model topology, received ArrayBuffer.');\n    }\n    return {\n        dateSaved: new Date(),\n        modelTopologyType: 'JSON',\n        modelTopologyBytes: modelArtifacts.modelTopology == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n        weightSpecsBytes: modelArtifacts.weightSpecs == null ?\n            0 :\n            stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n        weightDataBytes: modelArtifacts.weightData == null ?\n            0 :\n            modelArtifacts.weightData.byteLength,\n    };\n}\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\nfunction computeFloat16MantisaTable() {\n    const convertMantissa = (i) => {\n        let m = i << 13;\n        let e = 0;\n        while ((m & 0x00800000) === 0) {\n            e -= 0x00800000;\n            m <<= 1;\n        }\n        m &= ~0x00800000;\n        e += 0x38800000;\n        return m | e;\n    };\n    const mantisaTable = new Uint32Array(2048);\n    mantisaTable[0] = 0;\n    for (let i = 1; i < 1024; i++) {\n        mantisaTable[i] = convertMantissa(i);\n    }\n    for (let i = 1024; i < 2048; i++) {\n        mantisaTable[i] = 0x38000000 + ((i - 1024) << 13);\n    }\n    return mantisaTable;\n}\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\nfunction computeFloat16ExponentTable() {\n    const exponentTable = new Uint32Array(64);\n    exponentTable[0] = 0;\n    exponentTable[31] = 0x47800000;\n    exponentTable[32] = 0x80000000;\n    exponentTable[63] = 0xc7800000;\n    for (let i = 1; i < 31; i++) {\n        exponentTable[i] = i << 23;\n    }\n    for (let i = 33; i < 63; i++) {\n        exponentTable[i] = 0x80000000 + ((i - 32) << 23);\n    }\n    return exponentTable;\n}\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\nfunction computeFloat16OffsetTable() {\n    const offsetTable = new Uint32Array(64);\n    for (let i = 0; i < 64; i++) {\n        offsetTable[i] = 1024;\n    }\n    offsetTable[0] = offsetTable[32] = 0;\n    return offsetTable;\n}\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\nexport function getFloat16Decoder() {\n    // Algorithm is based off of\n    // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n    // Cache lookup tables\n    const mantisaTable = computeFloat16MantisaTable();\n    const exponentTable = computeFloat16ExponentTable();\n    const offsetTable = computeFloat16OffsetTable();\n    return (quantizedArray) => {\n        const buffer = new ArrayBuffer(4 * quantizedArray.length);\n        const bufferUint32View = new Uint32Array(buffer);\n        for (let index = 0; index < quantizedArray.length; index++) {\n            const float16Bits = quantizedArray[index];\n            const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] +\n                exponentTable[float16Bits >> 10];\n            bufferUint32View[index] = float32Bits;\n        }\n        return new Float32Array(buffer);\n    };\n}\n//# sourceMappingURL=io_utils.js.map"],"names":["DTYPE_VALUE_SIZE_MAP","monitorPromisesProgress","promises","onProgress","startFraction","endFraction","Array","isArray","length","checkPromises","checkFraction","resolvedPromise","Promise","all","map","promise","then","value","fraction","defer","f","resolve","setTimeout","BrowserDownloads","constructor","fileNamePrefix","getBool","Error","startsWith","URL_SCHEME","slice","this","modelTopologyFileName","weightDataFileName","save","modelArtifacts","weightsURL","window","URL","createObjectURL","Blob","weightData","type","modelTopology","ArrayBuffer","weightsManifest","paths","weights","weightSpecs","modelTopologyAndWeightManifest","format","generatedBy","convertedBy","signature","userDefinedMetadata","modelInitializer","modelTopologyAndWeightManifestURL","JSON","stringify","jsonAnchor","document","createElement","download","href","dispatchEvent","MouseEvent","weightDataAnchor","modelArtifactsInfo","BrowserFiles","files","load","jsonFile","weightFiles","reject","jsonReader","FileReader","onload","event","modelJSON","parse","target","result","name","pathToFile","checkManifestAndWeightFiles","err","perFileBuffers","forEach","weightsGroup","path","push","weightFileReader","index","indexOf","onerror","error","readAsArrayBuffer","readAsText","manifest","basenames","fileNames","file","group","pathBasename","browserFiles","registerSaveRouter","url","browserDownloads","HTTPRequest","loadOptions","DEFAULT_METHOD","weightPathPrefix","weightUrlConverter","fetchFunc","fetch","platform","requestInit","body","init","Object","assign","method","FormData","append","response","ok","responses","status","modelConfigRequest","modelConfig","json","e","message","endsWith","results","loadWeights","artifacts","initializer","weightPath","prefix","suffix","lastSlash","lastIndexOf","lastSearchParam","substring","parseUrl","pathPrefix","entry","fetchURLs","urlPromises","buffers","isHTTPScheme","match","URL_SCHEME_REGEX","httpRouter","isHTTP","every","urlItem","http","browserHTTPRequest","registerLoadRouter","PassthroughLoader","PassthroughSaver","saveHandler","fromMemory","trainingConfig","arguments","isModelArtifacts","withSaveHandler","DATABASE_NAME","MODEL_STORE_NAME","INFO_STORE_NAME","getIndexedDBFactory","theWindow","self","factory","indexedDB","mozIndexedDB","webkitIndexedDB","msIndexedDB","shimIndexedDB","setUpDatabase","openRequest","db","createObjectStore","keyPath","BrowserIndexedDB","modelPath","databaseAction","open","onupgradeneeded","onsuccess","modelTx","transaction","getRequest","objectStore","get","close","oncomplete","infoTx","infoStore","putInfoRequest","put","putModelRequest","deleteInfoRequest","delete","indexedDBRouter","BrowserIndexedDBManager","listModels","tx","getAllInfoRequest","getAll","out","item","removeModel","key","getInfoRequest","deleteModelData","deleteModelRequest","IORouterRegistry","saveRouters","loadRouters","getInstance","instance","saveRouter","loadRouter","getSaveHandlers","getHandlers","getLoadHandlers","handlerType","validHandlers","router","handler","loudRouter","URL_SCHEME_SUFFIX","ModelStoreManagerRegistry","managers","registerManager","scheme","manager","registry","getManager","getSchemes","keys","parseURL","join","split","async","cloneModelInternal","sourceURL","destURL","deleteSource","loadHandlers","loadHandler","saveHandlers","sourceScheme","sourcePath","sameMedium","saveResult","schemes","schemeOut","schemeAndPath","copyModel","moveModel","PATH_SEPARATOR","PATH_PREFIX","INFO_SUFFIX","MODEL_TOPOLOGY_SUFFIX","WEIGHT_SPECS_SUFFIX","WEIGHT_DATA_SUFFIX","MODEL_METADATA_SUFFIX","getModelKeys","info","topology","modelMetadata","getModelPathFromKey","items","BrowserLocalStorage","localStorage","LS","setItem","removeItem","modelTopologyBytes","weightSpecsBytes","weightDataBytes","getItem","modelTopologyType","metadataString","metadata","weightDataBase64","localStorageRouter","BrowserLocalStorageManager","i","NUM_BYTES_STRING_LENGTH","encodeWeights","tensors","specs","dataPromises","names","tensor","t","dtype","spec","shape","utf8bytes","vals","bytes","totalNumBytes","reduce","p","c","Uint8Array","offset","val","bytesOfLength","Uint32Array","buffer","set","data","concatenateTypedArrays","decodeWeights","float16Decode","size","values","quantization","quantizationSizeFactor","byteBuffer","quantizedArray","Uint16Array","Float32Array","v","scale","min","undefined","getFloat16Decoder","Int32Array","Math","round","byteLength","dtypeFactor","real","image","realTensor","imageTensor","dispose","xs","totalByteLength","normalizedXs","x","y","useNodeBuffer","Buffer","atob","btoa","stringByteLength","str","arrayBufferToBase64String","from","toString","buf","s","l","String","fromCharCode","base64StringToArrayBuffer","byteOffset","charCodeAt","concatenateArrayBuffers","temp","basename","trim","getModelArtifactsInfoForJSON","dateSaved","Date","mantisaTable","convertMantissa","m","computeFloat16MantisaTable","exponentTable","computeFloat16ExponentTable","offsetTable","computeFloat16OffsetTable","bufferUint32View","float16Bits","float32Bits"],"sourceRoot":""}