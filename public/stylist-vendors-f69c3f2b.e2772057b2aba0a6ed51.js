"use strict";(self.webpackChunkStylistWidget=self.webpackChunkStylistWidget||[]).push([[2658],{10959:function(t,e,n){n.d(e,{M5:function(){return o},tP:function(){return r},zO:function(){return a}});var i=n(9495);function s(t,e,n){const i=e.length;if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>null));if(1===i)return Array.isArray(t)&&1===t.length?t:"object"===typeof t&&e[0]in t?[t[e[0]]]:[t];if(Array.isArray(t)){if(t.length!==i)throw new Error(`Provided ${n} is an array of ${t.length} element(s), but the model has ${i} outputs. Make sure a set of weights is provided for each model output.`);return t}if("object"===typeof t&&Object.keys(t).length>0&&"object"===typeof t[Object.keys(t)[0]]){const n=[];return e.forEach((e=>{e in t?n.push(t[e]):n.push(null)})),n}throw new Error(`The model has multiple (${i}) outputs, so ${n} must be either an array with ${i} elements or an object with ${e} keys. Provided ${n} not understood: ${JSON.stringify(t)}`)}function a(t,e){return s(t,e,"classWeight")}async function r(t,e,n,s){if(null!=e||null!=s)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const e=(0,i.tidy)((()=>{if(1===t.shape.length)return(0,i.clone)(t);if(2===t.shape.length){if(t.shape[1]>1){const e=1;return(0,i.argMax)(t,e)}if(1===t.shape[1])return(0,i.reshape)(t,[t.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${t.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${t.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)})),s=Array.from(await e.data());(0,i.dispose)(e);const a=[];return s.forEach((t=>{if(null==n[t])throw new Error(`classWeight must contain all classes in the training data. The class ${t} exists in the data but not in classWeight`);a.push(n[t])})),(0,i.tensor1d)(a,"float32")}return null}function o(t,e){return(0,i.mul)(t,e)}},51372:function(t,e,n){n.d(e,{DE:function(){return o},Ec:function(){return c},Pe:function(){return r},XX:function(){return l},n4:function(){return u},yy:function(){return a}});var i=n(9495),s=n(47661);function a(t){i.util.assert(t>0&&Number.isInteger(t),(()=>`batchSize is required to be a positive integer, but got ${t}`))}function r(t,e,n){return null==t?[null]:Array.isArray(t)?t.map((t=>(0,s.Dh)(t,e,n-e))):(0,s.Dh)(t,e,n-e)}function o(t,e){return i.tidy((()=>null==t?null:Array.isArray(t)?t.map((t=>o(t,e))):(0,s.kg)(t,"int32"===e.dtype?e:i.cast(e,"int32"))))}function l(t,e){const n=[];let i=0,s=null;for(;i<t;)s=i+e,s>=t&&(s=t),n.push([i,s]),i=s;return n}function u(t){const e=[];t instanceof i.Tensor&&(t=[t]);for(let n=0;n<t.length;++n){const i=t[n];if(1===i.rank)e.push((0,s.UG)(i,1));else{if(0===i.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");e.push(i)}}return e}function c(t,e){if(null==t)return;const n=[];if(e instanceof i.Tensor)n.push(e.id);else if(Array.isArray(e))e.forEach((t=>n.push(t.id)));else if(null!=e)for(const i in e){const t=e[i];n.push(t.id)}const s=[];if(t instanceof i.Tensor)-1===n.indexOf(t.id)&&s.push(t);else if(Array.isArray(t))t.forEach((t=>{-1===n.indexOf(t.id)&&s.push(t)}));else if(null!=t)for(const i in t){const e=t[i];-1===n.indexOf(e.id)&&s.push(e)}s.forEach((t=>{t.isDisposed||t.dispose()}))}},68414:function(t,e,n){n.d(e,{O:function(){return p},c:function(){return d}});var i=n(9495),s=n(85244),a=n(15841),r=n(96681),o=n(44813),l=n(10959);const u=32;function c(t,e){let n,s;const a=e;n=a.xs,s=a.ys,i.util.assert(null!=n&&null!=s,(()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${e}`));const r=h("input",t.inputNames,n),o=h("output",t.outputNames,s),l=r[0].shape[0];i.util.assert(r.length===t.inputs.length,(()=>`LayersModel has ${t.inputs.length} inputs, but the dataset provides ${r.length} inputs.  (Expected input keys: ${JSON.stringify(t.inputNames)})`)),i.util.assert(o.length===t.outputs.length,(()=>`LayersModel has ${t.outputs.length} outputs, but the dataset provides ${o.length} outputs.  (Expected output keys: ${JSON.stringify(t.outputNames)})`));for(let u=0;u<r.length;u++)i.util.assert(r[u].shape[0]===l,(()=>`Batch size mismatch: input ${t.inputNames[u]} has ${r[u].shape[0]}; expected  ${l} based on input ${t.inputNames[0]}.`));for(let u=0;u<o.length;u++)i.util.assert(o[u].shape[0]===l,(()=>`Batch size mismatch: output ${t.outputNames[u]} has ${o[u].shape[0]}; expected  ${l} based on input ${t.inputNames[0]}.`));return{xs:r,ys:o}}function h(t,e,n){if(n instanceof i.Tensor)return[n];if(Array.isArray(n))return i.util.assert(n.length===e.length,(()=>`Received an array of ${n.length} Tensors, but expected ${e.length} to match the ${t} keys ${e}.`)),n;{const i=[];for(const s of e){if(null==n[s])throw new a.Qp(`The feature data generated by the dataset lacks the required ${t} key '${s}'.`);i.push(n[s])}return i}}async function p(t,e,n){const h=null!=n.batchesPerEpoch;if(i.util.assert(null!=t.optimizer,(()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).")),i.util.assert(null!=n,(()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.")),i.util.assert(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),(()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${n.epochs}`)),i.util.assert(!h||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),(()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${n.batchesPerEpoch}`)),i.util.assert(null==n.validationSplit,(()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.")),t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");t.isTraining=!0;try{const p=null!=n.validationData;let d,g;if(p)if(f(n.validationData))i.util.assert(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),(()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${n.validationBatches}`));else{const t=function(t){if(3===t.length)throw new a.EH("Validation with sample weights is not implemented yet.");return{xs:t[0],ys:t[1]}}(n.validationData);d=t.xs,g=t.ys}const y=t.makeTrainFunction(),b=t.getDedupedMetricsNames();let m;m=p?b.slice().concat(b.map((t=>"val_"+t))):b.slice();const v=(0,s.Eq)(n.callbacks,n.yieldEvery),w=null==n.verbose?1:n.verbose,{callbackList:E,history:$}=(0,s.dY)(v,w,n.epochs,null,null,function(t,e){let n=null;null!=e.batchesPerEpoch?n=e.batchesPerEpoch:Number.isFinite(t.size)&&(n=t.size);return n}(e,n),null,p,m);E.setModel(t),t.history=$,await E.onTrainBegin(),t.stopTraining_=!1;let x=null==n.initialEpoch?0:n.initialEpoch,k=await e.iterator();for(;x<n.epochs;){const s={};await E.onEpochBegin(x);let a=0,m=0;for(h||(k=await e.iterator());!h||a<n.batchesPerEpoch;){const e=await k.next();if(h&&e.done)break;if(null!=e.value){const{xs:s,ys:o}=c(t,e.value),u={};u.batch=m,u.size=s[0].shape[0],await E.onBatchBegin(m,u);const h=[];if(null!=n.classWeight){const e=(0,l.zO)(n.classWeight,t.outputNames);for(let t=0;t<e.length;++t)h.push(await(0,l.tP)(o[t],null,e[t]))}const p=s.concat(o).concat(h),f=y(p);i.dispose(p);for(let t=0;t<b.length;++t){const e=b[t],n=f[t];u[e]=n,i.keep(n)}await E.onBatchEnd(m,u),(0,r.i)(u),m++,a++}if(h?a>=n.batchesPerEpoch:e.done){if(p){let e;e=f(n.validationData)?(0,o.st)(await t.evaluateDataset(n.validationData,{batches:n.validationBatches})):(0,o.st)(t.evaluate(d,g,{batchSize:null==n.validationBatchSize?u:n.validationBatchSize,verbose:0}));for(let n=0;n<t.metricsNames.length;++n)s[`val_${t.metricsNames[n]}`]=e[n]}break}if(t.stopTraining_)break}if(await E.onEpochEnd(x,s),x++,t.stopTraining_)break}return await E.onTrainEnd(),await t.history.syncData(),t.history}finally{t.isTraining=!1}}function f(t){return"function"===typeof t.iterator}async function d(t,e,n){const s=null!=(n=n||{}).batches,r=t.testFunction;let l=[];if(n.verbose>0)throw new a.EH("Verbose mode is not implemented yet.");i.util.assert(!s||n.batches>0&&Number.isInteger(n.batches),(()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(n.batches)}`));const u="function"===typeof e.next?e:await e.iterator();let h=0,p=0;for(;!s||p<n.batches;){const e=await u.next();if(l=i.tidy((()=>{if(e.value){const{xs:n,ys:s}=c(t,e.value),a=n.concat(s),o=i.tidy((()=>r(a)));if(i.dispose(a),0===p)for(let t=0;t<o.length;++t)l.push((0,i.scalar)(0));const u=a[0].shape[0];for(let t=0;t<o.length;++t){const e=o[t],n=l[t];l[t]=i.tidy((()=>i.add(l[t],i.mul(u,e)))),p>0&&i.dispose(n)}i.dispose(o),h+=u,++p}return l})),e.done)break}for(let a=0;a<l.length;++a){const t=l[a];l[a]=i.div(l[a],h),i.dispose(t)}return(0,o.wL)(l)}}}]);
//# sourceMappingURL=stylist-vendors-f69c3f2b.e2772057b2aba0a6ed51.js.map