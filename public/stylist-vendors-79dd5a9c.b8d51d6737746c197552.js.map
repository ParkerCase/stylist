{"version":3,"file":"stylist-vendors-79dd5a9c.b8d51d6737746c197552.js","mappings":"gPAuBO,MAAMA,UAAgB,KACzB,WAAAC,CAAYC,GACRC,MAAMD,GACNE,KAAKC,KAAOC,KAAKC,IAAID,KAAKE,IAAIN,EAAKG,KAAM,GAAI,GAE7CD,KAAKK,WAAaP,EAAKO,WACvBL,KAAKM,KAAOR,EAAKQ,KACjBN,KAAKO,iBAAkB,CAC3B,CACA,aAAAC,CAAcC,GACV,GAAuB,MAAnBT,KAAKK,WACL,OAAOL,KAAKK,WAEhB,MAAMK,EAAaD,EAAME,MACnBN,EAAa,GACnB,IAAK,IAAIO,EAAI,EAAGA,EAAIZ,KAAKK,WAAWQ,SAAUD,EAC1CP,EAAWS,KAA2B,MAAtBd,KAAKK,WAAWO,GAAaF,EAAWE,GAAKZ,KAAKK,WAAWO,IAEjF,OAAOP,CACX,CACA,IAAAU,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRlB,KAAKmB,eAAeH,EAAQC,GAC5B,MAAMR,GAAQ,QAAoBO,GAClC,GAAI,EAAIhB,KAAKC,MAAQD,KAAKC,KAAO,EAAG,CAChC,MAAMmB,EAAiC,MAAtBH,EAAiB,UAAoBA,EAAiB,SACjEZ,EAAaL,KAAKQ,cAAcC,GAEtC,OADe,MAAe,IAAM,KAAUA,EAAOT,KAAKC,KAAMI,EAAYL,KAAKM,QAAO,IAAMG,GAAOW,EAEzG,CACA,OAAOJ,CAAM,GAErB,CACA,SAAAK,GACI,MAAMC,EAAS,CACXrB,KAAMD,KAAKC,KACXI,WAAYL,KAAKK,WACjBC,KAAMN,KAAKM,MAETiB,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,CACA,OAAAI,GACI,OAAO3B,MAAM2B,SACjB,EAGJ9B,EAAQ+B,UAAY,UACpB,EAAAC,cAAA,cAA4BhC,GACrB,MAAMiC,UAAyBjC,EAClC,WAAAC,CAAYC,GACRC,MAAMD,GACNE,KAAK8B,UAAY,CAAC,CAAEC,KAAM,GAC9B,CACA,aAAAvB,CAAcC,GACV,MAAMC,EAAaD,EAAME,MACzB,MAAO,CAACD,EAAW,GAAI,EAAGA,EAAW,GACzC,EAGJmB,EAAiBF,UAAY,mBAC7B,EAAAC,cAAA,cAA4BC,GACrB,MAAMG,UAAc,KACvB,WAAAnC,CAAYC,GASR,GARAC,MAAMD,GAENE,KAAKiC,WAAa,KAClBjC,KAAKkC,SAAU,EACflC,KAAKmC,OAAS,KACdnC,KAAKoC,KAAO,KACZpC,KAAKqC,2BAA6B,eAClCrC,KAAKsC,yBAA2B,QACJ,MAAxBxC,EAAKyC,iBAA8C,MAAnBzC,EAAKY,YACpB,MAAjBZ,EAAK0C,SAAkB,CAGvB,IAAIC,EAAY,KACM,MAAlB3C,EAAK2C,YACLA,EAAY3C,EAAK2C,WAErBzC,KAAKuC,gBAAkB,CAACE,EAAW3C,EAAK0C,SAC5C,CACAxC,KAAK0C,MAAQ5C,EAAK4C,OAClB,QAAsB1C,KAAK0C,MAAO,SAClC1C,KAAKiC,YAAa,QAAcnC,EAAKmC,YACjB,MAAhBnC,EAAKoC,UACLlC,KAAKkC,QAAUpC,EAAKoC,SAExBlC,KAAK2C,mBAAoB,QAAe7C,EAAK6C,mBAAqB3C,KAAKqC,4BACvErC,KAAK4C,iBACD,QAAe9C,EAAK8C,iBAAmB5C,KAAKsC,0BAChDtC,KAAK6C,kBAAmB,QAAc/C,EAAK+C,kBAC3C7C,KAAK8C,gBAAiB,QAAchD,EAAKgD,gBACzC9C,KAAK+C,mBAAoB,QAAejD,EAAKiD,mBAC7C/C,KAAKgD,iBAAkB,QAAelD,EAAKkD,iBAC3ChD,KAAKiD,qBAAsB,QAAenD,EAAKmD,qBAC/CjD,KAAKO,iBAAkB,EACvBP,KAAK8B,UAAY,CAAC,CAAEoB,QAAS,GACjC,CACA,KAAAC,CAAMzC,GAEF,MAAM0C,GADN1C,GAAa,QAAmBA,IACAA,EAAWG,OAAS,GACjC,MAAfb,KAAKmC,SACLnC,KAAKmC,OAASnC,KAAKqD,UAAU,SAAU,CAACD,EAAcpD,KAAK0C,OAAQ,KAAM1C,KAAK2C,kBAAmB3C,KAAK+C,mBAAmB,EAAM/C,KAAK6C,kBAChI7C,KAAKkC,UACLlC,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAACrD,KAAK0C,OAAQ,KAAM1C,KAAK4C,gBAAiB5C,KAAKgD,iBAAiB,EAAMhD,KAAK8C,kBAGtH9C,KAAK8B,UAAY,CAAC,CAAEoB,QAAS,EAAGI,KAAM,CAAE,EAAE,GAAIF,KAC9CpD,KAAKuD,OAAQ,CACjB,CACA,kBAAAC,CAAmB9C,GAEf,MAAM+C,GADN/C,GAAa,QAAmBA,IACDgD,QAE/B,OADAD,EAAYA,EAAY5C,OAAS,GAAKb,KAAK0C,MACpCe,CACX,CACA,IAAA1C,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRlB,KAAKmB,eAAeH,EAAQC,GAE5B,MAAMR,GAAQ,QAAoBO,GAC5B2C,GAAsB,QAA2B3D,KAAKiC,WAAW2B,gBACvE,IAAIC,EAaJ,OAZ2B,MAAvBF,EACAE,EAAS,KAAMpD,EAAOT,KAAKmC,OAAO2B,OAAQH,EAAqB3D,KAAKoC,KAAOpC,KAAKoC,KAAK0B,OAAS,OAG9FD,EAAS,KAAMpD,EAAOT,KAAKmC,OAAO2B,QACjB,MAAb9D,KAAKoC,OACLyB,EAAS,KAAUA,EAAQ7D,KAAKoC,KAAK0B,SAElB,MAAnB9D,KAAKiC,aACL4B,EAAS7D,KAAKiC,WAAW8B,MAAMF,KAGhCA,CAAM,GAErB,CACA,SAAAxC,GACI,MAAMC,EAAS,CACXoB,MAAO1C,KAAK0C,MACZT,YAAY,QAAoBjC,KAAKiC,YACrCC,QAASlC,KAAKkC,QACdS,mBAAmB,QAAqB3C,KAAK2C,mBAC7CC,iBAAiB,QAAqB5C,KAAK4C,iBAC3CG,mBAAmB,QAAqB/C,KAAK+C,mBAC7CC,iBAAiB,QAAqBhD,KAAKgD,iBAC3CC,qBAAqB,QAAqBjD,KAAKiD,qBAC/CJ,kBAAkB,QAAoB7C,KAAK6C,kBAC3CC,gBAAgB,QAAoB9C,KAAK8C,iBAEvCvB,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJU,EAAML,UAAY,QAClB,EAAAC,cAAA,cAA4BI,GACrB,MAAMgC,UAAgB,KACzB,WAAAnE,CAAYC,GAERC,MADAD,EAAOA,GAAQ,CAAC,GAEhBE,KAAK8B,UAAY,CAAC,CAAEoB,QAAS,IAC7BlD,KAAKiE,WAAanE,EAAKmE,UAC3B,CACA,kBAAAT,CAAmB9C,GACfA,GAAa,QAAmBA,GAChC,IAAK,MAAMwD,KAAOxD,EAAWgD,MAAM,GAC/B,GAAW,MAAPQ,EACA,MAAM,IAAI,KACN,iEAAQxD,EAAWgD,MAAM,qHAKrC,MAAO,CAAChD,EAAW,IAAI,QAAUA,EAAY,GACjD,CACA,IAAAK,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRlB,KAAKmB,eAAeH,EAAQC,GAC5B,IAAIR,GAAQ,QAAoBO,GAChC,GAAwB,kBAApBhB,KAAKiE,YAAkCxD,EAAM0D,KAAO,EAAG,CACvD,MAAMC,EAAc,CAAC,GACrB,IAAK,IAAIxD,EAAI,EAAGA,EAAIH,EAAM0D,OAAQvD,EAC9BwD,EAAYtD,KAAKF,GAErBwD,EAAYtD,KAAK,GACjBL,EAAQA,EAAM4D,UAAUD,EAC5B,CACA,OAAO,KAAe3D,EAAM,GAEpC,CACA,SAAAY,GACI,MAAMC,EAAS,CAAC,EACO,MAAnBtB,KAAKiE,aACL3C,EAAmB,WAAItB,KAAKiE,YAEhC,MAAM1C,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJ0C,EAAQrC,UAAY,UACpB,EAAAC,cAAA,cAA4BoC,GACrB,MAAMM,UAAmB,KAC5B,WAAAzE,CAAYC,GACRC,MAAMD,GACNE,KAAKO,iBAAkB,EACvBP,KAAKiC,YAAa,QAAcnC,EAAKmC,WACzC,CACA,IAAAlB,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRlB,KAAKmB,eAAeH,EAAQC,GAC5B,MAAMR,GAAQ,QAAoBO,GAClC,OAAOhB,KAAKiC,WAAW8B,MAAMtD,EAAM,GAE3C,CACA,SAAAY,GACI,MAAMC,EAAS,CAAEW,YAAY,QAAoBjC,KAAKiC,aAChDV,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJgD,EAAW3C,UAAY,aACvB,EAAAC,cAAA,cAA4B0C,GACrB,MAAMC,UAAqB,KAC9B,WAAA1E,CAAYC,GACRC,MAAMD,GACNE,KAAKwE,EAAI1E,EAAK0E,EACdxE,KAAK8B,UAAY,CAAC,CAAEC,KAAM,GAC9B,CACA,kBAAAyB,CAAmB9C,GACf,MAAO,CAACA,EAAW,GAAIV,KAAKwE,EAAG9D,EAAW,GAC9C,CACA,IAAAK,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRF,GAAS,QAAoBA,GACtB,KAASA,EAAQhB,KAAKwE,KAErC,CACA,SAAAnD,GACI,MAAMC,EAAS,CACXkD,EAAGxE,KAAKwE,GAENjD,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJiD,EAAa5C,UAAY,eACzB,EAAAC,cAAA,cAA4B2C,GACrB,MAAME,UAAgB,KACzB,WAAA5E,CAAYC,GACRC,MAAMD,GACNE,KAAK0E,YAAc5E,EAAK4E,YAExB,IAAK,IAAI9D,EAAI,EAAGA,EAAIZ,KAAK0E,YAAY7D,SAAUD,EACvCZ,KAAK2E,UAAU3E,KAAK0E,YAAY9D,MAChCZ,KAAK0E,YAAY9D,GAAK,KAGlC,CACA,SAAA+D,CAAUT,GACN,OAAOA,EAAM,GAAY,MAAPA,CACtB,CAeA,mBAAAU,CAAoBlE,EAAY+C,GAC5B,MAAMoB,EAAW,6CACXC,EAAarB,EAAYC,QAC/B,IAAIqB,EAAQ,EACRC,EAAU,KACd,IAAK,IAAIpE,EAAI,EAAGA,EAAIkE,EAAWjE,SAAUD,EAAG,CACxC,MAAMsD,EAAMY,EAAWlE,GACvB,GAAIZ,KAAK2E,UAAUT,GAAM,CACrB,GAAgB,OAAZc,EAIA,MAAM,IAAI,KAAW,4CAHrBA,EAAUpE,CAKlB,MAEImE,GAASb,CAEjB,CACA,MAAMe,GAAe,QAAUvE,GAC/B,GAAgB,OAAZsE,EAAkB,CAClB,GAAc,IAAVD,GAAeE,EAAeF,IAAU,EACxC,MAAM,IAAI,KAAWF,GAEzBC,EAAWE,GAAWC,EAAeF,CACzC,MACK,GAAIE,IAAiBF,EACtB,MAAM,IAAI,KAAWF,GAEzB,OAAOC,CACX,CACA,kBAAAtB,CAAmB9C,GACf,IAAIwE,GAAiB,EACrB,IAAK,IAAItE,EAAI,EAAGA,EAAIF,EAAWG,SAAUD,EACrC,GAAIZ,KAAK2E,UAAUjE,EAAWE,IAAK,CAC/BsE,GAAiB,EACjB,KACJ,CAEJ,OAAIA,EACOxE,EAAWgD,MAAM,EAAG,GAAGyB,OAAOnF,KAAK0E,aAGnChE,EAAWgD,MAAM,EAAG,GAAGyB,OAAOnF,KAAK4E,oBAAoBlE,EAAWgD,MAAM,GAAI1D,KAAK0E,aAEhG,CACA,IAAA3D,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRlB,KAAKmB,eAAeH,EAAQC,GAC5B,MAAMR,GAAQ,QAAoBO,GAC5BN,EAAaD,EAAME,MACnB8C,EAAc/C,EAAWgD,MAAM,EAAG,GAAGyB,OAAOnF,KAAK4E,oBAAoBlE,EAAWgD,MAAM,GAAI1D,KAAK0E,cACrG,OAAOjE,EAAM2E,QAAQ3B,EAAY,GAEzC,CACA,SAAApC,GACI,MAAMC,EAAS,CACXoD,YAAa1E,KAAK0E,aAEhBnD,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJmD,EAAQ9C,UAAY,UACpB,EAAAC,cAAA,cAA4B6C,GACrB,MAAMY,UAAgB,KACzB,WAAAxF,CAAYC,GAER,GADAC,MAAMD,GACW,MAAbA,EAAKwF,KACL,MAAM,IAAIC,MAAM,mFAGpB,IAAKC,MAAMC,QAAQ3F,EAAKwF,MACpB,MAAM,IAAIC,MACN,sEAAGzF,EAAKwF,iBAGhB,MAAMI,GAAwB,QAAM,EAAG5F,EAAKwF,KAAKzE,OAAS,GAC1D,IAAK,EAAA8E,KAAA,YAAiB7F,EAAKwF,KAAK5B,QAAQkC,OAAQF,GAC5C,MAAM,IAAIH,MAAM,+BAAiCM,KAAKC,UAAUhG,EAAKwF,MACjE,8DAERtF,KAAKsF,KAAOxF,EAAKwF,KACjBtF,KAAK+F,mBAAqB,CAAC,GAAGZ,OAAOnF,KAAKsF,MAC1CtF,KAAK8B,UAAY,CAAC,IAAI,KAAU,CAAEC,KAAM/B,KAAKsF,KAAKzE,OAAS,IAC/D,CACA,kBAAA2C,CAAmB9C,GAEf,MAAM+C,GADN/C,GAAa,QAAmBA,IACDgD,QAI/B,OAHA1D,KAAKsF,KAAKU,SAAQ,CAAC9B,EAAKtD,KACpB6C,EAAY7C,EAAI,GAAKF,EAAWwD,EAAI,IAEjCT,CACX,CACA,IAAA1C,CAAKC,EAAQC,GACT,OAAO,IAAAoD,YAAU,QAAoBrD,GAAShB,KAAK+F,mBACvD,CACA,SAAA1E,GACI,MAAMC,EAAS,CACXgE,KAAMtF,KAAKsF,MAET/D,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJ+D,EAAQ1D,UAAY,UACpB,EAAAC,cAAA,cAA4ByD,GACrB,MAAMY,UAAgB,KACzB,WAAApG,CAAYC,GACRC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAKO,iBAAkB,EAEnBP,KAAKkG,UADG,MAARpG,EACmC,MAAlBA,EAAKoG,UAAoB,EAAIpG,EAAKoG,UAGlC,CAEzB,CACA,kBAAA1C,CAAmB9C,GACf,OAAOA,CACX,CACA,SAAAW,GACI,MAAME,EAAaxB,MAAMsB,YACnBC,EAAS,CAAE4E,UAAWlG,KAAKkG,WAEjC,OADA1E,OAAOC,OAAOH,EAAQC,GACfD,CACX,CACA,WAAA6E,CAAYnF,EAAQoF,GAChB,MAAM3F,GAAQ,QAAoBO,GAElC,OAAO,IAAAqF,MAAI,IAAAC,UAAS7F,EAAOT,KAAKkG,YADlB,EAElB,CACA,IAAAnF,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KACRlB,KAAKmB,eAAeH,EAAQC,GAC5B,MAAMR,GAAQ,QAAoBO,GAG5BuF,GAAc,IAAAF,MAAI,IAAAC,UAAS7F,EAAOT,KAAKkG,YAF/B,GACG,GAGjB,OADezF,EAAM+F,IAAID,EAAYE,OAAOhG,EAAMiG,OACrC,GAErB,EAGJT,EAAQtE,UAAY,UACpB,EAAAC,cAAA,cAA4BqE,E,6HCtbrB,MAAMU,UAAa,KACtB,WAAA9G,CAAYC,GACRC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAKO,iBAAkB,EACX,MAART,IACAE,KAAK4G,SAAW9G,EAAK8G,SAE7B,CACA,IAAA7F,CAAKC,EAAQC,GACTD,GAAS,QAAoBA,GAC7B,IAAI6C,GAAS,IAAAgD,MAAK7F,GAIlB,OAHqB,MAAjBhB,KAAK4G,WACL/C,GAAS,IAAAiD,aAAYjD,EAAQ,EAAG7D,KAAK4G,WAElC/C,CACX,CACA,kBAAAL,CAAmB9C,GACf,OAAOA,CACX,CACA,SAAAW,GACI,MAAMC,EAAS,CAAEsF,SAAU5G,KAAK4G,UAC1BrF,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJqF,EAAKhF,UAAY,OACjB,EAAAC,cAAA,cAA4B+E,GACrB,MAAMI,UAAkB,KAC3B,WAAAlH,CAAYC,GACRC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAKgH,cAAgB,GACT,MAARlH,IACAA,EAAO,CAAC,GAEZE,KAAKiH,MAAsB,MAAdnH,EAAKmH,MAAgBjH,KAAKgH,cAAgBlH,EAAKmH,KAChE,CACA,IAAAlG,CAAKC,EAAQC,GACT,MAAMiG,GAAI,QAAoBlG,GAC9B,OAAO,IAAAmG,WAAUD,EAAGlH,KAAKiH,MAC7B,CACA,kBAAAzD,CAAmB9C,GACf,OAAOA,CACX,CACA,SAAAW,GACI,MAAMC,EAAS,CAAE2F,MAAOjH,KAAKiH,OACvB1F,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJyF,EAAUpF,UAAY,YACtB,EAAAC,cAAA,cAA4BmF,GACrB,MAAMK,UAAc,KACvB,WAAAvH,CAAYC,GAWR,GAVAC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAKqH,0BAA4B,QACrB,MAARvH,IACAA,EAAO,CAAC,GAEZE,KAAKO,iBAAkB,EACvBP,KAAKsH,kBACD,QAAexH,EAAKwH,kBAAoBtH,KAAKqH,2BACjDrH,KAAKuH,kBAAmB,QAAezH,EAAKyH,kBAC5CvH,KAAKwH,iBAAkB,QAAc1H,EAAK0H,iBACnB,MAAnB1H,EAAK2H,WACLzH,KAAKyH,WAAa,UAEjB,GAAIjC,MAAMC,QAAQ3F,EAAK2H,YACxBzH,KAAKyH,WAAa3H,EAAK2H,eAEtB,IAA+B,kBAApB3H,EAAK2H,WAIjB,MAAM,IAAI,KACN,sEAAW3H,EAAK2H,cAJpBzH,KAAKyH,WAAa,CAAC3H,EAAK2H,WAK5B,CACJ,CACA,KAAAtE,CAAMzC,GAEF,MAAMgH,GADNhH,GAAa,QAAmBA,IACFgD,MAAM,GACpC,GAAuB,MAAnB1D,KAAKyH,WACL,IAAK,MAAM7G,KAAKZ,KAAKyH,WACjBC,EAAW9G,EAAI,GAAK,EAG5BZ,KAAKiH,MAAQjH,KAAKqD,UAAU,QAASqE,EAAY,UAAW1H,KAAKsH,iBAAkBtH,KAAKuH,kBAAkB,EAAMvH,KAAKwH,iBAErH,MAAMlE,EAAO,CAAC,EACd,GAAuB,MAAnBtD,KAAKyH,WACL,IAAK,IAAI7G,EAAI,EAAGA,EAAIF,EAAWG,SAAUD,EACrC0C,EAAK1C,GAAKF,EAAWE,GAG7BZ,KAAK8B,UAAY,CAAC,IAAI,KAAU,CACxBC,KAAMrB,EAAWG,OACjByC,UAERtD,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GAET,OADAD,GAAS,QAAoBA,IACtB,IAAA2G,OAAM3G,EAAQhB,KAAKiH,MAAMnD,OACpC,CACA,SAAAzC,GACI,MAAMC,EAAS,CACXgG,kBAAkB,QAAqBtH,KAAKsH,kBAC5CC,kBAAkB,QAAqBvH,KAAKuH,kBAC5CC,iBAAiB,QAAoBxH,KAAKwH,iBAC1CC,WAAYzH,KAAKyH,YAEflG,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJ8F,EAAMzF,UAAY,QAClB,EAAAC,cAAA,cAA4BwF,GACrB,MAAMQ,UAAY,KACrB,WAAA/H,CAAYC,GAMR,GALAC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAKgH,cAAgB,EACT,MAARlH,IACAA,EAAO,CAAC,GAEM,MAAdA,EAAKmH,OAAiBnH,EAAKmH,QAAUjH,KAAKgH,cAC1C,MAAM,IAAI,KAAoB,4BAA4BlH,EAAKmH,iDAGnEjH,KAAKiH,MAAsB,MAAdnH,EAAKmH,MAAgBjH,KAAKgH,cAAgBlH,EAAKmH,KAChE,CACA,IAAAlG,CAAKC,EAAQC,GACT,MAAMiG,GAAI,QAAoBlG,GAC9B,OAAO,IAAA6G,KAAIX,EACf,CACA,kBAAA1D,CAAmB9C,GACf,OAAOA,CACX,CACA,SAAAW,GACI,MAAMC,EAAS,CAAE2F,MAAOjH,KAAKiH,OACvB1F,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJsG,EAAIjG,UAAY,MAChB,EAAAC,cAAA,cAA4BgG,GACrB,MAAME,UAAwB,KACjC,WAAAjI,CAAYC,GACRC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAK+H,cAAgB,EACT,MAARjI,IACAA,EAAO,CAAC,GAEZE,KAAKgI,MAAsB,MAAdlI,EAAKkI,MAAgBhI,KAAK+H,cAAgBjI,EAAKkI,KAChE,CACA,IAAAjH,CAAKC,EAAQC,GACT,MAAMiG,GAAI,QAAoBlG,GAC9B,OAAOkG,EAAEV,KAAI,QAAKU,EAAEe,QAAQjI,KAAKgI,OAAQ,WAC7C,CACA,kBAAAxE,CAAmB9C,GACf,OAAOA,CACX,CACA,SAAAW,GACI,MAAMC,EAAS,CAAE0G,MAAOhI,KAAKgI,OACvBzG,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJwG,EAAgBnG,UAAY,kBAC5B,EAAAC,cAAA,cAA4BkG,GACrB,MAAMI,UAAgB,KACzB,WAAArI,CAAYC,GACRC,MAAc,MAARD,EAAe,CAAC,EAAIA,GAC1BE,KAAKmI,aAAe,EACR,MAARrI,IACAA,EAAO,CAAC,GAEZE,KAAKoI,SAAU,IAAI,MAAoBrE,MACvC/D,KAAKqI,KAAoB,MAAbvI,EAAKuI,KAAerI,KAAKmI,aAAerI,EAAKuI,IAC7D,CACA,IAAAtH,CAAKC,EAAQC,GACT,MAAMiG,GAAI,QAAoBlG,GAC9B,OAAOhB,KAAKoI,QAAQlB,EAAGlH,KAAKqI,KAChC,CACA,kBAAA7E,CAAmB9C,GACf,OAAOA,CACX,CACA,SAAAW,GACI,MAAMC,EAAS,CAAE+G,KAAMrI,KAAKqI,MACtB9G,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJ4G,EAAQvG,UAAY,UACpB,EAAAC,cAAA,cAA4BsG,E,yPClMrB,SAASI,EAAsBpB,EAAGjD,GAErC,OAAO,IAAA/C,OAAK,MACR,QAAgB+C,GACG,kBAAfA,EACO,YAAciD,EAAG,CAAC,EAAG,EAAG,EAAG,IAG3BA,IAGnB,CAMO,SAASqB,EAAsBrB,EAAGjD,GACrC,OAAO,IAAA/C,OAAK,MACR,QAAgB+C,GACG,kBAAfA,EACO,YAAciD,EAAG,CAAC,EAAG,EAAG,EAAG,EAAG,IAG9BA,IAGnB,CAiBO,SAASsB,EAAetB,EAAG/E,EAAQC,EAAMqG,EAAU,EAAGC,EAAU,QAASzE,EAAY0E,EAAe,GACvG,OAAO,IAAAzH,OAAK,KAMR,GALkB,MAAd+C,IACAA,GAAa,YAEjB,QAAgBA,GAEO,IAAnBiD,EAAEvG,MAAME,OACR,MAAM,IAAI,KACN,+DAAGqG,EAAEvG,MAAME,mBAEnB,GAA4B,IAAxBsB,EAAOxB,MAAME,OACb,MAAM,IAAI,KACN,iEAAGsB,EAAOxB,MAAME,kBAExB,GAAY,MAARuB,GAAsC,IAAtBA,EAAKzB,MAAME,OAC3B,MAAM,IAAI,KACN,+DAAGsB,EAAOxB,MAAME,kBAMxB,GAHmB,kBAAfoD,IACAiD,EAAI,YAAcA,EAAG,CAAC,EAAG,EAAG,KAEhB,WAAZwB,EACA,MAAM,IAAI,KAAoB,iFAGlC,IAAIE,EAAI,SAAW1B,EAAG/E,EAAQsG,EAAqB,SAAZC,EAAqB,OAAS,QAAS,MAAOC,GAIrF,OAHY,MAARvG,IACAwG,EAAI,KAAUA,EAAGxG,IAEdwG,CAAC,GAEhB,CAwCO,SAASC,EAAyB3B,EAAG/E,EAAQC,EAAMqG,EAAU,CAAC,EAAG,GAAIC,EAAU,QAASzE,EAAY0E,EAAc1G,EAAa,MAClI,OAAO,IAAAf,OAAK,KAKR,GAJkB,MAAd+C,IACAA,GAAa,YAEjB,QAAgBA,GACD,IAAXiD,EAAE/C,MAAyB,IAAX+C,EAAE/C,KAClB,MAAM,IAAI,KACN,6EAAgB+C,EAAE/C,SAE1B,GAAoB,IAAhBhC,EAAOgC,MAA8B,IAAhBhC,EAAOgC,KAC5B,MAAM,IAAI,KACN,8EAAgB+C,EAAE/C,SAE1B,IAAIyE,EAAIN,EAAsBpB,EAAGjD,GACjC,GAAgB,WAAZyE,EACA,MAAM,IAAI,KAAoB,iFAgBlC,OAbAE,EAAI,eAAiB,CACjB1B,EAAG0B,EACHE,OAAQ3G,EACRsG,QAASA,EACTM,IAAiB,SAAZL,EAAqB,OAAS,QACnCM,UAAWL,EACX1E,WAAY,OACZ7B,OACAH,eAEe,kBAAfgC,IACA2E,EAAI,YAAcA,EAAG,CAAC,EAAG,EAAG,EAAG,KAE5BA,CAAC,GAEhB,CAsBO,SAASK,EAAe/B,EAAG/E,EAAQC,EAAMqG,EAAU,CAAC,EAAG,EAAG,GAAIC,EAAU,QAASzE,EAAY0E,GAChG,OAAO,IAAAzH,OAAK,KAKR,GAJkB,MAAd+C,IACAA,GAAa,YAEjB,QAAgBA,GACD,IAAXiD,EAAE/C,MAAyB,IAAX+C,EAAE/C,KAClB,MAAM,IAAI,KACN,mEAAG+C,EAAE/C,SAEb,GAAoB,IAAhBhC,EAAOgC,MAA8B,IAAhBhC,EAAOgC,KAC5B,MAAM,IAAI,KACN,oEAAG+C,EAAE/C,SAEb,IAAIyE,EAAIL,EAAsBrB,EAAGjD,GACjC,GAAgB,WAAZyE,EACA,MAAM,IAAI,KAAoB,iFAUlC,OAPAE,EAAI,SAAWA,EAAGzG,EAAQsG,EAAqB,SAAZC,EAAqB,OAAS,QAAS,QAASC,GACvE,MAARvG,IACAwG,EAAI,KAAUA,EAAGxG,IAEF,kBAAf6B,IACA2E,EAAI,YAAcA,EAAG,CAAC,EAAG,EAAG,EAAG,EAAG,KAE/BA,CAAC,GAEhB,CAIO,MAAMM,UAAiB,KAC1B,WAAArJ,CAAYsE,EAAMrE,GAQd,GAPAC,MAAMD,GACNE,KAAKoC,KAAO,KACZpC,KAAKqC,2BAA6B,eAClCrC,KAAKsC,yBAA2B,QAChC4G,EAASC,WAAWrJ,GACpBE,KAAKmE,KAAOA,EACZ,KAAoCnE,KAAKmE,KAAM,QAC7B,IAAdnE,KAAKmE,MAA4B,IAAdnE,KAAKmE,MAA4B,IAAdnE,KAAKmE,KAC3C,MAAM,IAAI,KAAoB,qDAAqDnE,KAAKmE,iCAkB5F,GAfAnE,KAAKoJ,YAAa,OAAetJ,EAAKsJ,WAAYjF,EAAM,cACxDnE,KAAKyI,SAAU,OAA+B,MAAhB3I,EAAK2I,QAAkB,EAAI3I,EAAK2I,QAAStE,EAAM,WAC7EnE,KAAK0I,QAA0B,MAAhB5I,EAAK4I,QAAkB,QAAU5I,EAAK4I,SACrD,QAAiB1I,KAAK0I,SACtB1I,KAAKiE,WACkB,MAAnBnE,EAAKmE,WAAqB,eAAiBnE,EAAKmE,YACpD,QAAgBjE,KAAKiE,YACrBjE,KAAKiC,YAAa,QAAcnC,EAAKmC,YACrCjC,KAAKkC,QAA0B,MAAhBpC,EAAKoC,SAAyBpC,EAAKoC,QAClDlC,KAAK4C,iBACD,QAAe9C,EAAK8C,iBAAmB5C,KAAKsC,0BAChDtC,KAAK8C,gBAAiB,QAAchD,EAAKgD,gBACzC9C,KAAKgD,iBAAkB,QAAelD,EAAKkD,iBAC3ChD,KAAKiD,qBAAsB,QAAenD,EAAKmD,qBAC/CjD,KAAK2I,cAAe,OAAoC,MAArB7I,EAAK6I,aAAuB,EAAI7I,EAAK6I,aAAcxE,EAAM,gBAC1E,IAAdnE,KAAKmE,MACJqB,MAAMC,QAAQzF,KAAK2I,eAA8C,IAA7B3I,KAAK2I,aAAa9H,OACvD,MAAM,IAAI,KAEN,iGAAGgF,KAAKC,UAAU9F,KAAK2I,iBAE1B,GAAkB,IAAd3I,KAAKmE,MACV,GAAiC,kBAAtBnE,KAAK2I,aACZ3I,KAAK2I,aAAe,CAAC3I,KAAK2I,aAAc3I,KAAK2I,mBAE5C,GAAiC,IAA7B3I,KAAK2I,aAAa9H,OACvB,MAAM,IAAI,KACN,0FAA6BgF,KAAKC,UAAU9F,KAAK2I,sBAGxD,GAAkB,IAAd3I,KAAKmE,KACV,GAAiC,kBAAtBnE,KAAK2I,aACZ3I,KAAK2I,aACD,CAAC3I,KAAK2I,aAAc3I,KAAK2I,aAAc3I,KAAK2I,mBAE/C,GAAiC,IAA7B3I,KAAK2I,aAAa9H,OACvB,MAAM,IAAI,KACN,4FAA6BgF,KAAKC,UAAU9F,KAAK2I,gBAGjE,CACA,iBAAOQ,CAAWrJ,GAGd,GADA,KAAqB,eAAgBA,EAAM,2CACZ,kBAApBA,EAAKsJ,aACX,KAAsCtJ,EAAKsJ,WAAY,SAAU,EAAG,GACrE,MAAM,IAAI,KACN,oGAAmCvD,KAAKC,UAAUhG,EAAKsJ,eAEnE,CACA,SAAA/H,GACI,MAAMC,EAAS,CACX8H,WAAYpJ,KAAKoJ,WACjBX,QAASzI,KAAKyI,QACdC,QAAS1I,KAAK0I,QACdzE,WAAYjE,KAAKiE,WACjB0E,aAAc3I,KAAK2I,aACnB1G,YAAY,QAAoBjC,KAAKiC,YACrCC,QAASlC,KAAKkC,QACdU,iBAAiB,QAAqB5C,KAAK4C,iBAC3CI,iBAAiB,QAAqBhD,KAAKgD,iBAC3CC,qBAAqB,QAAqBjD,KAAKiD,qBAC/CH,gBAAgB,QAAoB9C,KAAK8C,iBAEvCvB,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAMG,MAAM+H,UAAaH,EACtB,WAAArJ,CAAYsE,EAAMrE,GACdC,MAAMoE,EAAMrE,GACZE,KAAKmC,OAAS,KACdkH,EAAKF,WAAWrJ,GAChBE,KAAKsJ,QAAUxJ,EAAKwJ,QACpB,KAAoCtJ,KAAKsJ,QAAS,WAClDtJ,KAAK2C,mBAAoB,QAAe7C,EAAK6C,mBAAqB3C,KAAKqC,4BACvErC,KAAK6C,kBAAmB,QAAc/C,EAAK+C,kBAC3C7C,KAAK+C,mBAAoB,QAAejD,EAAKiD,kBACjD,CACA,KAAAI,CAAMzC,GACFA,GAAa,QAAmBA,GAChC,MAAM6I,EAAkC,kBAApBvJ,KAAKiE,WAAiC,EAAIvD,EAAWG,OAAS,EAClF,GAA+B,MAA3BH,EAAW6I,GACX,MAAM,IAAI,KACN,+DAAS7I,EAAW6I,MAE5B,MAAM/G,EAAW9B,EAAW6I,GACtBC,EAAcxJ,KAAKoJ,WAAWjE,OAAO,CAAC3C,EAAUxC,KAAKsJ,UAC3DtJ,KAAKmC,OAASnC,KAAKqD,UAAU,SAAUmG,EAAa,KAAMxJ,KAAK2C,kBAAmB3C,KAAK+C,mBAAmB,EAAM/C,KAAK6C,kBACjH7C,KAAKkC,UACLlC,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAACrD,KAAKsJ,SAAU,KAAMtJ,KAAK4C,gBAAiB5C,KAAKgD,iBAAiB,EAAMhD,KAAK8C,iBAEpH9C,KAAK8B,UAAY,CAAC,CAAEC,KAAM/B,KAAKmE,KAAO,EAAGb,KAAM,CAAE,CAACiG,GAAc/G,KAChExC,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KAER,IAAIuI,EADJzI,GAAS,QAAoBA,GAE7B,MAAM0I,EAAyB,MAAb1J,KAAKoC,KAAe,KAAOpC,KAAKoC,KAAK0B,OACjDH,EAAsB,KAAyC3D,KAAKiC,WAAW2B,gBACrF,GAA2B,MAAvBD,GAA6C,IAAd3D,KAAKmE,KACpCsF,EAAUZ,EAAyB7H,EAAQhB,KAAKmC,OAAO2B,OAAQ4F,EAAW1J,KAAKyI,QAASzI,KAAK0I,QAAS1I,KAAKiE,WAAYjE,KAAK2I,aAAchF,OAEzI,CACD,GAAkB,IAAd3D,KAAKmE,KACLsF,EAAUjB,EAAexH,EAAQhB,KAAKmC,OAAO2B,OAAQ4F,EAAW1J,KAAKyI,QAAQ,GAAIzI,KAAK0I,QAAS1I,KAAKiE,WAAYjE,KAAK2I,aAAa,SAEjI,GAAkB,IAAd3I,KAAKmE,KAEVsF,EAAUZ,EAAyB7H,EAAQhB,KAAKmC,OAAO2B,OAAQ4F,EAAW1J,KAAKyI,QAASzI,KAAK0I,QAAS1I,KAAKiE,WAAYjE,KAAK2I,kBAE3H,IAAkB,IAAd3I,KAAKmE,KAIV,MAAM,IAAI,KAAoB,yDAH9BsF,EAAUR,EAAejI,EAAQhB,KAAKmC,OAAO2B,OAAQ4F,EAAW1J,KAAKyI,QAASzI,KAAK0I,QAAS1I,KAAKiE,WAAYjE,KAAK2I,aAItH,CACuB,MAAnB3I,KAAKiC,aACLwH,EAAUzJ,KAAKiC,WAAW8B,MAAM0F,GAExC,CACA,OAAOA,CAAO,GAEtB,CACA,kBAAAjG,CAAmB9C,GACfA,GAAa,QAAmBA,GAChC,MAAMiJ,EAAW,GACXC,EAA6B,iBAApB5J,KAAKiE,WAChBvD,EAAWgD,MAAM,EAAGhD,EAAWG,OAAS,GACxCH,EAAWgD,MAAM,GACrB,IAAK,IAAI9C,EAAI,EAAGA,EAAIgJ,EAAM/I,SAAUD,EAAG,CACnC,MAAMiJ,GAAS,QAAiBD,EAAMhJ,GAAIZ,KAAKoJ,WAAWxI,GAAIZ,KAAK0I,QAAS1I,KAAKyI,QAAQ7H,GAAiC,kBAAtBZ,KAAK2I,aAA4B3I,KAAK2I,aACtI3I,KAAK2I,aAAa/H,IACtB+I,EAAS7I,KAAK+I,EAClB,CACA,IAAIpG,EAAc,CAAC/C,EAAW,IAS9B,MARwB,iBAApBV,KAAKiE,YACLR,EAAcA,EAAY0B,OAAOwE,GACjClG,EAAY3C,KAAKd,KAAKsJ,WAGtB7F,EAAY3C,KAAKd,KAAKsJ,SACtB7F,EAAcA,EAAY0B,OAAOwE,IAE9BlG,CACX,CACA,SAAApC,GACI,MAAMC,EAAS,CACXgI,QAAStJ,KAAKsJ,QACd3G,mBAAmB,QAAqB3C,KAAK2C,mBAC7CI,mBAAmB,QAAqB/C,KAAK+C,mBAC7CF,kBAAkB,QAAoB7C,KAAK6C,mBAEzCtB,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,CACA,iBAAO6H,CAAWrJ,GAEd,KAAM,YAAaA,IAAiC,kBAAjBA,EAAKwJ,SACpCxJ,EAAKwJ,QAAU,EACf,MAAM,IAAI,KACN,0EAAWzD,KAAKC,UAAUhG,EAAKwJ,WAE3C,EAEG,MAAMQ,UAAeT,EACxB,WAAAxJ,CAAYC,GACRC,MAAM,EAAGD,GACTgK,EAAOX,WAAWrJ,EACtB,CACA,SAAAuB,GACI,MAAMC,EAASvB,MAAMsB,YAErB,cADOC,EAAa,KACbA,CACX,CACA,iBAAO6H,CAAWrJ,GAEd,GAAgC,kBAApBA,EAAKsJ,aACZ,KAAsCtJ,EAAKsJ,WAAY,SAAU,EAAG,GACrE,MAAM,IAAI,KACN,8FAA+BvD,KAAKC,UAAUhG,EAAKsJ,eAE/D,EAGJU,EAAOnI,UAAY,SACnB,EAAAC,cAAA,cAA4BkI,GACrB,MAAMC,UAAeV,EACxB,WAAAxJ,CAAYC,GACRC,MAAM,EAAGD,GACTiK,EAAOZ,WAAWrJ,EACtB,CACA,SAAAuB,GACI,MAAMC,EAASvB,MAAMsB,YAErB,cADOC,EAAa,KACbA,CACX,CACA,iBAAO6H,CAAWrJ,GAEd,GAA+B,kBAApBA,EAAKsJ,cACN5D,MAAMC,QAAQ3F,EAAKsJ,aACO,IAA3BtJ,EAAKsJ,WAAWvI,QAA2C,IAA3Bf,EAAKsJ,WAAWvI,QACjD,MAAM,IAAI,KACN,2FAA2CgF,KAAKC,UAAUhG,EAAKsJ,eAG/E,EAGJW,EAAOpI,UAAY,SACnB,EAAAC,cAAA,cAA4BmI,GACrB,MAAMC,UAAwBF,EACjC,WAAAjK,CAAYC,GAGR,GAFAC,MAAMD,GACNE,KAAK8B,UAAY,CAAC,IAAI,KAAU,CAAEC,KAAM,KACnB,SAAjB/B,KAAK0I,SAAuC,UAAjB1I,KAAK0I,QAChC,MAAM,IAAI,KACN,uGAA0C1I,KAAK0I,UAE3D,CACA,KAAAvF,CAAMzC,GAEF,GAA0B,KAD1BA,GAAa,QAAmBA,IACjBG,OACX,MAAM,IAAI,KAAW,mDACjBgF,KAAKC,UAAUpF,IAEvB,MAAM6I,EAAkC,kBAApBvJ,KAAKiE,WAAiC,EAAIvD,EAAWG,OAAS,EAClF,GAA+B,MAA3BH,EAAW6I,GACX,MAAM,IAAI,KAAW,wEAGzB,MAAM/G,EAAW9B,EAAW6I,GACtBC,EAAcxJ,KAAKoJ,WAAWjE,OAAO,CAACnF,KAAKsJ,QAAS9G,IAC1DxC,KAAKmC,OAASnC,KAAKqD,UAAU,SAAUmG,EAAa,UAAWxJ,KAAK2C,kBAAmB3C,KAAK+C,mBAAmB,EAAM/C,KAAK6C,kBACtH7C,KAAKkC,UACLlC,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAACrD,KAAKsJ,SAAU,UAAWtJ,KAAK4C,gBAAiB5C,KAAKgD,iBAAiB,EAAMhD,KAAK8C,iBAGzH9C,KAAK8B,UACD,CAAC,IAAI,KAAU,CAAEC,KAAM,EAAGuB,KAAM,CAAE,CAACiG,GAAc/G,MACrDxC,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GACT,OAAO,QAAS,KACZ,IAAIR,GAAQ,QAAoBO,GAChC,GAA2B,IAAvBP,EAAME,MAAME,OACZ,MAAM,IAAI,KACN,2FAA6BJ,EAAME,MAAME,UAEjD,MAAMH,EAAaD,EAAME,MACnB8B,EAAY/B,EAAW,GAC7B,IAAIuJ,EACAC,EACoB,kBAApBlK,KAAKiE,YACLgG,EAAQ,EACRC,EAAQ,IAGRD,EAAQ,EACRC,EAAQ,GAEZ,MAAMC,EAASzJ,EAAWuJ,GACpBG,EAAQ1J,EAAWwJ,GACnBG,EAAUrK,KAAKoJ,WAAW,GAC1BkB,EAAUtK,KAAKoJ,WAAW,GAC1BmB,EAAUvK,KAAKyI,QAAQ,GACvB+B,EAAUxK,KAAKyI,QAAQ,GAQvBhF,EAAc,CAAChB,GANH,QAAa0H,EAAQI,EAASF,EAASrK,KAAK0I,UAC7C,QAAa0B,EAAOI,EAASF,EAAStK,KAAK0I,SAKP1I,KAAKsJ,SAClC,iBAApBtJ,KAAKiE,aACLxD,EAAQ,YAAcA,EAAO,CAAC,EAAG,EAAG,EAAG,KAE3C,IAAIgJ,EAAU,kBAAoBhJ,EAAOT,KAAKmC,OAAO2B,OAAQL,EAAazD,KAAKyI,QAASzI,KAAK0I,SAW7F,MAVwB,iBAApB1I,KAAKiE,aACLwF,EAAU,YAAcA,EAAS,CAAC,EAAG,EAAG,EAAG,KAE9B,MAAbzJ,KAAKoC,OACLqH,EACI,KAAUA,EAASzJ,KAAKoC,KAAK0B,OAAQ9D,KAAKiE,aAE3B,MAAnBjE,KAAKiC,aACLwH,EAAUzJ,KAAKiC,WAAW8B,MAAM0F,IAE7BA,CAAO,GAEtB,CACA,kBAAAjG,CAAmB9C,GAEf,MAAM+C,GADN/C,GAAa,QAAmBA,IACDgD,QAC/B,IAAI6F,EACAkB,EACAC,EACoB,kBAApB1K,KAAKiE,YACLsF,EAAc,EACdkB,EAAa,EACbC,EAAY,IAGZnB,EAAc,EACdkB,EAAa,EACbC,EAAY,GAEhB,MAAML,EAAUrK,KAAKoJ,WAAW,GAC1BkB,EAAUtK,KAAKoJ,WAAW,GAC1BmB,EAAUvK,KAAKyI,QAAQ,GACvB+B,EAAUxK,KAAKyI,QAAQ,GAM7B,OALAhF,EAAY8F,GAAevJ,KAAKsJ,QAChC7F,EAAYgH,IACR,QAAahH,EAAYgH,GAAaF,EAASF,EAASrK,KAAK0I,SACjEjF,EAAYiH,IACR,QAAajH,EAAYiH,GAAYF,EAASF,EAAStK,KAAK0I,SACzDjF,CACX,CACA,SAAApC,GACI,MAAMC,EAASvB,MAAMsB,YAErB,cADOC,EAAqB,aACrBA,CACX,EAGJ0I,EAAgBrI,UAAY,kBAC5B,EAAAC,cAAA,cAA4BoI,GACrB,MAAMW,UAAwBZ,EACjC,WAAAlK,CAAYC,GAGR,GAFAC,MAAMD,GACNE,KAAK8B,UAAY,CAAC,IAAI,KAAU,CAAEC,KAAM,KACnB,SAAjB/B,KAAK0I,SAAuC,UAAjB1I,KAAK0I,QAChC,MAAM,IAAI,KACN,uGAA0C1I,KAAK0I,UAE3D,CACA,KAAAvF,CAAMzC,GAEF,GAA0B,KAD1BA,GAAa,QAAmBA,IACjBG,OACX,MAAM,IAAI,KAAW,mDACjBgF,KAAKC,UAAUpF,IAEvB,MAAM6I,EAAkC,kBAApBvJ,KAAKiE,WAAiC,EAAIvD,EAAWG,OAAS,EAClF,GAA+B,MAA3BH,EAAW6I,GACX,MAAM,IAAI,KAAW,wEAGzB,MAAM/G,EAAW9B,EAAW6I,GACtBC,EAAcxJ,KAAKoJ,WAAWjE,OAAO,CAACnF,KAAKsJ,QAAS9G,IAC1DxC,KAAKmC,OAASnC,KAAKqD,UAAU,SAAUmG,EAAa,UAAWxJ,KAAK2C,kBAAmB3C,KAAK+C,mBAAmB,EAAM/C,KAAK6C,kBACtH7C,KAAKkC,UACLlC,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAACrD,KAAKsJ,SAAU,UAAWtJ,KAAK4C,gBAAiB5C,KAAKgD,iBAAiB,EAAMhD,KAAK8C,iBAGzH9C,KAAK8B,UACD,CAAC,IAAI,KAAU,CAAEC,KAAM,EAAGuB,KAAM,CAAE,CAACiG,GAAc/G,MACrDxC,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GACT,OAAO,QAAS,KACZ,IAAIR,GAAQ,QAAoBO,GAChC,GAA2B,IAAvBP,EAAME,MAAME,OACZ,MAAM,IAAI,KACN,2FAA6BJ,EAAME,MAAME,UAEjD,MAAMH,EAAaD,EAAME,MACnB8B,EAAY/B,EAAW,GAC7B,IAAIuJ,EACAC,EACAU,EACoB,kBAApB5K,KAAKiE,YACL2G,EAAQ,EACRX,EAAQ,EACRC,EAAQ,IAGRU,EAAQ,EACRX,EAAQ,EACRC,EAAQ,GAEZ,MAAMW,EAAQnK,EAAWkK,GACnBT,EAASzJ,EAAWuJ,GACpBG,EAAQ1J,EAAWwJ,GACnBY,EAAU9K,KAAKoJ,WAAW,GAC1BiB,EAAUrK,KAAKoJ,WAAW,GAC1BkB,EAAUtK,KAAKoJ,WAAW,GAC1B2B,EAAU/K,KAAKyI,QAAQ,GACvB8B,EAAUvK,KAAKyI,QAAQ,GACvB+B,EAAUxK,KAAKyI,QAAQ,GAMvBhF,EAAc,CAAChB,GAJJ,QAAaoI,EAAOE,EAASD,EAAS9K,KAAK0I,UAC1C,QAAayB,EAAQI,EAASF,EAASrK,KAAK0I,UAC7C,QAAa0B,EAAOI,EAASF,EAAStK,KAAK0I,SAEG1I,KAAKsJ,SAC5C,iBAApBtJ,KAAKiE,aACLxD,EAAQ,YAAcA,EAAO,CAAC,EAAG,EAAG,EAAG,EAAG,KAE9C,IAAIgJ,EAAU,kBAAoBhJ,EAAOT,KAAKmC,OAAO2B,OAAQL,EAAazD,KAAKyI,QAASzI,KAAK0I,SAW7F,MAVwB,iBAApB1I,KAAKiE,aACLwF,EAAU,YAAcA,EAAS,CAAC,EAAG,EAAG,EAAG,EAAG,KAEhC,OAAdzJ,KAAKoC,OACLqH,EACI,KAAUA,EAASzJ,KAAKoC,KAAK0B,OAAQ9D,KAAKiE,aAE1B,OAApBjE,KAAKiC,aACLwH,EAAUzJ,KAAKiC,WAAW8B,MAAM0F,IAE7BA,CAAO,GAEtB,CACA,kBAAAjG,CAAmB9C,GAEf,MAAM+C,GADN/C,GAAa,QAAmBA,IACDgD,QAC/B,IAAI6F,EACAyB,EACAP,EACAC,EACoB,kBAApB1K,KAAKiE,YACLsF,EAAc,EACdyB,EAAY,EACZP,EAAa,EACbC,EAAY,IAGZnB,EAAc,EACdyB,EAAY,EACZP,EAAa,EACbC,EAAY,GAEhB,MAAMI,EAAU9K,KAAKoJ,WAAW,GAC1BiB,EAAUrK,KAAKoJ,WAAW,GAC1BkB,EAAUtK,KAAKoJ,WAAW,GAC1B2B,EAAU/K,KAAKyI,QAAQ,GACvB8B,EAAUvK,KAAKyI,QAAQ,GACvB+B,EAAUxK,KAAKyI,QAAQ,GAQ7B,OAPAhF,EAAY8F,GAAevJ,KAAKsJ,QAChC7F,EAAYuH,IACR,QAAavH,EAAYuH,GAAYD,EAASD,EAAS9K,KAAK0I,SAChEjF,EAAYgH,IACR,QAAahH,EAAYgH,GAAaF,EAASF,EAASrK,KAAK0I,SACjEjF,EAAYiH,IACR,QAAajH,EAAYiH,GAAYF,EAASF,EAAStK,KAAK0I,SACzDjF,CACX,CACA,SAAApC,GACI,MAAMC,EAASvB,MAAMsB,YAErB,cADOC,EAAqB,aACrBA,CACX,EAGJqJ,EAAgBhJ,UAAY,kBAC5B,EAAAC,cAAA,cAA4B+I,GACrB,MAAMM,UAAsB5B,EAC/B,WAAAxJ,CAAYsE,EAAM7C,GAMd,GALAvB,MAAMoE,EAAM7C,GACZtB,KAAKkL,8BAAgC,gBACrClL,KAAKmL,8BAAgC,gBACrCnL,KAAKoL,gBAAkB,KACvBpL,KAAKqL,gBAAkB,KACD,MAAlB/J,EAAOgI,QACP,MAAM,IAAI,KAAW,uFAGzB,GAAgC,MAA5BhI,EAAOqB,mBAAyD,MAA5BrB,EAAOyB,mBAChB,MAA3BzB,EAAOuB,iBACP,MAAM,IAAI,KAAW,sPAKzB,GAAsB,MAAlBvB,EAAOoH,SAAsC,SAAnBpH,EAAOoH,SACd,UAAnBpH,EAAOoH,QACP,MAAM,IAAI,KAAW,gBAAgB1I,KAAKmE,uEACF0B,KAAKC,UAAUxE,EAAOoH,YAElE1I,KAAKsL,gBACyB,MAA1BhK,EAAOgK,gBAA0B,EAAIhK,EAAOgK,gBAChDtL,KAAKuL,sBAAuB,QAAejK,EAAOiK,sBAAwBvL,KAAKkL,+BAC/ElL,KAAKwL,sBAAuB,QAAelK,EAAOkK,sBAClDxL,KAAKyL,qBAAsB,QAAcnK,EAAOmK,qBAChDzL,KAAK0L,sBAAuB,QAAepK,EAAOiK,sBAAwBvL,KAAKmL,+BAC/EnL,KAAK2L,sBAAuB,QAAerK,EAAOqK,sBAClD3L,KAAK4L,qBAAsB,QAActK,EAAOsK,oBACpD,CACA,KAAAzI,CAAMzC,GAEF,IADAA,GAAa,QAAmBA,IACjBG,OAASb,KAAKmE,KAAO,EAChC,MAAM,IAAI,KAAW,0BAA0BnE,KAAKmE,0BAC7CnE,KAAKmE,KAAO,gCACZ0B,KAAKC,UAAUpF,MAE1B,MAAM6I,EAAkC,kBAApBvJ,KAAKiE,WAAiC,EAAIvD,EAAWG,OAAS,EAClF,GAA+B,MAA3BH,EAAW6I,IAAwB7I,EAAW6I,GAAe,EAC7D,MAAM,IAAI,KACN,oEAAa1D,KAAKC,UAAUpF,EAAW6I,OAE/C,MAAM/G,EAAW9B,EAAW6I,GACtBsC,EAAuB7L,KAAKoJ,WAAWjE,OAAO,CAAC3C,EAAUxC,KAAKsL,kBAC9DQ,EAAuB,GAC7B,IAAK,IAAIlL,EAAI,EAAGA,EAAIZ,KAAKmE,OAAQvD,EAC7BkL,EAAqBhL,KAAK,GAE9BgL,EAAqBhL,KAAK0B,EAAWxC,KAAKsL,gBAAiBtL,KAAKsJ,SAChE,MAAMyC,GAAY,EAClB/L,KAAKoL,gBAAkBpL,KAAKqD,UAAU,mBAAoBwI,EAAsB,UAAW7L,KAAKuL,qBAAsBvL,KAAKwL,qBAAsBO,EAAW/L,KAAKyL,qBACjKzL,KAAKqL,gBAAkBrL,KAAKqD,UAAU,mBAAoByI,EAAsB,UAAW9L,KAAK0L,qBAAsB1L,KAAK2L,qBAAsBI,EAAW/L,KAAK4L,qBAC7J5L,KAAKkC,QACLlC,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAACrD,KAAKsJ,SAAU,UAAWtJ,KAAK4C,gBAAiB5C,KAAKgD,gBAAiB+I,EAAW/L,KAAK8C,gBAG1H9C,KAAKoC,KAAO,KAEhBpC,KAAK8B,UACD,CAAC,IAAI,KAAU,CAAEC,KAAM/B,KAAKmE,KAAO,EAAGb,KAAM,CAAE,CAACiG,GAAc/G,MACjExC,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KAER,IAAI2C,EACJ,GAFA7C,GAAS,QAAoBA,GAEX,IAAdhB,KAAKmE,KACL,MAAM,IAAI,KAAoB,oDAiBlC,OAfuB,IAAdnE,KAAKmE,OACc,kBAApBnE,KAAKiE,aACLjD,EAAS,YAAcA,EAAQ,CAAC,EAAG,EAAG,EAAG,KAE7C6C,EAAS,kBAAoB7C,EAAQhB,KAAKoL,gBAAgBtH,OAAQ9D,KAAKqL,gBAAgBvH,OAAQ9D,KAAKyI,QAASzI,KAAK0I,QAAS1I,KAAK2I,aAAc,SAE9I3I,KAAKkC,UACL2B,EAAS,KAAUA,EAAQ7D,KAAKoC,KAAK0B,OAAQ9D,KAAKiE,aAE/B,MAAnBjE,KAAKiC,aACL4B,EAAS7D,KAAKiC,WAAW8B,MAAMF,IAEX,kBAApB7D,KAAKiE,aACLJ,EAAS,YAAcA,EAAQ,CAAC,EAAG,EAAG,EAAG,KAEtCA,CAAM,GAErB,CACA,SAAAxC,GACI,MAAMC,EAASvB,MAAMsB,YAiBrB,cAhBOC,EAAa,YACbA,EAA0B,yBAC1BA,EAA0B,yBAC1BA,EAAyB,iBAChCA,EAA6B,sBACzB,QAAqBtB,KAAKuL,sBAC9BjK,EAA6B,sBACzB,QAAqBtB,KAAK0L,sBAC9BpK,EAA6B,sBACzB,QAAqBtB,KAAKwL,sBAC9BlK,EAA6B,sBACzB,QAAqBtB,KAAK2L,sBAC9BrK,EAA4B,qBACxB,QAAoBtB,KAAKyL,qBAC7BnK,EAA4B,qBACxB,QAAoBtB,KAAK4L,qBACtBtK,CACX,EAGJ2J,EAActJ,UAAY,gBACnB,MAAMqK,UAAwBf,EACjC,WAAApL,CAAYC,GACRC,MAAM,EAAGD,EACb,EAGJkM,EAAgBrK,UAAY,kBAC5B,EAAAC,cAAA,cAA4BoK,GACrB,MAAMC,UAAe5C,EACxB,WAAAxJ,CAAYC,GACRC,MAAM,EAAGD,GACTmM,EAAO9C,WAAWrJ,GAClBE,KAAK8B,UAAY,CAAC,CAAEC,KAAM,GAC9B,CACA,SAAAV,GACI,MAAMC,EAASvB,MAAMsB,YAGrB,cAFOC,EAAa,YACbA,EAAmB,WACnBA,CACX,CACA,iBAAO6H,CAAWrJ,GAEd,GAA+B,kBAApBA,EAAKsJ,aACX,KAAsCtJ,EAAKsJ,WAAY,SAAU,EAAG,GACrE,MAAM,IAAI,KACN,yFAA0BvD,KAAKC,UAAUhG,EAAKsJ,eAE1D,EAGJ6C,EAAOtK,UAAY,SACnB,EAAAC,cAAA,cAA4BqK,GACrB,MAAMC,UAAmB,KAC5B,WAAArM,CAAYC,GACRC,MAAMD,GACuB,kBAAlBA,EAAKqM,SACZnM,KAAKmM,SACD,CAAC,CAACrM,EAAKqM,SAAUrM,EAAKqM,UAAW,CAACrM,EAAKqM,SAAUrM,EAAKqM,WAEzB,kBAArBrM,EAAKqM,SAAS,GAC1BnM,KAAKmM,SAAW,CACZ,CAACrM,EAAKqM,SAAS,GAAIrM,EAAKqM,SAAS,IACjC,CAACrM,EAAKqM,SAAS,GAAIrM,EAAKqM,SAAS,KAIrCnM,KAAKmM,SAAWrM,EAAKqM,SAEzBnM,KAAKiE,gBACmBmI,IAApBtM,EAAKmE,WAA2B,eAAiBnE,EAAKmE,WAC1DjE,KAAK8B,UAAY,CAAC,CAAEC,KAAM,GAC9B,CACA,kBAAAyB,CAAmB9C,GACf,MAAwB,kBAApBV,KAAKiE,WACE,CACHvD,EAAW,GAAIA,EAAW,GAC1BA,EAAW,GAAKV,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GACvDzL,EAAW,GAAKV,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,IAIpD,CACHzL,EAAW,GACXA,EAAW,GAAKV,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GACvDzL,EAAW,GAAKV,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GAAIzL,EAAW,GAGlF,CACA,IAAAK,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KAER,GADAF,GAAS,QAAoBA,GACL,iBAApBhB,KAAKiE,WAA+B,CACpC,MAAMoI,EAAU,KAAiBrL,EAAQhB,KAAKmM,SAAS,GAAG,GAAInL,EAAOL,MAAM,GAAKX,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GAAI,GAC3H,OAAO,KAAiBE,EAASrM,KAAKmM,SAAS,GAAG,GAAInL,EAAOL,MAAM,GAAKX,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GAAI,EACvH,CACK,CACD,MAAME,EAAU,KAAiBrL,EAAQhB,KAAKmM,SAAS,GAAG,GAAInL,EAAOL,MAAM,GAAKX,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GAAI,GAC3H,OAAO,KAAiBE,EAASrM,KAAKmM,SAAS,GAAG,GAAInL,EAAOL,MAAM,GAAKX,KAAKmM,SAAS,GAAG,GAAKnM,KAAKmM,SAAS,GAAG,GAAI,EACvH,IAER,CACA,SAAA9K,GACI,MAAMC,EAAS,CAAE6K,SAAUnM,KAAKmM,SAAUlI,WAAYjE,KAAKiE,YACrD1C,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJ4K,EAAWvK,UAAY,aACvB,EAAAC,cAAA,cAA4BsK,GACrB,MAAMI,UAAqB,KAC9B,WAAAzM,CAAYC,GACRC,MAAMD,GACNE,KAAKuM,aAAe,CAAC,EAAG,GACxBvM,KAAK8B,UAAY,CAAC,CAAEC,KAAM,IAC1B/B,KAAKwM,KAAoB,MAAb1M,EAAK0M,KAAexM,KAAKuM,aAAezM,EAAK0M,KACzDxM,KAAKiE,WACkB,MAAnBnE,EAAKmE,WAAqB,eAAiBnE,EAAKmE,YACpD,QAAgBjE,KAAKiE,YACrBjE,KAAKyM,cACqB,MAAtB3M,EAAK2M,cAAwB,UAAY3M,EAAK2M,eAClD,QAAyBzM,KAAKyM,cAClC,CACA,kBAAAjJ,CAAmB9C,GACf,GAAwB,kBAApBV,KAAKiE,WAAgC,CACrC,MAAMkG,EAA0B,MAAjBzJ,EAAW,GAAa,KAAOV,KAAKwM,KAAK,GAAK9L,EAAW,GAClE0J,EAAyB,MAAjB1J,EAAW,GAAa,KAAOV,KAAKwM,KAAK,GAAK9L,EAAW,GACvE,MAAO,CAACA,EAAW,GAAIA,EAAW,GAAIyJ,EAAQC,EAClD,CACK,CACD,MAAMD,EAA0B,MAAjBzJ,EAAW,GAAa,KAAOV,KAAKwM,KAAK,GAAK9L,EAAW,GAClE0J,EAAyB,MAAjB1J,EAAW,GAAa,KAAOV,KAAKwM,KAAK,GAAK9L,EAAW,GACvE,MAAO,CAACA,EAAW,GAAIyJ,EAAQC,EAAO1J,EAAW,GACrD,CACJ,CACA,IAAAK,CAAKC,EAAQC,GACT,OAAO,QAAS,KACZ,IAAIR,GAAQ,QAAoBO,GAChC,MAAMN,EAAaD,EAAME,MACzB,GAAwB,kBAApBX,KAAKiE,WAAgC,CACrCxD,EAAQ,YAAcA,EAAO,CAAC,EAAG,EAAG,EAAG,IACvC,MAAM0J,EAASnK,KAAKwM,KAAK,GAAK9L,EAAW,GACnC0J,EAAQpK,KAAKwM,KAAK,GAAK9L,EAAW,GAClCgM,EAAiC,YAAvB1M,KAAKyM,cACjBhM,EAAMkM,sBAAsB,CAACxC,EAAQC,IACrC3J,EAAMmM,eAAe,CAACzC,EAAQC,IAClC,OAAO,YAAcsC,EAAS,CAAC,EAAG,EAAG,EAAG,GAC5C,CACK,CACD,MAAMvC,EAASnK,KAAKwM,KAAK,GAAK9L,EAAW,GACnC0J,EAAQpK,KAAKwM,KAAK,GAAK9L,EAAW,GACxC,MAA8B,YAAvBV,KAAKyM,cACRhM,EAAMkM,sBAAsB,CAACxC,EAAQC,IACrC3J,EAAMmM,eAAe,CAACzC,EAAQC,GACtC,IAER,CACA,SAAA/I,GACI,MAAMC,EAAS,CAAEkL,KAAMxM,KAAKwM,KAAMvI,WAAYjE,KAAKiE,YAC7C1C,EAAaxB,MAAMsB,YAEzB,OADAG,OAAOC,OAAOH,EAAQC,GACfD,CACX,EAGJgL,EAAa3K,UAAY,eACzB,EAAAC,cAAA,cAA4B0K,E,gFCl8BrB,MAAMO,EAAwB,CAAC,QAAS,SAAU,UAC5CC,EAA4B,CAAC,SAAU,UAAW,kB,kJCgDxD,MAAMC,UAAwB,KACjC,WAAAlN,CAAYC,GACRC,MAAM,EAAGD,GACTE,KAAKoL,gBAAkB,KACvBpL,KAAKsL,gBACuB,MAAxBxL,EAAKwL,gBAA0B,EAAIxL,EAAKwL,gBAC5CtL,KAAKuL,sBAAuB,QAAezL,EAAKyL,sBAAwBvL,KAAKqC,4BAC7ErC,KAAKyL,qBAAsB,QAAc3L,EAAK2L,qBAC9CzL,KAAKwL,sBAAuB,QAAe1L,EAAK0L,qBACpD,CACA,KAAArI,CAAMzC,GAEF,IADAA,GAAa,QAAmBA,IACjBG,OAAS,EACpB,MAAM,IAAI,KACN,uEAAyBgF,KAAKC,UAAUpF,OAEhD,MAAM6I,EAAkC,kBAApBvJ,KAAKiE,WAAiC,EAAI,EAC9D,GAA+B,MAA3BvD,EAAW6I,IAAwB7I,EAAW6I,GAAe,EAC7D,MAAM,IAAI,KACN,yFAA2B7I,EAAW6I,QAE9C,MAAM/G,EAAW9B,EAAW6I,GACtBsC,EAAuB,CACzB7L,KAAKoJ,WAAW,GAAIpJ,KAAKoJ,WAAW,GAAI5G,EAAUxC,KAAKsL,iBAE3DtL,KAAKoL,gBAAkBpL,KAAKqD,UAAU,mBAAoBwI,EAAsB,KAAM7L,KAAKuL,qBAAsBvL,KAAKwL,sBAAsB,EAAMxL,KAAKyL,qBACnJzL,KAAKkC,QACLlC,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAACb,EAAWxC,KAAKsL,iBAAkB,KAAMtL,KAAK4C,gBAAiB5C,KAAKgD,iBAAiB,EAAMhD,KAAK8C,gBAGnI9C,KAAKoC,KAAO,KAEhBpC,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GACT,OAAO,IAAAC,OAAK,KAER,IAAIuI,EA3DT,SAAyBvC,EAAGkE,EAAiB3C,EAAU,CAAC,EAAG,GAAIC,EAAU,QAASzE,EAAY0E,GACjG,OAAO,IAAAzH,OAAK,KACU,MAAd+C,IACAA,GAAa,YAEjB,QAAgBA,GAChB,IAAI2E,GAAI,QAAsB1B,EAAGjD,GACjC,GAAe,IAAXiD,EAAE/C,KACF,MAAM,IAAI,KACN,mEAAG+C,EAAE/C,UAEb,GAA6B,IAAzBiH,EAAgBjH,KAChB,MAAM,IAAI,KACN,yDAAGiH,EAAgBjH,UAM3B,OAJAyE,EAAI,kBAAoBA,EAAGwC,EAAiB3C,EAAqB,SAAZC,EAAqB,OAAS,QAAS,OAAQC,GACjF,kBAAf1E,IACA2E,EAAI,YAAcA,EAAG,CAAC,EAAG,EAAG,EAAG,KAE5BA,CAAC,GAEhB,CAsC0BoE,CADdhM,GAAS,QAAoBA,GACShB,KAAKoL,gBAAgBtH,OAAQ9D,KAAKyI,QAASzI,KAAK0I,QAAS1I,KAAKiE,WAAY,MAQhH,OANIjE,KAAKkC,UACLuH,EAAU,KAAUA,EAASzJ,KAAKoC,KAAK0B,OAAQ9D,KAAKiE,aAEjC,MAAnBjE,KAAKiC,aACLwH,EAAUzJ,KAAKiC,WAAW8B,MAAM0F,IAE7BA,CAAO,GAEtB,CACA,kBAAAjG,CAAmB9C,GACfA,GAAa,QAAmBA,GAChC,MAAMuM,EAA2B,kBAApBjN,KAAKiE,WAAiCvD,EAAW,GAAKA,EAAW,GACxEwM,EAA2B,kBAApBlN,KAAKiE,WAAiCvD,EAAW,GAAKA,EAAW,GACxEyM,EAAiC,kBAApBnN,KAAKiE,WACpBvD,EAAW,GAAKV,KAAKsL,gBACrB5K,EAAW,GAAKV,KAAKsL,gBACnB8B,GAAU,QAAiBH,EAAMjN,KAAKoJ,WAAW,GAAIpJ,KAAK0I,QAAS1I,KAAKyI,QAAQ,IAChF4E,GAAU,QAAiBH,EAAMlN,KAAKoJ,WAAW,GAAIpJ,KAAK0I,QAAS1I,KAAKyI,QAAQ,IACtF,MAAwB,kBAApBzI,KAAKiE,WACE,CAACvD,EAAW,GAAIyM,EAAYC,EAASC,GAIrC,CAAC3M,EAAW,GAAI0M,EAASC,EAASF,EAEjD,CACA,SAAA9L,GACI,MAAMC,EAASvB,MAAMsB,YAQrB,OAPAC,EAAwB,gBAAItB,KAAKsL,gBACjChK,EAA6B,sBACzB,QAAqBtB,KAAKuL,sBAC9BjK,EAA6B,sBACzB,QAAqBtB,KAAKwL,sBAC9BlK,EAA4B,qBACxB,QAAoBtB,KAAKwL,sBACtBlK,CACX,EAGJyL,EAAgBpL,UAAY,kBAC5B,EAAAC,cAAA,cAA4BmL,E,yIChIxBO,EAAkC,SAAUC,EAAGC,GAC/C,IAAIC,EAAI,CAAC,EACT,IAAK,IAAIC,KAAKH,EAAO/L,OAAOmM,UAAUC,eAAe7M,KAAKwM,EAAGG,IAAMF,EAAEK,QAAQH,GAAK,IAC9ED,EAAEC,GAAKH,EAAEG,IACb,GAAS,MAALH,GAAqD,oBAAjC/L,OAAOsM,sBACtB,KAAIlN,EAAI,EAAb,IAAgB8M,EAAIlM,OAAOsM,sBAAsBP,GAAI3M,EAAI8M,EAAE7M,OAAQD,IAC3D4M,EAAEK,QAAQH,EAAE9M,IAAM,GAAKY,OAAOmM,UAAUI,qBAAqBhN,KAAKwM,EAAGG,EAAE9M,MACvE6M,EAAEC,EAAE9M,IAAM2M,EAAEG,EAAE9M,IAF4B,CAItD,OAAO6M,CACX,EAiBA,MAAMO,UAAkB,KACpB,WAAAnO,CAAYC,GACR,GAAIA,EAAKmO,OACL,MAAM,IAAI,KAAoB,sDAElC,GAAIzI,MAAMC,QAAQ3F,EAAKoO,MACnB,MAAM,IAAI,KAAoB,kEAElCnO,MAAMD,GACNE,KAAK8B,UAAY,CAAC,IAAI,KAAU,CAAEC,KAAM,IAC5C,CACA,IAAAhB,CAAKC,EAAQC,GACT,OAAO,QAAS,KASZ,GAR6B,MAAzBjB,KAAKkO,KAAKC,cACV,UAAYnO,KAAKkO,KAAKC,aACtBnO,KAAKkO,KAAKC,YAAc,MAEU,MAAlCnO,KAAKkO,KAAKE,uBACV,UAAYpO,KAAKkO,KAAKE,sBACtBpO,KAAKkO,KAAKE,qBAAuB,MAEjCnN,GAAUA,EAAkB,UAC5B,MAAM,IAAI,KAAW,6CAEzB,MAAMmF,EAAiB,MAAVnF,EAAiB,KAAOA,EAAa,KAC5CG,EAAqB,MAAVH,EAAiB,KAAOA,EAAiB,SACpDoN,EAAyB,MAAVpN,EAAiB,KAAOA,EAAqB,aAClE,OAAOlB,MAAMgB,KAAKC,EAAQ,CAAEoF,OAAMhF,WAAUiN,gBAAe,GAEnE,CACA,kBAAA7K,CAAmB9C,GACf,IAAI4N,EAAWtO,KAAKuO,yBAAyB7N,GAQ7C,OAPKV,KAAKwO,kBACNF,EAAW,CAACA,EAAS,MAAOA,EAAS5K,MAAM,KAE3C1D,KAAKyO,cACLH,EACI,CAACA,KAAa9I,MAAM,GAAGkJ,KAAK,CAAChO,EAAW,MAAO4N,EAAS5K,OAAO,OAEhE4K,CACX,CACA,eAAAK,CAAgB3N,GACZ,OAAO,QAAS,KACZ,MAAM,UAAE4N,GAAc5O,KAAKkO,KACrBxN,EAAaM,EAAOL,MACpB8C,EAAczD,KAAKuO,yBAAyB7N,GAC5CmO,EAAa,CAACpL,EAAY,MAAOA,EAAYC,MAAM,IACnD2K,EAAe,QAAUQ,GAC/B,OAAIrJ,MAAMC,QAAQmJ,GACPpJ,MAAMoJ,EAAU/N,QAAQ6N,KAAKL,GAEjC,CAACA,EAAa,GAE7B,CACA,WAAAS,CAAYC,EAAQ3N,GAAW,GAC3B,QAAS,KACL,IAAKpB,KAAKgP,SACN,MAAM,IAAI,KAAe,mEAE7B,MAAMtO,EAAaV,KAAK8B,UAAU,GAAGnB,MAC/B8C,EAAczD,KAAKuO,yBAAyB7N,GAC5CmO,EAAa,CAACpL,EAAY,MAAOA,EAAYC,MAAM,IAEzD,GAAiB,MADChD,EAAW,GAEzB,MAAM,IAAI,KAAW,yUAQzB,GAAwB,MAApBV,KAAKiP,YACDzJ,MAAMC,QAAQzF,KAAKkO,KAAKU,WACxB5O,KAAKkP,QAAUlP,KAAKkO,KAAKU,UAAUO,KAAI,IAAM,QAAUN,KAGvD7O,KAAKkP,QAAU,CAAC,QAAUL,SAG7B,GAAc,MAAVE,EAEL,UAAY/O,KAAKkP,SAEM,MAAnBlP,KAAKoP,aACL,UAAYpP,KAAKoP,YACjBpP,KAAKoP,WAAa,IAElB5J,MAAMC,QAAQzF,KAAKkO,KAAKU,WACxB5O,KAAKkP,QAAUlP,KAAKkO,KAAKU,UAAUO,KAAI,IAAM,QAAUN,KAGvD7O,KAAKkP,QAAQ,GAAK,QAAUL,OAG/B,CAID,GAHKrJ,MAAMC,QAAQsJ,KACfA,EAAS,CAACA,IAEVA,EAAOlO,SAAWb,KAAKkP,QAAQrO,OAC/B,MAAM,IAAI,KAAW,SAASb,KAAKqP,gBAAgBrP,KAAKkP,QAAQrO,oCACzCkO,EAAOlO,0CACbkO,KAEjB3N,EAKApB,KAAKoP,WAAWtO,KAAKd,KAAKkP,QAAQxL,SAGlC,UAAY1D,KAAKkP,SAErB,IAAK,IAAII,EAAQ,EAAGA,EAAQtP,KAAKkP,QAAQrO,SAAUyO,EAAO,CACtD,MAAMC,EAAQR,EAAOO,GACfE,EAAgBX,EACtB,IAAK,EAAAlJ,KAAA,YAAiB4J,EAAM5O,MAAO6O,GAC/B,MAAM,IAAI,KAAW,SAASF,gCAAoCtP,KAAKqP,wBACjDG,qBAAiCD,EAAM5O,SAEjEX,KAAKkP,QAAQI,GAASC,CAC1B,CACJ,CACAvP,KAAKkP,QAAUlP,KAAKkP,QAAQC,KAAIM,GAAS,OAASA,EAAMC,UAAS,GAEzE,CACA,wBAAAnB,CAAyB7N,GACrB,MAAM,WAAEuD,EAAU,QAAEqF,EAAO,WAAEF,EAAU,QAAEV,EAAO,QAAED,EAAO,aAAEE,GAAiB3I,KAAKkO,KAC3EyB,EAAiC,kBAAf1L,EAClB2L,EAAIlP,EAAWiP,EAAkB,EAAI,GACrCE,EAAInP,EAAWiP,EAAkB,EAAI,GACrCG,GAAO,QAAiBF,EAAGxG,EAAW,GAAIV,EAASD,EAAQ,GAAIE,EAAa,IAC5EoH,GAAO,QAAiBF,EAAGzG,EAAW,GAAIV,EAASD,EAAQ,GAAIE,EAAa,IAKlF,MAJiB,IACVjI,EAAWgD,MAAM,EAAG,MACnBiM,EAAkB,CAACrG,EAASwG,EAAMC,GAAQ,CAACD,EAAMC,EAAMzG,GAGnE,EAGJ0E,EAAUrM,UAAY,YACf,MAAMqO,UAAuB,KAChC,WAAAnQ,CAAYC,GACR,MAAM,QAAEwJ,EAAO,WAAEF,EAAU,QAAEX,EAAO,QAAEC,EAAO,WAAEzE,EAAU,aAAE0E,GAAkB7I,EAC7EC,MAAMyB,OAAOC,OAAO,CAAC,EAAG3B,EAAM,CAAE4C,MAAO4G,KACvCtJ,KAAKsJ,QAAUA,GACf,QAAsBtJ,KAAKsJ,QAAS,WACpCtJ,KAAKoJ,YAAa,OAAeA,EAAY,EAAG,cAChDpJ,KAAKoJ,WAAWpD,SAAQwG,IAAQ,QAAsBA,EAAM,gBAC5DxM,KAAKyI,SAAU,OAAeA,GAAW,EAAG,EAAG,WAC/CzI,KAAKyI,QAAQzC,SAAQiK,IAAU,QAAsBA,EAAQ,aAC7DjQ,KAAK0I,QAAUA,GAAW,SAC1B,QAAiB1I,KAAK0I,SACtB1I,KAAKiE,WAAaA,GAAc,gBAChC,QAAgBjE,KAAKiE,YACrBjE,KAAK2I,cAAe,OAAeA,GAAgB,EAAG,EAAG,gBACzD3I,KAAK2I,aAAa3C,SAAQ/F,IAAQ,QAAsBA,EAAM,iBAClE,CACA,KAAAkD,CAAMzC,GACF,IAAIwP,EACJxP,GAAa,QAAmBA,GAChC,MAAM6I,EAAkC,kBAApBvJ,KAAKiE,WAAiC,EAAIvD,EAAWG,OAAS,EAClF,GAA+B,MAA3BH,EAAW6I,GACX,MAAM,IAAI,KACN,+DAAS7I,EAAW6I,MAE5B,MAAM/G,EAAW9B,EAAW6I,GAEtBC,EAAcxJ,KAAKoJ,WAAWjE,OAAO,CAAC3C,EADvB,EACiCxC,KAAKsJ,UAC3DtJ,KAAKmC,OAASnC,KAAKqD,UAAU,SAAUmG,EAAa,KAAMxJ,KAAK2C,kBAAmB3C,KAAK+C,mBAAmB,EAAM/C,KAAK6C,kBACrH,MAAMsN,EAAuBnQ,KAAKoJ,WAAWjE,OAAO,CAACnF,KAAKsJ,QAHrC,EAG8CtJ,KAAKsJ,UAExE,GADAtJ,KAAKoQ,gBAAkBpQ,KAAKqD,UAAU,mBAAoB8M,EAAsB,KAAMnQ,KAAKqQ,qBAAsBrQ,KAAKsQ,sBAAsB,EAAMtQ,KAAKuQ,qBACnJvQ,KAAKkC,QAAS,CACd,IAAIU,EACJ,GAAI5C,KAAKwQ,eAAgB,CACrB,MAAMC,EAAOzQ,KAAK4C,gBACZ0G,EAAUtJ,KAAKsJ,QACrB1G,EAAkB,KAAKsN,EAAK,cAAyB,KAC7C,KAAAnM,CAAMpD,EAAO+F,GACT,MAAMgK,EAAQD,EAAK1M,MAAM,CAACuF,IACpBqH,EAAQ,OAAS,CAACrH,IAClBsH,EAAYH,EAAK1M,MAAM,CAAW,EAAVuF,IAC9B,OAAO,KAAc,CAACoH,EAAOC,EAAOC,GACxC,IAGDjP,UAAY,aACfuO,EACR,MAEItN,EAAkB5C,KAAK4C,gBAE3B5C,KAAKoC,KAAOpC,KAAKqD,UAAU,OAAQ,CAzBlB,EAyBmBrD,KAAKsJ,SAAyB,KAAM1G,EAAiB5C,KAAKgD,iBAAiB,EAAMhD,KAAK8C,eAC9H,CACA9C,KAAKuD,OAAQ,CACjB,CACA,IAAAxC,CAAKC,EAAQC,GACT,OAAO,QAAS,KACZ,GAAsB,IAAlBD,EAAOH,OACP,MAAM,IAAI,KACN,8DAAGG,EAAOH,WAElB,MAAMO,EAAWH,EAAiB,WAAK,EACjCiG,EAAIlG,EAAO,GACX6P,EAAW7P,EAAO,GAClB8P,EAAW9P,EAAO,GAEpB,EAAIhB,KAAK+Q,SAAW/Q,KAAK+Q,QAAU,GAAyB,MAApB/Q,KAAKmO,cAC7CnO,KAAKmO,aAAc,QAAoB,CACnC6C,KAAM,IAAM,WAAa9J,GACzBjH,KAAMD,KAAK+Q,QACX3P,WACA6P,MANa,KASrB,MAAM9C,EAAcnO,KAAKmO,YACnB+C,EAAe,CAAChK,EAAGd,EAAMkJ,IACtBlJ,GAASA,EAAKkJ,GAGZ,MAAQlJ,EAAKkJ,GAAQpI,GAFjBA,EAIf,IAAIiK,EAAKD,EAAahK,EAAGiH,EAAa,GAClCiD,EAAKF,EAAahK,EAAGiH,EAAa,GAClCkD,EAAKH,EAAahK,EAAGiH,EAAa,GAClCmD,EAAKJ,EAAahK,EAAGiH,EAAa,GAClC,EAAInO,KAAKuR,kBAAoBvR,KAAKuR,iBAAmB,GACxB,MAA7BvR,KAAKoO,uBACLpO,KAAKoO,sBAAuB,QAAoB,CAC5C4C,KAAM,IAAM,WAAaH,GACzB5Q,KAAMD,KAAKuR,iBACXnQ,WACA6P,MA1Ba,KA6BrB,MAAMO,EAAiBxR,KAAKoO,qBAC5B,IAAIqD,EAAKP,EAAaL,EAAUW,EAAgB,GAC5CE,EAAKR,EAAaL,EAAUW,EAAgB,GAC5CG,EAAKT,EAAaL,EAAUW,EAAgB,GAC5CI,EAAKV,EAAaL,EAAUW,EAAgB,GAChD,MACOK,EAASC,EAASC,EAASC,GAAW,QAAUhS,KAAKmC,OAAO2B,OAnC9C,EAkCK,IAEnB4M,EAAOC,EAAOsB,EAAOC,GAASlS,KAAKkC,QACtC,QAAUlC,KAAKoC,KAAK0B,OArCH,GAsCjB,CAAC,KAAM,KAAM,KAAM,MACvBqN,EAAKnR,KAAKmS,UAAUhB,EAAIU,EAASnB,EAAO1Q,KAAK0I,SAC7C0I,EAAKpR,KAAKmS,UAAUf,EAAIU,EAASnB,EAAO3Q,KAAK0I,SAC7C2I,EAAKrR,KAAKmS,UAAUd,EAAIU,EAASE,EAAOjS,KAAK0I,SAC7C4I,EAAKtR,KAAKmS,UAAUb,EAAIU,EAASE,EAAOlS,KAAK0I,SAC7C,MAAO0J,EAAYC,EAAYC,EAAYC,GAAc,QAAUvS,KAAKoQ,gBAAgBtM,OA3CnE,EAkCK,GAU1B2N,EAAKzR,KAAKwS,cAAcf,EAAIW,GAC5BV,EAAK1R,KAAKwS,cAAcd,EAAIW,GAC5BV,EAAK3R,KAAKwS,cAAcb,EAAIW,GAC5BV,EAAK5R,KAAKwS,cAAcZ,EAAIW,GAC5B,MAAM3R,EAAIZ,KAAKyS,oBAAoB1O,MAAM,MAAQoN,EAAIM,IAC/CiB,EAAI1S,KAAKyS,oBAAoB1O,MAAM,MAAQqN,EAAIM,IAC/CiB,EAAI,MAAQ,MAAQD,EAAG5B,GAAW,MAAQlQ,EAAGZ,KAAKiC,WAAW8B,MAAM,MAAQsN,EAAIM,MAC/E/B,EAAI,MAAQ5P,KAAKyS,oBAAoB1O,MAAM,MAAQuN,EAAIM,IAAM5R,KAAKiC,WAAW8B,MAAM4O,IACzF,MAAO,CAAC/C,EAAGA,EAAG+C,EAAE,GAExB,CACA,SAAAtR,GACI,MAAM6O,EAAKnQ,MAAMsB,aAAe,MAASuR,GAAM1C,EAAI3O,EAAa+L,EAAO4C,EAAI,CAAC,UACtE5O,EAAS,CACXgI,QAAStJ,KAAKsJ,QACdF,WAAYpJ,KAAKoJ,WACjBV,QAAS1I,KAAK0I,QACdzE,WAAYjE,KAAKiE,WACjB0E,aAAc3I,KAAK2I,aACnBF,QAASzI,KAAKyI,SAElB,OAAOjH,OAAOC,OAAO,CAAC,EAAGF,EAAYD,EACzC,CACA,SAAA6Q,CAAUjL,EAAG2I,EAAGgD,EAAGnK,GACf,MAAMoK,EAAM,SAAW5L,EAAG2I,EAAG7P,KAAKyI,QAAUC,GAAW,QAA8B,kBAApB1I,KAAKiE,WAAiC,OAAS,OAAQjE,KAAK2I,cAC7H,OAAIkK,EACO,KAAUC,EAAKD,EAAG7S,KAAKiE,YAE3B6O,CACX,CACA,aAAAN,CAActL,EAAG2I,GAEb,OAAO,SAAW3I,EAAG2I,EADL,EACiB,OAA4B,kBAApB7P,KAAKiE,WAAiC,OAAS,OAC5F,EAGJ+L,EAAerO,UAAY,iBAC3B,8BAAgCqO,GACzB,MAAM+C,UAAmB/E,EAC5B,WAAAnO,CAAYC,GACR,MAAMoO,EAAO,IAAI8B,EAAelQ,GAChCC,MAAMyB,OAAOC,OAAO,CAAC,EAAG3B,EAAM,CAAEoO,SACpC,CAEA,iBAAO8E,CAAWC,EAAK3R,GACnB,OAAO,IAAI2R,EAAI3R,EACnB,EAGJyR,EAAWpR,UAAY,aACvB,8BAAgCoR,E,yJCzUzB,MAAMG,EAA2B,CAAC,gBAAiB,gBAC7CC,EAAoC,CAAC,UAAW,YAChDC,EAA4B,CAAC,QAAS,OAAQ,UAC9CC,EAAyB,CAAC,MAAO,OACjCC,EAAkC,CAAC,MAAO,MAAO,SAAU,M","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/layers/core.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/layers/advanced_activations.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/keras_format/initializer_config.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_depthwise.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_recurrent.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/keras_format/common.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, notEqual, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Dropout extends Layer {\n    constructor(args) {\n        super(args);\n        this.rate = Math.max(Math.min(args.rate, 1), 0);\n        // So that the scalar doesn't get tidied up between executions.\n        this.noiseShape = args.noiseShape;\n        this.seed = args.seed;\n        this.supportsMasking = true;\n    }\n    getNoiseShape(input) {\n        if (this.noiseShape == null) {\n            return this.noiseShape;\n        }\n        const inputShape = input.shape;\n        const noiseShape = [];\n        for (let i = 0; i < this.noiseShape.length; ++i) {\n            noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n        }\n        return noiseShape;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            if (0 < this.rate && this.rate < 1) {\n                const training = kwargs['training'] == null ? false : kwargs['training'];\n                const noiseShape = this.getNoiseShape(input);\n                const output = K.inTrainPhase(() => K.dropout(input, this.rate, noiseShape, this.seed), () => input, training);\n                return output;\n            }\n            return inputs;\n        });\n    }\n    getConfig() {\n        const config = {\n            rate: this.rate,\n            noiseShape: this.noiseShape,\n            seed: this.seed,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    dispose() {\n        return super.dispose();\n    }\n}\n/** @nocollapse */\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport class SpatialDropout1D extends Dropout {\n    constructor(args) {\n        super(args);\n        this.inputSpec = [{ ndim: 3 }];\n    }\n    getNoiseShape(input) {\n        const inputShape = input.shape;\n        return [inputShape[0], 1, inputShape[2]];\n    }\n}\n/** @nocollapse */\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport class Dense extends Layer {\n    constructor(args) {\n        super(args);\n        // Default activation: Linear (none).\n        this.activation = null;\n        this.useBias = true;\n        this.kernel = null;\n        this.bias = null;\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        if (args.batchInputShape == null && args.inputShape == null &&\n            args.inputDim != null) {\n            // This logic is copied from Layer's constructor, since we can't\n            // do exactly what the Python constructor does for Dense().\n            let batchSize = null;\n            if (args.batchSize != null) {\n                batchSize = args.batchSize;\n            }\n            this.batchInputShape = [batchSize, args.inputDim];\n        }\n        this.units = args.units;\n        assertPositiveInteger(this.units, 'units');\n        this.activation = getActivation(args.activation);\n        if (args.useBias != null) {\n            this.useBias = args.useBias;\n        }\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.activityRegularizer = getRegularizer(args.activityRegularizer);\n        this.supportsMasking = true;\n        this.inputSpec = [{ minNDim: 2 }];\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const inputLastDim = inputShape[inputShape.length - 1];\n        if (this.kernel == null) {\n            this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n            if (this.useBias) {\n                this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n            }\n        }\n        this.inputSpec = [{ minNDim: 2, axes: { [-1]: inputLastDim } }];\n        this.built = true;\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        outputShape[outputShape.length - 1] = this.units;\n        return outputShape;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            // Dense layer accepts only a single input.\n            const input = getExactlyOneTensor(inputs);\n            const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());\n            let output;\n            if (fusedActivationName != null) {\n                output = K.dot(input, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);\n            }\n            else {\n                output = K.dot(input, this.kernel.read());\n                if (this.bias != null) {\n                    output = K.biasAdd(output, this.bias.read());\n                }\n                if (this.activation != null) {\n                    output = this.activation.apply(output);\n                }\n            }\n            return output;\n        });\n    }\n    getConfig() {\n        const config = {\n            units: this.units,\n            activation: serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint),\n            biasConstraint: serializeConstraint(this.biasConstraint)\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport class Flatten extends Layer {\n    constructor(args) {\n        args = args || {};\n        super(args);\n        this.inputSpec = [{ minNDim: 3 }];\n        this.dataFormat = args.dataFormat;\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        for (const dim of inputShape.slice(1)) {\n            if (dim == null) {\n                throw new ValueError(`The shape of the input to \"Flatten\" is not fully defined ` +\n                    `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n                    `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n                    `layer in your model.`);\n            }\n        }\n        return [inputShape[0], arrayProd(inputShape, 1)];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            let input = getExactlyOneTensor(inputs);\n            if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n                const permutation = [0];\n                for (let i = 2; i < input.rank; ++i) {\n                    permutation.push(i);\n                }\n                permutation.push(1);\n                input = input.transpose(permutation);\n            }\n            return K.batchFlatten(input);\n        });\n    }\n    getConfig() {\n        const config = {};\n        if (this.dataFormat != null) {\n            config['dataFormat'] = this.dataFormat;\n        }\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport class Activation extends Layer {\n    constructor(args) {\n        super(args);\n        this.supportsMasking = true;\n        this.activation = getActivation(args.activation);\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            return this.activation.apply(input);\n        });\n    }\n    getConfig() {\n        const config = { activation: serializeActivation(this.activation) };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport class RepeatVector extends Layer {\n    constructor(args) {\n        super(args);\n        this.n = args.n;\n        this.inputSpec = [{ ndim: 2 }];\n    }\n    computeOutputShape(inputShape) {\n        return [inputShape[0], this.n, inputShape[1]];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            return K.repeat(inputs, this.n);\n        });\n    }\n    getConfig() {\n        const config = {\n            n: this.n,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport class Reshape extends Layer {\n    constructor(args) {\n        super(args);\n        this.targetShape = args.targetShape;\n        // Make sure that all unknown dimensions are represented as `null`.\n        for (let i = 0; i < this.targetShape.length; ++i) {\n            if (this.isUnknown(this.targetShape[i])) {\n                this.targetShape[i] = null;\n            }\n        }\n    }\n    isUnknown(dim) {\n        return dim < 0 || dim == null;\n    }\n    /**\n     * Finds and replaces a missing dimension in output shape.\n     *\n     * This is a near direct port of the internal Numpy function\n     * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n     *\n     * @param inputShape: Original shape of array begin reshape.\n     * @param outputShape: Target shape of the array, with at most a single\n     * `null` or negative number, which indicates an underdetermined dimension\n     * that should be derived from `inputShape` and the known dimensions of\n     *   `outputShape`.\n     * @returns: The output shape with `null` replaced with its computed value.\n     * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n     */\n    fixUnknownDimension(inputShape, outputShape) {\n        const errorMsg = 'Total size of new array must be unchanged.';\n        const finalShape = outputShape.slice();\n        let known = 1;\n        let unknown = null;\n        for (let i = 0; i < finalShape.length; ++i) {\n            const dim = finalShape[i];\n            if (this.isUnknown(dim)) {\n                if (unknown === null) {\n                    unknown = i;\n                }\n                else {\n                    throw new ValueError('Can only specifiy one unknown dimension.');\n                }\n            }\n            else {\n                known *= dim;\n            }\n        }\n        const originalSize = arrayProd(inputShape);\n        if (unknown !== null) {\n            if (known === 0 || originalSize % known !== 0) {\n                throw new ValueError(errorMsg);\n            }\n            finalShape[unknown] = originalSize / known;\n        }\n        else if (originalSize !== known) {\n            throw new ValueError(errorMsg);\n        }\n        return finalShape;\n    }\n    computeOutputShape(inputShape) {\n        let anyUnknownDims = false;\n        for (let i = 0; i < inputShape.length; ++i) {\n            if (this.isUnknown(inputShape[i])) {\n                anyUnknownDims = true;\n                break;\n            }\n        }\n        if (anyUnknownDims) {\n            return inputShape.slice(0, 1).concat(this.targetShape);\n        }\n        else {\n            return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n        }\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            const inputShape = input.shape;\n            const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n            return input.reshape(outputShape);\n        });\n    }\n    getConfig() {\n        const config = {\n            targetShape: this.targetShape,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport class Permute extends Layer {\n    constructor(args) {\n        super(args);\n        if (args.dims == null) {\n            throw new Error('Required configuration field `dims` is missing during Permute ' +\n                'constructor call.');\n        }\n        if (!Array.isArray(args.dims)) {\n            throw new Error('Permute constructor requires `dims` to be an Array, but received ' +\n                `${args.dims} instead.`);\n        }\n        // Check the validity of the permutation indices.\n        const expectedSortedIndices = range(1, args.dims.length + 1);\n        if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n            throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n                ' `dims` must contain consecutive integers starting from 1.');\n        }\n        this.dims = args.dims;\n        this.dimsIncludingBatch = [0].concat(this.dims);\n        this.inputSpec = [new InputSpec({ ndim: this.dims.length + 1 })];\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        this.dims.forEach((dim, i) => {\n            outputShape[i + 1] = inputShape[dim];\n        });\n        return outputShape;\n    }\n    call(inputs, kwargs) {\n        return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n    }\n    getConfig() {\n        const config = {\n            dims: this.dims,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport class Masking extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.supportsMasking = true;\n        if (args != null) {\n            this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n        }\n        else {\n            this.maskValue = 0;\n        }\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = { maskValue: this.maskValue };\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    computeMask(inputs, mask) {\n        const input = getExactlyOneTensor(inputs);\n        const axis = -1;\n        return any(notEqual(input, this.maskValue), axis);\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            const axis = -1;\n            const keepDims = true;\n            const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n            const output = input.mul(booleanMask.asType(input.dtype));\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMasking.className = 'Masking';\nserialization.registerClass(Masking);\n//# sourceMappingURL=core.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n *  Advanced activation layers.\n */\nimport { clipByValue, elu, leakyRelu, prelu, relu, serialization } from '@tensorflow/tfjs-core';\nimport { Softmax as softmaxActivation } from '../activations';\nimport { cast } from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class ReLU extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.supportsMasking = true;\n        if (args != null) {\n            this.maxValue = args.maxValue;\n        }\n    }\n    call(inputs, kwargs) {\n        inputs = getExactlyOneTensor(inputs);\n        let output = relu(inputs);\n        if (this.maxValue != null) {\n            output = clipByValue(output, 0, this.maxValue);\n        }\n        return output;\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const config = { maxValue: this.maxValue };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nReLU.className = 'ReLU';\nserialization.registerClass(ReLU);\nexport class LeakyReLU extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.DEFAULT_ALPHA = 0.3;\n        if (args == null) {\n            args = {};\n        }\n        this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;\n    }\n    call(inputs, kwargs) {\n        const x = getExactlyOneTensor(inputs);\n        return leakyRelu(x, this.alpha);\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const config = { alpha: this.alpha };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nLeakyReLU.className = 'LeakyReLU';\nserialization.registerClass(LeakyReLU);\nexport class PReLU extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.DEFAULT_ALPHA_INITIALIZER = 'zeros';\n        if (args == null) {\n            args = {};\n        }\n        this.supportsMasking = true;\n        this.alphaInitializer =\n            getInitializer(args.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER);\n        this.alphaRegularizer = getRegularizer(args.alphaRegularizer);\n        this.alphaConstraint = getConstraint(args.alphaConstraint);\n        if (args.sharedAxes == null) {\n            this.sharedAxes = null;\n        }\n        else if (Array.isArray(args.sharedAxes)) {\n            this.sharedAxes = args.sharedAxes;\n        }\n        else if (typeof args.sharedAxes === 'number') {\n            this.sharedAxes = [args.sharedAxes];\n        }\n        else {\n            throw new ValueError(`Expected sharedAxes to be a number or an array of numbers, ` +\n                `but got ${args.sharedAxes}`);\n        }\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const paramShape = inputShape.slice(1);\n        if (this.sharedAxes != null) {\n            for (const i of this.sharedAxes) {\n                paramShape[i - 1] = 1;\n            }\n        }\n        this.alpha = this.addWeight('alpha', paramShape, 'float32', this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);\n        // Set input spec.\n        const axes = {};\n        if (this.sharedAxes != null) {\n            for (let i = 1; i < inputShape.length; ++i) {\n                axes[i] = inputShape[i];\n            }\n        }\n        this.inputSpec = [new InputSpec({\n                ndim: inputShape.length,\n                axes,\n            })];\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        inputs = getExactlyOneTensor(inputs);\n        return prelu(inputs, this.alpha.read());\n    }\n    getConfig() {\n        const config = {\n            alphaInitializer: serializeInitializer(this.alphaInitializer),\n            alphaRegularizer: serializeRegularizer(this.alphaRegularizer),\n            alphaConstraint: serializeConstraint(this.alphaConstraint),\n            sharedAxes: this.sharedAxes\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nPReLU.className = 'PReLU';\nserialization.registerClass(PReLU);\nexport class ELU extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.DEFAULT_ALPHA = 1.0;\n        if (args == null) {\n            args = {};\n        }\n        if (args.alpha != null && args.alpha !== this.DEFAULT_ALPHA) {\n            throw new NotImplementedError(`Non-default alpha value (${args.alpha}) is not supported by the ` +\n                `ELU layer yet.`);\n        }\n        this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;\n    }\n    call(inputs, kwargs) {\n        const x = getExactlyOneTensor(inputs);\n        return elu(x);\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const config = { alpha: this.alpha };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nELU.className = 'ELU';\nserialization.registerClass(ELU);\nexport class ThresholdedReLU extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.DEFAULT_THETA = 1.0;\n        if (args == null) {\n            args = {};\n        }\n        this.theta = args.theta == null ? this.DEFAULT_THETA : args.theta;\n    }\n    call(inputs, kwargs) {\n        const x = getExactlyOneTensor(inputs);\n        return x.mul(cast(x.greater(this.theta), 'float32'));\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const config = { theta: this.theta };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nThresholdedReLU.className = 'ThresholdedReLU';\nserialization.registerClass(ThresholdedReLU);\nexport class Softmax extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.DEFAULT_AXIS = 1.0;\n        if (args == null) {\n            args = {};\n        }\n        this.softmax = new softmaxActivation().apply;\n        this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n    }\n    call(inputs, kwargs) {\n        const x = getExactlyOneTensor(inputs);\n        return this.softmax(x, this.axis);\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const config = { axis: this.axis };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nSoftmax.className = 'Softmax';\nserialization.registerClass(Softmax);\n//# sourceMappingURL=advanced_activations.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Convolutional Layers\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport { imageDataFormat } from '../backend/common';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkInterpolationFormat, checkPaddingMode } from '../common';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { convOutputLength, deconvLength, normalizeArray } from '../utils/conv_utils';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\n/**\n * Transpose and cast the input before the conv2d.\n * @param x Input image tensor.\n * @param dataFormat\n */\nexport function preprocessConv2DInput(x, dataFormat) {\n    // TODO(cais): Cast type to float32 if not.\n    return tidy(() => {\n        checkDataFormat(dataFormat);\n        if (dataFormat === 'channelsFirst') {\n            return tfc.transpose(x, [0, 2, 3, 1]); // NCHW -> NHWC.\n        }\n        else {\n            return x;\n        }\n    });\n}\n/**\n * Transpose and cast the input before the conv3d.\n * @param x Input image tensor.\n * @param dataFormat\n */\nexport function preprocessConv3DInput(x, dataFormat) {\n    return tidy(() => {\n        checkDataFormat(dataFormat);\n        if (dataFormat === 'channelsFirst') {\n            return tfc.transpose(x, [0, 2, 3, 4, 1]); // NCDHW -> NDHWC.\n        }\n        else {\n            return x;\n        }\n    });\n}\n/**\n * 1D-convolution with bias added.\n *\n * Porting Note: This function does not exist in the Python Keras backend.\n *   It is exactly the same as `conv2d`, except the added `bias`.\n *\n * @param x Input tensor, rank-3, of shape `[batchSize, width, inChannels]`.\n * @param kernel Kernel, rank-3, of shape `[filterWidth, inDepth, outDepth]`.\n * @param bias Bias, rank-3, of shape `[outDepth]`.\n * @param strides\n * @param padding Padding mode.\n * @param dataFormat Data format.\n * @param dilationRate\n * @returns The result of the 1D convolution.\n * @throws ValueError, if `x`, `kernel` or `bias` is not of the correct rank.\n */\nexport function conv1dWithBias(x, kernel, bias, strides = 1, padding = 'valid', dataFormat, dilationRate = 1) {\n    return tidy(() => {\n        if (dataFormat == null) {\n            dataFormat = imageDataFormat();\n        }\n        checkDataFormat(dataFormat);\n        // Check the ranks of x, kernel and bias.\n        if (x.shape.length !== 3) {\n            throw new ValueError(`The input of a conv1dWithBias operation should be 3, but is ` +\n                `${x.shape.length} instead.`);\n        }\n        if (kernel.shape.length !== 3) {\n            throw new ValueError(`The kernel for a conv1dWithBias operation should be 3, but is ` +\n                `${kernel.shape.length} instead`);\n        }\n        if (bias != null && bias.shape.length !== 1) {\n            throw new ValueError(`The bias for a conv1dWithBias operation should be 1, but is ` +\n                `${kernel.shape.length} instead`);\n        }\n        // TODO(cais): Support CAUSAL padding mode.\n        if (dataFormat === 'channelsFirst') {\n            x = tfc.transpose(x, [0, 2, 1]); // NCW -> NWC.\n        }\n        if (padding === 'causal') {\n            throw new NotImplementedError('The support for CAUSAL padding mode in conv1dWithBias is not ' +\n                'implemented yet.');\n        }\n        let y = tfc.conv1d(x, kernel, strides, padding === 'same' ? 'same' : 'valid', 'NWC', dilationRate);\n        if (bias != null) {\n            y = K.biasAdd(y, bias);\n        }\n        return y;\n    });\n}\n/**\n * 1D-convolution.\n *\n * @param x Input tensor, rank-3, of shape `[batchSize, width, inChannels]`.\n * @param kernel Kernel, rank-3, of shape `[filterWidth, inDepth, outDepth]`.s\n * @param strides\n * @param padding Padding mode.\n * @param dataFormat Data format.\n * @param dilationRate\n * @returns The result of the 1D convolution.\n * @throws ValueError, if `x`, `kernel` or `bias` is not of the correct rank.\n */\nexport function conv1d(x, kernel, strides = 1, padding = 'valid', dataFormat, dilationRate = 1) {\n    return tidy(() => {\n        checkDataFormat(dataFormat);\n        return conv1dWithBias(x, kernel, null, strides, padding, dataFormat, dilationRate);\n    });\n}\n/**\n * 2D Convolution\n * @param x\n * @param kernel kernel of the convolution.\n * @param strides strides array.\n * @param padding padding mode. Default to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param dilationRate dilation rate array.\n * @returns Result of the 2D pooling.\n */\nexport function conv2d(x, kernel, strides = [1, 1], padding = 'valid', dataFormat, dilationRate) {\n    return tidy(() => {\n        checkDataFormat(dataFormat);\n        return conv2dWithBiasActivation(x, kernel, null, strides, padding, dataFormat, dilationRate);\n    });\n}\n/**\n * 2D Convolution with an added bias and optional activation.\n * Note: This function does not exist in the Python Keras Backend. This function\n * is exactly the same as `conv2d`, except the added `bias`.\n */\nexport function conv2dWithBiasActivation(x, kernel, bias, strides = [1, 1], padding = 'valid', dataFormat, dilationRate, activation = null) {\n    return tidy(() => {\n        if (dataFormat == null) {\n            dataFormat = imageDataFormat();\n        }\n        checkDataFormat(dataFormat);\n        if (x.rank !== 3 && x.rank !== 4) {\n            throw new ValueError(`conv2dWithBiasActivation expects input to be of rank 3 or 4, ` +\n                `but received ${x.rank}.`);\n        }\n        if (kernel.rank !== 3 && kernel.rank !== 4) {\n            throw new ValueError(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, ` +\n                `but received ${x.rank}.`);\n        }\n        let y = preprocessConv2DInput(x, dataFormat);\n        if (padding === 'causal') {\n            throw new NotImplementedError('The support for CAUSAL padding mode in conv1dWithBias is not ' +\n                'implemented yet.');\n        }\n        y = tfc.fused.conv2d({\n            x: y,\n            filter: kernel,\n            strides: strides,\n            pad: padding === 'same' ? 'same' : 'valid',\n            dilations: dilationRate,\n            dataFormat: 'NHWC',\n            bias,\n            activation\n        });\n        if (dataFormat === 'channelsFirst') {\n            y = tfc.transpose(y, [0, 3, 1, 2]);\n        }\n        return y;\n    });\n}\n/**\n * 3D Convolution.\n * @param x\n * @param kernel kernel of the convolution.\n * @param strides strides array.\n * @param padding padding mode. Default to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param dilationRate dilation rate array.\n * @returns Result of the 3D convolution.\n */\nexport function conv3d(x, kernel, strides = [1, 1, 1], padding = 'valid', dataFormat, dilationRate) {\n    return tidy(() => {\n        checkDataFormat(dataFormat);\n        return conv3dWithBias(x, kernel, null, strides, padding, dataFormat, dilationRate);\n    });\n}\n/**\n * 3D Convolution with an added bias.\n * Note: This function does not exist in the Python Keras Backend. This function\n * is exactly the same as `conv3d`, except the added `bias`.\n */\nexport function conv3dWithBias(x, kernel, bias, strides = [1, 1, 1], padding = 'valid', dataFormat, dilationRate) {\n    return tidy(() => {\n        if (dataFormat == null) {\n            dataFormat = imageDataFormat();\n        }\n        checkDataFormat(dataFormat);\n        if (x.rank !== 4 && x.rank !== 5) {\n            throw new ValueError(`conv3dWithBias expects input to be of rank 4 or 5, but received ` +\n                `${x.rank}.`);\n        }\n        if (kernel.rank !== 4 && kernel.rank !== 5) {\n            throw new ValueError(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ` +\n                `${x.rank}.`);\n        }\n        let y = preprocessConv3DInput(x, dataFormat);\n        if (padding === 'causal') {\n            throw new NotImplementedError('The support for CAUSAL padding mode in conv3dWithBias is not ' +\n                'implemented yet.');\n        }\n        y = tfc.conv3d(y, kernel, strides, padding === 'same' ? 'same' : 'valid', 'NDHWC', dilationRate);\n        if (bias != null) {\n            y = K.biasAdd(y, bias);\n        }\n        if (dataFormat === 'channelsFirst') {\n            y = tfc.transpose(y, [0, 4, 1, 2, 3]);\n        }\n        return y;\n    });\n}\n/**\n * Abstract convolution layer.\n */\nexport class BaseConv extends Layer {\n    constructor(rank, args) {\n        super(args);\n        this.bias = null;\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        BaseConv.verifyArgs(args);\n        this.rank = rank;\n        generic_utils.assertPositiveInteger(this.rank, 'rank');\n        if (this.rank !== 1 && this.rank !== 2 && this.rank !== 3) {\n            throw new NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is ` +\n                `not implemented yet.`);\n        }\n        this.kernelSize = normalizeArray(args.kernelSize, rank, 'kernelSize');\n        this.strides = normalizeArray(args.strides == null ? 1 : args.strides, rank, 'strides');\n        this.padding = args.padding == null ? 'valid' : args.padding;\n        checkPaddingMode(this.padding);\n        this.dataFormat =\n            args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n        checkDataFormat(this.dataFormat);\n        this.activation = getActivation(args.activation);\n        this.useBias = args.useBias == null ? true : args.useBias;\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.activityRegularizer = getRegularizer(args.activityRegularizer);\n        this.dilationRate = normalizeArray(args.dilationRate == null ? 1 : args.dilationRate, rank, 'dilationRate');\n        if (this.rank === 1 &&\n            (Array.isArray(this.dilationRate) && this.dilationRate.length !== 1)) {\n            throw new ValueError(`dilationRate must be a number or an array of a single number ` +\n                `for 1D convolution, but received ` +\n                `${JSON.stringify(this.dilationRate)}`);\n        }\n        else if (this.rank === 2) {\n            if (typeof this.dilationRate === 'number') {\n                this.dilationRate = [this.dilationRate, this.dilationRate];\n            }\n            else if (this.dilationRate.length !== 2) {\n                throw new ValueError(`dilationRate must be a number or array of two numbers for 2D ` +\n                    `convolution, but received ${JSON.stringify(this.dilationRate)}`);\n            }\n        }\n        else if (this.rank === 3) {\n            if (typeof this.dilationRate === 'number') {\n                this.dilationRate =\n                    [this.dilationRate, this.dilationRate, this.dilationRate];\n            }\n            else if (this.dilationRate.length !== 3) {\n                throw new ValueError(`dilationRate must be a number or array of three numbers for 3D ` +\n                    `convolution, but received ${JSON.stringify(this.dilationRate)}`);\n            }\n        }\n    }\n    static verifyArgs(args) {\n        // Check config.kernelSize type and shape.\n        generic_utils.assert('kernelSize' in args, `required key 'kernelSize' not in config`);\n        if (typeof args.kernelSize !== 'number' &&\n            !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 3)) {\n            throw new ValueError(`BaseConv expects config.kernelSize to be number or number[] with ` +\n                `length 1, 2, or 3, but received ${JSON.stringify(args.kernelSize)}.`);\n        }\n    }\n    getConfig() {\n        const config = {\n            kernelSize: this.kernelSize,\n            strides: this.strides,\n            padding: this.padding,\n            dataFormat: this.dataFormat,\n            dilationRate: this.dilationRate,\n            activation: serializeActivation(this.activation),\n            useBias: this.useBias,\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            biasConstraint: serializeConstraint(this.biasConstraint)\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/**\n * Abstract nD convolution layer.  Ancestor of convolution layers which reduce\n * across channels, i.e., Conv1D and Conv2D, but not DepthwiseConv2D.\n */\nexport class Conv extends BaseConv {\n    constructor(rank, args) {\n        super(rank, args);\n        this.kernel = null;\n        Conv.verifyArgs(args);\n        this.filters = args.filters;\n        generic_utils.assertPositiveInteger(this.filters, 'filters');\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new ValueError(`The channel dimension of the input should be defined. ` +\n                `Found ${inputShape[channelAxis]}`);\n        }\n        const inputDim = inputShape[channelAxis];\n        const kernelShape = this.kernelSize.concat([inputDim, this.filters]);\n        this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        this.inputSpec = [{ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } }];\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            let outputs;\n            const biasValue = this.bias == null ? null : this.bias.read();\n            const fusedActivationName = generic_utils.mapActivationToFusedKernel(this.activation.getClassName());\n            if (fusedActivationName != null && this.rank === 2) {\n                outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate, fusedActivationName);\n            }\n            else {\n                if (this.rank === 1) {\n                    outputs = conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);\n                }\n                else if (this.rank === 2) {\n                    // TODO(cais): Move up to constructor.\n                    outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);\n                }\n                else if (this.rank === 3) {\n                    outputs = conv3dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);\n                }\n                else {\n                    throw new NotImplementedError('convolutions greater than 3D are not implemented yet.');\n                }\n                if (this.activation != null) {\n                    outputs = this.activation.apply(outputs);\n                }\n            }\n            return outputs;\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const newSpace = [];\n        const space = (this.dataFormat === 'channelsLast') ?\n            inputShape.slice(1, inputShape.length - 1) :\n            inputShape.slice(2);\n        for (let i = 0; i < space.length; ++i) {\n            const newDim = convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === 'number' ? this.dilationRate :\n                this.dilationRate[i]);\n            newSpace.push(newDim);\n        }\n        let outputShape = [inputShape[0]];\n        if (this.dataFormat === 'channelsLast') {\n            outputShape = outputShape.concat(newSpace);\n            outputShape.push(this.filters);\n        }\n        else {\n            outputShape.push(this.filters);\n            outputShape = outputShape.concat(newSpace);\n        }\n        return outputShape;\n    }\n    getConfig() {\n        const config = {\n            filters: this.filters,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint)\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    static verifyArgs(args) {\n        // Check config.filters type, shape, and value.\n        if (!('filters' in args) || typeof args.filters !== 'number' ||\n            args.filters < 1) {\n            throw new ValueError(`Convolution layer expected config.filters to be a 'number' > 0 ` +\n                `but got ${JSON.stringify(args.filters)}`);\n        }\n    }\n}\nexport class Conv2D extends Conv {\n    constructor(args) {\n        super(2, args);\n        Conv2D.verifyArgs(args);\n    }\n    getConfig() {\n        const config = super.getConfig();\n        delete config['rank'];\n        return config;\n    }\n    static verifyArgs(args) {\n        // config.kernelSize must be a number or array of numbers.\n        if ((typeof args.kernelSize !== 'number') &&\n            !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 2)) {\n            throw new ValueError(`Conv2D expects config.kernelSize to be number or number[] with ` +\n                `length 1 or 2, but received ${JSON.stringify(args.kernelSize)}.`);\n        }\n    }\n}\n/** @nocollapse */\nConv2D.className = 'Conv2D';\nserialization.registerClass(Conv2D);\nexport class Conv3D extends Conv {\n    constructor(args) {\n        super(3, args);\n        Conv3D.verifyArgs(args);\n    }\n    getConfig() {\n        const config = super.getConfig();\n        delete config['rank'];\n        return config;\n    }\n    static verifyArgs(args) {\n        // config.kernelSize must be a number or array of numbers.\n        if (typeof args.kernelSize !== 'number') {\n            if (!(Array.isArray(args.kernelSize) &&\n                (args.kernelSize.length === 1 || args.kernelSize.length === 3))) {\n                throw new ValueError(`Conv3D expects config.kernelSize to be number or` +\n                    ` [number, number, number], but received ${JSON.stringify(args.kernelSize)}.`);\n            }\n        }\n    }\n}\n/** @nocollapse */\nConv3D.className = 'Conv3D';\nserialization.registerClass(Conv3D);\nexport class Conv2DTranspose extends Conv2D {\n    constructor(args) {\n        super(args);\n        this.inputSpec = [new InputSpec({ ndim: 4 })];\n        if (this.padding !== 'same' && this.padding !== 'valid') {\n            throw new ValueError(`Conv2DTranspose currently supports only padding modes 'same' ` +\n                `and 'valid', but received padding mode ${this.padding}`);\n        }\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        if (inputShape.length !== 4) {\n            throw new ValueError('Input should have rank 4; Received input shape: ' +\n                JSON.stringify(inputShape));\n        }\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new ValueError('The channel dimension of the inputs should be defined. ' +\n                'Found `None`.');\n        }\n        const inputDim = inputShape[channelAxis];\n        const kernelShape = this.kernelSize.concat([this.filters, inputDim]);\n        this.kernel = this.addWeight('kernel', kernelShape, 'float32', this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        // Set input spec.\n        this.inputSpec =\n            [new InputSpec({ ndim: 4, axes: { [channelAxis]: inputDim } })];\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            let input = getExactlyOneTensor(inputs);\n            if (input.shape.length !== 4) {\n                throw new ValueError(`Conv2DTranspose.call() expects input tensor to be rank-4, but ` +\n                    `received a tensor of rank-${input.shape.length}`);\n            }\n            const inputShape = input.shape;\n            const batchSize = inputShape[0];\n            let hAxis;\n            let wAxis;\n            if (this.dataFormat === 'channelsFirst') {\n                hAxis = 2;\n                wAxis = 3;\n            }\n            else {\n                hAxis = 1;\n                wAxis = 2;\n            }\n            const height = inputShape[hAxis];\n            const width = inputShape[wAxis];\n            const kernelH = this.kernelSize[0];\n            const kernelW = this.kernelSize[1];\n            const strideH = this.strides[0];\n            const strideW = this.strides[1];\n            // Infer the dynamic output shape.\n            const outHeight = deconvLength(height, strideH, kernelH, this.padding);\n            const outWidth = deconvLength(width, strideW, kernelW, this.padding);\n            // Porting Note: We don't branch based on `this.dataFormat` here,\n            // because\n            //   the tjfs-core function `conv2dTranspose` called below always\n            //   assumes channelsLast.\n            const outputShape = [batchSize, outHeight, outWidth, this.filters];\n            if (this.dataFormat !== 'channelsLast') {\n                input = tfc.transpose(input, [0, 2, 3, 1]);\n            }\n            let outputs = tfc.conv2dTranspose(input, this.kernel.read(), outputShape, this.strides, this.padding);\n            if (this.dataFormat !== 'channelsLast') {\n                outputs = tfc.transpose(outputs, [0, 3, 1, 2]);\n            }\n            if (this.bias != null) {\n                outputs =\n                    K.biasAdd(outputs, this.bias.read(), this.dataFormat);\n            }\n            if (this.activation != null) {\n                outputs = this.activation.apply(outputs);\n            }\n            return outputs;\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        let channelAxis;\n        let heightAxis;\n        let widthAxis;\n        if (this.dataFormat === 'channelsFirst') {\n            channelAxis = 1;\n            heightAxis = 2;\n            widthAxis = 3;\n        }\n        else {\n            channelAxis = 3;\n            heightAxis = 1;\n            widthAxis = 2;\n        }\n        const kernelH = this.kernelSize[0];\n        const kernelW = this.kernelSize[1];\n        const strideH = this.strides[0];\n        const strideW = this.strides[1];\n        outputShape[channelAxis] = this.filters;\n        outputShape[heightAxis] =\n            deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);\n        outputShape[widthAxis] =\n            deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);\n        return outputShape;\n    }\n    getConfig() {\n        const config = super.getConfig();\n        delete config['dilationRate'];\n        return config;\n    }\n}\n/** @nocollapse */\nConv2DTranspose.className = 'Conv2DTranspose';\nserialization.registerClass(Conv2DTranspose);\nexport class Conv3DTranspose extends Conv3D {\n    constructor(args) {\n        super(args);\n        this.inputSpec = [new InputSpec({ ndim: 5 })];\n        if (this.padding !== 'same' && this.padding !== 'valid') {\n            throw new ValueError(`Conv3DTranspose currently supports only padding modes 'same' ` +\n                `and 'valid', but received padding mode ${this.padding}`);\n        }\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        if (inputShape.length !== 5) {\n            throw new ValueError('Input should have rank 5; Received input shape: ' +\n                JSON.stringify(inputShape));\n        }\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new ValueError('The channel dimension of the inputs should be defined. ' +\n                'Found `None`.');\n        }\n        const inputDim = inputShape[channelAxis];\n        const kernelShape = this.kernelSize.concat([this.filters, inputDim]);\n        this.kernel = this.addWeight('kernel', kernelShape, 'float32', this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        // Set input spec.\n        this.inputSpec =\n            [new InputSpec({ ndim: 5, axes: { [channelAxis]: inputDim } })];\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            let input = getExactlyOneTensor(inputs);\n            if (input.shape.length !== 5) {\n                throw new ValueError(`Conv3DTranspose.call() expects input tensor to be rank-4, but ` +\n                    `received a tensor of rank-${input.shape.length}`);\n            }\n            const inputShape = input.shape;\n            const batchSize = inputShape[0];\n            let hAxis;\n            let wAxis;\n            let dAxis;\n            if (this.dataFormat === 'channelsFirst') {\n                dAxis = 2;\n                hAxis = 3;\n                wAxis = 4;\n            }\n            else {\n                dAxis = 1;\n                hAxis = 2;\n                wAxis = 3;\n            }\n            const depth = inputShape[dAxis];\n            const height = inputShape[hAxis];\n            const width = inputShape[wAxis];\n            const kernelD = this.kernelSize[0];\n            const kernelH = this.kernelSize[1];\n            const kernelW = this.kernelSize[2];\n            const strideD = this.strides[0];\n            const strideH = this.strides[1];\n            const strideW = this.strides[2];\n            // Infer the dynamic output shape.\n            const outDepth = deconvLength(depth, strideD, kernelD, this.padding);\n            const outHeight = deconvLength(height, strideH, kernelH, this.padding);\n            const outWidth = deconvLength(width, strideW, kernelW, this.padding);\n            // Same as `conv2dTranspose`. We always assumes channelsLast.\n            const outputShape = [batchSize, outDepth, outHeight, outWidth, this.filters];\n            if (this.dataFormat !== 'channelsLast') {\n                input = tfc.transpose(input, [0, 2, 3, 4, 1]);\n            }\n            let outputs = tfc.conv3dTranspose(input, this.kernel.read(), outputShape, this.strides, this.padding);\n            if (this.dataFormat !== 'channelsLast') {\n                outputs = tfc.transpose(outputs, [0, 4, 1, 2, 3]);\n            }\n            if (this.bias !== null) {\n                outputs =\n                    K.biasAdd(outputs, this.bias.read(), this.dataFormat);\n            }\n            if (this.activation !== null) {\n                outputs = this.activation.apply(outputs);\n            }\n            return outputs;\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        let channelAxis;\n        let depthAxis;\n        let heightAxis;\n        let widthAxis;\n        if (this.dataFormat === 'channelsFirst') {\n            channelAxis = 1;\n            depthAxis = 2;\n            heightAxis = 3;\n            widthAxis = 4;\n        }\n        else {\n            channelAxis = 4;\n            depthAxis = 1;\n            heightAxis = 2;\n            widthAxis = 3;\n        }\n        const kernelD = this.kernelSize[0];\n        const kernelH = this.kernelSize[1];\n        const kernelW = this.kernelSize[2];\n        const strideD = this.strides[0];\n        const strideH = this.strides[1];\n        const strideW = this.strides[2];\n        outputShape[channelAxis] = this.filters;\n        outputShape[depthAxis] =\n            deconvLength(outputShape[depthAxis], strideD, kernelD, this.padding);\n        outputShape[heightAxis] =\n            deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);\n        outputShape[widthAxis] =\n            deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);\n        return outputShape;\n    }\n    getConfig() {\n        const config = super.getConfig();\n        delete config['dilationRate'];\n        return config;\n    }\n}\n/** @nocollapse */\nConv3DTranspose.className = 'Conv3DTranspose';\nserialization.registerClass(Conv3DTranspose);\nexport class SeparableConv extends Conv {\n    constructor(rank, config) {\n        super(rank, config);\n        this.DEFAULT_DEPTHWISE_INITIALIZER = 'glorotUniform';\n        this.DEFAULT_POINTWISE_INITIALIZER = 'glorotUniform';\n        this.depthwiseKernel = null;\n        this.pointwiseKernel = null;\n        if (config.filters == null) {\n            throw new ValueError('The `filters` configuration field is required by SeparableConv, ' +\n                'but is unspecified.');\n        }\n        if (config.kernelInitializer != null || config.kernelRegularizer != null ||\n            config.kernelConstraint != null) {\n            throw new ValueError('Fields kernelInitializer, kernelRegularizer and kernelConstraint ' +\n                'are invalid for SeparableConv2D. Use depthwiseInitializer, ' +\n                'depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, ' +\n                'pointwiseRegularizer and pointwiseConstraint instead.');\n        }\n        if (config.padding != null && config.padding !== 'same' &&\n            config.padding !== 'valid') {\n            throw new ValueError(`SeparableConv${this.rank}D supports only padding modes: ` +\n                `'same' and 'valid', but received ${JSON.stringify(config.padding)}`);\n        }\n        this.depthMultiplier =\n            config.depthMultiplier == null ? 1 : config.depthMultiplier;\n        this.depthwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER);\n        this.depthwiseRegularizer = getRegularizer(config.depthwiseRegularizer);\n        this.depthwiseConstraint = getConstraint(config.depthwiseConstraint);\n        this.pointwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER);\n        this.pointwiseRegularizer = getRegularizer(config.pointwiseRegularizer);\n        this.pointwiseConstraint = getConstraint(config.pointwiseConstraint);\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        if (inputShape.length < this.rank + 2) {\n            throw new ValueError(`Inputs to SeparableConv${this.rank}D should have rank ` +\n                `${this.rank + 2}, but received input shape: ` +\n                `${JSON.stringify(inputShape)}`);\n        }\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n            throw new ValueError(`The channel dimension of the inputs should be defined, ` +\n                `but found ${JSON.stringify(inputShape[channelAxis])}`);\n        }\n        const inputDim = inputShape[channelAxis];\n        const depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);\n        const pointwiseKernelShape = [];\n        for (let i = 0; i < this.rank; ++i) {\n            pointwiseKernelShape.push(1);\n        }\n        pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);\n        const trainable = true;\n        this.depthwiseKernel = this.addWeight('depthwise_kernel', depthwiseKernelShape, 'float32', this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);\n        this.pointwiseKernel = this.addWeight('pointwise_kernel', pointwiseKernelShape, 'float32', this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.inputSpec =\n            [new InputSpec({ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } })];\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            let output;\n            if (this.rank === 1) {\n                throw new NotImplementedError('1D separable convolution is not implemented yet.');\n            }\n            else if (this.rank === 2) {\n                if (this.dataFormat === 'channelsFirst') {\n                    inputs = tfc.transpose(inputs, [0, 2, 3, 1]); // NCHW -> NHWC.\n                }\n                output = tfc.separableConv2d(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, 'NHWC');\n            }\n            if (this.useBias) {\n                output = K.biasAdd(output, this.bias.read(), this.dataFormat);\n            }\n            if (this.activation != null) {\n                output = this.activation.apply(output);\n            }\n            if (this.dataFormat === 'channelsFirst') {\n                output = tfc.transpose(output, [0, 3, 1, 2]); // NHWC -> NCHW.\n            }\n            return output;\n        });\n    }\n    getConfig() {\n        const config = super.getConfig();\n        delete config['rank'];\n        delete config['kernelInitializer'];\n        delete config['kernelRegularizer'];\n        delete config['kernelConstraint'];\n        config['depthwiseInitializer'] =\n            serializeInitializer(this.depthwiseInitializer);\n        config['pointwiseInitializer'] =\n            serializeInitializer(this.pointwiseInitializer);\n        config['depthwiseRegularizer'] =\n            serializeRegularizer(this.depthwiseRegularizer);\n        config['pointwiseRegularizer'] =\n            serializeRegularizer(this.pointwiseRegularizer);\n        config['depthwiseConstraint'] =\n            serializeConstraint(this.depthwiseConstraint);\n        config['pointwiseConstraint'] =\n            serializeConstraint(this.pointwiseConstraint);\n        return config;\n    }\n}\n/** @nocollapse */\nSeparableConv.className = 'SeparableConv';\nexport class SeparableConv2D extends SeparableConv {\n    constructor(args) {\n        super(2, args);\n    }\n}\n/** @nocollapse */\nSeparableConv2D.className = 'SeparableConv2D';\nserialization.registerClass(SeparableConv2D);\nexport class Conv1D extends Conv {\n    constructor(args) {\n        super(1, args);\n        Conv1D.verifyArgs(args);\n        this.inputSpec = [{ ndim: 3 }];\n    }\n    getConfig() {\n        const config = super.getConfig();\n        delete config['rank'];\n        delete config['dataFormat'];\n        return config;\n    }\n    static verifyArgs(args) {\n        // config.kernelSize must be a number or array of numbers.\n        if (typeof args.kernelSize !== 'number' &&\n            !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 1)) {\n            throw new ValueError(`Conv1D expects config.kernelSize to be number or number[] with ` +\n                `length 1, but received ${JSON.stringify(args.kernelSize)}.`);\n        }\n    }\n}\n/** @nocollapse */\nConv1D.className = 'Conv1D';\nserialization.registerClass(Conv1D);\nexport class Cropping2D extends Layer {\n    constructor(args) {\n        super(args);\n        if (typeof args.cropping === 'number') {\n            this.cropping =\n                [[args.cropping, args.cropping], [args.cropping, args.cropping]];\n        }\n        else if (typeof args.cropping[0] === 'number') {\n            this.cropping = [\n                [args.cropping[0], args.cropping[0]],\n                [args.cropping[1], args.cropping[1]]\n            ];\n        }\n        else {\n            this.cropping = args.cropping;\n        }\n        this.dataFormat =\n            args.dataFormat === undefined ? 'channelsLast' : args.dataFormat;\n        this.inputSpec = [{ ndim: 4 }];\n    }\n    computeOutputShape(inputShape) {\n        if (this.dataFormat === 'channelsFirst') {\n            return [\n                inputShape[0], inputShape[1],\n                inputShape[2] - this.cropping[0][0] - this.cropping[0][1],\n                inputShape[3] - this.cropping[1][0] - this.cropping[1][1]\n            ];\n        }\n        else {\n            return [\n                inputShape[0],\n                inputShape[1] - this.cropping[0][0] - this.cropping[0][1],\n                inputShape[2] - this.cropping[1][0] - this.cropping[1][1], inputShape[3]\n            ];\n        }\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            if (this.dataFormat === 'channelsLast') {\n                const hSliced = K.sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);\n                return K.sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);\n            }\n            else {\n                const hSliced = K.sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);\n                return K.sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);\n            }\n        });\n    }\n    getConfig() {\n        const config = { cropping: this.cropping, dataFormat: this.dataFormat };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nCropping2D.className = 'Cropping2D';\nserialization.registerClass(Cropping2D);\nexport class UpSampling2D extends Layer {\n    constructor(args) {\n        super(args);\n        this.DEFAULT_SIZE = [2, 2];\n        this.inputSpec = [{ ndim: 4 }];\n        this.size = args.size == null ? this.DEFAULT_SIZE : args.size;\n        this.dataFormat =\n            args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n        checkDataFormat(this.dataFormat);\n        this.interpolation =\n            args.interpolation == null ? 'nearest' : args.interpolation;\n        checkInterpolationFormat(this.interpolation);\n    }\n    computeOutputShape(inputShape) {\n        if (this.dataFormat === 'channelsFirst') {\n            const height = inputShape[2] == null ? null : this.size[0] * inputShape[2];\n            const width = inputShape[3] == null ? null : this.size[1] * inputShape[3];\n            return [inputShape[0], inputShape[1], height, width];\n        }\n        else {\n            const height = inputShape[1] == null ? null : this.size[0] * inputShape[1];\n            const width = inputShape[2] == null ? null : this.size[1] * inputShape[2];\n            return [inputShape[0], height, width, inputShape[3]];\n        }\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            let input = getExactlyOneTensor(inputs);\n            const inputShape = input.shape;\n            if (this.dataFormat === 'channelsFirst') {\n                input = tfc.transpose(input, [0, 2, 3, 1]);\n                const height = this.size[0] * inputShape[2];\n                const width = this.size[1] * inputShape[3];\n                const resized = this.interpolation === 'nearest' ?\n                    input.resizeNearestNeighbor([height, width]) :\n                    input.resizeBilinear([height, width]);\n                return tfc.transpose(resized, [0, 3, 1, 2]);\n            }\n            else {\n                const height = this.size[0] * inputShape[1];\n                const width = this.size[1] * inputShape[2];\n                return this.interpolation === 'nearest' ?\n                    input.resizeNearestNeighbor([height, width]) :\n                    input.resizeBilinear([height, width]);\n            }\n        });\n    }\n    getConfig() {\n        const config = { size: this.size, dataFormat: this.dataFormat };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nUpSampling2D.className = 'UpSampling2D';\nserialization.registerClass(UpSampling2D);\n//# sourceMappingURL=convolutional.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nexport const VALID_FAN_MODE_VALUES = ['fanIn', 'fanOut', 'fanAvg'];\nexport const VALID_DISTRIBUTION_VALUES = ['normal', 'uniform', 'truncatedNormal'];\n// We can't easily extract a string[] from the string union type, but we can\n// recapitulate the list, enforcing at compile time that the values are valid\n// and that we have the right number of them.\n/**\n * A string array of valid Initializer class names.\n *\n * This is guaranteed to match the `InitializerClassName` union type.\n */\nexport const initializerClassNames = [\n    'Zeros', 'Ones', 'Constant', 'RandomNormal', 'RandomUniform',\n    'TruncatedNormal', 'VarianceScaling', 'Orthogonal', 'Identity'\n];\n//# sourceMappingURL=initializer_config.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Depthwise Convolutional Layers\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy } from '@tensorflow/tfjs-core';\nimport { imageDataFormat } from '../backend/common';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat } from '../common';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { convOutputLength } from '../utils/conv_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nimport { BaseConv, preprocessConv2DInput } from './convolutional';\n/**\n * 2D convolution with separable filters.\n * @param x Input tensor.\n * @param depthwiseKernel Convolution kernel for depthwise convolution.\n * @param strides Strides (Array of two integers).\n * @param padding Padding model.\n * @param dataFormat Data format.\n * @param dilationRate Array of two integers, dilation rates for the separable\n *   convolution.\n * @returns Output tensor.\n * @throws ValueError If depthwiseKernel is not a 4D array.\n */\nexport function depthwiseConv2d(x, depthwiseKernel, strides = [1, 1], padding = 'valid', dataFormat, dilationRate) {\n    return tidy(() => {\n        if (dataFormat == null) {\n            dataFormat = imageDataFormat();\n        }\n        checkDataFormat(dataFormat);\n        let y = preprocessConv2DInput(x, dataFormat);\n        if (x.rank !== 4) {\n            throw new ValueError(`Input for depthwiseConv2d is required to be 4-D, but is instead ` +\n                `${x.rank}-D`);\n        }\n        if (depthwiseKernel.rank !== 4) {\n            throw new ValueError(`depthwiseKernel is required to be 4-D, but is instead ` +\n                `${depthwiseKernel.rank}-D`);\n        }\n        y = tfc.depthwiseConv2d(y, depthwiseKernel, strides, padding === 'same' ? 'same' : 'valid', 'NHWC', dilationRate);\n        if (dataFormat === 'channelsFirst') {\n            y = tfc.transpose(y, [0, 3, 1, 2]);\n        }\n        return y;\n    });\n}\nexport class DepthwiseConv2D extends BaseConv {\n    constructor(args) {\n        super(2, args);\n        this.depthwiseKernel = null;\n        this.depthMultiplier =\n            args.depthMultiplier == null ? 1 : args.depthMultiplier;\n        this.depthwiseInitializer = getInitializer(args.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.depthwiseConstraint = getConstraint(args.depthwiseConstraint);\n        this.depthwiseRegularizer = getRegularizer(args.depthwiseRegularizer);\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        if (inputShape.length < 4) {\n            throw new ValueError(`Inputs to DepthwiseConv2D should have rank 4. ` +\n                `Received input shape: ${JSON.stringify(inputShape)}.`);\n        }\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : 3;\n        if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n            throw new ValueError('The channel dimension of the inputs to DepthwiseConv2D should ' +\n                `be defined, but is not (${inputShape[channelAxis]}).`);\n        }\n        const inputDim = inputShape[channelAxis];\n        const depthwiseKernelShape = [\n            this.kernelSize[0], this.kernelSize[1], inputDim, this.depthMultiplier\n        ];\n        this.depthwiseKernel = this.addWeight('depthwise_kernel', depthwiseKernelShape, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint);\n        if (this.useBias) {\n            this.bias = this.addWeight('bias', [inputDim * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        else {\n            this.bias = null;\n        }\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            let outputs = depthwiseConv2d(inputs, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);\n            // TODO(cais): Add support for dilation.\n            if (this.useBias) {\n                outputs = K.biasAdd(outputs, this.bias.read(), this.dataFormat);\n            }\n            if (this.activation != null) {\n                outputs = this.activation.apply(outputs);\n            }\n            return outputs;\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const rows = this.dataFormat === 'channelsFirst' ? inputShape[2] : inputShape[1];\n        const cols = this.dataFormat === 'channelsFirst' ? inputShape[3] : inputShape[2];\n        const outFilters = this.dataFormat === 'channelsFirst' ?\n            inputShape[1] * this.depthMultiplier :\n            inputShape[3] * this.depthMultiplier;\n        const outRows = convOutputLength(rows, this.kernelSize[0], this.padding, this.strides[0]);\n        const outCols = convOutputLength(cols, this.kernelSize[1], this.padding, this.strides[1]);\n        if (this.dataFormat === 'channelsFirst') {\n            return [inputShape[0], outFilters, outRows, outCols];\n        }\n        else {\n            // In this case, assume 'channelsLast'.\n            return [inputShape[0], outRows, outCols, outFilters];\n        }\n    }\n    getConfig() {\n        const config = super.getConfig();\n        config['depthMultiplier'] = this.depthMultiplier;\n        config['depthwiseInitializer'] =\n            serializeInitializer(this.depthwiseInitializer);\n        config['depthwiseRegularizer'] =\n            serializeRegularizer(this.depthwiseRegularizer);\n        config['depthwiseConstraint'] =\n            serializeConstraint(this.depthwiseRegularizer);\n        return config;\n    }\n}\n/** @nocollapse */\nDepthwiseConv2D.className = 'DepthwiseConv2D';\nserialization.registerClass(DepthwiseConv2D);\n//# sourceMappingURL=convolutional_depthwise.js.map","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = (this && this.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\nclass ConvRNN2DCell extends RNNCell {\n}\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n    constructor(args) {\n        if (args.unroll) {\n            throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n        }\n        if (Array.isArray(args.cell)) {\n            throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n        }\n        super(args);\n        this.inputSpec = [new InputSpec({ ndim: 5 })];\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            if (this.cell.dropoutMask != null) {\n                tfc.dispose(this.cell.dropoutMask);\n                this.cell.dropoutMask = null;\n            }\n            if (this.cell.recurrentDropoutMask != null) {\n                tfc.dispose(this.cell.recurrentDropoutMask);\n                this.cell.recurrentDropoutMask = null;\n            }\n            if (kwargs && kwargs['constants']) {\n                throw new ValueError('ConvRNN2D cell does not support constants');\n            }\n            const mask = kwargs == null ? null : kwargs['mask'];\n            const training = kwargs == null ? null : kwargs['training'];\n            const initialState = kwargs == null ? null : kwargs['initialState'];\n            return super.call(inputs, { mask, training, initialState });\n        });\n    }\n    computeOutputShape(inputShape) {\n        let outShape = this.computeSingleOutputShape(inputShape);\n        if (!this.returnSequences) {\n            outShape = [outShape[0], ...outShape.slice(2)];\n        }\n        if (this.returnState) {\n            outShape =\n                [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n        }\n        return outShape;\n    }\n    getInitialState(inputs) {\n        return tfc.tidy(() => {\n            const { stateSize } = this.cell;\n            const inputShape = inputs.shape;\n            const outputShape = this.computeSingleOutputShape(inputShape);\n            const stateShape = [outputShape[0], ...outputShape.slice(2)];\n            const initialState = tfc.zeros(stateShape);\n            if (Array.isArray(stateSize)) {\n                return Array(stateSize.length).fill(initialState);\n            }\n            return [initialState];\n        });\n    }\n    resetStates(states, training = false) {\n        tfc.tidy(() => {\n            if (!this.stateful) {\n                throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n            }\n            const inputShape = this.inputSpec[0].shape;\n            const outputShape = this.computeSingleOutputShape(inputShape);\n            const stateShape = [outputShape[0], ...outputShape.slice(2)];\n            const batchSize = inputShape[0];\n            if (batchSize == null) {\n                throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' +\n                    'the batch size of your input tensors: \\n' +\n                    '- If using a Sequential model, specify the batch size by ' +\n                    'passing a `batchInputShape` option to your first layer.\\n' +\n                    '- If using the functional API, specify the batch size by ' +\n                    'passing a `batchShape` option to your Input layer.');\n            }\n            // Initialize state if null.\n            if (this.getStates() == null) {\n                if (Array.isArray(this.cell.stateSize)) {\n                    this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n                }\n                else {\n                    this.states_ = [tfc.zeros(stateShape)];\n                }\n            }\n            else if (states == null) {\n                // Dispose old state tensors.\n                tfc.dispose(this.states_);\n                // For stateful RNNs, fully dispose kept old states.\n                if (this.keptStates != null) {\n                    tfc.dispose(this.keptStates);\n                    this.keptStates = [];\n                }\n                if (Array.isArray(this.cell.stateSize)) {\n                    this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n                }\n                else {\n                    this.states_[0] = tfc.zeros(stateShape);\n                }\n            }\n            else {\n                if (!Array.isArray(states)) {\n                    states = [states];\n                }\n                if (states.length !== this.states_.length) {\n                    throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), ` +\n                        `but it received ${states.length} state value(s). Input ` +\n                        `received: ${states}`);\n                }\n                if (training) {\n                    // Store old state tensors for complete disposal later, i.e., during\n                    // the next no-arg call to this method. We do not dispose the old\n                    // states immediately because that BPTT (among other things) require\n                    // them.\n                    this.keptStates.push(this.states_.slice());\n                }\n                else {\n                    tfc.dispose(this.states_);\n                }\n                for (let index = 0; index < this.states_.length; ++index) {\n                    const value = states[index];\n                    const expectedShape = stateShape;\n                    if (!util.arraysEqual(value.shape, expectedShape)) {\n                        throw new ValueError(`State ${index} is incompatible with layer ${this.name}: ` +\n                            `expected shape=${expectedShape}, received shape=${value.shape}`);\n                    }\n                    this.states_[index] = value;\n                }\n            }\n            this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n        });\n    }\n    computeSingleOutputShape(inputShape) {\n        const { dataFormat, filters, kernelSize, padding, strides, dilationRate } = this.cell;\n        const isChannelsFirst = dataFormat === 'channelsFirst';\n        const h = inputShape[isChannelsFirst ? 3 : 2];\n        const w = inputShape[isChannelsFirst ? 4 : 3];\n        const hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n        const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n        const outShape = [\n            ...inputShape.slice(0, 2),\n            ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])\n        ];\n        return outShape;\n    }\n}\n/** @nocollapse */\nConvRNN2D.className = 'ConvRNN2D';\nexport class ConvLSTM2DCell extends LSTMCell {\n    constructor(args) {\n        const { filters, kernelSize, strides, padding, dataFormat, dilationRate, } = args;\n        super(Object.assign({}, args, { units: filters }));\n        this.filters = filters;\n        assertPositiveInteger(this.filters, 'filters');\n        this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n        this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n        this.strides = normalizeArray(strides || 1, 2, 'strides');\n        this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n        this.padding = padding || 'valid';\n        checkPaddingMode(this.padding);\n        this.dataFormat = dataFormat || 'channelsLast';\n        checkDataFormat(this.dataFormat);\n        this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n        this.dilationRate.forEach(rate => assertPositiveInteger(rate, 'dilationRate'));\n    }\n    build(inputShape) {\n        var _a;\n        inputShape = getExactlyOneShape(inputShape);\n        const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n        if (inputShape[channelAxis] == null) {\n            throw new ValueError(`The channel dimension of the input should be defined. ` +\n                `Found ${inputShape[channelAxis]}`);\n        }\n        const inputDim = inputShape[channelAxis];\n        const numOfKernels = 4;\n        const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n        this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n        const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n        this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n        if (this.useBias) {\n            let biasInitializer;\n            if (this.unitForgetBias) {\n                const init = this.biasInitializer;\n                const filters = this.filters;\n                biasInitializer = new (_a = class CustomInit extends Initializer {\n                        apply(shape, dtype) {\n                            const biasI = init.apply([filters]);\n                            const biasF = tfc.ones([filters]);\n                            const biasCAndO = init.apply([filters * 2]);\n                            return K.concatenate([biasI, biasF, biasCAndO]);\n                        }\n                    },\n                    /** @nocollapse */\n                    _a.className = 'CustomInit',\n                    _a)();\n            }\n            else {\n                biasInitializer = this.biasInitializer;\n            }\n            this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n        }\n        this.built = true;\n    }\n    call(inputs, kwargs) {\n        return tfc.tidy(() => {\n            if (inputs.length !== 3) {\n                throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` +\n                    `${inputs.length}.`);\n            }\n            const training = kwargs['training'] || false;\n            const x = inputs[0]; // Current input\n            const hTMinus1 = inputs[1]; // Previous memory state.\n            const cTMinus1 = inputs[2]; // Previous carry state.\n            const numOfKernels = 4;\n            if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n                this.dropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(x),\n                    rate: this.dropout,\n                    training,\n                    count: numOfKernels\n                });\n            }\n            const dropoutMask = this.dropoutMask;\n            const applyDropout = (x, mask, index) => {\n                if (!mask || !mask[index]) {\n                    return x;\n                }\n                return tfc.mul(mask[index], x);\n            };\n            let xI = applyDropout(x, dropoutMask, 0);\n            let xF = applyDropout(x, dropoutMask, 1);\n            let xC = applyDropout(x, dropoutMask, 2);\n            let xO = applyDropout(x, dropoutMask, 3);\n            if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n                this.recurrentDropoutMask == null) {\n                this.recurrentDropoutMask = generateDropoutMask({\n                    ones: () => tfc.onesLike(hTMinus1),\n                    rate: this.recurrentDropout,\n                    training,\n                    count: numOfKernels\n                });\n            }\n            const recDropoutMask = this.recurrentDropoutMask;\n            let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n            let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n            let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n            let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n            const kernelChannelAxis = 3;\n            const [kernelI, kernelF, kernelC, kernelO] = tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n            const [biasI, biasF, biasC, biasO] = this.useBias ?\n                tfc.split(this.bias.read(), numOfKernels) :\n                [null, null, null, null];\n            xI = this.inputConv(xI, kernelI, biasI, this.padding);\n            xF = this.inputConv(xF, kernelF, biasF, this.padding);\n            xC = this.inputConv(xC, kernelC, biasC, this.padding);\n            xO = this.inputConv(xO, kernelO, biasO, this.padding);\n            const [recKernelI, recKernelF, recKernelC, recKernelO] = tfc.split(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n            hI = this.recurrentConv(hI, recKernelI);\n            hF = this.recurrentConv(hF, recKernelF);\n            hC = this.recurrentConv(hC, recKernelC);\n            hO = this.recurrentConv(hO, recKernelO);\n            const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n            const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n            const c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n            const h = tfc.mul(this.recurrentActivation.apply(tfc.add(xO, hO)), this.activation.apply(c));\n            return [h, h, c];\n        });\n    }\n    getConfig() {\n        const _a = super.getConfig(), { 'units': _ } = _a, baseConfig = __rest(_a, ['units']);\n        const config = {\n            filters: this.filters,\n            kernelSize: this.kernelSize,\n            padding: this.padding,\n            dataFormat: this.dataFormat,\n            dilationRate: this.dilationRate,\n            strides: this.strides,\n        };\n        return Object.assign({}, baseConfig, config);\n    }\n    inputConv(x, w, b, padding) {\n        const out = tfc.conv2d(x, w, this.strides, (padding || 'valid'), this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n        if (b) {\n            return K.biasAdd(out, b, this.dataFormat);\n        }\n        return out;\n    }\n    recurrentConv(x, w) {\n        const strides = 1;\n        return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n    }\n}\n/** @nocollapse */\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport class ConvLSTM2D extends ConvRNN2D {\n    constructor(args) {\n        const cell = new ConvLSTM2DCell(args);\n        super(Object.assign({}, args, { cell }));\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls(config);\n    }\n}\n/** @nocollapse */\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);\n//# sourceMappingURL=convolutional_recurrent.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nexport const VALID_DATA_FORMAT_VALUES = ['channelsFirst', 'channelsLast'];\nexport const VALID_INTERPOLATION_FORMAT_VALUES = ['nearest', 'bilinear'];\nexport const VALID_PADDING_MODE_VALUES = ['valid', 'same', 'causal'];\nexport const VALID_POOL_MODE_VALUES = ['max', 'avg'];\nexport const VALID_BIDIRECTIONAL_MERGE_MODES = ['sum', 'mul', 'concat', 'ave'];\nexport const VALID_SAMPLE_WEIGHT_MODES = ['temporal'];\n//# sourceMappingURL=common.js.map"],"names":["Dropout","constructor","args","super","this","rate","Math","max","min","noiseShape","seed","supportsMasking","getNoiseShape","input","inputShape","shape","i","length","push","call","inputs","kwargs","tidy","invokeCallHook","training","getConfig","config","baseConfig","Object","assign","dispose","className","serialization","SpatialDropout1D","inputSpec","ndim","Dense","activation","useBias","kernel","bias","DEFAULT_KERNEL_INITIALIZER","DEFAULT_BIAS_INITIALIZER","batchInputShape","inputDim","batchSize","units","kernelInitializer","biasInitializer","kernelConstraint","biasConstraint","kernelRegularizer","biasRegularizer","activityRegularizer","minNDim","build","inputLastDim","addWeight","axes","built","computeOutputShape","outputShape","slice","fusedActivationName","getClassName","output","read","apply","Flatten","dataFormat","dim","rank","permutation","transpose","Activation","RepeatVector","n","Reshape","targetShape","isUnknown","fixUnknownDimension","errorMsg","finalShape","known","unknown","originalSize","anyUnknownDims","concat","reshape","Permute","dims","Error","Array","isArray","expectedSortedIndices","util","sort","JSON","stringify","dimsIncludingBatch","forEach","Masking","maskValue","computeMask","mask","any","notEqual","booleanMask","mul","asType","dtype","ReLU","maxValue","relu","clipByValue","LeakyReLU","DEFAULT_ALPHA","alpha","x","leakyRelu","PReLU","DEFAULT_ALPHA_INITIALIZER","alphaInitializer","alphaRegularizer","alphaConstraint","sharedAxes","paramShape","prelu","ELU","elu","ThresholdedReLU","DEFAULT_THETA","theta","greater","Softmax","DEFAULT_AXIS","softmax","axis","preprocessConv2DInput","preprocessConv3DInput","conv1dWithBias","strides","padding","dilationRate","y","conv2dWithBiasActivation","filter","pad","dilations","conv3dWithBias","BaseConv","verifyArgs","kernelSize","Conv","filters","channelAxis","kernelShape","outputs","biasValue","newSpace","space","newDim","Conv2D","Conv3D","Conv2DTranspose","hAxis","wAxis","height","width","kernelH","kernelW","strideH","strideW","heightAxis","widthAxis","Conv3DTranspose","dAxis","depth","kernelD","strideD","depthAxis","SeparableConv","DEFAULT_DEPTHWISE_INITIALIZER","DEFAULT_POINTWISE_INITIALIZER","depthwiseKernel","pointwiseKernel","depthMultiplier","depthwiseInitializer","depthwiseRegularizer","depthwiseConstraint","pointwiseInitializer","pointwiseRegularizer","pointwiseConstraint","depthwiseKernelShape","pointwiseKernelShape","trainable","SeparableConv2D","Conv1D","Cropping2D","cropping","undefined","hSliced","UpSampling2D","DEFAULT_SIZE","size","interpolation","resized","resizeNearestNeighbor","resizeBilinear","VALID_FAN_MODE_VALUES","VALID_DISTRIBUTION_VALUES","DepthwiseConv2D","depthwiseConv2d","rows","cols","outFilters","outRows","outCols","__rest","s","e","t","p","prototype","hasOwnProperty","indexOf","getOwnPropertySymbols","propertyIsEnumerable","ConvRNN2D","unroll","cell","dropoutMask","recurrentDropoutMask","initialState","outShape","computeSingleOutputShape","returnSequences","returnState","fill","getInitialState","stateSize","stateShape","resetStates","states","stateful","getStates","states_","map","keptStates","name","index","value","expectedShape","state","clone","isChannelsFirst","h","w","hOut","wOut","ConvLSTM2DCell","stride","_a","recurrentKernelShape","recurrentKernel","recurrentInitializer","recurrentRegularizer","recurrentConstraint","unitForgetBias","init","biasI","biasF","biasCAndO","hTMinus1","cTMinus1","dropout","ones","count","applyDropout","xI","xF","xC","xO","recurrentDropout","recDropoutMask","hI","hF","hC","hO","kernelI","kernelF","kernelC","kernelO","biasC","biasO","inputConv","recKernelI","recKernelF","recKernelC","recKernelO","recurrentConv","recurrentActivation","f","c","_","b","out","ConvLSTM2D","fromConfig","cls","VALID_DATA_FORMAT_VALUES","VALID_INTERPOLATION_FORMAT_VALUES","VALID_PADDING_MODE_VALUES","VALID_POOL_MODE_VALUES","VALID_BIDIRECTIONAL_MERGE_MODES"],"sourceRoot":""}