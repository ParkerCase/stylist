"use strict";(self.webpackChunkStylistWidget=self.webpackChunkStylistWidget||[]).push([[9588],{9548:function(i,t,e){e.d(t,{RK:function(){return m},al:function(){return k},kO:function(){return v}});var s=e(9495),n=e(59885),r=e(6090),a=e(47661),l=e(39459),o=e(87504),h=e(79730),d=e(15841),p=e(59351),u=e(84379),c=e(69184),g=e(44813),f=e(63057);function m(i,t){return(0,s.tidy)((()=>((0,l.uM)(t),"channelsFirst"===t?s.transpose(i,[0,2,3,1]):i)))}function k(i,t){return(0,s.tidy)((()=>((0,l.uM)(t),"channelsFirst"===t?s.transpose(i,[0,2,3,4,1]):i)))}function b(i,t,e,n=1,o="valid",h,p=1){return(0,s.tidy)((()=>{if(null==h&&(h=(0,r.VI)()),(0,l.uM)(h),3!==i.shape.length)throw new d.Qp(`The input of a conv1dWithBias operation should be 3, but is ${i.shape.length} instead.`);if(3!==t.shape.length)throw new d.Qp(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);if(null!=e&&1!==e.shape.length)throw new d.Qp(`The bias for a conv1dWithBias operation should be 1, but is ${e.shape.length} instead`);if("channelsFirst"===h&&(i=s.transpose(i,[0,2,1])),"causal"===o)throw new d.EH("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let u=s.conv1d(i,t,n,"same"===o?"same":"valid","NWC",p);return null!=e&&(u=a.ni(u,e)),u}))}function z(i,t,e,n=[1,1],a="valid",o,h,p=null){return(0,s.tidy)((()=>{if(null==o&&(o=(0,r.VI)()),(0,l.uM)(o),3!==i.rank&&4!==i.rank)throw new d.Qp(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${i.rank}.`);if(3!==t.rank&&4!==t.rank)throw new d.Qp(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${i.rank}.`);let u=m(i,o);if("causal"===a)throw new d.EH("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return u=s.fused.conv2d({x:u,filter:t,strides:n,pad:"same"===a?"same":"valid",dilations:h,dataFormat:"NHWC",bias:e,activation:p}),"channelsFirst"===o&&(u=s.transpose(u,[0,3,1,2])),u}))}function w(i,t,e,n=[1,1,1],o="valid",h,p){return(0,s.tidy)((()=>{if(null==h&&(h=(0,r.VI)()),(0,l.uM)(h),4!==i.rank&&5!==i.rank)throw new d.Qp(`conv3dWithBias expects input to be of rank 4 or 5, but received ${i.rank}.`);if(4!==t.rank&&5!==t.rank)throw new d.Qp(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${i.rank}.`);let u=k(i,h);if("causal"===o)throw new d.EH("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return u=s.conv3d(u,t,n,"same"===o?"same":"valid","NDHWC",p),null!=e&&(u=a.ni(u,e)),"channelsFirst"===h&&(u=s.transpose(u,[0,4,1,2,3])),u}))}class v extends h.Wd{constructor(i,t){if(super(t),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",v.verifyArgs(t),this.rank=i,g.oo(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new d.EH(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=(0,c.J)(t.kernelSize,i,"kernelSize"),this.strides=(0,c.J)(null==t.strides?1:t.strides,i,"strides"),this.padding=null==t.padding?"valid":t.padding,(0,l.tB)(this.padding),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,l.uM)(this.dataFormat),this.activation=(0,n.b_)(t.activation),this.useBias=null==t.useBias||t.useBias,this.biasInitializer=(0,p.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=(0,o.YZ)(t.biasConstraint),this.biasRegularizer=(0,u.Bm)(t.biasRegularizer),this.activityRegularizer=(0,u.Bm)(t.activityRegularizer),this.dilationRate=(0,c.J)(null==t.dilationRate?1:t.dilationRate,i,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new d.Qp(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"===typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new d.Qp(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"===typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new d.Qp(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(i){if(g.vA("kernelSize"in i,"required key 'kernelSize' not in config"),"number"!==typeof i.kernelSize&&!g.HP(i.kernelSize,"number",1,3))throw new d.Qp(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(i.kernelSize)}.`)}getConfig(){const i={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:(0,n.Bu)(this.activation),useBias:this.useBias,biasInitializer:(0,p.zo)(this.biasInitializer),biasRegularizer:(0,u.R9)(this.biasRegularizer),activityRegularizer:(0,u.R9)(this.activityRegularizer),biasConstraint:(0,o.uH)(this.biasConstraint)},t=super.getConfig();return Object.assign(i,t),i}}class C extends v{constructor(i,t){super(i,t),this.kernel=null,C.verifyArgs(t),this.filters=t.filters,g.oo(this.filters,"filters"),this.kernelInitializer=(0,p.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=(0,o.YZ)(t.kernelConstraint),this.kernelRegularizer=(0,u.Bm)(t.kernelRegularizer)}build(i){i=(0,f.U$)(i);const t="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[t])throw new d.Qp(`The channel dimension of the input should be defined. Found ${i[t]}`);const e=i[t],s=this.kernelSize.concat([e,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:e}}],this.built=!0}call(i,t){return(0,s.tidy)((()=>{let t;i=(0,f.un)(i);const e=null==this.bias?null:this.bias.read(),s=g.Cd(this.activation.getClassName());if(null!=s&&2===this.rank)t=z(i,this.kernel.read(),e,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)t=b(i,this.kernel.read(),e,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)t=z(i,this.kernel.read(),e,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new d.EH("convolutions greater than 3D are not implemented yet.");t=w(i,this.kernel.read(),e,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(t=this.activation.apply(t))}return t}))}computeOutputShape(i){i=(0,f.U$)(i);const t=[],e="channelsLast"===this.dataFormat?i.slice(1,i.length-1):i.slice(2);for(let n=0;n<e.length;++n){const i=(0,c.Ol)(e[n],this.kernelSize[n],this.padding,this.strides[n],"number"===typeof this.dilationRate?this.dilationRate:this.dilationRate[n]);t.push(i)}let s=[i[0]];return"channelsLast"===this.dataFormat?(s=s.concat(t),s.push(this.filters)):(s.push(this.filters),s=s.concat(t)),s}getConfig(){const i={filters:this.filters,kernelInitializer:(0,p.zo)(this.kernelInitializer),kernelRegularizer:(0,u.R9)(this.kernelRegularizer),kernelConstraint:(0,o.uH)(this.kernelConstraint)},t=super.getConfig();return Object.assign(i,t),i}static verifyArgs(i){if(!("filters"in i)||"number"!==typeof i.filters||i.filters<1)throw new d.Qp(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(i.filters)}`)}}class R extends C{constructor(i){super(2,i),R.verifyArgs(i)}getConfig(){const i=super.getConfig();return delete i.rank,i}static verifyArgs(i){if("number"!==typeof i.kernelSize&&!g.HP(i.kernelSize,"number",1,2))throw new d.Qp(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(i.kernelSize)}.`)}}R.className="Conv2D",s.serialization.registerClass(R);class S extends C{constructor(i){super(3,i),S.verifyArgs(i)}getConfig(){const i=super.getConfig();return delete i.rank,i}static verifyArgs(i){if("number"!==typeof i.kernelSize&&(!Array.isArray(i.kernelSize)||1!==i.kernelSize.length&&3!==i.kernelSize.length))throw new d.Qp(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(i.kernelSize)}.`)}}S.className="Conv3D",s.serialization.registerClass(S);class F extends R{constructor(i){if(super(i),this.inputSpec=[new h.eO({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new d.Qp(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(i){if(4!==(i=(0,f.U$)(i)).length)throw new d.Qp("Input should have rank 4; Received input shape: "+JSON.stringify(i));const t="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[t])throw new d.Qp("The channel dimension of the inputs should be defined. Found `None`.");const e=i[t],s=this.kernelSize.concat([this.filters,e]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new h.eO({ndim:4,axes:{[t]:e}})],this.built=!0}call(i,t){return s.tidy((()=>{let t=(0,f.un)(i);if(4!==t.shape.length)throw new d.Qp(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const e=t.shape,n=e[0];let r,l;"channelsFirst"===this.dataFormat?(r=2,l=3):(r=1,l=2);const o=e[r],h=e[l],p=this.kernelSize[0],u=this.kernelSize[1],g=this.strides[0],m=this.strides[1],k=[n,(0,c.mW)(o,g,p,this.padding),(0,c.mW)(h,m,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=s.transpose(t,[0,2,3,1]));let b=s.conv2dTranspose(t,this.kernel.read(),k,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(b=s.transpose(b,[0,3,1,2])),null!=this.bias&&(b=a.ni(b,this.bias.read(),this.dataFormat)),null!=this.activation&&(b=this.activation.apply(b)),b}))}computeOutputShape(i){const t=(i=(0,f.U$)(i)).slice();let e,s,n;"channelsFirst"===this.dataFormat?(e=1,s=2,n=3):(e=3,s=1,n=2);const r=this.kernelSize[0],a=this.kernelSize[1],l=this.strides[0],o=this.strides[1];return t[e]=this.filters,t[s]=(0,c.mW)(t[s],l,r,this.padding),t[n]=(0,c.mW)(t[n],o,a,this.padding),t}getConfig(){const i=super.getConfig();return delete i.dilationRate,i}}F.className="Conv2DTranspose",s.serialization.registerClass(F);class I extends S{constructor(i){if(super(i),this.inputSpec=[new h.eO({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new d.Qp(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(i){if(5!==(i=(0,f.U$)(i)).length)throw new d.Qp("Input should have rank 5; Received input shape: "+JSON.stringify(i));const t="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[t])throw new d.Qp("The channel dimension of the inputs should be defined. Found `None`.");const e=i[t],s=this.kernelSize.concat([this.filters,e]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new h.eO({ndim:5,axes:{[t]:e}})],this.built=!0}call(i,t){return s.tidy((()=>{let t=(0,f.un)(i);if(5!==t.shape.length)throw new d.Qp(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const e=t.shape,n=e[0];let r,l,o;"channelsFirst"===this.dataFormat?(o=2,r=3,l=4):(o=1,r=2,l=3);const h=e[o],p=e[r],u=e[l],g=this.kernelSize[0],m=this.kernelSize[1],k=this.kernelSize[2],b=this.strides[0],z=this.strides[1],w=this.strides[2],v=[n,(0,c.mW)(h,b,g,this.padding),(0,c.mW)(p,z,m,this.padding),(0,c.mW)(u,w,k,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=s.transpose(t,[0,2,3,4,1]));let C=s.conv3dTranspose(t,this.kernel.read(),v,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(C=s.transpose(C,[0,4,1,2,3])),null!==this.bias&&(C=a.ni(C,this.bias.read(),this.dataFormat)),null!==this.activation&&(C=this.activation.apply(C)),C}))}computeOutputShape(i){const t=(i=(0,f.U$)(i)).slice();let e,s,n,r;"channelsFirst"===this.dataFormat?(e=1,s=2,n=3,r=4):(e=4,s=1,n=2,r=3);const a=this.kernelSize[0],l=this.kernelSize[1],o=this.kernelSize[2],h=this.strides[0],d=this.strides[1],p=this.strides[2];return t[e]=this.filters,t[s]=(0,c.mW)(t[s],h,a,this.padding),t[n]=(0,c.mW)(t[n],d,l,this.padding),t[r]=(0,c.mW)(t[r],p,o,this.padding),t}getConfig(){const i=super.getConfig();return delete i.dilationRate,i}}I.className="Conv3DTranspose",s.serialization.registerClass(I);class y extends C{constructor(i,t){if(super(i,t),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==t.filters)throw new d.Qp("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=t.kernelInitializer||null!=t.kernelRegularizer||null!=t.kernelConstraint)throw new d.Qp("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=t.padding&&"same"!==t.padding&&"valid"!==t.padding)throw new d.Qp(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(t.padding)}`);this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=(0,p.Fe)(t.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=(0,u.Bm)(t.depthwiseRegularizer),this.depthwiseConstraint=(0,o.YZ)(t.depthwiseConstraint),this.pointwiseInitializer=(0,p.Fe)(t.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=(0,u.Bm)(t.pointwiseRegularizer),this.pointwiseConstraint=(0,o.YZ)(t.pointwiseConstraint)}build(i){if((i=(0,f.U$)(i)).length<this.rank+2)throw new d.Qp(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(i)}`);const t="channelsFirst"===this.dataFormat?1:i.length-1;if(null==i[t]||i[t]<0)throw new d.Qp(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(i[t])}`);const e=i[t],s=this.kernelSize.concat([e,this.depthMultiplier]),n=[];for(let a=0;a<this.rank;++a)n.push(1);n.push(e*this.depthMultiplier,this.filters);const r=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",s,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,r,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",n,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,r,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,r,this.biasConstraint):this.bias=null,this.inputSpec=[new h.eO({ndim:this.rank+2,axes:{[t]:e}})],this.built=!0}call(i,t){return(0,s.tidy)((()=>{let t;if(i=(0,f.un)(i),1===this.rank)throw new d.EH("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(i=s.transpose(i,[0,2,3,1])),t=s.separableConv2d(i,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(t=a.ni(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),"channelsFirst"===this.dataFormat&&(t=s.transpose(t,[0,3,1,2])),t}))}getConfig(){const i=super.getConfig();return delete i.rank,delete i.kernelInitializer,delete i.kernelRegularizer,delete i.kernelConstraint,i.depthwiseInitializer=(0,p.zo)(this.depthwiseInitializer),i.pointwiseInitializer=(0,p.zo)(this.pointwiseInitializer),i.depthwiseRegularizer=(0,u.R9)(this.depthwiseRegularizer),i.pointwiseRegularizer=(0,u.R9)(this.pointwiseRegularizer),i.depthwiseConstraint=(0,o.uH)(this.depthwiseConstraint),i.pointwiseConstraint=(0,o.uH)(this.pointwiseConstraint),i}}y.className="SeparableConv";class N extends y{constructor(i){super(2,i)}}N.className="SeparableConv2D",s.serialization.registerClass(N);class A extends C{constructor(i){super(1,i),A.verifyArgs(i),this.inputSpec=[{ndim:3}]}getConfig(){const i=super.getConfig();return delete i.rank,delete i.dataFormat,i}static verifyArgs(i){if("number"!==typeof i.kernelSize&&!g.HP(i.kernelSize,"number",1,1))throw new d.Qp(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(i.kernelSize)}.`)}}A.className="Conv1D",s.serialization.registerClass(A);class W extends h.Wd{constructor(i){super(i),"number"===typeof i.cropping?this.cropping=[[i.cropping,i.cropping],[i.cropping,i.cropping]]:"number"===typeof i.cropping[0]?this.cropping=[[i.cropping[0],i.cropping[0]],[i.cropping[1],i.cropping[1]]]:this.cropping=i.cropping,this.dataFormat=void 0===i.dataFormat?"channelsLast":i.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(i){return"channelsFirst"===this.dataFormat?[i[0],i[1],i[2]-this.cropping[0][0]-this.cropping[0][1],i[3]-this.cropping[1][0]-this.cropping[1][1]]:[i[0],i[1]-this.cropping[0][0]-this.cropping[0][1],i[2]-this.cropping[1][0]-this.cropping[1][1],i[3]]}call(i,t){return(0,s.tidy)((()=>{if(i=(0,f.un)(i),"channelsLast"===this.dataFormat){const t=a.r0(i,this.cropping[0][0],i.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return a.r0(t,this.cropping[1][0],i.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const t=a.r0(i,this.cropping[0][0],i.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return a.r0(t,this.cropping[1][0],i.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}}))}getConfig(){const i={cropping:this.cropping,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(i,t),i}}W.className="Cropping2D",s.serialization.registerClass(W);class T extends h.Wd{constructor(i){super(i),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==i.size?this.DEFAULT_SIZE:i.size,this.dataFormat=null==i.dataFormat?"channelsLast":i.dataFormat,(0,l.uM)(this.dataFormat),this.interpolation=null==i.interpolation?"nearest":i.interpolation,(0,l.uU)(this.interpolation)}computeOutputShape(i){if("channelsFirst"===this.dataFormat){const t=null==i[2]?null:this.size[0]*i[2],e=null==i[3]?null:this.size[1]*i[3];return[i[0],i[1],t,e]}{const t=null==i[1]?null:this.size[0]*i[1],e=null==i[2]?null:this.size[1]*i[2];return[i[0],t,e,i[3]]}}call(i,t){return s.tidy((()=>{let t=(0,f.un)(i);const e=t.shape;if("channelsFirst"===this.dataFormat){t=s.transpose(t,[0,2,3,1]);const i=this.size[0]*e[2],n=this.size[1]*e[3],r="nearest"===this.interpolation?s.image.resizeNearestNeighbor(t,[i,n]):s.image.resizeBilinear(t,[i,n]);return s.transpose(r,[0,3,1,2])}{const i=this.size[0]*e[1],n=this.size[1]*e[2];return"nearest"===this.interpolation?s.image.resizeNearestNeighbor(t,[i,n]):s.image.resizeBilinear(t,[i,n])}}))}getConfig(){const i={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},t=super.getConfig();return Object.assign(i,t),i}}T.className="UpSampling2D",s.serialization.registerClass(T)}}]);
//# sourceMappingURL=stylist-vendors-360c6e28.56927c9efdbe0126b89e.js.map