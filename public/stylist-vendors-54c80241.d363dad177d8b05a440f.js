"use strict";(self.webpackChunkStylistWidget=self.webpackChunkStylistWidget||[]).push([[2216],{4282:function(e,t,s){s.d(t,{Tb:function(){return h},lD:function(){return u},uK:function(){return o},vY:function(){return a}});var n=s(9495),r=s(31321);class i{constructor(e,t,s,i=-1){this.tensors=e,this.elementShape=t,this.elementDtype=s,null!=e&&e.forEach((e=>{if(s!==e.dtype)throw new Error(`Invalid data types; op elements ${s}, but list elements ${e.dtype}`);(0,r.Wq)(t,e.shape,"TensorList shape mismatch: "),(0,n.keep)(e)})),this.idTensor=(0,n.scalar)(0),this.maxNumElements=i,(0,n.keep)(this.idTensor)}get id(){return this.idTensor.id}copy(){return new i([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(e){this.tensors.forEach((t=>{null!=e&&e.has(t.id)||t.dispose()})),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(e,t,s=-1){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(-1!==s&&this.tensors.length!==s)throw new Error(`Operation expected a list with ${s} elements but got a list with ${this.tensors.length} elements.`);(0,r.Wq)(e,this.elementShape,"TensorList shape mismatch: ");const i=(0,r.E8)(this.elementShape,this.tensors,e);return(0,n.tidy)((()=>{const e=this.tensors.map((e=>(0,n.reshape)(e,i)));return(0,n.stack)(e,0)}))}popBack(e,t){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const s=(0,r.E8)(this.elementShape,this.tensors,e),i=this.tensors.pop();return(0,r.Wq)(i.shape,e,"TensorList shape mismatch: "),(0,n.reshape)(i,s)}pushBack(e){if(e.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if((0,r.Wq)(e.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");(0,n.keep)(e),this.tensors.push(e)}resize(e){if(e<0)throw new Error(`TensorListResize expects size to be non-negative. Got: ${e}`);if(-1!==this.maxNumElements&&e>this.maxNumElements)throw new Error(`TensorListResize input size ${e} is greater maxNumElement ${this.maxNumElements}.`);this.tensors.length=e}getItem(e,t,s){if(s!==this.elementDtype)throw new Error(`Invalid data types; op elements ${s}, but list elements ${this.elementDtype}`);if(e<0||e>this.tensors.length)throw new Error(`Trying to access element ${e} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[e])throw new Error(`element at index ${e} is null.`);(0,r.Wq)(this.tensors[e].shape,t,"TensorList shape mismatch: ");const i=(0,r.E8)(this.elementShape,this.tensors,t);return(0,n.reshape)(this.tensors[e],i)}setItem(e,t){if(t.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(e<0||-1!==this.maxNumElements&&e>=this.maxNumElements)throw new Error(`Trying to set element ${e} in a list with max ${this.maxNumElements} elements.`);(0,r.Wq)(this.elementShape,t.shape,"TensorList shape mismatch: "),(0,n.keep)(t),this.tensors[e]=t}gather(e,t,s){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);(0,r.Wq)(this.elementShape,s,"TensorList shape mismatch: "),e=e.slice(0,this.size());const i=(0,r.E8)(this.elementShape,this.tensors,s);return 0===e.length?(0,n.tensor)([],[0].concat(i)):(0,n.tidy)((()=>{const t=e.map((e=>(0,n.reshape)(this.tensors[e],i)));return(0,n.stack)(t,0)}))}concat(e,t){if(e&&e!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e}`);(0,r.Wq)(this.elementShape,t,"TensorList shape mismatch: ");const s=(0,r.E8)(this.elementShape,this.tensors,t);return 0===this.size()?(0,n.tensor)([],[0].concat(s)):(0,n.tidy)((()=>{const e=this.tensors.map((e=>(0,n.reshape)(e,s)));return(0,n.concat)(e,0)}))}}function o(e,t,s){const o=e.dtype;if(e.shape.length<1)throw new Error(`Tensor must be at least a vector, but saw shape: ${e.shape}`);if(e.dtype!==s)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${s}`);const a=e.shape.slice(1);(0,r.Wq)(a,t,"TensorList shape mismatch: ");const h=(0,n.unstack)(e);return new i(h,t,o)}function a(e,t,s){return new i([],e,t,s)}function h(e,t,s,r){if(t.length!==e.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const o=Math.max(...t);if(null!=r&&-1!==r&&o>=r)throw new Error(`Max index must be < array size (${o}  vs. ${r})`);const a=new i([],s,e.dtype,r),h=(0,n.unstack)(e,0);return t.forEach(((e,t)=>{a.setItem(e,h[t])})),a}function u(e,t,s){let o=0;const a=t.map((e=>(o+=e,o)));if(o!==e.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${o}, and tensor's shape is: ${e.shape}`);const h=e.shape.slice(1),u=(0,r.YI)(h,s),p=0===o?0:e.size/o,l=(0,n.tidy)((()=>{const s=[];e=(0,n.reshape)(e,[1,o,p]);for(let r=0;r<t.length;++r){const i=[0,0===r?0:a[r-1],0],o=[1,t[r],p];s[r]=(0,n.reshape)((0,n.slice)(e,i,o),u)}return e.dispose(),s})),c=new i([],s,e.dtype,t.length);for(let n=0;n<l.length;n++)c.setItem(n,l[n]);return c}},24853:function(e,t,s){s.d(t,{J:function(){return i}});var n=s(9495),r=s(45702);class i{constructor(e,t){this.keyDType=e,this.valueDType=t,this.handle=(0,n.scalar)(0),this.tensorMap=new Map,(0,n.keep)(this.handle)}get id(){return this.handle.id}clearAndClose(){this.tensorMap.forEach((e=>e.dispose())),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}tensorSize(){return r.d(this.size(),"int32")}async import(e,t){this.checkKeyAndValueTensor(e,t);const s=await e.data();return this.tensorMap.forEach((e=>e.dispose())),this.tensorMap.clear(),(0,n.tidy)((()=>{const e=(0,n.unstack)(t),r=s.length,i=e.length;n.util.assert(r===i,(()=>`The number of elements doesn't match, keys has ${r} elements, the values has ${i} elements.`));for(let t=0;t<r;t++){const r=s[t],i=e[t];(0,n.keep)(i),this.tensorMap.set(r,i)}return this.handle}))}async find(e,t){this.checkKeyAndValueTensor(e,t);const s=await e.data();return(0,n.tidy)((()=>{const e=[];for(let n=0;n<s.length;n++){const r=s[n],i=this.findWithDefault(r,t);e.push(i)}return(0,n.stack)(e)}))}findWithDefault(e,t){const s=this.tensorMap.get(e);return null!=s?s:t}checkKeyAndValueTensor(e,t){if(e.dtype!==this.keyDType)throw new Error(`Expect key dtype ${this.keyDType}, but got ${e.dtype}`);if(t.dtype!==this.valueDType)throw new Error(`Expect value dtype ${this.valueDType}, but got ${t.dtype}`)}}},26105:function(e,t,s){s.d(t,{n:function(){return i}});var n=s(9495),r=s(31321);class i{constructor(e,t,s,r,i,o,a){this.name=e,this.dtype=t,this.maxSize=s,this.elementShape=r,this.identicalElementShapes=i,this.dynamicSize=o,this.clearAfterRead=a,this.tensors=[],this.closed_=!1,this.idTensor=(0,n.scalar)(0),(0,n.keep)(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(e){this.tensors.forEach((t=>{null!=e&&e.has(t.tensor.id)||t.tensor.dispose()})),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||e>=this.size())throw new Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);const t=this.tensors[e];if(t.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(t.cleared=!0),t.read=!0,t.tensor}readMany(e){return e.map((e=>this.read(e)))}write(e,t){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||!this.dynamicSize&&e>=this.maxSize)throw new Error(`Tried to write to index ${e}, but array is not resizeable and size is: ${this.maxSize}`);const s=this.tensors[e]||{};if(t.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e},\n          because the value dtype is ${t.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=t.shape),(0,r.Wq)(this.elementShape,t.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${e}.`),s.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been read.`);if(s.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been written.`);s.tensor=t,(0,n.keep)(t),s.written=!0,this.tensors[e]=s}writeMany(e,t){if(e.length!==t.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);e.forEach(((e,s)=>this.write(e,t[s])))}gather(e,t){if(t&&t!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t}`);if(e)e=e.slice(0,this.size());else{e=[];for(let t=0;t<this.size();t++)e.push(t)}if(0===e.length)return(0,n.tensor)([],[0].concat(this.elementShape));const s=this.readMany(e);return(0,r.Wq)(this.elementShape,s[0].shape,"TensorArray shape mismatch: "),(0,n.stack)(s,0)}concat(e){if(e&&e!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e}`);if(0===this.size())return(0,n.tensor)([],[0].concat(this.elementShape));const t=[];for(let n=0;n<this.size();n++)t.push(n);const s=this.readMany(t);return(0,r.Wq)(this.elementShape,s[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${s[0].shape})`),(0,n.concat)(s,0)}scatter(e,t){if(t.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);if(e.length!==t.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const s=Math.max(...e);if(!this.dynamicSize&&s>=this.maxSize)throw new Error(`Max index must be < array size (${s}  vs. ${this.maxSize})`);this.writeMany(e,(0,n.unstack)(t,0))}split(e,t){if(t.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);let s=0;const r=e.map((e=>(s+=e,s)));if(s!==t.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${s}, and tensor's shape is: ${t.shape}`);if(!this.dynamicSize&&e.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e.length}), and the TensorArray is not marked as dynamically resizeable`);const i=0===s?0:t.size/s,o=[];(0,n.tidy)((()=>{t=(0,n.reshape)(t,[1,s,i]);for(let s=0;s<e.length;++s){const a=[0,0===s?0:r[s-1],0],h=[1,e[s],i];o[s]=(0,n.reshape)((0,n.slice)(t,a,h),this.elementShape)}return o}));const a=[];for(let n=0;n<e.length;n++)a[n]=n;this.writeMany(a,o)}}},31321:function(e,t,s){s.d(t,{E8:function(){return o},Wq:function(){return r},YI:function(){return a}});var n=s(9495);function r(e,t,s=""){if("number"!==typeof e&&"number"!==typeof t){n.util.assert(e.length===t.length,(()=>s+` Shapes ${e} and ${t} must match`));for(let r=0;r<e.length;r++){const i=e[r],o=t[r];n.util.assert(i<0||o<0||i===o,(()=>s+` Shapes ${e} and ${t} must match`))}}}function i(e){return"number"!==typeof e&&!e.some((e=>e<0))}function o(e,t,s){let n=a(e,s);const r=!i(n);if(r&&0===t.length)throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${n}`);if(r&&t.forEach((e=>{n=a(e.shape,n)})),!i(n))throw new Error(`Non-fully-defined elementShape: ${n}`);return n}function a(e,t){if("number"===typeof e)return t;if("number"===typeof t)return e;if(e.length!==t.length)throw new Error(`Incompatible ranks during merge: ${e} vs. ${t}`);const s=[];for(let n=0;n<e.length;++n){const r=e[n],i=t[n];if(r>=0&&i>=0&&r!==i)throw new Error(`Incompatible shape during merge: ${e} vs. ${t}`);s[n]=r>=0?r:i}return s}},65576:function(e,t,s){s.d(t,{ox:function(){return E},uW:function(){return x.r}});var n=s(9495),r=s(29720),i=s(6439),o=s(45285);class a{constructor(e={},t={},s={},n={}){this.weightMap=e,this.tensorArrayMap=t,this.tensorListMap=s,this.functionMap=n,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(e,t){return{id:e,frameName:t,iterationId:0}}set currentContext(e){this.contexts!==e&&(this.contexts=e,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const e=[];for(let t=0;t<this.contexts.length-1;t++){const s=this.contexts.slice(0,this.contexts.length-t);e.push(this.contextIdforContexts(s))}e.push(""),this._currentContextIds=e}contextIdforContexts(e){return e?e.map((e=>0===e.id&&0===e.iterationId?"":`${e.frameName}-${e.iterationId}`)).join("/"):""}enterFrame(e){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,e)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const e=Object.assign({},this.contexts[this.contexts.length-1]);e.iterationId+=1,e.id=this.lastId,this.contexts.splice(-1,1,e),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(e){return this.weightMap[e]}addTensorArray(e){this.tensorArrayMap[e.id]=e}getTensorArray(e){return this.tensorArrayMap[e]}addTensorList(e){this.tensorListMap[e.id]=e}getTensorList(e){return this.tensorListMap[e]}dispose(e){for(const t in this.tensorArrayMap)this.tensorArrayMap[t].clearAndClose(e);for(const t in this.tensorListMap)this.tensorListMap[t].clearAndClose(e)}}function h(e,t,s,n){const r=new Set,o=[];let a=null,h=null;const u=new Set,p=Object.keys(e).map((e=>(0,i.Xi)(e)[0]));let l=[];null!=n&&(l=n.map((e=>(0,i.Xi)(e.name)[0])));const f=[...t];for(;f.length>0;){const e=f.pop();(c(e)||d(e)||m(e))&&null==a&&(a=e,h=a.children.map((e=>e.name)).filter((e=>r.has(e)))),r.add(e.name),null==s[e.name]&&(-1===p.indexOf(e.name)&&-1===l.indexOf(e.name)&&(0!==e.inputs.length?e.inputs.forEach((e=>{u.has(e.name)||(u.add(e.name),f.push(e))})):o.push(e.name)))}return{inputs:e,outputs:t,usedNodes:r,missingInputs:o,dynamicNode:a,syncInputs:h}}const u=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"],p=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"],l=["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"];function c(e){return u.indexOf(e.op)>=0}function d(e){return p.indexOf(e.op)>=0}function m(e){return l.indexOf(e.op)>=0}class f{constructor(e,t){this.graph=e,this.parent=t,this.compiledMap=new Map,this._weightMap={},this.SEPERATOR=",",this._functions={},this._functionExecutorMap={},this._outputs=e.outputs,this._inputs=e.inputs,this._initNodes=e.initNodes,this._signature=e.signature,this._functions=e.functions,null!=e.functions&&Object.keys(e.functions).forEach((t=>{this._functionExecutorMap[t]=new f(e.functions[t],this)}))}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(e){const t=Object.keys(e).map((t=>e[t].map((e=>e.id))));this._weightIds=[].concat(...t),this._weightMap=e}set resourceManager(e){this._resourceManager=e}get inputs(){return this._inputs.map((e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0})))}get outputs(){return this._outputs.map((e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0})))}get inputNodes(){return this._inputs.map((e=>e.signatureKey||e.name))}get outputNodes(){return this._outputs.map((e=>{const t=e.signatureKey||e.name;return e.defaultOutput?`${t}:${e.defaultOutput}`:t}))}get functions(){return Object.keys(this._functions).reduce(((e,t)=>(e[t]=this._functions[t].signature,e)),{})}getCompilationKey(e,t){const s=e.map((e=>e.name)).sort(),n=t.map((e=>e.name)).sort();return s.join(this.SEPERATOR)+"--"+n.join(this.SEPERATOR)}compile(e,t){const s=h(e,t,this.weightMap,this._initNodes),{missingInputs:n,dynamicNode:r,syncInputs:o}=s;if(null!=r)throw new Error(`This execution contains the node '${r.name}', which has the dynamic op '${r.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${o}]`);if(n.length>0){const s=t.map((e=>e.name)),r=Object.keys(e);throw new Error(`Cannot compute the outputs [${s}] from the provided inputs [${r}]. Missing the following inputs: [${n}]`)}return function(e,t,s){const{usedNodes:n,inputs:r}=s,o=[],a=Object.keys(r).map((e=>(0,i.Xi)(e)[0])).map((t=>e.nodes[t])),h=e.initNodes;a.forEach((e=>{n.has(e.name)&&o.push(e)})),e.weights.forEach((e=>{n.has(e.name)&&o.push(e)})),null!=h&&h.forEach((e=>{n.has(e.name)&&o.push(e)}));const u=new Set,p=[];for(;o.length>0;){const e=o.pop();u.add(e.name),t[e.name]||p.push(e),e.children.forEach((e=>{!u.has(e.name)&&n.has(e.name)&&e.inputs.every((e=>u.has(e.name)))&&o.push(e)}))}return p}(this.graph,this.weightMap,s)}execute(e,t){e=this.mapInputs(e);const s=Object.keys(e).sort();this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t);const r=s.map((e=>this.graph.nodes[(0,i.Xi)(e)[0]])),h=t.map((e=>(0,i.Xi)(e)[0]));let u=h.map((e=>this.graph.nodes[e]));0===u.length&&(u=this._outputs);const p=this.getCompilationKey(r,u);let l=this.compiledMap.get(p);null==l&&(l=this.compile(e,u),this.compiledMap.set(p,l));const c={},d={};return(0,n.tidy)((()=>{const s=new a(this.weightMap,c,d,this.functionExecutorMap),r=Object.assign({},this.weightMap);Object.keys(e).forEach((t=>{const[s,n]=(0,i.Xi)(t),o=[];o[n]=e[t],r[s]=o}));const u=this.getFrozenTensorIds(r),p={};for(let e=0;e<l.length;e++){const t=l[e];if(!r[t.name]){const e=(0,o.j)(t,r,s,this._resourceManager);if(n.util.isPromise(e))throw new Error(`The execution of the op '${t.op}' returned a promise. Please use model.executeAsync() instead.`);r[t.name]=e,this.checkTensorForDisposal(t.name,t,r,s,u,h,p)}}return null==this.parent&&s.dispose(u),t.map((e=>(0,i.cS)(e,r,s)))}))}getFrozenTensorIds(e){const t=[].concat.apply([],Object.keys(e).map((t=>e[t])).map((e=>e.map((e=>e.id)))));return new Set(t)}checkTensorForDisposal(e,t,s,n,r,o,a){"control"!==t.category&&-1===o.indexOf(e)&&(s[e].forEach((e=>{null!=e&&(a[e.id]=(a[e.id]||0)+t.children.length)})),t.inputs.forEach((e=>{if("control"!==e.category){const t=(0,i.CC)(e.name,s,n);null!=t&&t.forEach((e=>{if(e&&!e.kept&&!r.has(e.id)){const t=a[e.id];1===t?(e.dispose(),delete a[e.id]):null!=t&&a[e.id]--}}))}})))}async executeAsync(e,t){return this._executeAsync(e,t)}async _executeAsync(e,t,s=!1,n={},r={}){s||(e=this.mapInputs(e),this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t));const o=new a(this.weightMap,n,r,this.functionExecutorMap),h=await this.executeWithControlFlow(e,o,t,s),u=t.map((e=>(0,i.cS)(e,h,o))),p=u.map((e=>e.id)),l=Object.keys(e).map((t=>e[t].id)),c=new Set([...p,...l,...this.weightIds]);return Object.keys(h).forEach((e=>{h[e].forEach((e=>{!e||e.kept||e.isDisposed||c.has(e.id)||e.dispose()}))})),null==this.parent&&o.dispose(c),u}async executeFunctionAsync(e,t,s){const n=e.reduce(((e,t,s)=>(e[this.inputs[s].name]=t,e)),{});return this._executeAsync(n,this.outputNodes,!0,t,s)}async executeWithControlFlow(e,t,s,n){const r=Object.keys(e),o=r.map((e=>this.graph.nodes[(0,i.Xi)(e)[0]])),a=s.map((e=>(0,i.Xi)(e)[0]));let u=a.map((e=>this.graph.nodes[e]));0===u.length&&(u=this._outputs);const{usedNodes:p,missingInputs:l,dynamicNode:d,syncInputs:m}=h(e,u,this.weightMap,this._initNodes),f=[...o,...this.graph.weights,...this._initNodes||[]].map((e=>({node:e,contexts:t.currentContext}))),y=Object.assign({},this.weightMap);Object.keys(e).forEach((t=>{const[s,n]=(0,i.Xi)(t),r=[];r[n]=e[t],y[s]=r}));const g={},T=this.getFrozenTensorIds(y),w={};for(;f.length>0;){const e=this.processStack(o,f,t,y,w,T,a,g,p);await Promise.all(e)}const E=u.filter((e=>!c(e)&&!(0,i.cS)(e.name,y,t))).map((e=>e.name));if(E.length>0){let e="";throw null!=d&&(e=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${m}]`),new Error(`Cannot compute the outputs [${E}] from the provided inputs [${r}]. Consider providing the following inputs: [${l}]. ${e}`)}return y}processStack(e,t,s,r,a,h,u,p,l){const c=[];for(;t.length>0;){const e=t.pop();s.currentContext=e.contexts;let d="";if("Enter"===e.node.op&&(0,i.Zg)("isConstant",e.node,r,s)&&([d]=(0,i.lz)(e.node.name,s)),null==r[e.node.name]){const m=(0,o.j)(e.node,r,s,this._resourceManager);d||([d]=(0,i.lz)(e.node.name,s));const f=s.currentContext;n.util.isPromise(m)?c.push(m.then((n=>(r[d]=n,s.currentContext=f,this.checkTensorForDisposal(d,e.node,r,s,h,u,p),this.processChildNodes(e.node,t,s,r,a,l),n)))):(r[d]=m,this.checkTensorForDisposal(d,e.node,r,s,h,u,p),this.processChildNodes(e.node,t,s,r,a,l))}else this.processChildNodes(e.node,t,s,r,a,l)}return c}processChildNodes(e,t,s,n,r,o){e.children.forEach((e=>{const[a]=(0,i.lz)(e.name,s);!r[a]&&o.has(e.name)&&("Merge"===e.op?e.inputNames.some((e=>!!(0,i.cS)(e,n,s)))&&(r[a]=!0,t.push({contexts:s.currentContext,node:e})):e.inputNames.every((e=>!!(0,i.cS)(e,n,s)))&&(r[a]=!0,t.push({contexts:s.currentContext,node:e})))}))}dispose(){Object.keys(this.weightMap).forEach((e=>this.weightMap[e].forEach((e=>e.dispose()))))}checkInputShapeAndType(e){Object.keys(e).forEach((t=>{const s=e[t],[r]=(0,i.Xi)(t),o=this.graph.nodes[r];if(o.attrParams.shape&&o.attrParams.shape.value){const e=o.attrParams.shape.value,t=e.length===s.shape.length&&s.shape.every(((t,s)=>-1===e[s]||e[s]===t));n.util.assert(t,(()=>`The shape of dict['${o.name}'] provided in model.execute(dict) must be [${e}], but was [${s.shape}]`))}o.attrParams.dtype&&o.attrParams.dtype.value&&n.util.assert(s.dtype===o.attrParams.dtype.value,(()=>`The dtype of dict['${o.name}'] provided in model.execute(dict) must be ${o.attrParams.dtype.value}, but was ${s.dtype}`))}))}mapInputs(e){const t={};for(const s in e)if(null!=this._signature&&null!=this._signature.inputs&&null!=this._signature.inputs[s]){t[this._signature.inputs[s].name]=e[s]}else t[s]=e[s];return t}checkInputs(e){const t=Object.keys(e).filter((e=>{const[t]=(0,i.Xi)(e);return null==this.graph.nodes[t]}));if(t.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${t}] that are not part of graph`)}mapOutputs(e){return e.map((e=>{if(null!=this._signature&&null!=this._signature.outputs&&null!=this._signature.outputs[e]){return this._signature.outputs[e].name}return e}),{})}checkOutputs(e){e.forEach((e=>{const[t]=(0,i.Xi)(e);if(!this.graph.nodes[t])throw new Error(`The output '${e}' is not found in the graph`)}))}}class y{constructor(e={},t={}){this.hashTableNameToHandle=e,this.hashTableMap=t}addHashTable(e,t){this.hashTableNameToHandle[e]=t.handle,this.hashTableMap[t.id]=t}getHashTableHandleByName(e){return this.hashTableNameToHandle[e]}getHashTableById(e){return this.hashTableMap[e]}dispose(){for(const e in this.hashTableMap)this.hashTableMap[e].clearAndClose(),delete this.hashTableMap[e];for(const e in this.hashTableNameToHandle)this.hashTableNameToHandle[e].dispose(),delete this.hashTableNameToHandle[e]}}const g="?tfjs-format=file",T="model.json";class w{constructor(e,t={}){this.modelUrl=e,this.loadOptions=t,this.version="n/a",null==t&&(this.loadOptions={}),this.resourceManager=new y}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}findIOHandler(){const e=this.modelUrl;if(null!=e.load)this.handler=e;else if(null!=this.loadOptions.requestInit)this.handler=n.io.browserHTTPRequest(e,this.loadOptions);else{const t=n.io.getLoadHandlers(e,this.loadOptions);if(0===t.length)t.push(n.io.browserHTTPRequest(e,this.loadOptions));else if(t.length>1)throw new Error(`Found more than one (${t.length}) load handlers for URL '${[e]}'`);this.handler=t[0]}}async load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const e=await this.handler.load();return this.loadSync(e)}loadSync(e){this.artifacts=e;const t=this.artifacts.modelTopology;let s;s=null!=this.artifacts.userDefinedMetadata&&null!=this.artifacts.userDefinedMetadata.signature?this.artifacts.userDefinedMetadata.signature:this.artifacts.signature,this.signature=s,this.version=`${t.versions.producer}.${t.versions.minConsumer}`;const i=n.io.decodeWeights(this.artifacts.weightData,this.artifacts.weightSpecs);if(this.executor=new f(r.bo.Instance.transformGraph(t,this.signature)),this.executor.weightMap=this.convertTensorMapToTensorsMap(i),this.executor.resourceManager=this.resourceManager,null!=e.modelInitializer&&null!=e.modelInitializer.node){const t=r.bo.Instance.transformGraph(e.modelInitializer);this.initializer=new f(t),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializer.executeAsync({},[])}return!0}async save(e,t){if("string"===typeof e){const t=n.io.getSaveHandlers(e);if(0===t.length)throw new Error(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw new Error(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}if(null==e.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return e.save(this.artifacts)}predict(e,t){return this.execute(e,this.outputNodes)}normalizeInputs(e){if(!(e instanceof n.Tensor)&&!Array.isArray(e))return e;if((e=Array.isArray(e)?e:[e]).length!==this.inputNodes.length)throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${e.length} input tensors.`);return this.inputNodes.reduce(((t,s,n)=>(t[s]=e[n],t)),{})}normalizeOutputs(e){return e=e||this.outputNodes,Array.isArray(e)?e:[e]}execute(e,t){e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const s=this.executor.execute(e,t);return s.length>1?s:s[0]}async executeAsync(e,t){e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const s=await this.executor.executeAsync(e,t);return s.length>1?s:s[0]}convertTensorMapToTensorsMap(e){return Object.keys(e).reduce(((t,s)=>(t[s]=[e[s]],t)),{})}dispose(){this.executor.dispose(),this.initializer&&this.initializer.dispose(),this.resourceManager.dispose()}}async function E(e,t={}){if(null==e)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==t&&(t={}),t.fromTFHub&&null==e.load&&(e.endsWith("/")||(e+="/"),e=`${e}${T}${g}`);const s=new w(e,t);return await s.load(),s}s(23470);var x=s(96820)},92737:function(e,t,s){var n,r;s.d(t,{p:function(){return n}}),function(e){e[e.DT_INVALID=0]="DT_INVALID",e[e.DT_FLOAT=1]="DT_FLOAT",e[e.DT_DOUBLE=2]="DT_DOUBLE",e[e.DT_INT32=3]="DT_INT32",e[e.DT_UINT8=4]="DT_UINT8",e[e.DT_INT16=5]="DT_INT16",e[e.DT_INT8=6]="DT_INT8",e[e.DT_STRING=7]="DT_STRING",e[e.DT_COMPLEX64=8]="DT_COMPLEX64",e[e.DT_INT64=9]="DT_INT64",e[e.DT_BOOL=10]="DT_BOOL",e[e.DT_QINT8=11]="DT_QINT8",e[e.DT_QUINT8=12]="DT_QUINT8",e[e.DT_QINT32=13]="DT_QINT32",e[e.DT_BFLOAT16=14]="DT_BFLOAT16",e[e.DT_FLOAT_REF=101]="DT_FLOAT_REF",e[e.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",e[e.DT_INT32_REF=103]="DT_INT32_REF",e[e.DT_UINT8_REF=104]="DT_UINT8_REF",e[e.DT_INT16_REF=105]="DT_INT16_REF",e[e.DT_INT8_REF=106]="DT_INT8_REF",e[e.DT_STRING_REF=107]="DT_STRING_REF",e[e.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",e[e.DT_INT64_REF=109]="DT_INT64_REF",e[e.DT_BOOL_REF=110]="DT_BOOL_REF",e[e.DT_QINT8_REF=111]="DT_QINT8_REF",e[e.DT_QUINT8_REF=112]="DT_QUINT8_REF",e[e.DT_QINT32_REF=113]="DT_QINT32_REF",e[e.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF"}(n||(n={})),function(e){let t;!function(e){e[e.LEGACY=0]="LEGACY",e[e.V1=1]="V1",e[e.V2=2]="V2"}(t=e.CheckpointFormatVersion||(e.CheckpointFormatVersion={}))}(r||(r={}))}}]);
//# sourceMappingURL=stylist-vendors-54c80241.d363dad177d8b05a440f.js.map