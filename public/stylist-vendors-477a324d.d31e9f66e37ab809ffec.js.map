{"version":3,"file":"stylist-vendors-477a324d.d31e9f66e37ab809ffec.js","mappings":"iKAkBA,MAIaA,GAAe,E,SAAA,IAAiB,CACzCC,UALkB,wBAMlBC,gBALyB,6CAMzBC,MAAO,SAEEC,EAAqB,CAC9BC,WAAY,EAAAC,aACZC,YAAa,QACbC,WAAYR,E,qECZhB,MACaS,GAAQ,E,SAAA,IAAgB,CAAER,UADxB,0BAC2CE,MAAO,SACpDO,EAAc,CACvBL,WAAY,EAAAM,MACZJ,YAAa,QACbC,WAAYC,E,qECLT,MAIMG,GAAY,E,SAAA,IAAiB,CAAEX,UAJlB,wBAIyCC,gBAHlC,0CAGsEC,MAAO,SACjGU,EAAkB,CAC3BR,WAAY,EAAAS,UACZP,YAAa,QACbC,WAAYI,E,qECRhB,MACaG,GAAa,E,SAAA,IAAgB,CAAEd,UADxB,+BAEPe,EAAmB,CAC5BX,WAAY,EAAAY,WACZV,YAAa,QACbC,WAAYO,E,sGCyCT,MAAMG,EAAe,CACxBb,WAAY,EAAAc,OACZZ,YAAa,QACbC,WA/CG,SAAgBY,GACnB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,KAAEI,EAAI,UAAEC,EAAS,QAAEC,GAAYJ,EAC/BK,EAAQJ,EAAEK,MAAMC,OAChBC,EAAc,EAAAC,aAAA,mBAAgC,CAACP,GAAOG,GAC5D,IAAIK,EAAYT,EACG,MAAfO,IACAE,GAAY,OAAU,CAAEZ,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEW,KAAMH,MAEnE,MAAMI,EAAe,EAAAH,aAAA,iBAA8B,EAAGJ,GAAO,GAC7D,GAAIO,IAAiBP,EAAQ,EACzB,MAAM,IAAIQ,MAAM,kDAAkDZ,EAAEK,MAAMC,OAAS,kBAC/DL,KAExB,MAAMY,EAAOJ,EAAUJ,MAAMM,GAC7B,IAAIG,GAAS,OAAS,CAAEjB,OAAQ,CAAEG,EAAGS,GAAaX,YAGlD,IAAK,IAAIiB,EAAI,EAAGA,GAAKC,KAAKC,KAAKD,KAAKE,KAAKL,IAAS,EAAGE,IAAK,CACtD,MAAMI,EAAU,IAAI,IAAcV,EAAUJ,OAAO,EAAOF,GACpDiB,EAAcD,EAAQE,mBAAmBN,GACzCO,EAAaR,EACnBA,EACIhB,EAAQyB,gBAAgBJ,EAAS,CAACL,GAASA,EAAOnC,MAAOyC,GAC7DtB,EAAQ0B,8BAA8BF,EAC1C,CAGA,GAAIpB,EAAW,CACX,MAAMiB,EAAU,IAAI,IAAcV,EAAUJ,MAAOH,EAAWC,GACxDmB,EAAaR,EACnBA,EAAShB,EAAQyB,gBAAgBJ,EAAS,CAACL,GAASA,EAAOnC,OAC3DmB,EAAQ0B,8BAA8BF,EAC1C,CACA,GAAmB,MAAff,EAAqB,CACrB,MAAMkB,EAAqB,EAAAjB,aAAA,uBAAoCD,GACzDmB,GAA0B,OAAU,CAAE7B,OAAQ,CAAEG,EAAGc,GAAUhB,UAASC,MAAO,CAAEW,KAAMe,KAG3F,OAFA3B,EAAQ0B,8BAA8BV,GACtChB,EAAQ0B,8BAA8Bf,GAC/BiB,CACX,CACA,OAAOZ,CACX,E,2FC5CO,MAUMa,EAAY,CACrB9C,WAAY,EAAA+C,IACZ7C,YAAa,QACbC,WAbgBY,IAChB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,YAAEgC,EAAW,KAAEC,EAAI,MAAEC,EAAK,KAAEC,GAASjC,EACrCoB,GAAU,IAAAc,OAAMC,QAAQ,4BAC1B,IAAI,IAAiBlC,EAAEK,MAAOwB,EAAaC,EAAMC,EAAOC,GACxD,IAAI,IAAWhC,EAAEK,MAAOwB,EAAaC,EAAMC,EAAOC,GACtD,OAAOlC,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAIA,EAAErB,MAAM,E,2FCMlD,MAAMwD,EAAa,CACtBtD,WAAY,EAAAuD,KACZrD,YAAa,QACbC,WAhBG,SAAcY,GACjB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,EAAEI,GAAMH,EACRwC,EAAW,IAAIrC,EAAEK,SAAUL,EAAEK,OAC7BiC,EAAQ,EAAAC,KAAA,cAAmBvC,EAAEK,OAC7BmC,GAAO,OAAQ,CAAE3C,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEM,MAAO,CAACiC,MAC1DnB,EAAU,IAAI,IAAYmB,GAC1BG,EAAM3C,EAAQyB,gBAAgBJ,EAAS,CAACqB,GAAOA,EAAK7D,OACpD+D,GAAM,OAAQ,CAAE7C,OAAQ,CAAEG,EAAGyC,GAAO3C,UAASC,MAAO,CAAEM,MAAOgC,KAGnE,OAFAvC,EAAQ0B,8BAA8BgB,GACtC1C,EAAQ0B,8BAA8BiB,GAC/BC,CACX,E,gFCLO,MAAMC,EAA+B,CACxC9D,WAAY,EAAA+D,uBACZ7D,YAAa,QACbC,WAXG,SAAgCY,GACnC,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,GAAE6C,GAAOhD,GACZ,QAAEiD,EAAO,IAAEC,EAAG,YAAEC,GAAgBjD,EAChCkD,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAO2C,EAAaF,EAAS,EAAmBC,GAC5F5B,EAAU,IAAI,KAAuB8B,GAC3C,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6C,GAAK,UACrD,E,gFCDO,MAAMK,EAAoB,CAC7BrE,WAAY,EAAAsE,YACZpE,YAAa,QACbC,WATG,SAAqBY,GACxB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEwD,EAAC,EAAEC,GAAMxD,GACX,WAAEyD,EAAU,WAAEC,GAAexD,EACnC,OAAO,OAAgB,CAAEqD,IAAGC,IAAGC,aAAYC,aAAYzD,WAC3D,E,uGCIO,SAAS0D,EAAQ5D,GACpB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,KAAE6D,EAAI,KAAEC,GAAS7D,EACjB8D,EAAc7D,EAAQ8D,eAAeH,EAAKpD,MAAO,aACjDmD,EAAU1D,EAAQ+D,QAAQC,IAAIH,EAAYI,QAC1CC,GAAiB,OAAS,CAAEnE,OAAQ,CAAEG,EAAGyD,GAAQ3D,YACjDmE,GAAiB,OAAS,CAAEpE,OAAQ,CAAEG,EAAG0D,GAAQ5D,YAEvD,OADA0D,EAAQU,mBAAqB,CAAET,KAAMO,EAAgBN,KAAMO,GACpDN,CACX,CACO,MAAMQ,EAAgB,CACzBtF,WAAY,EAAAuF,QACZrF,YAAa,QACbC,WAAYwE,E,sECtBhB,MAOaa,GAAY,E,SAAA,IAAiB,CAAE5F,UAPzB,sCAOgDC,gBANzC,4HAM6EC,MAAO,SACjG2F,EAAkB,CAC3BzF,WAAY,EAAA0F,UACZxF,YAAa,QACbC,WAAYqF,E,sECXhB,MACaG,GAAQ,E,SAAA,IAAgB,CAAE/F,UADzB,yBAEDgG,EAAc,CACvB5F,WAAY,EAAA6F,MACZ3F,YAAa,QACbC,WAAYwF,E,sECNhB,MAAMG,EAA0B,EAAAC,aAAA,wBAezB,MAAMC,EAA4B,CACrChG,WAAY,EAAAiG,oBACZ/F,YAAa,QACbC,WAjBG,SAA6BY,GAChC,EAAAY,aAAA,KAAkB,iGAElB,MAAM,OAAEX,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,MAAEmF,EAAK,OAAEC,GAAWnF,GACpB,cAAEoF,EAAa,aAAEC,EAAY,eAAEC,EAAc,mBAAEC,GAAuBrF,EACtEsF,EAAYvF,EAAQwF,SAASP,EAAMhB,QACnCwB,EAAazF,EAAQwF,SAASN,EAAOjB,SACrC,gBAAEyB,EAAe,aAAEC,GAAiBd,EAAwBU,EAAWE,EAAYN,EAAeC,EAAcC,EAAgBC,GACtI,MAAO,CACHtF,EAAQ8D,eAAe,CAAC4B,EAAgBlF,QAAS,QAAS,IAAIoF,WAAWF,IACzE1F,EAAQ8D,eAAe,GAAI,QAAS,IAAI8B,WAAW,CAACD,KAE5D,E,2FCSO,MAAME,EAA8B,CACvC9G,WAAY,EAAA+G,sBACZ7G,YAAa,QACbC,WAxBG,SAA+BY,GAClC,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,OAAE6F,GAAWhG,GAChB,QAAEiD,EAAO,IAAEC,EAAG,UAAE+C,EAAS,gBAAEC,GAAoBhG,EACrD,IAAIiG,EAAaF,EACC,MAAdE,IACAA,EAAa,CAAC,EAAG,IAErB,EAAAzD,KAAA,OAAY,EAAA/B,aAAA,+BAA4CsC,EAASkD,IAAa,IAC1E,gFAAkBlD,oBAA0BkD,OAChD,MAAM/C,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwF,EAAOxF,MAAOyC,EAASkD,EAAYjD,EAAKgD,GAAiB,GAClH,IAAI5E,EAQJ,OALIA,GAFA,IAAAc,OAAMC,QAAQ,6BAA+Be,EAASgD,aAAe,GACrEhD,EAASiD,YAAcjD,EAASkD,aAAe,EACrC,IAAI,IAA6BlD,GAGjC,IAAI,IAAuBA,GAElCnD,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6F,GAAS,UACzD,E,iFCbO,MAAMO,EAAe,CACxBvH,WAAY,EAAAwH,OACZtH,YAAa,QACbC,WAXG,SAAgBY,GACnB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,OAAE6F,GAAWhG,GAChB,QAAEiD,EAAO,IAAEC,EAAG,UAAE+C,GAAc/F,EAC9BkD,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwF,EAAOxF,MAAOyC,EAASgD,EAAW/C,GACrF5B,EAAU,IAAI,IAAc8B,GAClC,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6F,GAAS,UACzD,E,sECHA,MAiCaS,GAAW,E,SAAA,IAAiB,CAAE7H,UAjC3B,uPAiC+CC,gBAtBxC,sgBAsByEC,MAAO,UAC1F4H,EAAiB,CAC1B1H,WAAY,EAAA2H,SACZzH,YAAa,QACbC,WAAYsH,E,iFCzChB,MAAMG,EAAM,KAA0B,uBAGzBC,GAAM,QAAgB,CAAEjI,UAAWgI,IACnCE,EAAY,CACrB9H,WAAY,EAAA+H,IACZ7H,YAAa,QACbC,WAAY0H,E,4FCRT,MAAMG,EACT,WAAAC,CAAYC,GACRC,KAAKC,cAAgB,CAAC,KACtB,MAAMC,GAAO,UACNC,EAAQC,GAAUL,EACzBC,KAAKD,YAAcA,EACnBC,KAAKK,SAAW,wNAM+BD,QAAYD,kCAE3CD,EAAKI,0WAezB,EC7BG,MAAMC,EACT,WAAAT,CAAYC,GACRC,KAAKC,cAAgB,CAAC,KACtBD,KAAKQ,cAAe,EACpBR,KAAKS,cAAe,EACpB,MAAMP,GAAO,UACNC,EAAQC,GAAUL,EACzBC,KAAKD,YAAcA,EACnBC,KAAKK,SAAW,0bAeMD,QAAYD,oCACdD,EAAKI,ybAgBvBJ,EAAKQ,iCAGX,ECvCG,MAAMC,EAAmB,CAC5B9I,WAAY,EAAA+I,WACZ7I,YAAa,QACbC,WAGJ,SAAoBY,GAChB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,EACnC,IAAI,OAAEiI,GAAWhI,EACjB,MAAM,YAAEiI,GAAgB/H,EAClBgI,EAAwC,qBAAvB,kBACnBF,aAAkBG,iBAChBC,EAAwC,qBAAvB,kBACnBJ,aAAkBK,kBACfd,EAAOD,GAAUY,EACpB,CACIF,EAAOM,WACPN,EAAOO,aAEX,CAACP,EAAOT,MAAOS,EAAOV,QACpBkB,EAAW,CAAClB,EAAQC,GACpB/E,EAAW,CAAC8E,EAAQC,EAAOU,IAC7BG,GAAWF,KACgB,MAAvBO,IACAA,EAAsBC,SAASC,cAAc,UAAUC,WAAW,OAEtEH,EAAoBI,OAAOtB,MAAQA,EACnCkB,EAAoBI,OAAOvB,OAASA,EACpCmB,EAAoBK,UAAUd,EAAQ,EAAG,EAAGT,EAAOD,GACnDU,EAASS,EAAoBI,QAEjC,MAAME,EAAkB9I,EAAQ8D,eAAeyE,EAAU,SAEzDvI,EAAQ+D,QAAQC,IAAI8E,EAAgB7E,QAAQ8E,MAAQ,KAAaC,OACjEhJ,EAAQiJ,MAAMC,yBAAyBlJ,EAAQmJ,WAAWL,EAAgB7E,QAAS8D,GACnF,MAAM1G,GAAU,IAAAc,OAAMC,QAAQ,cAC1B,IAAIqF,EAAwBlF,GAC5B,IAAIwE,EAAkBxE,GACpBI,EAAM3C,EAAQyB,gBAAgBJ,EAAS,CAACyH,GAAkB,SAEhE,OADA9I,EAAQoJ,YAAYN,EAAgB7E,QAC7BtB,CACX,GApCA,IAAI6F,C,iFCRG,MAOMa,EAAsB,CAC/BtK,WAAY,EAAAuK,cACZrK,YAAa,QACbC,WAV0BY,IAC1B,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,MAAEyJ,EAAK,MAAEtE,EAAK,OAAEuE,GAAWzJ,GAC3B,SAAE0J,EAAQ,OAAEC,EAAM,mBAAEC,GAAuB1J,EAC3CoB,EAAU,IAAI,IAAqBkI,EAAMhJ,MAAO0E,EAAM1E,MAAOkJ,EAAUC,EAAQC,GACrF,OAAO3J,EAAQyB,gBAAgBJ,EAAS,CAACkI,EAAOtE,EAAOuE,GAAS,UAAU,E,uGCYvE,MAAMI,EAAoB,CAC7B7K,WAAY,EAAA8K,YACZ5K,YAAa,QACbC,WAlBG,SAAqBY,GACxB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,GAAEiD,EAAE,MAAE+G,EAAK,OAAElC,GAAW7H,EACxBG,EAAI4J,GACV,QAAiB,CAACA,EAAOlC,GAAS,eAClC,MAAM,WAAEmC,EAAU,QAAE/G,EAAO,IAAEC,EAAG,gBAAEgD,GAAoBhG,EAChDkD,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwJ,EAAY/G,EAAS,EAAmBC,EAAKgD,GAEhG+D,EAA0B,IAAI,IAAc7G,EAAU,OADvC,GAEf8G,EAAmBjK,EAAQyB,gBAAgBuI,EAAyB,CAAC9J,GAAIA,EAAErB,OAC3EqL,EAAyB,IAAI,IAAyB/G,GACtDnC,EAAShB,EAAQyB,gBAAgByI,EAAwB,CAACnH,EAAIkH,GAAmB/J,EAAErB,OAEzF,OADAmB,EAAQ0B,8BAA8BuI,GAC/BjJ,CACX,E,uGCEO,MAAMmJ,EAAgB,CACzBpL,WAAY,EAAAqL,QACZnL,YAAa,QACbC,WAnBG,SAAiBY,GACpB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACd,QAAiBG,EAAG,WACpB,MAAM,WAAE6J,EAAU,QAAE/G,EAAO,IAAEC,EAAG,gBAAEgD,GAAoBhG,EAEtD,EAAAwC,KAAA,OAAY,EAAA/B,aAAA,+BAA4CsC,EADtC,IAC2D,IACzE,wEAAeA,wBACnB,MAAMG,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwJ,EAAY/G,EAHnD,EAGuEC,EAAKgD,GAC9F,GAA6B,IAAzB9C,EAASkH,aAA+C,IAA1BlH,EAASmH,cACvC,EAAA7H,KAAA,YAAiBU,EAASoH,QAASpH,EAASZ,UAC5C,OAAO,OAAS,CAAExC,OAAQ,CAAEG,KAAKF,YAErC,MAAMwK,EAAiB,IAAI,IAAcrH,EAAU,OAAO,GAC1D,OAAOnD,EAAQyB,gBAAgB+I,EAAgB,CAACtK,GAAIA,EAAErB,MAC1D,E,4FChBA,MAEM4L,EAAa,8EAIf,KAAoB,uBAGXC,GAAM,QAAiB,CAChC/L,UAVQ,iDAWRC,gBAAiB6L,IAERE,EAAY,CACrB5L,WAAY,EAAA6L,IACZ3L,YAAa,QACbC,WAAYwL,E,iFCVT,MAAMG,EAAiB,CAC1B9L,WAAY,EAAA+L,SACZ7L,YAAa,QACbC,WAVG,SAAkBY,GACrB,MAAM,QAAEE,EAAO,MAAEC,GAAUH,GACrB,MAAEiL,EAAK,KAAEC,EAAI,IAAEC,GAAQhL,EAEvBiL,GAAU,QAAgBH,EAAOC,EAAMC,GAC7C,OAAOjL,EAAQ8D,eAAe,CAACoH,EAAQ1K,QAAS,UAAW0K,EAC/D,E,kHCHA,MAAMC,EAAU,KAAoB,0BAG9BC,EAAiB,0GAInB,KAA2B,uBAGlBC,GAAU,QAAiB,CACpC1M,UAAWwM,EACXvM,gBAAiBwM,EACjBE,cAAe,OAENC,EAAgB,CACzBxM,WAAY,EAAAyM,QACZvM,YAAa,QACbC,WAAYmM,E,uGCwBT,MAAMI,EAAiB,CAC1B1M,WAAY,EAAA2M,SACZzM,YAAa,QACbC,WA9CG,SAAkBY,GACrB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,QAAEyL,GAAY5L,GACjB,KAAEI,EAAI,UAAEyL,GAAc3L,EACtB4L,EAAa,EAAApJ,KAAA,eAAoBtC,EAAMD,EAAEK,OAAO,GAChDuL,EAAY,EAAApL,aAAA,sCAAmDR,EAAGyL,EAASE,EAAYD,GACvFG,EAAc,EAAAtJ,KAAA,cAAmBkJ,EAAQpL,OACzCyL,EAAY,GACZC,GAAW,OAAQ,CACrBlM,OAAQ,CAAEG,KACVF,UACAC,MAAO,CACHM,MAAO,CACHuL,EAAUI,UAAWJ,EAAUK,UAAWL,EAAUM,QACpDN,EAAUO,cAIhBC,GAAe,OAAQ,CACzBvM,OAAQ,CAAEG,EAAGyL,GACb3L,UACAC,MAAO,CAAEM,MAAO,CAACuL,EAAUI,UAAWH,EAAcD,EAAUI,cAElEF,EAAUO,KAAKN,GACfD,EAAUO,KAAKD,GACf,MAAME,EAAqB,CACvBV,EAAUI,UAAWJ,EAAUK,UAAWJ,EAAcD,EAAUI,UAClEJ,EAAUO,WAEd,GAAIrM,EAAQyM,mBAAmB,CAACvM,EAAGyL,KAAyB,WAAZzL,EAAErB,MAAoB,CAClE,MAAM6N,EAAa1M,EAAQ2M,WAAWL,GAChCM,EAAO5M,EAAQ2M,WAAWV,GAC1BY,GAAS,QAAgBD,EAAMF,EAAYF,GAEjD,OADAR,EAAUc,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KACtD/M,EAAQ8D,eAAegI,EAAU7E,YAAa4F,EAAOhO,MAAOgO,EAAOG,OAC9E,CACA,MAAM3L,EAAU,IAAI,IAAc4K,EAAS1L,MAAOiM,GAC5C7J,EAAM3C,EAAQyB,gBAAgBJ,EAAS,CAAC4K,EAAUK,GAAeL,EAASpN,OAChFmN,EAAUO,KAAK5J,GACf,MAAMsK,GAAW,OAAQ,CAAElN,OAAQ,CAAEG,EAAGyC,GAAO3C,UAASC,MAAO,CAAEM,MAAOuL,EAAU7E,eAElF,OADA+E,EAAUc,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KACtDE,CACX,E,kHCzCA,MAAMC,EAAU,KAAoB,0BAG9BC,EAAiB,0GAInB,KAA2B,uBAGlBC,GAAU,QAAiB,CACpCzO,UAAWuO,EACXtO,gBAAiBuO,EACjB7B,cAAe,MAEN+B,EAAgB,CACzBtO,WAAY,EAAAuO,QACZrO,YAAa,QACbC,WAAYkO,E,mJChBhB,MAAMG,EAAM,gBACL,SAASC,EAAS1N,GACrB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,EAAEwD,EAAC,EAAEC,GAAMxD,EACXlB,EAAQ,EAAA6B,aAAA,WAAwB4C,EAAEzE,MAAO0E,EAAE1E,OACjD,GAAgB,cAAZyE,EAAEzE,MAAuB,CACzB,MAAM4O,EAAQzN,EAAQ+D,QAAQC,IAAIV,EAAEW,QAC9ByJ,EAAQ1N,EAAQ+D,QAAQC,IAAIT,EAAEU,QAC9B0J,EAAc,IAAI,IAAuB,IAAsCC,KAAMtK,EAAE/C,MAAOgD,EAAEhD,OAChGsN,EAAc,IAAI,IAAuB,IAAsCC,KAAMxK,EAAE/C,MAAOgD,EAAEhD,OAChGR,EAAS,CACX,CACIkE,OAAQwJ,EAAMrJ,mBAAmBT,KAAKM,OACtCpF,MAAO4O,EAAMrJ,mBAAmBT,KAAK9E,MACrC0B,MAAO+C,EAAE/C,OAEb,CACI0D,OAAQwJ,EAAMrJ,mBAAmBR,KAAKK,OACtCpF,MAAO4O,EAAMrJ,mBAAmBR,KAAK/E,MACrC0B,MAAO+C,EAAE/C,OAEb,CACI0D,OAAQyJ,EAAMtJ,mBAAmBT,KAAKM,OACtCpF,MAAO6O,EAAMtJ,mBAAmBT,KAAK9E,MACrC0B,MAAOgD,EAAEhD,OAEb,CACI0D,OAAQyJ,EAAMtJ,mBAAmBR,KAAKK,OACtCpF,MAAO6O,EAAMtJ,mBAAmBR,KAAK/E,MACrC0B,MAAOgD,EAAEhD,QAGXwN,EAAW/N,EAAQyB,gBAAgBkM,EAAa5N,EAAQ,WACxDiO,EAAWhO,EAAQyB,gBAAgBoM,EAAa9N,EAAQ,WACxDkO,GAAgB,OAAQ,CAAElO,OAAQ,CAAE4D,KAAMoK,EAAUnK,KAAMoK,GAAYhO,YAI5E,OAHAA,EAAQ0B,8BAA8BqM,GACtC/N,EAAQ0B,8BAA8BsM,GAE/BC,CACX,CACA,GAAIjO,EAAQyM,mBAAmB,CAACnJ,EAAGC,IAAK,CACpC,MAAMkK,EAAQzN,EAAQ+D,QAAQC,IAAIV,EAAEW,QAC9ByJ,EAAQ1N,EAAQ+D,QAAQC,IAAIT,EAAEU,SAC7BiK,EAAW3L,IAAY,QAAYe,EAAE/C,MAAOgD,EAAEhD,MAAOkN,EAAMT,OAAQU,EAAMV,OAAQnO,GAClF+D,EAAM5C,EAAQ8D,eAAevB,EAAU1D,GAG7C,OAFgBmB,EAAQ+D,QAAQC,IAAIpB,EAAIqB,QAChC+I,OAASkB,EACVtL,CACX,CACA,IAAIvB,EAOJ,OALIA,GADA,IAAAc,OAAMC,QAAQ,gCACJ,IAAI,KAAsBmL,EAAKjK,EAAE/C,MAAOgD,EAAEhD,OAG1C,IAAI,IAAgBgN,EAAKjK,EAAE/C,MAAOgD,EAAEhD,OAE3CP,EAAQyB,gBAAgBJ,EAAS,CAACiC,EAAGC,GAAI1E,EACpD,CACO,MAAMsP,EAAiB,CAC1BpP,WAAY,EAAAqP,SACZnP,YAAa,QACbC,WAAYsO,E,4FCjEhB,MAIaa,GAAO,QAAiB,CACjC1P,UALS,uBAMTC,gBALgB,qCAMhB0M,cAAe,KACfzM,MAAO,SAEEyP,EAAa,CACtBvP,WAAY,EAAAwP,KACZtP,YAAa,QACbC,WAAYmP,E,iFCLT,MAAMG,EAA4B,CACrCzP,WAAY,EAAA0P,oBACZxP,YAAa,QACbC,WAZG,SAA6BY,GAChC,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,GAAEiD,EAAE,OAAEgD,GAAWhG,GACjB,WAAE2O,EAAU,QAAE1L,EAAO,IAAEC,EAAG,WAAE0L,EAAU,gBAAE1I,GAAoBhG,EAC5D2O,EAAc,EAAAlO,aAAA,wBAAqCiO,GACnDxL,EAAW,EAAAzC,aAAA,kBAA+BgO,EAAY3I,EAAOxF,MAAOyC,EAAS,EAAmBC,EAAKgD,GAAiB,EAAO2I,GAC7HvN,EAAU,IAAI,KAAsB8B,GAC1C,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAAC0B,EAAIgD,GAAS,UAC1D,E,qHCPO,MAAM8I,EAAM,iBACNC,GAAM,QAAgB,CAAEnQ,UAAWkQ,EAAKjQ,gBAAiBiQ,EAAKvD,cAAe,OAC7EyD,EAAY,CACrBhQ,WAAY,EAAAiQ,IACZ/P,YAAa,QACbC,WAAY4P,E,4FCOT,MAAMG,EAAmB,CAC5BlQ,WAAY,EAAAmQ,WACZjQ,YAAa,QACbC,WAfG,SAAoBY,GACvB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,OAAE6F,GAAWhG,GAChB,QAAEiD,EAAO,IAAEC,EAAG,UAAE+C,GAAc/F,EAC9BkD,EAAW,EAAAzC,aAAA,sBAAmCR,EAAEK,MAAOwF,EAAOxF,MAAOyC,EAASC,EAAK,OAAyB+C,GAClH,IAAIpD,EACJ,MAAMvB,EAAU,IAAI,IAAkB8B,GACtCP,EAAM5C,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6F,GAAS,WACpD,MAAMoJ,GAAc,OAAQ,CAAEpP,OAAQ,CAAEG,EAAG0C,GAAO5C,UAASC,MAAO,CAAEM,MAAO4C,EAASZ,YAEpF,OADAvC,EAAQ0B,8BAA8BkB,GAC/BuM,CACX,E,4FCXA,MAAMC,EAAO,kBACAjO,GAAO,QAAgB,CAAExC,UAAWyQ,EAAMxQ,gBAAiBwQ,EAAM9D,cAAe,OAChF+D,EAAa,CACtBtQ,WAAY,EAAAuQ,KACZrQ,YAAa,QACbC,WAAYiC,E,0HCyCT,MAAMoO,EAAa,CACtBxQ,WAAY,EAAAyQ,KACZvQ,YAAa,QACbC,WA7CG,SAASuQ,EAAK3P,GACjB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,MAAElB,GAAUoB,EAElB,GAAc,cAAVpB,EAAuB,CACvB,GAAgB,cAAZqB,EAAErB,MACF,OAAO,OAAS,CAAEkB,OAAQ,CAAEG,KAAKF,YAGrC,MAAM0P,EAAc,QAASxP,EAAEK,OACzBoP,EAASF,EAAK,CAAE1P,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEpB,MAAO,aACxDmC,GAAS,OAAQ,CAAEjB,OAAQ,CAAE4D,KAAMgM,EAAQ/L,KAAM8L,GAAe1P,YAGtE,OAFA0P,EAAYE,UACZ5P,EAAQ0B,8BAA8BiO,GAC/B3O,CACX,CAEA,GAAgB,cAAZd,EAAErB,MAAuB,CACzB,MAAMkP,GAAW,OAAK,CAAEhO,OAAQ,CAAE+J,MAAO5J,GAAKF,YACxCgB,EAASyO,EAAK,CAAE1P,OAAQ,CAAEG,EAAG6N,GAAY/N,UAASC,MAAO,CAAEpB,WAEjE,OADAmB,EAAQ0B,8BAA8BqM,GAC/B/M,CACX,CACA,IAAK,EAAAyB,KAAA,gBAAqBvC,EAAErB,MAAOA,GAAQ,CAGvC,MAAMmC,GAAS,OAAS,CAAEjB,OAAQ,CAAEG,KAAKF,YACzC,MAAO,CAAEiE,OAAQjD,EAAOiD,OAAQ1D,MAAOS,EAAOT,MAAO1B,QACzD,CACA,GAAc,UAAVA,EACA,OAAO,OAAIqB,EAAGF,GAElB,GAAc,SAAVnB,EAAkB,CAClB,MAAMgR,EAAkB7P,EAAQ8D,eAAe,GAAI,OAAQ,EAAArB,KAAA,uBAA4B,OAAQ,IACzFqN,EAAe,CAAExM,EAAGpD,EAAGqD,EAAGsM,GAC1B7O,GAAS,OAAS,CAAEjB,OAAQ+P,EAAc9P,YAEhD,OADAA,EAAQ0B,8BAA8BmO,GAC/B7O,CACX,CACA,MAAM,IAAIF,MAAM,iCAAiCZ,EAAErB,YAAYA,IACnE,E,iFC3CA,SAASkR,EAA+BC,EAAeC,GACnD,MAAO,CACHhM,OAAQgM,EAAYhM,OACpBpF,MAAOoR,EAAYpR,MACnB0B,MAAOyP,EAAczP,MAE7B,CAYO,MAAM2P,EAAmB,CAC5BnR,WAAY,EAAAoR,WACZlR,YAAa,QACbC,WAdG,SAAoBY,GACvB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,EAAEI,GAAMH,EACRqQ,EAAQpQ,EAAQ+D,QAAQC,IAAI9D,EAAE+D,QAC9B5C,EAAU,IAAI,IAAkBnB,EAAEK,OAClC8P,EAAgB,CAClBN,EAA+B7P,EAAGkQ,EAAMhM,mBAAmBT,MAC3DoM,EAA+B7P,EAAGkQ,EAAMhM,mBAAmBR,OAE/D,OAAO5D,EAAQyB,gBAAgBJ,EAASgP,EAAeA,EAAc,GAAGxR,MAC5E,E,wGCpBO,SAASyR,EAAKxQ,GACjB,MAAM,QAAEE,EAAO,MAAEC,GAAUH,GACrB,MAAES,EAAK,MAAEgQ,GAAUtQ,EACzB,IAAI,MAAEpB,GAAUoB,EAEhB,GADApB,EAAQA,GAAS,EAAA4D,KAAA,WAAgB8N,GACnB,WAAV1R,EAAoB,CAEpB,MAAMmO,EAAS,EAAAvK,KAAA,kBAAuB5D,EAAO,EAAA4D,KAAA,cAAmBlC,IAEhE,OADAyM,EAAOsD,KAAKC,GACLvQ,EAAQ8D,eAAevD,EAAO1B,EAAOmO,EAChD,CACK,CACD,MAAM3L,EAAU,IAAI,IAAYd,EAAOgQ,GACjCjP,EAAcD,EAAQE,mBAAmBgP,GAC/C,OAAOvQ,EAAQyB,gBAAgBJ,EAAS,GAAIxC,EAAOyC,EACvD,CACJ,CACO,MAAMkP,EAAa,CACtBzR,WAAY,EAAA0R,KACZxR,YAAa,QACbC,WAAYoR,E,iFCnBT,MAAMI,EAA0B,CACnC3R,WAAY,EAAA4R,kBACZ1R,YAAa,QACbC,WAAY,EAAGa,SAAQE,QAAOD,cAC1B,MAAM,EAAEE,GAAMH,GACR,WAAEgK,EAAU,QAAE/G,EAAO,IAAEC,EAAG,oBAAE2N,GAAwB3Q,EACpD4Q,EAAe7Q,EACrB,EAAAyC,KAAA,OAA+B,IAAnBvC,EAAEK,MAAMC,QAAc,IAAM,uDAAuDN,EAAEK,MAAMC,YACvG,MAAMwF,EAAY,CAAC,EAAG,GACtB,EAAAvD,KAAA,OAAY,EAAA/B,aAAA,+BAA4CsC,EAASgD,IAAY,IACzE,wEAAehD,oBAA0BgD,OAC7C,MAAM7C,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwJ,EAAY/G,EAASgD,EAAW/C,IAClFjC,EAAQ8P,GCdhB,SAA+B5Q,EAAG0Q,EAAqBzN,EAAUnD,GACpE,IAAIqB,EAAU,IAAI,IAAc8B,EAAU,OAAO,GACjD,MAAM4N,EAAa/Q,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAI,WAGzD,OAFAmB,EAAU,IAAI,IAAc8B,EAAU,OAAO,GAAM,EAAMyN,GAElD,CAACG,EADY/Q,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAI,WAE9D,CDQkC8Q,CAAsB9Q,EAAG0Q,EAAqBzN,EAAU0N,GAClF,MAAO,CAAC7P,EAAQ8P,EAAQ,E,wGEdzB,SAASlN,EAAK9D,GACjB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,MAAEgK,GAAU/J,EACZkR,EAAYjR,EAAQ+D,QAAQC,IAAI8F,EAAM7F,QAC5C,OAAO,OAAS,CAAElE,OAAQ,CAAEG,EAAG+Q,EAAU7M,mBAAmBR,MAAQ5D,WACxE,CACO,MAAMkR,EAAa,CACtBnS,WAAY,EAAAoS,KACZlS,YAAa,QACbC,WAAY0E,E,kHCsDT,MAAMwN,EAAoB,CAC7BrS,WAAY,EAAAsS,YACZpS,YAAa,QACbC,WA/DG,SAAqBY,GACxB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,OAAE6F,EAAM,KAAE/D,EAAI,uBAAEsP,GAA2BvR,GAC9C,QAAEiD,EAAO,IAAEC,EAAG,WAAE0L,EAAU,UAAE3I,EAAS,gBAAEC,EAAe,WAAEsL,EAAU,eAAEC,GAAmBvR,EACvF2O,EAAc,EAAAlO,aAAA,wBAAqCiO,GACnDxL,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwF,EAAOxF,MAAOyC,EAASgD,EAAW/C,EAAKgD,GAAiB,EAAuB2I,GACxI,IAAIhM,EACJ,MAAM6O,EAAgB,GACtB,GAA8B,IAA1BtO,EAASmH,cAA+C,IAAzBnH,EAASkH,aACZ,IAA5BlH,EAASuO,gBAAmD,IAA3BvO,EAASwO,eAChB,IAA1BxO,EAASyO,cAA+C,IAAzBzO,EAASgD,aACb,SAA1BhD,EAAS0O,QAAQC,MAA6C,UAA1B3O,EAAS0O,QAAQC,KAYrD,IAAI,IAAA3P,OAAMC,QAAQ,sBAAuC,IAAflC,EAAEK,MAAM,GACnDqC,GAAM,OAAiB,CACnB1C,IACA6F,SACA5C,WACAnD,UACAgC,OACAuP,aACAD,yBACAE,uBAGH,CACD,MAAMO,EAAkB,MAAR/P,EACVgQ,EAAsD,MAA1BV,EAC5BW,EAAmC,cAAfV,EACpBW,EAAkBX,GAAa,QAA6BA,GAAY,GAAS,KACjFlQ,EAAU,IAAI,IAAc8B,EAAU4O,EAASG,EAAiBF,EAA2BC,GAC3FlS,EAAS,CAACG,EAAG6F,GAOnB,GANI/D,GACAjC,EAAOwM,KAAKvK,GAEZsP,GACAvR,EAAOwM,KAAK+E,GAEZW,EAAmB,CACnB,MAAME,EAAkBnS,EAAQ8D,eAAe,GAAI,UAAW,EAAArB,KAAA,kBAAuB+O,EAAgB,YACrGzR,EAAOwM,KAAK4F,GACZV,EAAclF,KAAK4F,EACvB,CACAvP,EAAM5C,EAAQyB,gBAAgBJ,EAAStB,EAAQ,UACnD,MA1CI6C,GAAM,OAAe,CACjB1C,IACA6F,SACA5C,WACAnD,UACAgC,OACAuP,aACAD,yBACAE,mBAmCR,MAAMrC,GAAc,OAAQ,CAAEpP,OAAQ,CAAEG,EAAG0C,GAAO5C,UAASC,MAAO,CAAEM,MAAO4C,EAASZ,YAGpF,OAFAkP,EAAclF,KAAK3J,GACnB6O,EAAc3E,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KAC1DoC,CACX,E,uGC5DA,MAAMiD,EAAM,aAoBL,MAAMC,EAAY,CACrBtT,WAAY,EAAAuT,IACZrT,YAAa,QACbC,WApBG,SAAaY,GAChB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,EAAEI,GAAMH,EACd,GAAIC,EAAQyM,mBAAmB,CAACvM,IAAK,CACjC,MAAMkQ,EAAQpQ,EAAQ+D,QAAQC,IAAI9D,EAAE+D,SAC7BiK,EAAWqE,IAAY,QAAWnC,EAAMpD,OAAQ9M,EAAEK,MAAOL,EAAErB,OAClE,OAAOmB,EAAQ8D,eAAeyO,EAAUrS,EAAErB,MAAOqP,EACrD,CACA,IAAI7M,EAOJ,OALIA,GADA,IAAAc,OAAMC,QAAQ,+BACJ,IAAI,KAAqBlC,EAAEK,MAAO6R,GAGlC,IAAI,KAAelS,EAAEK,MAAO6R,GAEnCpS,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAIA,EAAErB,MACnD,E,sECrBA,MAWM2T,GAAM,E,SAAA,IAAgB,CAAE7T,UAXlB,0CAWkCC,gBAV3B,iQAWN6T,EAAY,CACrB1T,WAAY,EAAA2T,IACZzT,YAAa,QACbC,WAAYsT,E,iFCGT,MAAMG,EAAqB,CAC9B5T,WAAY,EAAA6T,aACZ3T,YAAa,QACbC,WArBG,SAAsBY,GACzB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,UAAE8S,EAAS,WAAElE,GAAe1O,EAClC,EAAAwC,KAAA,OAAYoQ,EAAY,GAAG,IAAM,sDAAsDA,MACvF,MAAM3G,EAAYhM,EAAEK,MAAM,GACpBuS,EAA8B,SAAfnE,EAAyBzO,EAAEK,MAAM,GAAKL,EAAEK,MAAM,GAC7DwS,EAA6B,SAAfpE,EAAyBzO,EAAEK,MAAM,GAAKL,EAAEK,MAAM,GAC5DyS,EAA6B,SAAfrE,EAAyBzO,EAAEK,MAAM,GAAKL,EAAEK,MAAM,GAC5D0S,EAAeH,EAAcD,EAC7BK,EAAcH,EAAaF,EAC3BM,EAAcH,GAAcH,EAAYA,GACxC5L,EAA8B,SAAf0H,EACjB,CAACzC,EAAW+G,EAAcC,EAAaC,GACvC,CAACjH,EAAWiH,EAAaF,EAAcC,GACrC7R,EAAU,IAAI,IAAoB4F,EAAa4L,EAAWlE,GAChE,OAAO3O,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAIA,EAAErB,MACnD,E,2FCFO,MAAMuU,EAAoB,CAC7BrU,WAAY,EAAAsU,YACZpU,YAAa,QACbC,WAjBG,SAAqBY,GACxB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,aAAEuT,EAAY,aAAEC,GAAiBtT,EACvC,IAAIoB,EAEAA,GADA,IAAAc,OAAMC,QAAQ,mBACJ,IAAI,IAAkBlC,EAAEK,OAGxB,IAAI,IAAYL,EAAEK,OAEhC,MAAMe,EAAcD,EAAQE,mBAAmB+R,EAAcC,GAC7D,OAAOvT,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAIA,EAAErB,MAAOyC,EAC1D,E,iFCNO,MAAMkS,EAA2C,CACpDzU,WAAY,EAAA0U,mCACZxU,YAAa,QACbC,WAXG,SAA4CY,GAC/C,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,GAAEiD,EAAE,OAAEgD,GAAWhG,GACjB,QAAEiD,EAAO,UAAEgD,EAAS,IAAE/C,EAAG,gBAAEgD,EAAe,WAAEyI,GAAezO,EAC3DkD,EAAW,EAAAzC,aAAA,kBAA+BgO,EAAY3I,EAAOxF,MAAOyC,EAASgD,EAAW/C,EAAKgD,GAAiB,GAC9G5E,EAAU,IAAI,IAA+B8B,GACnD,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAAC0B,EAAIgD,GAAS,UAC1D,E,sHCNO,MAAM2N,EAAa,CACtB3U,WAAY,EAAA4U,KACZ1U,YAAa,QACbC,WAAY,EAAGa,SAAQE,QAAOD,cAC1B,MAAM,EAAEE,GAAMH,GACR,SAAE6T,EAAQ,KAAEzT,GAASF,EACrB4Q,EAAe7Q,EACfM,EAAQJ,EAAEK,MAAMC,OAChBqT,EAAW,EAAApR,KAAA,eAAoBtC,EAAMD,EAAEK,OAC7C,IAAIuT,EAAOD,EACX,MAAME,EAAe,EAAArT,aAAA,mBAAgCoT,EAAMxT,GACrD0T,EAAwC,MAAhBD,EACxBtH,EAAqBoE,EAAapE,mBAAmB,CAACvM,IACtDuR,EAAgB,GACtB,IAAIwC,EAAY/T,EAChB,GAAI8T,EAAuB,CACvB,GAAIvH,EAAoB,CACpB,MACMO,EADW6D,EAAa9M,QAAQC,IAAIiQ,EAAUhQ,QAC5B+I,OAClBuF,EAAW,IAAI2B,MAAM5T,GAC3B,IAAK,IAAIW,EAAI,EAAGA,EAAIsR,EAAS/R,OAAQS,IACjCsR,EAAStR,GAAKf,EAAEK,MAAMwT,EAAa9S,IAEvC,MAAMkT,GAAkB,QAAiBnH,EAAQ9M,EAAEK,MAAOL,EAAErB,MAAOkV,EAAcxB,GACjF0B,EAAYpD,EAAa/M,eAAeyO,EAAUrS,EAAErB,OAC9BgS,EAAa9M,QAAQC,IAAIiQ,EAAUhQ,QAC3C+I,OAASmH,CAC3B,MAEIF,GAAY,OAAc/T,EAAG6T,EAAclD,GAE/CY,EAAclF,KAAK0H,GACnBH,EAAO,EAAApT,aAAA,iBAA8BoT,EAAKtT,OAAQF,EACtD,CACA,EAAAI,aAAA,2BAAwC,MAAOoT,EAAMxT,GACrD,MAAO8T,EAAcC,GAAe,EAAA3T,aAAA,0BAAuCuT,EAAU1T,MAAOuT,GAC5F,IAAIvR,EAAW6R,EACXR,IAEArR,EAAW,EAAA7B,aAAA,qBAAkC0T,EAAcP,IAE/D,MAAMjR,ECzCP,SAAkB1C,EAAGmU,EAAa9R,EAAUvC,GAC/C,MAAMsU,EAAS,EAAA7R,KAAA,cAAmB4R,GAE5BnI,EADQ,EAAAzJ,KAAA,cAAmBvC,EAAEK,OACT+T,EACpBC,GAAgB,OAAQ,CAAExU,OAAQ,CAAEG,KAAKD,MAAO,CAAEM,MAAO,CAAC2L,EAAWoI,IAAWtU,YAChFwU,GAAU,EAAAC,EAAA,GAAOF,EAAe,UAAW,OAAQvU,GACnD0U,GAAiB,OAAQ,CAAE3U,OAAQ,CAAEG,EAAGsU,GAAWvU,MAAO,CAAEM,MAAOgC,GAAYvC,YAGrF,OAFAA,EAAQ0B,8BAA8B6S,GACtCvU,EAAQ0B,8BAA8B8S,GAC/BE,CACX,CD+BoBC,CAASV,EAAWI,EAAa9R,EAAUsO,GACvD,IAAK,MAAM5P,KAAKwQ,EACZZ,EAAanP,8BAA8BT,GAE/C,OAAO2B,CAAG,E,0KErCX,SAASgS,GAAe,EAAE1U,EAAC,OAAE6F,EAAM,SAAE5C,EAAQ,QAAEnD,EAAO,KAAEgC,EAAO,KAAI,uBAAEsP,EAAyB,KAAI,eAAEE,EAAiB,EAAC,WAAED,EAAa,OAGxI,MAAMsD,EAAS3U,EAAEK,MACXuU,EAAW9U,EAAQ+D,QAAQC,IAAI9D,EAAE+D,QACjC8Q,EAAkB5R,EAASkD,WAC3B2O,EAAcH,EAAO,GAAKA,EAAO,GAAKA,EAAO,GAC7CI,EAAmB9R,EAASiD,YAC5B8O,EAAyC,iBAAxB/R,EAASwL,WAC1BnL,GAAa,EACbC,GAAa,EACnB,IAAIb,EACJ,MAAM6O,EAAgB,GAGhB0D,GAA6C,IAAhBH,GAA0C,IAArBC,IACpDF,EAAkB,IAChBK,EAAyBP,EAAO,GAAK,IAAM,KAAOC,EAASO,SACjE,IAAIF,IAA8B,IAAAhT,OAAMC,QAAQ,yBAC3C,IAAAD,OAAMC,QAAQ,iCACdgT,EA6BA,CASD,MAAME,EAAcJ,EAChBL,EAAO,GAAKA,EAAO,IAAMA,EAAO,GAAK,GACrCA,EAAO,GAAKA,EAAO,IAAMA,EAAO,GAAK,GACnCU,EAAY,CACdtR,OAAQ/D,EAAE+D,OACV1D,MAAO,CAAC,EAAG+U,EAAanS,EAASkD,YACjCxH,MAAOqB,EAAErB,OAUP2W,EAAwBV,EAASvU,MACvCuU,EAASvU,MAAQuU,EAASvU,MAAMkV,QAChCX,EAASvU,MAAMuU,EAASvU,MAAMC,OAAS,KACvC,EAAAiC,KAAA,OAAY,KAAyBqS,EAASvU,MAAOgV,EAAUhV,QAAQ,IAAM,kBAAkBuU,EAASvU,YAAYgV,EAAUhV,qBAC9H,MAAMmV,GAAiB,OAAQ,CAC3B3V,OAAQ,CAAEG,EAAG6F,GACb/F,UACAC,MAAO,CAAEM,MAAO,CAAC,EAAG4C,EAASkD,WAAYlD,EAASiD,gBAEtDqL,EAAclF,KAAKmJ,GACnB,MAAMC,GAAgB,OAAgB,CAClCrS,EAAGiS,EACHhS,EAAGmS,EACH1V,UACAwD,aACAC,aACAzB,OACAuP,aACAD,yBACAE,mBAEEoE,EAAuB5V,EAAQ+D,QAAQC,IAAI2R,EAAc1R,QAC/D,EAAAxB,KAAA,OAAYmT,EAAqBP,UAAU,IAAM,gDAEjDP,EAASvU,MAAQiV,EAGjBI,EAAqBrV,MAAQ4C,EAASZ,SACtCK,GAAM,OAAS,CAAE7C,OAAQ,CAAEG,EAAGyV,GAAiB3V,YAC/C4C,EAAIrC,MAAQ4C,EAASZ,SACrBkP,EAAclF,KAAKoJ,EACvB,KArF6B,CACzB,MAAML,EAAcJ,EAAiBL,EAAO,GAAKA,EAAO,GAAKA,EAAO,GAChEA,EAAO,GAAKA,EAAO,GAAKA,EAAO,GAC7BU,GAAY,OAAQ,CACtBxV,OAAQ,CAAEG,KACVF,UACAC,MAAO,CAAEM,MAAO,CAAC,EAAG+U,EAAanS,EAASkD,eAExCqP,GAAiB,OAAQ,CAC3B3V,OAAQ,CAAEG,EAAG6F,GACb/F,UACAC,MAAO,CAAEM,MAAO,CAAC,EAAG4C,EAASkD,WAAYlD,EAASiD,gBAEhDpF,GAAS,OAAgB,CAC3BsC,EAAGiS,EACHhS,EAAGmS,EACHlS,aACAC,aACAzD,UACAgC,OACAuP,aACAD,yBACAE,mBAEJ5O,GAAM,OAAQ,CAAE7C,OAAQ,CAAEG,EAAGc,GAAUhB,UAASC,MAAO,CAAEM,MAAO4C,EAASZ,YACzEkP,EAAclF,KAAKgJ,GACnB9D,EAAclF,KAAKmJ,GACnBjE,EAAclF,KAAKvL,EACvB,CA0DA,IAAK,MAAMC,KAAKwQ,EACZzR,EAAQ0B,8BAA8BT,GAE1C,OAAO2B,CACX,CAGO,SAASiT,GAAiB,EAAE3V,EAAC,OAAE6F,EAAM,SAAE5C,EAAQ,QAAEnD,EAAO,KAAEgC,EAAO,KAAI,uBAAEsP,EAAyB,KAAI,eAAEE,EAAiB,EAAC,WAAED,EAAa,OAO1I,MAAM,YAAElH,EAAW,aAAEC,EAAY,WAAEjE,EAAU,SAAEyP,EAAQ,UAAEC,EAAS,WAAEpH,GAAexL,EAC7E+R,EAAgC,iBAAfvG,EACjBqH,EAAY3L,EAAcC,EAAejE,EACzC4P,EAAUF,EAAYD,EACtBI,EAAa,CAACF,EAAWC,GAGzBxE,EAAgB,GAChB0E,GAAY,OAAQ,CAAEpW,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEM,MAAOL,EAAEK,MAAMkV,MAAM,MAC5EW,GAAQ,OAAQ,CAClBrW,OAAQ,CAAEG,EAAG6F,GACb/F,UACAC,MAAO,CAAEM,MAAO,CAAC,EAAGyV,EAAW,EAAAvT,KAAA,cAAmBsD,EAAOxF,OAASyV,MAEtEvE,EAAclF,KAAK4J,GACnB1E,EAAclF,KAAK6J,GACnB,MAAMC,EAAgB,IAAI,IAAoBH,EAAYC,EAAU5V,MAAO4C,GACrEmT,EAAStW,EAAQyB,gBAAgB4U,EAAe,CAACF,GAAY,WAC7DI,GAAiB,OAAQ,CAC3BxW,OAAQ,CAAEG,EAAGoW,GACbtW,UACAC,MAAO,CAAEM,MAAO,CAAC,EAAG2V,EAAW,GAAIA,EAAW,OAElDzE,EAAclF,KAAK+J,GACnB7E,EAAclF,KAAKgK,GACnB,MAAMxE,EAAkB,MAAR/P,EACVgQ,EAAsD,MAA1BV,EAC5BW,EAAmC,cAAfV,EACpBW,EAAkBX,GAAa,QAA6BA,GAAY,GAAQ,KAChFiF,EAAgB,IAAI,IAAoBD,EAAehW,MAAO6V,EAAM7V,MAAO,CAAC,EAAG0V,EAAS9S,EAASiD,cAxBpF,GACA,EAuB0H2L,EAASG,EAAiBF,EAA2BC,GAC5LlS,EAAS,CAACwW,EAAgBH,GAOhC,GANIpU,GACAjC,EAAOwM,KAAKvK,GAEZgQ,GACAjS,EAAOwM,KAAK+E,GAEZW,EAAmB,CACnB,MAAME,EAAkBnS,EAAQ8D,eAAe,GAAI,UAAW,EAAArB,KAAA,kBAAuB+O,EAAgB,YACrGzR,EAAOwM,KAAK4F,GACZV,EAAclF,KAAK4F,EACvB,CACA,MAAMsE,EAAUzW,EAAQyB,gBAAgB+U,EAAezW,EAAQ,WACzDwC,EAAW2S,EACb,CAAC,EAAGa,EAAWD,EAAU3S,EAASiD,aAClC,CAAC,EAAGjD,EAASiD,YAAa2P,EAAWD,GACnClT,GAAM,OAAQ,CAAE7C,OAAQ,CAAEG,EAAGuW,GAAWzW,UAASC,MAAO,CAAEM,MAAOgC,KACvEkP,EAAclF,KAAKkK,GACnB,IAAK,MAAMxV,KAAKwQ,EACZzR,EAAQ0B,8BAA8BT,GAE1C,OAAO2B,CACX,C,4FCpLA,MAAM8T,EAAQ,mBACDC,GAAQ,QAAgB,CAAEhY,UAAW+X,EAAO9X,gBAAiB8X,EAAOpL,cAAe,OACnFsL,EAAc,CACvB7X,WAAY,EAAA8X,MACZ5X,YAAa,QACbC,WAAYyX,E,4FCiBT,MAAMG,EAAa,CACtB/X,WAAY,EAAAgY,KACZ9X,YAAa,QACbC,WAzBG,SAAcY,GACjB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,KAAEK,GAASF,EACjB,GAAsB,IAAlBF,EAAOS,OACP,OAAO,OAAW,CAAET,OAAQ,CAAE+J,MAAO/J,EAAO,IAAMC,UAASC,MAAO,CAAE+W,IAAK7W,KAE7E,MAAMI,EAAQR,EAAO,GAAGQ,MAClB1B,EAAQkB,EAAO,GAAGlB,MACxBkB,EAAO+M,SAAQC,IACX,EAAAtK,KAAA,kBAAuBlC,EAAOwM,EAAExM,MAAO,yDACvC,EAAAkC,KAAA,OAAY5D,IAAUkO,EAAElO,OAAO,IAAM,yDAAwD,IAEjG,MAAMoY,EAA0B,GAC1BC,EAAkBnX,EAAOoX,KAAIpK,IAC/B,MAAMqK,GAAY,OAAW,CAAErX,OAAQ,CAAE+J,MAAOiD,GAAK/M,UAASC,MAAO,CAAE+W,IAAK7W,KAE5E,OADA8W,EAAwB1K,KAAK6K,GACtBA,CAAS,IAEdpW,GAAS,OAAO,CAAEjB,OAAQmX,EAAiBlX,UAASC,MAAO,CAAEE,UAEnE,OADA8W,EAAwBnK,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KACpE/L,CACX,E,sECtBA,MAMaqW,GAAa,E,SAAA,IAAiB,CACvC1Y,UAPgB,sCAQhBC,gBAPuB,6GAQvBC,MAAO,SAEEyY,EAAmB,CAC5BvY,WAAY,EAAAwY,WACZtY,YAAa,QACbC,WAAYmY,E,4FCbT,MAcMG,EAAe,CACxBzY,WAAY,EAAA0Y,OACZxY,YAAa,QACbC,WAjBmBY,IACnB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,QAAE6L,GAAY5L,GACd,MAAE2X,EAAK,QAAEC,EAAO,SAAEC,GAAa3X,EAC/B8L,EAAc,EAAAtJ,KAAA,cAAmBkJ,EAAQpL,OACzCc,EAAU,IAAI,IAAc0K,EAAa2L,EAAOC,EAASC,GACzD3K,GAAW,OAAQ,CAAElN,OAAQ,CAAEG,EAAGyL,GAAW3L,UAASC,MAAO,CAAEM,MAAO,CAACwL,MACvE/K,EAAShB,EAAQyB,gBAAgBJ,EAAS,CAAC4L,GAAWtB,EAAQ9M,OACpEmB,EAAQ0B,8BAA8BuL,GACtC,MAAM1K,EAAW,IAAIoJ,EAAQpL,MAAOmX,GAC9B9U,GAAM,OAAQ,CAAE7C,OAAQ,CAAEG,EAAGc,GAAUhB,UAASC,MAAO,CAAEM,MAAOgC,KAEtE,OADAvC,EAAQ0B,8BAA8BV,GAC/B4B,CAAG,E,+JCLP,MAAMiV,EAA8B,IACpC,SAASC,GAAgB,EAAExU,EAAC,EAAEC,EAAC,WAAEC,EAAU,WAAEC,EAAU,QAAEzD,EAAO,KAAEgC,EAAO,KAAI,uBAAEsP,EAAyB,KAAI,eAAEE,EAAiB,EAAC,WAAED,EAAa,OAClJ,MAAMwG,EAAQzU,EAAE/C,MAAMC,OAChBwX,EAAQzU,EAAEhD,MAAMC,OAChByX,EAAczU,EAAaF,EAAE/C,MAAMwX,EAAQ,GAAKzU,EAAE/C,MAAMwX,EAAQ,GAChEG,EAAczU,EAAaF,EAAEhD,MAAMyX,EAAQ,GAAKzU,EAAEhD,MAAMyX,EAAQ,GAChEG,EAAc3U,EAAaF,EAAE/C,MAAMwX,EAAQ,GAAKzU,EAAE/C,MAAMwX,EAAQ,GAChEK,EAAc3U,EAAaF,EAAEhD,MAAMyX,EAAQ,GAAKzU,EAAEhD,MAAMyX,EAAQ,GAChEK,EAAa/U,EAAE/C,MAAMkV,MAAM,GAAI,GAC/B6C,EAAa/U,EAAEhD,MAAMkV,MAAM,GAAI,GAC/B8C,EAAY,EAAA9V,KAAA,cAAmB4V,GAC/BG,EAAY,EAAA/V,KAAA,cAAmB6V,GAC/BG,EAAsBF,IAAcC,GAA2B,IAAdD,GAAiC,IAAdC,EAC1E,EAAA/V,KAAA,OAAYsV,GAAS,GAAKC,GAAS,GAAKS,GAAqB,IAEzD,uJAAwBJ,WAAoBC,QAChD,MACM/V,GADoBgW,EAAYC,EAAYlV,EAAE/C,MAAMkV,MAAM,GAAI,GAAKlS,EAAEhD,MAAMkV,MAAM,GAAI,IACxDiD,OAAO,CAACP,EAAaC,IACxD,EAAA3V,KAAA,OAAYwV,IAAgBC,GAAa,IAAM,kCAAkCD,WAC1EC,6BAAuC5U,EAAE/C,aACzCgD,EAAEhD,wBAAwBiD,oBACVC,kBACvB,MAAMkV,EAAWnV,EACb,CAAC+U,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,GACvBW,EAAWnV,EACb,CAAC+U,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAEvBS,GAAM,OAAQ,CAAE9Y,OAAQ,CAAEG,EAAGoD,GAAKtD,UAASC,MAAO,CAAEM,MAAOoY,KAC3DG,GAAM,OAAQ,CAAE/Y,OAAQ,CAAEG,EAAGqD,GAAKvD,UAASC,MAAO,CAAEM,MAAOqY,KAC3DnH,EAAgB,CAACoH,EAAKC,GACtBC,EAAW7X,KAAK8X,IAAIT,EAAWC,GAC/BxC,EAAYxS,EAAaqV,EAAItY,MAAM,GAAKsY,EAAItY,MAAM,GAClDwR,EAAkB,MAAR/P,EACVgQ,EAAsD,MAA1BV,EAC5BW,EAAmC,cAAfV,EACpBW,EAAgC,MAAdX,GACpB,QAA6BA,GAAY,GACzC,KAGJ,IAAI3O,EAGJ,IAAqB,IAAhBuV,GAAqC,IAAhBC,IACtBpC,EAAY6B,IAAoD,KAN3C9F,GAAWC,GAChCC,GAAwC,MAAnBC,GAKkD,CACvE,IAAI+G,EAAOJ,EACPK,EAAOJ,EACPtV,IACAyV,GAAO,OAAU,CAAElZ,OAAQ,CAAEG,EAAG2Y,GAAO7Y,UAASC,MAAO,CAAEW,KAAM,CAAC,EAAG,EAAG,MACtE6Q,EAAclF,KAAK0M,IAEnBxV,IACAyV,GAAO,OAAU,CAAEnZ,OAAQ,CAAEG,EAAG4Y,GAAO9Y,UAASC,MAAO,CAAEW,KAAM,CAAC,EAAG,EAAG,MACtE6Q,EAAclF,KAAK2M,IAEvB,MACMC,EAAiC,IAAhBf,EACvB,IAAIgB,EAASH,EAF0B,IAAhBb,IAInBgB,GAAS,OAAQ,CACbrZ,OAAQ,CAAEG,EAAG+Y,GACbjZ,UACAC,MAAO,CAAEM,MAAO,CAACwY,EAAU/C,EAAW,MAE1CvE,EAAclF,KAAK6M,IAEvB,MAAMjZ,EAAuB,IAAhBiY,EAAoB,EAAI,EACrC,IAAIiB,EAASH,EACTC,IACAE,GAAS,OAAQ,CACbtZ,OAAQ,CAAEG,EAAGgZ,GACblZ,UACAC,MAAO,CAAEM,MAAO,CAACwY,EAAU,EAAG/C,MAElCvE,EAAclF,KAAK8M,IAEvB,MAAM5C,GAAU,OAAS,CAAE1W,OAAQ,CAAEuD,EAAG8V,EAAQ7V,EAAG8V,GAAUrZ,YAC7D4C,GAAM,OAAI,CAAE7C,OAAQ,CAAEG,EAAGuW,GAAWzW,UAASC,MAAO,CAAEE,OAAMyT,UAAU,KACtEnC,EAAclF,KAAKkK,EACvB,KACK,CACD,MAAM5X,GAAQ,IAAAya,YAAWhW,EAAEzE,MAAO0E,EAAE1E,OAC9BwC,EAAU,IAAI,IAAoBsX,EAAUC,EAAU,CAACG,EAAUZ,EAAaC,GAAc5U,EAAYC,EAAYsO,EAASG,EAAiBF,EAA2BC,GACzKlS,EAAS,CAAC8Y,EAAKC,GAOrB,GANY,MAAR9W,GACAjC,EAAOwM,KAAKvK,GAEZgQ,GACAjS,EAAOwM,KAAK+E,GAEZW,EAAmB,CACnB,MAAME,EAAkBnS,EAAQ8D,eAAe,GAAI,UAAW,EAAArB,KAAA,kBAAuB+O,EAAgB,YACrGzR,EAAOwM,KAAK4F,GACZV,EAAclF,KAAK4F,EACvB,CACAvP,EAAM5C,EAAQyB,gBAAgBJ,EAAStB,EAAQlB,EACnD,CACA,MAAMsQ,GAAc,OAAQ,CAAEpP,OAAQ,CAAEG,EAAG0C,GAAO5C,UAASC,MAAO,CAAEM,MAAOgC,KAC3EkP,EAAclF,KAAK3J,GACnB,IAAK,MAAM3B,KAAKwQ,EACZzR,EAAQ0B,8BAA8BT,GAE1C,OAAOkO,CACX,C,2HCrFO,MAAMoK,EAAiB,CAC1Bxa,WAAY,EAAAya,SACZva,YAAa,QACbC,WA3BG,SAASua,EAAS3Z,GACrB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,EAAEI,GAAMH,EACd,GAAgB,WAAZG,EAAErB,MACF,MAAM,IAAIiC,MAAM,gDAEf,GAAgB,cAAZZ,EAAErB,MAAuB,CAC9B,MAAMkP,GAAW,OAAK,CAAEhO,OAAQ,CAAE+J,MAAO5J,GAAKF,YACxC0Z,EAAID,EAAS,CAAE1Z,OAAQ,CAAEG,EAAG6N,GAAY/N,YACxCgO,GAAW,OAAK,CAAEjO,OAAQ,CAAE+J,MAAO5J,GAAKF,YACxCiB,GAAI,OAAU,CAAElB,OAAQ,CAAEG,EAAG8N,GAAYhO,YACzCgB,GAAS,OAAQ,CAAEjB,OAAQ,CAAE4D,KAAM+V,EAAG9V,KAAM3C,GAAKjB,YAKvD,OAJAA,EAAQ0B,8BAA8BqM,GACtC/N,EAAQ0B,8BAA8BgY,GACtC1Z,EAAQ0B,8BAA8BsM,GACtChO,EAAQ0B,8BAA8BT,GAC/BD,CACX,CAII,OAAO,OAAK,CAAEf,MAAO,CAAEM,MAAOL,EAAEK,MAAO1B,MAAOqB,EAAErB,MAAO0R,MAAO,GAAKvQ,WAE3E,E,sGCmBO,MAAM2Z,EAA6B,CACtC5a,WAAY,EAAA6a,qBACZ3a,YAAa,QACbC,WA/CG,SAA8BY,GACjC,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,OAAE6F,EAAM,KAAE/D,EAAI,uBAAEsP,GAA2BvR,GAC9C,QAAEiD,EAAO,IAAEC,EAAG,UAAE+C,EAAS,gBAAEC,EAAe,WAAEsL,EAAU,eAAEC,GAAmBvR,EAC3EwR,EAAgB,GACtB,IAAIvL,EAAaF,EACC,MAAdE,IACAA,EAAa,CAAC,EAAG,IAErB,EAAAzD,KAAA,OAAY,EAAA/B,aAAA,+BAA4CsC,EAASkD,IAAa,IAC1E,gFAAkBlD,oBAA0BkD,OAChD,MAAM/C,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwF,EAAOxF,MAAOyC,EAASkD,EAAYjD,EAAKgD,GAAiB,GAC5G4T,GAA0B,IAAA1X,OAAMC,QAAQ,6BAC1Ce,EAASgD,aAAe,GACxBhD,EAASiD,YAAcjD,EAASkD,aAAe,EAC7C6L,EAAkBX,GACpB,QAA6BA,EAAYsI,GACzC,KACExJ,EAAgB,CAACnQ,EAAG6F,GACpBgM,EAAkB,MAAR/P,EACVgQ,EAAsD,MAA1BV,EAC5BW,EAAmC,cAAfV,EAO1B,GANIQ,GACA1B,EAAc9D,KAAKvK,GAEnBgQ,GACA3B,EAAc9D,KAAK+E,GAEnBW,EAAmB,CACnB,MAAME,EAAkBnS,EAAQ8D,eAAe,GAAI,UAAW,EAAArB,KAAA,kBAAuB+O,EAAgB,YACrGnB,EAAc9D,KAAK4F,GACnBV,EAAclF,KAAK4F,EACvB,CACA,IAAI9Q,EAEAA,EADAwY,EACU,IAAI,IAA6B1W,EAAU4O,EAASG,EAAiBF,EAA2BC,GAGhG,IAAI,IAAuB9O,EAAU4O,EAASG,EAAiBF,EAA2BC,GAExG,MAAMjR,EAAShB,EAAQyB,gBAAgBJ,EAASgP,EAAe,WAE/D,OADAoB,EAAc3E,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KAC1D/L,CACX,E,uGC3CO,MA+BM8Y,EAAuB,CAChC/a,WAAY,EAAAgb,eACZ9a,YAAa,QACbC,WAlC2BY,IAC3B,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,WAAEia,EAAU,MAAEC,GAAUha,EAC9B,EAAAwC,KAAA,OAAYvC,EAAEK,MAAMC,QAAU,GAAG,IAAM,yEAEvC,MAAM0Z,EAAOF,EAAWvF,QAAO,CAACnR,EAAGC,IAAMD,EAAIC,IACvC0J,EAAW,EAAAvM,aAAA,YAAyBR,EAAEK,MAAOyZ,EAAYE,GACzDC,EAAW,EAAAzZ,aAAA,YAAyBuM,EAASzM,OAAQwZ,EAAWxZ,QAChE4Z,EAAmB,EAAA1Z,aAAA,oBAAiCR,EAAEK,MAAOyZ,EAAYE,GACzEG,EAAmB,EAAA3Z,aAAA,oBAAiCuZ,EAAOD,EAAWxZ,QACtE6L,EAAY,EAAA3L,aAAA,aAA0B0Z,EAAkBH,EAAOD,EAAWxZ,QAC1EwL,EAAY,GACZsO,GAAuB,OAAQ,CAAEva,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEM,MAAO0M,KACzEsN,GAAyB,OAAU,CAAExa,OAAQ,CAAEG,EAAGoa,GAAwBta,UAASC,MAAO,CAAEW,KAAMuZ,KAClGK,GAAwB,OAAQ,CAClCza,OAAQ,CAAEG,EAAGqa,GACbva,UACAC,MAAO,CAAEM,MAAO6Z,KAEdK,GAAS,OAAM,CACjB1a,OAAQ,CAAEG,EAAGsa,GACbxa,UACAC,MAAO,CAAEya,MAAOL,EAAkBtZ,KAAMsL,KAM5C,OAJAL,EAAUO,KAAK+N,GACftO,EAAUO,KAAKgO,GACfvO,EAAUO,KAAKiO,GACfxO,EAAUc,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KACtD0N,CAAM,E,4FChBV,MAAME,EAAsB,CAC/B5b,WAAY,EAAA6b,cACZ3b,YAAa,QACbC,WAjBG,SAAuBY,GAC1B,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,GAAEiD,EAAE,MAAE+G,GAAU/J,EAChBG,EAAI4J,GACJ,WAAEC,EAAU,QAAE/G,EAAO,IAAEC,EAAG,gBAAEgD,GAAoBhG,EAEhDkD,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwJ,EAAY/G,EADnD,CAAC,EAAG,EAAG,GACgEC,EAAKgD,GACxF4U,EAA4B,IAAI,IAAc1X,EAAU,OAAO,GAC/D2X,EAAqB9a,EAAQyB,gBAAgBoZ,EAA2B,CAAC3a,GAAIA,EAAErB,OAC/Ekc,EAAyB,IAAI,IAAyB5X,GACtDnC,EAAShB,EAAQyB,gBAAgBsZ,EAAwB,CAAChY,EAAI+X,GAAqB5a,EAAErB,OAE3F,OADAmB,EAAQ0B,8BAA8BoZ,GAC/B9Z,CACX,E,uGCYO,MAAMga,EAAe,CACxBjc,WAAY,EAAAkc,OACZhc,YAAa,QACbC,WA3BG,SAAgBY,GACnB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,OAAE6F,GAAWhG,GAChB,QAAEiD,EAAO,IAAEC,EAAG,WAAE0L,EAAU,UAAE3I,EAAS,gBAAEC,GAAoBhG,EAC3D2O,EAAc,EAAAlO,aAAA,wBAAqCiO,GACnDxL,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwF,EAAOxF,MAAOyC,EAASgD,EAAW/C,EAAKgD,GAAiB,EAAuB2I,GACxI,IAAIhM,EACJ,GAA8B,IAA1BO,EAASmH,cAA+C,IAAzBnH,EAASkH,aACZ,IAA5BlH,EAASuO,gBAAmD,IAA3BvO,EAASwO,eAChB,IAA1BxO,EAASyO,cAA+C,IAAzBzO,EAASgD,aACb,SAA1BhD,EAAS0O,QAAQC,MAA6C,UAA1B3O,EAAS0O,QAAQC,KAGrD,IAAI,IAAA3P,OAAMC,QAAQ,sBAAuC,IAAflC,EAAEK,MAAM,GACnDqC,GAAM,OAAiB,CAAE1C,IAAG6F,SAAQ5C,WAAUnD,gBAE7C,CACD,MAAMqB,EAAU,IAAI,IAAc8B,GAClCP,EAAM5C,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6F,GAAS,UACxD,MARInD,GAAM,OAAe,CAAE1C,IAAG6F,SAAQ5C,WAAUnD,YAShD,MAAMmP,GAAc,OAAQ,CAAEpP,OAAQ,CAAEG,EAAG0C,GAAO5C,UAASC,MAAO,CAAEM,MAAO4C,EAASZ,YAEpF,OADAvC,EAAQ0B,8BAA8BkB,GAC/BuM,CACX,E,iFCpBO,MAAM+L,EAAa,CACtBnc,WAAY,EAAAoc,KACZlc,YAAa,QACbC,WARG,SAAcY,GACjB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,MAAEgK,GAAU/J,EAClB,OAAO,OAAQ+J,GAAO,EAAoB9J,EAC9C,E,4FCiBO,MAAMob,EAAiB,CAC1Brc,WAAY,EAAAsc,SACZpc,YAAa,QACbC,WAvBG,SAAkBY,GACrB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,OAAEwb,EAAM,QAAE3P,GAAY5L,EACtBwb,EAAe5P,EAAQpL,MACvBib,EAAYD,EAAaA,EAAa/a,OAAS,IAC9Cib,EAAaC,EAAWrP,EAAWrJ,GAAW,EAAAtC,aAAA,mBAAgC4a,EAAQ3P,GACvFgQ,GAAiB,OAAQ,CAAE5b,OAAQ,CAAEG,EAAGyL,GAAW3L,UAASC,MAAO,CAAEM,MAAO,CAACmb,EAAWF,MACxFvP,GAAW,OAAQ,CACrBlM,OAAQ,CAAEG,EAAGob,GACbtb,UACAC,MAAO,CAAEM,MAAO,CAAE,EAAAkC,KAAA,cAAmB6Y,EAAO/a,OAAS8L,EAAYA,MAE/DhL,EAAU,IAAI,IAAgBma,EAAWxY,EAAS,CAAC0Y,EAAWrP,IAC9D1J,EAAM3C,EAAQyB,gBAAgBJ,EAAS,CAAC4K,EAAU0P,GAAiB1P,EAASpN,OAC5EoO,GAAW,OAAQ,CAAElN,OAAQ,CAAEG,EAAGyC,GAAO3C,UAASC,MAAO,CAAEM,MAAOkb,KAIxE,OAHAzb,EAAQ0B,8BAA8Bia,GACtC3b,EAAQ0B,8BAA8BuK,GACtCjM,EAAQ0B,8BAA8BiB,GAC/BsK,CACX,E,6ICnBO,MAAM2O,EAAY,+BACZC,EAAmB,mIAgBzB,MAAMC,EAAkB,CAC3B/c,WAAY,EAAAgd,UACZ9c,YAAa,QACbC,WAfG,SAAmBY,GACtB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,MAAEkC,GAAUhC,EACZ+b,EAAShc,EAAQ8D,eAAe,GAAI,UAAW,EAAArB,KAAA,kBAAuBR,EAAO,YAC7EZ,GAAU,IAAAc,OAAMC,QAAQ,gCAC1B,IAAI,KAAsByZ,EAAkB3b,EAAEK,MAAOyb,EAAOzb,OAC5D,IAAI,IAAgBqb,EAAW1b,EAAEK,MAAOyb,EAAOzb,OAC7CS,EAAShB,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG8b,GAAS9b,EAAErB,OAE/D,OADAmB,EAAQ0B,8BAA8Bsa,GAC/Bhb,CACX,E,uGCkBO,MAAMib,EAAY,CACrBld,WAAY,EAAAmd,IACZjd,YAAa,QACbC,WApCG,SAAaY,GAChB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,KAAEI,EAAI,SAAEyT,GAAa3T,EACrBK,EAAQJ,EAAEK,MAAMC,OAChBqT,EAAW,EAAApR,KAAA,eAAoBtC,EAAMD,EAAEK,OAC7C,IAAIuT,EAAOD,EACX,MAAME,EAAe,EAAArT,aAAA,mBAAgCoT,EAAMxT,GAC3D,IAAIK,EAAYT,EACI,MAAhB6T,IACApT,GAAY,OAAU,CAAEZ,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEW,KAAMmT,KAC/DD,EAAO,EAAApT,aAAA,iBAA8BoT,EAAKtT,OAAQN,EAAEK,MAAMC,SAE9D,EAAAE,aAAA,2BAAwC,MAAOoT,EAAMxT,GACrD,MAAOiC,EAAU8R,GAAe,EAAA3T,aAAA,0BAAuCC,EAAUJ,MAAOuT,GAClFQ,EAAS,EAAA7R,KAAA,cAAmB4R,GAC5B8H,GAAM,OAAQ,CAAEpc,OAAQ,CAAEG,EAAGS,GAAaX,UAASC,MAAO,CAAEM,MAAO,EAAE,EAAG+T,MACxEE,GAAU,OAAO2H,EAAKA,EAAItd,MAAO,MAAOmB,GAC9C,IAAI2C,EACJ,GAAIiR,EAAU,CACV,MAAMrB,EAAW,EAAA7R,aAAA,qBAAkC6B,EAAUsR,GAC7DlR,GAAM,OAAQ,CAAE5C,OAAQ,CAAEG,EAAGsU,GAAWxU,UAASC,MAAO,CAAEM,MAAOgS,IACrE,MAEI5P,GAAM,OAAQ,CAAE5C,OAAQ,CAAEG,EAAGsU,GAAWxU,UAASC,MAAO,CAAEM,MAAOgC,KAOrE,OALAvC,EAAQ0B,8BAA8Bya,GACtCnc,EAAQ0B,8BAA8B8S,GAClB,MAAhBT,GACA/T,EAAQ0B,8BAA8Bf,GAEnCgC,CACX,E,sECnCA,MAAMyZ,EAA0B,EAAAtX,aAAA,wBAmBzB,MAAMuX,EAA4B,CACrCtd,WAAY,EAAAud,oBACZrd,YAAa,QACbC,WArBG,SAA6BY,GAChC,EAAAY,aAAA,KAAkB,iGAElB,MAAM,OAAEX,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,MAAEmF,EAAK,OAAEC,GAAWnF,GACpB,cAAEoF,EAAa,aAAEC,EAAY,eAAEC,EAAc,aAAEkX,GAAiBtc,EAChEsF,EAAYvF,EAAQwF,SAASP,EAAMhB,QACnCwB,EAAazF,EAAQwF,SAASN,EAAOjB,QACrCuY,EAAmBrX,EACnBsX,EAAkBrX,EAClBsX,EAAoBrX,EACpBsX,EAAkBJ,GAClB,gBAAE7W,EAAe,eAAEkX,GAAmBR,EAAwB7W,EAAWE,EAAY+W,EAAkBC,EAAiBC,EAAmBC,GACjJ,MAAO,CACH3c,EAAQ8D,eAAe,CAAC4B,EAAgBlF,QAAS,QAAS,IAAIoF,WAAWF,IACzE1F,EAAQ8D,eAAe,CAAC8Y,EAAepc,QAAS,UAAW,IAAIqc,aAAaD,IAEpF,E,4FChBA,MAAME,EAAQ,uBACDC,GAAQ,QAAgB,CAAEpe,UAAWme,EAAOle,gBAAiBke,EAAOxR,cAAe,OACnF0R,EAAc,CACvBje,WAAY,EAAAke,MACZhe,YAAa,QACbC,WAAY6d,E,4FCLhB,MAYaG,GAAM,QAAgB,CAAEve,UAZzB,6CAYyCC,gBAVlC,4RAU+D0M,cAAe,OACpF6R,EAAY,CACrBpe,WAAY,EAAAqe,IACZne,YAAa,QACbC,WAAYge,E,iFCRT,MAAMG,EAAiB,CAC1Bte,WAAY,EAAAue,SACZre,YAAa,QACbC,WAZG,SAAkBY,GACrB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,QAAEqd,GAAYxd,GACjB,KAAEgB,GAASd,EACXud,EAAQxd,EAAQwF,SAAStF,EAAE+D,QAC3BwZ,EAAczd,EAAQwF,SAAS+X,EAAQtZ,QACvCiH,GAAU,QAAgBsS,EAAOC,EAAaF,EAAQ1e,MAAO0e,EAAQhd,MAAOQ,GAClF,OAAOf,EAAQ8D,eAAe,CAAC/C,GAAOwc,EAAQ1e,MAAOqM,EACzD,E,kHC0DO,MAAMwS,EAAe,CACxB3e,WAAY,EAAA4e,OACZ1e,YAAa,QACbC,WAlEG,SAAgBY,GACnB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,SAAE8d,GAAa3d,EACf4d,EAAU9d,GACV,QAAE+d,EAAO,WAAEC,EAAU,OAAEC,GAAW,EAAAtd,aAAA,qBAAkCkd,EAAUC,EAAQrd,QAC5F,EAAAE,aAAA,oBAAiCod,EAAQtd,OAAQwd,EAAQH,GACzD,MAAM,KAAEI,EAAI,MAAEC,GAAU,EAAAxd,aAAA,qBAAkCqd,EAAYC,GAChEG,EAASD,EAAM1d,OACrB,IAAIoC,EAAM,KACNwb,EAAmBN,EAAQtd,OAC/B,MAAM6d,EAAmB,GACzB,IAAK,IAAIpd,EAAI,EAAGA,EAAIkd,IAAUld,EAAG,CAC7B,IAAK,MAAMqd,KAAUJ,EAAMjd,GAAI,CAC3B,MAAQsd,mBAAoB3d,EAAM4d,WAAYC,GAAiB,EAAA/d,aAAA,qBAAkC0d,EAAkBJ,EAAOM,IAC1H,IAAIpe,EACA,EAAAQ,aAAA,sBAAmCE,GACnCV,EAAI2d,EAAQS,IAGZpe,GAAI,OAAU,CAAEH,OAAQ,CAAEG,EAAG2d,EAAQS,IAAWte,UAASC,MAAO,CAAEW,UAClEyd,EAAiB9R,KAAKrM,IAE1B,MAAMoV,EAAcpV,EAAEK,MAAMkV,QAC5B,IAAK,IAAIiJ,EAAI,EAAGA,EAAID,EAAaje,SAAUke,EACvCpJ,EAAYqJ,OAAOF,EAAaC,GAAI,EAAG,GAEtC,EAAAjc,KAAA,YAAiBvC,EAAEK,MAAO+U,KAC3BpV,GAAI,OAAQ,CAAEH,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEM,MAAO+U,KACtD+I,EAAiB9R,KAAKrM,IAEd,OAAR0C,EACAA,EAAM1C,GAIN0C,GAAM,OAAS,CAAE7C,OAAQ,CAAEuD,EAAGpD,EAAGqD,EAAGX,GAAO5C,YAC3Cqe,EAAiB9R,KAAK3J,GAE9B,CACI3B,EAAIkd,EAAS,IACTF,EAAKhd,IAAM,IACX2B,GAAM,OAAI,CACN7C,OAAQ,CAAEG,EAAG0C,GACb5C,UACAC,MAAO,CACHE,KAAM8d,EAAKhd,IAAM6c,EAAQtd,OAAS4d,GAClCxK,UAAU,KAGlByK,EAAiB9R,KAAK3J,IAE1Bwb,IAER,CAEA,IAAK,MAAMQ,KAAcP,EACjBO,IAAehc,GAGnB5C,EAAQ0B,8BAA8Bkd,GAE1C,OAAOhc,CACX,E,sECjEA,MAIaic,GAAQ,E,SAAA,IAAiB,CAAElgB,UAD1B,wBAC4CC,gBAJrC,kCAIoEC,MAAO,SACnFigB,EAAc,CACvB/f,WAAY,EAAAggB,MACZ9f,YAAa,QACbC,WAAY2f,E,sECThB,MAAMG,EAA0B,EAAAla,aAAA,wBAYzB,MAAMma,EAA4B,CACrClgB,WAAY,EAAAmgB,oBACZjgB,YAAa,QACbC,WAdG,SAA6BY,GAChC,EAAAY,aAAA,KAAkB,iGAElB,MAAM,OAAEX,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,MAAEmF,EAAK,OAAEC,GAAWnF,GACpB,cAAEoF,EAAa,aAAEC,EAAY,eAAEC,GAAmBpF,EAClDsF,EAAYvF,EAAQwF,SAASP,EAAMhB,QACnCwB,EAAazF,EAAQwF,SAASN,EAAOjB,SACrC,gBAAEyB,GAAoBsZ,EAAwBzZ,EAAWE,EAAYN,EAAeC,EAAcC,GACxG,OAAOrF,EAAQ8D,eAAe,CAAC4B,EAAgBlF,QAAS,QAAS,IAAIoF,WAAWF,GACpF,E,wBCXO,SAASyZ,EAASrf,GACrB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,EAAEI,GAAMH,EAEd,OADAC,EAAQof,OAAOlf,EAAE+D,QACV,CAAEA,OAAQ/D,EAAE+D,OAAQ1D,MAAOL,EAAEK,MAAO1B,MAAOqB,EAAErB,MACxD,C,uDACO,MAAMwgB,EAAiB,CAC1BtgB,W,QAAYugB,SACZrgB,YAAa,QACbC,WAAYigB,E,4FCPT,MA6BMI,EAAkB,CAC3BxgB,WAAY,EAAAygB,eACZvgB,YAAa,QACbC,WAhCqB,EAAGa,SAAQC,UAASC,YACzC,MAAM,EAAEC,EAAC,KAAEuf,EAAI,SAAEC,EAAQ,OAAEC,EAAM,MAAEC,GAAU7f,EAC7C,EAAA0C,KAAA,OAAYgd,EAAKlf,MAAMC,SAAWkf,EAASnf,MAAMC,QAAQ,IAAM,iFAE/D,EAAAiC,KAAA,OAAsB,MAAVkd,GAAkBF,EAAKlf,MAAMC,SAAWmf,EAAOpf,MAAMC,QAAQ,IAAM,+EAE/E,EAAAiC,KAAA,OAAqB,MAATmd,GAAiBH,EAAKlf,MAAMC,SAAWof,EAAMrf,MAAMC,QAAQ,IAAM,8EAE7E,IAAI,gBAAEqf,GAAoB5f,EACH,MAAnB4f,IACAA,EAAkB,MAEtB,MAAMC,EAAc,CAAC5f,EAAGuf,EAAMC,GAC9B,IAAIK,EAAc,KACJ,MAAVJ,IACAI,EAAcJ,EAAOpf,MACrBuf,EAAYvT,KAAKoT,IAErB,IAAIK,EAAa,KACJ,MAATJ,IACAI,EAAaJ,EAAMrf,MACnBuf,EAAYvT,KAAKqT,IAErB,MAAMve,GAAU,IAAAc,OAAMC,QAAQ,4BAC1B,IAAI,IAAuBlC,EAAEK,MAAOkf,EAAKlf,MAAOmf,EAASnf,MAAOwf,EAAaC,EAAYH,GACzF,IAAI,IAAiB3f,EAAEK,MAAOkf,EAAKlf,MAAOmf,EAASnf,MAAOwf,EAAaC,EAAYH,GAEvF,OADe7f,EAAQyB,gBAAgBJ,EAASye,EAAaA,EAAY,GAAGjhB,MAC/D,E,sEC5BjB,MACaohB,GAAW,E,SAAA,IAAgB,CAAEthB,UADxB,wCAC8CE,MAAO,SAC1DqhB,EAAiB,CAC1BnhB,WAAY,EAAAohB,SACZlhB,YAAa,QACbC,WAAY+gB,E,iFCLhB,MAAMG,EAAM,wNAIE,EAAA1f,aAAA,wBACC,EAAAA,aAAA,yBACA,EAAAA,aAAA,yBACA,EAAAA,aAAA,yBACA,EAAAA,aAAA,yBACA,EAAAA,aAAA,uKAOF2f,GAAM,QAAgB,CAAE1hB,UAAWyhB,IACnCE,EAAY,CACrBvhB,WAAY,EAAAwhB,IACZthB,YAAa,QACbC,WAAYmhB,E,iFCZT,MAAMG,EAA4C,CACrDzhB,WAAY,EAAA0hB,oCACZxhB,YAAa,QACbC,WAXG,SAA6CY,GAChD,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,GAAE6C,GAAOhD,GACZ,QAAEiD,EAAO,UAAEgD,EAAS,IAAE/C,EAAG,gBAAEgD,EAAe,YAAE/C,GAAgBjD,EAC5DkD,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAO2C,EAAaF,EAASgD,EAAW/C,EAAKgD,GAAiB,GAC1G5E,EAAU,IAAI,IAAgC8B,GACpD,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6C,GAAK,UACrD,E,sECPA,MAIa2d,GAAO,E,SAAA,IAAgB,CAAE/hB,UAJzB,kEAKAgiB,EAAa,CACtB5hB,WAAY,EAAA6hB,KACZ3hB,YAAa,QACbC,WAAYwhB,E,iFCRT,MAQMG,EAAgB,CACzB9hB,WAAY,EAAA+hB,QACZ7hB,YAAa,QACbC,WAXoBY,IACpB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,EAAE6gB,EAAC,GAAEhe,GAAOhD,GACf,YAAEgC,EAAW,KAAEC,EAAI,MAAEC,EAAK,KAAEC,GAASjC,EACrCoB,EAAU,IAAI,IAAenB,EAAEK,MAAOwB,EAAaC,EAAMC,EAAOC,GACtE,OAAOlC,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6gB,EAAGhe,GAAK7C,EAAErB,MAAM,E,4FCazD,MAAMmiB,EAAoB,CAC7BjiB,WAAY,EAAAkiB,YACZhiB,YAAa,QACbC,WApBG,SAAqBY,GACxB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,OAAEohB,GAAWnhB,GACb,WAAEohB,EAAU,KAAEC,EAAI,WAAEC,GAAephB,EACnCqhB,EAAQD,EACVH,GACA,OAAQ,CAAEnhB,OAAQ,CAAEmhB,UAAUlhB,UAASC,MAAO,CAAE+W,IAAKkK,EAAO3gB,MAAMC,OAAS,KACzE0L,EAAYoV,EAAM/gB,MAAM,GACxBghB,EAAcD,EAAM/gB,MAAM,GAC1Bc,EAAU,IAAI,IAAmB6K,EAAWqV,EAAaJ,GACzD7f,EAAcD,EAAQE,mBAAmB6f,GACzCze,EAAM3C,EAAQyB,gBAAgBJ,EAAS,CAACigB,GAAQ,QAAShgB,GAI/D,OAHK+f,GACDrhB,EAAQ0B,8BAA8B4f,GAEnC3e,CACX,E,iFCZO,MAAM6e,EAAY,CACrBziB,WAAY,EAAA0iB,IACZxiB,YAAa,QACbC,WARG,SAAaY,GAChB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,MAAEgK,GAAU/J,EAClB,OAAO,OAAQ+J,GAAO,EAAqB9J,EAC/C,E,iFCKO,MAAM0hB,EAA6B,CACtC3iB,WAAY,EAAA4iB,qBACZ1iB,YAAa,QACbC,WAZG,SAA8BY,GACjC,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,GAAE6C,GAAOhD,GACZ,QAAEiD,EAAO,IAAEC,EAAG,WAAE0L,EAAU,gBAAE1I,EAAe,YAAE/C,GAAgBjD,EAC7D2O,EAAc,EAAAlO,aAAA,wBAAqCiO,GACnDxL,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAO2C,EAAaF,EAAS,EAAmBC,EAAKgD,GAAiB,EAAuB2I,GACzIvN,EAAU,IAAI,KAAuB8B,GAC3C,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAACnB,EAAG6C,GAAK,UACrD,E,mHCPO,MAAM6e,EAAS9hB,IAClB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,SAAE8hB,EAAQ,cAAEC,GAAkB7hB,EAC9BoB,GAAU,IAAAc,OAAMC,QAAQ,+BAC1B,IAAI,IAAiBlC,EAAEK,MAAOshB,EAAUC,GACxC,IAAI,IAAW5hB,EAAEK,MAAOshB,EAAUC,GAChCxgB,EAAcD,EAAQE,mBAAmBugB,GAC/C,OAAO9hB,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAIA,EAAErB,MAAOyC,EAAY,EAEzDygB,EAAc,CACvBhjB,WAAY,EAAAijB,MACZ/iB,YAAa,QACbC,WAAY0iB,E,iFCLT,MAAMK,EAAkB,CAC3BljB,WAAY,EAAAmjB,UACZjjB,YAAa,QACbC,WAZG,SAAmBY,GACtB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,WAAEgK,EAAU,QAAE/G,EAAO,IAAEC,EAAG,WAAE0L,EAAU,gBAAE1I,GAAoBhG,EAE5DkD,EAAW,EAAAzC,aAAA,kBAA+BR,EAAEK,MAAOwJ,EAAY/G,EADnD,CAAC,EAAG,EAAG,GACgEC,EAAKgD,EAAiB0I,GACzGnE,EAAiB,IAAI,IAAcrH,EAAU,OAAO,GAC1D,OAAOnD,EAAQyB,gBAAgB+I,EAAgB,CAACtK,GAAIA,EAAErB,MAC1D,E,4FCPA,MAaasjB,EAAgB,CACzBpjB,WAAY,EAAAqjB,QACZnjB,YAAa,QACbC,WAXoBY,IACpB,MAAM,OAAEC,EAAM,QAAEC,GAAYF,GACtB,GAAEiD,EAAE,EAAEge,GAAMhhB,EACZsB,GAAU,IAAAc,OAAMC,QAAQ,gCAC1B,IAAI,KARW,0IAQ2BW,EAAGxC,MAAOwgB,EAAExgB,OACtD,IAAI,IAVI,yCAUqBwC,EAAGxC,MAAOwgB,EAAExgB,OAC7C,OAAOP,EAAQyB,gBAAgBJ,EAAS,CAAC0B,EAAIge,GAAIhe,EAAGlE,MAAM,E,wKCNvD,SAASwjB,EAAWtiB,EAAQI,EAAMH,GACrC,MAAMnB,EAAQkB,EAAO,GAAGlB,MACxB,GAAc,cAAVA,EAAuB,CACvB,MAAMyjB,EAAQviB,EAAOoX,KAAKpK,IAAM,OAAK,CAAEhN,OAAQ,CAAE+J,MAAOiD,GAAK/M,cACvDuiB,EAAQxiB,EAAOoX,KAAKpK,IAAM,OAAK,CAAEhN,OAAQ,CAAE+J,MAAOiD,GAAK/M,cACvDwiB,EAAeH,EAAWC,EAAOniB,EAAMH,GACvCyiB,EAAeJ,EAAWE,EAAOpiB,EAAMH,GACvCgB,GAAS,OAAQ,CAAEjB,OAAQ,CAAE4D,KAAM6e,EAAc5e,KAAM6e,GAAgBziB,YAK7E,OAJAsiB,EAAMxV,SAAQ4M,GAAK1Z,EAAQ0B,8BAA8BgY,KACzD6I,EAAMzV,SAAQ7L,GAAKjB,EAAQ0B,8BAA8BT,KACzDjB,EAAQ0B,8BAA8B8gB,GACtCxiB,EAAQ0B,8BAA8B+gB,GAC/BzhB,CACX,CACA,IAAI0hB,EAAW1iB,EAAQyM,mBAAmB1M,GAU1C,GAHc,WAAVlB,IACA6jB,GAAW,GAEXA,EAAU,CAQV,MAAMC,EAAY5iB,EAAOoX,KAAIpK,IACzB,MACMxM,EAAQ,EAAE,EADE,EAAAkC,KAAA,cAAmBsK,EAAExM,MAAMkV,MAAMtV,KAEnD,OAAO,OAAQ,CAAEJ,OAAQ,CAAEG,EAAG6M,GAAK/M,UAASC,MAAO,CAAEM,UAAU,IAE7DqiB,EAAkBD,EAAUxL,KAAIpK,IAC3B,CAAE8V,KAAM7iB,EAAQwF,SAASuH,EAAE9I,QAAS1D,MAAOwM,EAAExM,UAGlDgC,EAAW,EAAA7B,aAAA,gBAA6BiiB,EAAUxL,KAAIpK,GAAKA,EAAExM,QAAQ,GACrEuiB,EAAyC,IAA1BH,EAAU,GAAGpiB,MAAM,GAClC2K,GAAU,QAAc0X,EAAiBrgB,EAAU1D,EAAOikB,GAC1DC,EAAgB,EAAAriB,aAAA,gBAA6BX,EAAOoX,KAAIpK,GAAKA,EAAExM,QAAQJ,GACvE6iB,EAAUhjB,EAAQ8D,eAAeif,EAAelkB,EAAOqM,GAE7D,OADAyX,EAAU7V,SAAQC,GAAK/M,EAAQ0B,8BAA8BqL,KACtDiW,CACX,CACA,GAAIjjB,EAAOS,QAAS,IAAA2B,OAAM8gB,UAAU,gCAAiC,CACjE,MAAMC,EAAWhiB,KAAKyV,MAAM5W,EAAOS,OAAS,GACtC2iB,EAAWd,EAAWtiB,EAAO0V,MAAM,EAAGyN,GAAW/iB,EAAMH,GACvDojB,EAAYf,EAAWtiB,EAAO0V,MAAMyN,GAAW/iB,EAAMH,GACrDgB,EAASqhB,EAAW,CAACc,EAAUC,GAAYjjB,EAAMH,GAGvD,OAFAA,EAAQ0B,8BAA8ByhB,GACtCnjB,EAAQ0B,8BAA8B0hB,GAC/BpiB,CACX,CACA,IAAI,IAAAmB,OAAMC,QAAQ,gCACdrC,EAAO,GAAGQ,MAAMC,OAAS,EAAG,CAC5B,MAAMa,EAAU,IAAI,IAAoBtB,EAAOoX,KAAIpK,GAAKA,EAAExM,QAAQJ,GAClE,OAAOH,EAAQyB,gBAAgBJ,EAAStB,EAAQlB,EACpD,CACA,MAAM,UAAE8jB,EAAS,SAAEpgB,GAQvB,SAA0BxC,EAAQI,EAAMH,GAQpC,MAAMuC,EAAW,EAAA7B,aAAA,gBAA6BX,EAAOoX,KAAIpK,GAAKA,EAAExM,QAAQJ,GAClEwiB,EAAY5iB,EAAOoX,KAAIjX,IAAK,OAAQ,CACtCH,OAAQ,CAAEG,KACVD,MAAO,CAAEM,MAAO,EAAE,EAAG,EAAAkC,KAAA,cAAmBvC,EAAEK,MAAMkV,MAAMtV,MACtDH,cAEJ,MAAO,CAAE2iB,YAAWpgB,WACxB,CAvBoC8gB,CAAiBtjB,EAAQI,EAAMH,GACzDqB,EAAU,IAAI,IAAcshB,EAAUxL,KAAIpK,GAAKA,EAAExM,SACjDS,EAAShB,EAAQyB,gBAAgBJ,EAASshB,EAAW9jB,GAC3D8jB,EAAU7V,SAAQ4M,GAAK1Z,EAAQ0B,8BAA8BgY,KAC7D,MAAM4J,GAAiB,OAAQ,CAAEvjB,OAAQ,CAAEG,EAAGc,GAAUf,MAAO,CAAEM,MAAOgC,GAAYvC,YAEpF,OADAA,EAAQ0B,8BAA8BV,GAC/BsiB,CACX,C,eC3EO,SAAS5K,EAAO5Y,GACnB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,KAAEK,GAASF,EACXsjB,EAAQ,EAAA9gB,KAAA,eAAoBtC,EAAMJ,EAAO,GAAGQ,OAAO,GACnDgC,EAAW,EAAA7B,aAAA,gBAA6BX,EAAOoX,KAAIpK,GAAKA,EAAExM,QAAQgjB,GACxE,GAAqC,IAAjC,EAAA9gB,KAAA,cAAmBF,GACnB,OAAOvC,EAAQ8D,eAAevB,EAAUxC,EAAO,GAAGlB,MAAO,IAG7D,MAAM2kB,EAAUzjB,EAAOgG,QAAOgH,GAAK,EAAAtK,KAAA,cAAmBsK,EAAExM,OAAS,IACjE,GAAuB,IAAnBijB,EAAQhjB,OACR,OAAO,OAAS,CAAET,OAAQ,CAAEG,EAAGsjB,EAAQ,IAAMxjB,YAEjD,MAAMyjB,EAASD,EAAQrM,KAAIpK,GAAKA,EAAExM,QAElC,OADA,EAAAG,aAAA,uBAAoC+iB,EAAQF,GACrClB,EAAWmB,EAASD,EAAOvjB,EACtC,CACO,MAAM0jB,EAAe,CACxB3kB,WAAY,EAAA4kB,OACZ1kB,YAAa,QACbC,WAAYwZ,E,2FCpBT,MASMkL,EAAkB,CAC3B7kB,WAAY,EAAA8kB,UACZ5kB,YAAa,QACbC,WAZ+B,EAAGa,SAAQC,UAASC,YACnD,MAAM,EAAEC,GAAMH,GACR,SAAE8hB,EAAQ,KAAEiC,GAAS7jB,EACrBoB,GAAU,IAAAc,OAAMC,QAAQ,+BAC1B,IAAI,IAAuBlC,EAAEK,MAAOshB,EAAUiC,GAC9C,IAAI,IAAiB5jB,EAAEK,MAAOshB,EAAUiC,GAE5C,OADe9jB,EAAQyB,gBAAgBJ,EAAS,CAACnB,GAAIA,EAAErB,MAC1C,E,iFCAV,MAAMklB,EAA4B,CACrChlB,WAAY,EAAAilB,sBACZ/kB,YAAa,QACbC,WAXG,SAA6BY,GAChC,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,GAAEiD,EAAE,OAAEgD,GAAWhG,GACjB,IAAEkD,EAAG,QAAED,EAAO,WAAE0L,GAAezO,EAC/BkD,EAAW,EAAAzC,aAAA,kBAA+BgO,EAAY3I,EAAOxF,MAAOyC,EAAS,EAAmBC,GAChG5B,EAAU,IAAI,KAAsB8B,GAC1C,OAAOnD,EAAQyB,gBAAgBJ,EAAS,CAAC0B,EAAIgD,GAAS,UAC1D,E,4FCNA,MAIake,GAAU,QAAiB,CACpCtlB,UALY,uBAMZC,gBALmB,wCAMnB0M,cAAe,KACfzM,MAAO,SAEEqlB,EAAgB,CACzBnlB,WAAY,EAAAolB,QACZllB,YAAa,QACbC,WAAY+kB,E,sECdhB,MACaG,GAAQ,E,SAAA,IAAgB,CAAEzlB,UADxB,0BAC2CE,MAAO,SACpDwlB,EAAc,CACvBtlB,WAAY,EAAAulB,MACZrlB,YAAa,QACbC,WAAYklB,E,sGCHT,SAASG,EAAQrkB,EAAGskB,EAASxkB,GAChC,MAAMoQ,EAAQpQ,EAAQ+D,QAAQC,IAAI9D,EAAE+D,QAC9BwgB,EAAY,EAAAhiB,KAAA,cAAmBvC,EAAEK,OAEjCmkB,EAAqBxkB,EAAEK,MAAML,EAAEK,MAAMC,OAAS,GAC9CmkB,EAAQF,EAAYC,EACpBE,GAAU,OAAQ,CAAE7kB,OAAQ,CAAEG,KAAKF,UAASC,MAAO,CAAEM,MAAO,CAACokB,EAAOD,MACpE7P,EAAS+P,EAAQrkB,MACjBoN,EAAc,IAAI,IAAW,OAAQkH,EAAQ2P,GAC7C3W,EAAc,IAAI,IAAW,OAAQgH,EAAQ2P,GAC7CzkB,EAAS,CACX,CACIkE,OAAQmM,EAAMhM,mBAAmBT,KAAKM,OACtCpF,MAAOuR,EAAMhM,mBAAmBT,KAAK9E,MACrC0B,MAAOsU,GAEX,CACI5Q,OAAQmM,EAAMhM,mBAAmBR,KAAKK,OACtCpF,MAAOuR,EAAMhM,mBAAmBR,KAAK/E,MACrC0B,MAAOsU,IAGT9G,EAAW/N,EAAQyB,gBAAgBkM,EAAa5N,EAAQ,WACxDiO,EAAWhO,EAAQyB,gBAAgBoM,EAAa9N,EAAQ,WACxDkO,GAAgB,OAAQ,CAAElO,OAAQ,CAAE4D,KAAMoK,EAAUnK,KAAMoK,GAAYhO,YAC5EA,EAAQ0B,8BAA8BqM,GACtC/N,EAAQ0B,8BAA8BsM,GACtC,MAAM6W,GAAwB,OAAQ,CAAE9kB,OAAQ,CAAEG,EAAG+N,GAAiBjO,UAASC,MAAO,CAAEM,MAAOL,EAAEK,SAGjG,OAFAP,EAAQ0B,8BAA8BkjB,GACtC5kB,EAAQ0B,8BAA8BuM,GAC/B4W,CACX,C,wGCjCO,SAASrG,EAAW1e,GACvB,MAAM,OAAEC,EAAM,MAAEE,EAAK,QAAED,GAAYF,GAC7B,IAAEkX,GAAQ/W,GACV,MAAE6J,GAAU/J,EACZ+kB,EAAYhb,EAAMvJ,MAAMC,OACxB+R,EAAWzI,EAAMvJ,MAAMkV,QAC7B,IAAIsP,EAAO/N,EAOX,OANIA,EAAM,IAEN,EAAAvU,KAAA,SAAcqiB,EAAY,IAAM9N,GAAK,IAAM,mCAAmC8N,EAAY,OAAOA,OACjGC,EAAOD,EAAY9N,EAAM,GAE7BzE,EAASoM,OAAOoG,EAAM,EAAG,IAClB,OAAQ,CAAEhlB,OAAQ,CAAEG,EAAG4J,GAAS9J,UAASC,MAAO,CAAEM,MAAOgS,IACpE,CACO,MAAMyS,EAAmB,CAC5BjmB,WAAY,EAAAkmB,WACZhmB,YAAa,QACbC,WAAYsf,E,6FClBhB,MACa0G,GAAW,E,SAAA,IAAiB,CAAEvmB,UADzB,wBAC+CE,MAAO,SAC3DsmB,EAAiB,CAC1BpmB,WAAY,EAAAqmB,SACZnmB,YAAa,QACbC,WAAYgmB,E,6ICFT,SAASlM,EAAIlZ,GAChB,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,GAAMH,GACR,iBAAEslB,EAAgB,SAAEzR,GAAa3T,EACjCK,EAAQJ,EAAEK,MAAMC,OAChBqT,EAAW,EAAApR,KAAA,eAAoB4iB,EAAkBnlB,EAAEK,OACzD,IAAIuT,EAAOD,EACX,MAAME,EAAe,EAAArT,aAAA,mBAAgCoT,EAAMxT,GACrDglB,EAAuC,MAAhBvR,EACvBtH,EAAqBzM,EAAQyM,mBAAmB,CAACvM,IACvD,IAAIqlB,EAAWrlB,EACf,GAAIolB,EAAsB,CACtB,GAAI7Y,EAAoB,CACpB,MACMO,EADWhN,EAAQ+D,QAAQC,IAAIuhB,EAASthB,QACtB+I,OAClBuF,EAAW,IAAI2B,MAAM5T,GAC3B,IAAK,IAAIW,EAAI,EAAGA,EAAIsR,EAAS/R,OAAQS,IACjCsR,EAAStR,GAAKf,EAAEK,MAAMwT,EAAa9S,IAEvC,MAAMukB,GAAiB,QAAiBxY,EAAQ9M,EAAEK,MAAOL,EAAErB,MAAOkV,EAAcxB,GAChFgT,EAAWvlB,EAAQ8D,eAAeyO,EAAUrS,EAAErB,OACzBmB,EAAQ+D,QAAQC,IAAIuhB,EAASthB,QACrC+I,OAASwY,CAC1B,MAEID,GAAW,OAAcrlB,EAAG6T,EAAc/T,GAE9C8T,EAAO,EAAApT,aAAA,iBAA8BoT,EAAKtT,OAAQF,EACtD,CACA,EAAAI,aAAA,2BAAwC,MAAOoT,EAAMxT,GACrD,MAAOmlB,EAAapR,GAAe,EAAA3T,aAAA,0BAAuC6kB,EAAShlB,MAAOuT,GAC1F,IAKIlR,EALAL,EAAWkjB,EAMf,GALI7R,IAEArR,EAAW,EAAA7B,aAAA,qBAAkC+kB,EAAa5R,IAG1DpH,EAAoB,CACpB,MACMO,EADWhN,EAAQ+D,QAAQC,IAAIuhB,EAASthB,QACtB+I,OAClBkB,GAAY,QAAWlB,EAAQ,EAAAvK,KAAA,cAAmB4R,GAAc9R,EAAUrC,EAAErB,OAClF+D,EAAM5C,EAAQ8D,eAAevB,EAAUrC,EAAErB,OACzBmB,EAAQ+D,QAAQC,IAAIpB,EAAIqB,QAChC+I,OAASkB,CACrB,MAEItL,EChDD,SAAiB1C,EAAGmU,EAAa9R,EAAUvC,GAC9C,MAAMsU,EAAS,EAAA7R,KAAA,cAAmB4R,GAE5BnI,EADQ,EAAAzJ,KAAA,cAAmBvC,EAAEK,OACT+T,EACpBC,GAAgB,OAAQ,CAAExU,OAAQ,CAAEG,KAAKD,MAAO,CAAEM,MAAO,CAAC2L,EAAWoI,IAAWtU,YAChFwU,GAAU,EAAAC,EAAA,GAAOF,EAAerU,EAAErB,MAAO,MAAOmB,GAChD0U,GAAiB,OAAQ,CAAE3U,OAAQ,CAAEG,EAAGsU,GAAWvU,MAAO,CAAEM,MAAOgC,GAAYvC,YAGrF,OAFAA,EAAQ0B,8BAA8B6S,GACtCvU,EAAQ0B,8BAA8B8S,GAC/BE,CACX,CDsCcgR,CAAQH,EAAUlR,EAAa9R,EAAUvC,GAKnD,OAHIslB,GACAtlB,EAAQ0B,8BAA8B6jB,GAEnC3iB,CACX,CACO,MAAM+iB,EAAY,CACrB5mB,WAAY,EAAA6mB,IACZ3mB,YAAa,QACbC,WAAY8Z,E,iFExCT,MAAM6M,EAAsB,CAC/B9mB,WAAY,EAAA+mB,cACZ7mB,YAAa,QACbC,WAtBG,SAAuBY,GAC1B,MAAM,OAAEC,EAAM,QAAEC,EAAO,MAAEC,GAAUH,GAC7B,EAAEI,EAAC,QAAEqd,GAAYxd,GACjB,KAAEgB,EAAI,aAAEglB,GAAiB9lB,EAC/B,GAAuB,IAAnBC,EAAEK,MAAMC,OAAc,CACtB,MAAMgd,EAAQxd,EAAQwF,SAAStF,EAAE+D,QAC3BwZ,EAAczd,EAAQwF,SAAS+X,EAAQtZ,QACvCiH,GAAU,QAAgBsS,EAAOC,EAAaF,EAAQ1e,MAAO0e,EAAQhd,MAAOQ,GAClF,OAAOf,EAAQ8D,eAAe,CAAC/C,GAAOwc,EAAQ1e,MAAOqM,EACzD,CACK,GAAuB,IAAnBhL,EAAEK,MAAMC,OAAc,CAC3B,MAAMoM,EAAO5M,EAAQ2M,WAAWzM,GAC1B8lB,EAAahmB,EAAQ2M,WAAW4Q,GAChC1Q,GAAS,QAAsBD,EAAMoZ,EAAYjlB,EAAMglB,GAC7D,OAAO/lB,EAAQ8D,eAAe+I,EAAOtM,MAAOgd,EAAQ1e,MAAOgO,EAAOG,OACtE,CACA,MAAM,IAAIlM,MACN,qEAAGZ,EAAEK,MAAMC,UACnB,E,iFClBO,MAAMylB,EAAsB,CAC/BlnB,WAAY,EAAAmnB,cACZjnB,YAAa,QACbC,WAAY,EAAGa,SAAQC,cACnB,MAAM,MAAEuJ,GAAUxJ,EACZ8Q,EAAe7Q,EACfqB,EAAU,IAAI,IAAqBkI,EAAMhJ,OAE/C,OADesQ,EAAapP,gBAAgBJ,EAAS,CAACkI,GAAQA,EAAM1K,MACvD,E","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GreaterEqual.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsNaN.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LessEqual.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalNot.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cumsum.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LRN.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Diag.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropFilterV2.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Complex.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalOr.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Log1p.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV4.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNative.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3D.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FloorDiv.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cos.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_gpu.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_packed_gpu.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/CropAndResize.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolGrad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mod.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LinSpace.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Maximum.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GatherV2.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Minimum.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Multiply.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Less.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropInput.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Exp.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Dilation2D.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Ceil.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cast.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ComplexAbs.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Fill.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Imag.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FusedConv2D.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Neg.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Elu.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthToSpace.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ClipByValue.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropInput.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mean.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mean_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Floor.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Pack.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalAnd.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/OneHot.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/OnesLike.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FusedDepthwiseConv2D.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchToSpaceND.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3DGrad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IFFT.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GatherNd.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LeakyRelu.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Min.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV5.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Expm1.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Log.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Bincount.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Einsum.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Equal.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV3.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Identity.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchNorm.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsFinite.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Erf.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cosh.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LRNGrad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Multinomial.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FFT.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropFilter.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/PadV2.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3D.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/EluGrad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Concat_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Concat.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MirrorPad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropInputV2.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Greater.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsInf.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FFT_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ExpandDims.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NotEqual.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Max.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Max_impl.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DenseBincount.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FlipLeftRight.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { GreaterEqual } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst GREATER_EQUAL = `return float(a >= b);`;\nconst GREATER_EQUAL_PACKED = `\n  return vec4(greaterThanEqual(a, b));\n`;\nexport const greaterEqual = binaryKernelFunc({\n    opSnippet: GREATER_EQUAL,\n    packedOpSnippet: GREATER_EQUAL_PACKED,\n    dtype: 'bool'\n});\nexport const greaterEqualConfig = {\n    kernelName: GreaterEqual,\n    backendName: 'webgl',\n    kernelFunc: greaterEqual\n};\n//# sourceMappingURL=GreaterEqual.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { IsNan } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst IS_NAN = `return float(isnan(x));`;\nexport const isNaN = unaryKernelFunc({ opSnippet: IS_NAN, dtype: 'bool' });\nexport const isNaNConfig = {\n    kernelName: IsNan,\n    backendName: 'webgl',\n    kernelFunc: isNaN,\n};\n//# sourceMappingURL=IsNaN.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LessEqual } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nexport const LESS_EQUAL = `return float(a <= b);`;\nexport const LESS_EQUAL_PACKED = `\n  return vec4(lessThanEqual(a, b));\n`;\nexport const lessEqual = binaryKernelFunc({ opSnippet: LESS_EQUAL, packedOpSnippet: LESS_EQUAL_PACKED, dtype: 'bool' });\nexport const lessEqualConfig = {\n    kernelName: LessEqual,\n    backendName: 'webgl',\n    kernelFunc: lessEqual\n};\n//# sourceMappingURL=LessEqual.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LogicalNot } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst LOGICAL_NOT = `return float(!(x >= 1.0));`;\nexport const logicalNot = unaryKernelFunc({ opSnippet: LOGICAL_NOT });\nexport const logicalNotConfig = {\n    kernelName: LogicalNot,\n    backendName: 'webgl',\n    kernelFunc: logicalNot,\n};\n//# sourceMappingURL=LogicalNot.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Cumsum } from '@tensorflow/tfjs-core';\nimport { CumSumProgram } from '../cumsum_gpu';\nimport { identity } from './Identity';\nimport { transpose } from './Transpose';\nexport function cumsum(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { axis, exclusive, reverse } = attrs;\n    const xRank = x.shape.length;\n    const permutation = backend_util.getAxesPermutation([axis], xRank);\n    let permutedX = x;\n    if (permutation != null) {\n        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutation } });\n    }\n    const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n    if (permutedAxis !== xRank - 1) {\n        throw new Error(`WebGL cumsum shader expects an inner-most axis=${x.shape.length - 1} ` +\n            `but got axis=${axis}`);\n    }\n    const size = permutedX.shape[permutedAxis];\n    let result = identity({ inputs: { x: permutedX }, backend });\n    // Use cumsum parallel algorithm, ref:\n    // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n    for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n        const program = new CumSumProgram(permutedX.shape, false, reverse);\n        const customSetup = program.getCustomSetupFunc(i);\n        const prevResult = result;\n        result =\n            backend.runWebGLProgram(program, [result], result.dtype, customSetup);\n        backend.disposeIntermediateTensorInfo(prevResult);\n    }\n    // For exclusive cumsum, shift the end result in the direction of sum\n    // and add 0 to the front index.\n    if (exclusive) {\n        const program = new CumSumProgram(permutedX.shape, exclusive, reverse);\n        const prevResult = result;\n        result = backend.runWebGLProgram(program, [result], result.dtype);\n        backend.disposeIntermediateTensorInfo(prevResult);\n    }\n    if (permutation != null) {\n        const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n        const reverseTransposedResult = transpose({ inputs: { x: result }, backend, attrs: { perm: reversePermutation } });\n        backend.disposeIntermediateTensorInfo(result);\n        backend.disposeIntermediateTensorInfo(permutedX);\n        return reverseTransposedResult;\n    }\n    return result;\n}\nexport const cumsumConfig = {\n    kernelName: Cumsum,\n    backendName: 'webgl',\n    kernelFunc: cumsum\n};\n//# sourceMappingURL=Cumsum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, LRN } from '@tensorflow/tfjs-core';\nimport { LRNProgram } from '../lrn_gpu';\nimport { LRNPackedProgram } from '../lrn_packed_gpu';\nexport const lrn = (args) => {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { depthRadius, bias, alpha, beta } = attrs;\n    const program = env().getBool('WEBGL_PACK_NORMALIZATION') ?\n        new LRNPackedProgram(x.shape, depthRadius, bias, alpha, beta) :\n        new LRNProgram(x.shape, depthRadius, bias, alpha, beta);\n    return backend.runWebGLProgram(program, [x], x.dtype);\n};\n// tslint:disable-next-line: variable-name\nexport const LRNConfig = {\n    kernelName: LRN,\n    backendName: 'webgl',\n    kernelFunc: lrn\n};\n//# sourceMappingURL=LRN.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Diag, util } from '@tensorflow/tfjs-core';\nimport { DiagProgram } from '../diag_gpu';\nimport { reshape } from './Reshape';\nexport function diag(args) {\n    const { inputs, backend } = args;\n    const { x } = inputs;\n    const outShape = [...x.shape, ...x.shape];\n    const xSize = util.sizeFromShape(x.shape);\n    const flat = reshape({ inputs: { x }, backend, attrs: { shape: [xSize] } });\n    const program = new DiagProgram(xSize);\n    const res = backend.runWebGLProgram(program, [flat], flat.dtype);\n    const out = reshape({ inputs: { x: res }, backend, attrs: { shape: outShape } });\n    backend.disposeIntermediateTensorInfo(flat);\n    backend.disposeIntermediateTensorInfo(res);\n    return out;\n}\nexport const diagConfig = {\n    kernelName: Diag,\n    backendName: 'webgl',\n    kernelFunc: diag\n};\n//# sourceMappingURL=Diag.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Conv3DBackpropFilterV2 } from '@tensorflow/tfjs-core';\nimport { Conv3DDerFilterProgram } from '../conv_backprop_gpu';\nexport function conv3DBackpropFilterV2(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, dy } = inputs;\n    const { strides, pad, filterShape } = attrs;\n    const convInfo = backend_util.computeConv3DInfo(x.shape, filterShape, strides, 1 /* dilations */, pad);\n    const program = new Conv3DDerFilterProgram(convInfo);\n    return backend.runWebGLProgram(program, [x, dy], 'float32');\n}\nexport const conv3DBackpropFilterV2Config = {\n    kernelName: Conv3DBackpropFilterV2,\n    backendName: 'webgl',\n    kernelFunc: conv3DBackpropFilterV2\n};\n//# sourceMappingURL=Conv3DBackpropFilterV2.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { BatchMatMul } from '@tensorflow/tfjs-core';\nimport { batchMatMulImpl } from './BatchMatMul_impl';\nexport function batchMatMul(args) {\n    const { inputs, backend, attrs } = args;\n    const { a, b } = inputs;\n    const { transposeA, transposeB } = attrs;\n    return batchMatMulImpl({ a, b, transposeA, transposeB, backend });\n}\nexport const batchMatMulConfig = {\n    kernelName: BatchMatMul,\n    backendName: 'webgl',\n    kernelFunc: batchMatMul,\n};\n//# sourceMappingURL=BatchMatMul.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Complex } from '@tensorflow/tfjs-core';\nimport { identity } from './Identity';\n/**\n * In WebGL data is stored in GPU textures which can't be efficiently copied, so\n * complex tensors share data with their real and imaginary components. Complex\n * tensors' reference to the components is tracked by refCount on the individual\n * component. The refCounts are increased by the identity call.\n *\n * When a complex tensor is disposed, it will reduce the refCount on the\n * components by calling disposeData on each.\n */\nexport function complex(args) {\n    const { inputs, backend } = args;\n    const { real, imag } = inputs;\n    const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n    const complex = backend.texData.get(complexInfo.dataId);\n    const realTensorInfo = identity({ inputs: { x: real }, backend });\n    const imagTensorInfo = identity({ inputs: { x: imag }, backend });\n    complex.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };\n    return complexInfo;\n}\nexport const complexConfig = {\n    kernelName: Complex,\n    backendName: 'webgl',\n    kernelFunc: complex\n};\n//# sourceMappingURL=Complex.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LogicalOr } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst LOGICAL_OR = `return float(a >= 1.0 || b >= 1.0);`;\nconst LOGICAL_OR_PACKED = `\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n`;\nexport const logicalOr = binaryKernelFunc({ opSnippet: LOGICAL_OR, packedOpSnippet: LOGICAL_OR_PACKED, dtype: 'bool' });\nexport const logicalOrConfig = {\n    kernelName: LogicalOr,\n    backendName: 'webgl',\n    kernelFunc: logicalOr\n};\n//# sourceMappingURL=LogicalOr.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Log1p } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst LOG1P = `return log(1.0 + x);`;\nexport const log1p = unaryKernelFunc({ opSnippet: LOG1P });\nexport const log1pConfig = {\n    kernelName: Log1p,\n    backendName: 'webgl',\n    kernelFunc: log1p,\n};\n//# sourceMappingURL=Log1p.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, kernel_impls, NonMaxSuppressionV4 } from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nexport function nonMaxSuppressionV4(args) {\n    backend_util.warn('tf.nonMaxSuppression() in webgl locks the UI thread. ' +\n        'Call tf.nonMaxSuppressionAsync() instead');\n    const { inputs, backend, attrs } = args;\n    const { boxes, scores } = inputs;\n    const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;\n    const boxesVals = backend.readSync(boxes.dataId);\n    const scoresVals = backend.readSync(scores.dataId);\n    const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);\n    return [\n        backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n        backend.makeTensorInfo([], 'int32', new Int32Array([validOutputs]))\n    ];\n}\nexport const nonMaxSuppressionV4Config = {\n    kernelName: NonMaxSuppressionV4,\n    backendName: 'webgl',\n    kernelFunc: nonMaxSuppressionV4\n};\n//# sourceMappingURL=NonMaxSuppressionV4.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, DepthwiseConv2dNative, env, util } from '@tensorflow/tfjs-core';\nimport { DepthwiseConv2DProgram } from '../conv_gpu_depthwise';\nimport { DepthwiseConvPacked2DProgram } from '../conv_packed_gpu_depthwise';\nexport function depthwiseConv2dNative(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter } = inputs;\n    const { strides, pad, dilations, dimRoundingMode } = attrs;\n    let $dilations = dilations;\n    if ($dilations == null) {\n        $dilations = [1, 1];\n    }\n    util.assert(backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n        `1. Got strides ${strides} and dilations '${$dilations}'`);\n    const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad, dimRoundingMode, true /* depthwise */);\n    let program;\n    if (env().getBool('WEBGL_PACK_DEPTHWISECONV') && convInfo.strideWidth <= 2 &&\n        convInfo.outChannels / convInfo.inChannels === 1) {\n        program = new DepthwiseConvPacked2DProgram(convInfo);\n    }\n    else {\n        program = new DepthwiseConv2DProgram(convInfo);\n    }\n    return backend.runWebGLProgram(program, [x, filter], 'float32');\n}\nexport const depthwiseConv2dNativeConfig = {\n    kernelName: DepthwiseConv2dNative,\n    backendName: 'webgl',\n    kernelFunc: depthwiseConv2dNative,\n};\n//# sourceMappingURL=DepthwiseConv2dNative.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Conv3D } from '@tensorflow/tfjs-core';\nimport { Conv3DProgram } from '../conv_gpu';\nexport function conv3D(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter } = inputs;\n    const { strides, pad, dilations } = attrs;\n    const convInfo = backend_util.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad);\n    const program = new Conv3DProgram(convInfo);\n    return backend.runWebGLProgram(program, [x, filter], 'float32');\n}\nexport const conv3DConfig = {\n    kernelName: Conv3D,\n    backendName: 'webgl',\n    kernelFunc: conv3D,\n};\n//# sourceMappingURL=Conv3D.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FloorDiv } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\n// We use native integer division to deal with floating point imprecision. Since\n// we implement floor division and glsl implements truncated division, we\n// correct for this by subtracting 1 from result when the result is negative and\n// there is a remainder.\nconst INT_DIV = `\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n`;\nconst INT_DIV_PACKED = `\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n`;\nexport const floorDiv = binaryKernelFunc({ opSnippet: INT_DIV, packedOpSnippet: INT_DIV_PACKED, dtype: 'int32' });\nexport const floorDivConfig = {\n    kernelName: FloorDiv,\n    backendName: 'webgl',\n    kernelFunc: floorDiv\n};\n//# sourceMappingURL=FloorDiv.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Cos } from '@tensorflow/tfjs-core';\nimport { CHECK_NAN_SNIPPET_UNARY, unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst COS = CHECK_NAN_SNIPPET_UNARY + `\n  return cos(x);\n`;\nexport const cos = unaryKernelFunc({ opSnippet: COS });\nexport const cosConfig = {\n    kernelName: Cos,\n    backendName: 'webgl',\n    kernelFunc: cos,\n};\n//# sourceMappingURL=Cos.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { getGlslDifferences } from '../../glsl_version';\nexport class FromPixelsProgram {\n    constructor(outputShape) {\n        this.variableNames = ['A'];\n        const glsl = getGlslDifferences();\n        const [height, width,] = outputShape;\n        this.outputShape = outputShape;\n        this.userCode = `\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);\n\n        vec4 values = ${glsl.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `;\n    }\n}\n//# sourceMappingURL=from_pixels_gpu.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { getGlslDifferences } from '../../glsl_version';\nexport class FromPixelsPackedProgram {\n    constructor(outputShape) {\n        this.variableNames = ['A'];\n        this.packedInputs = false;\n        this.packedOutput = true;\n        const glsl = getGlslDifferences();\n        const [height, width,] = outputShape;\n        this.outputShape = outputShape;\n        this.userCode = `\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${width}.0, ${height}.0);\n            vec4 values = ${glsl.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${glsl.output} = result;\n      }\n    `;\n    }\n}\n//# sourceMappingURL=from_pixels_packed_gpu.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { FromPixels } from '@tensorflow/tfjs-core';\nimport { TextureUsage } from '../tex_util';\nimport { FromPixelsProgram } from './FromPixels_utils/from_pixels_gpu';\nimport { FromPixelsPackedProgram } from './FromPixels_utils/from_pixels_packed_gpu';\nexport const fromPixelsConfig = {\n    kernelName: FromPixels,\n    backendName: 'webgl',\n    kernelFunc: fromPixels,\n};\nlet fromPixels2DContext;\nfunction fromPixels(args) {\n    const { inputs, backend, attrs } = args;\n    let { pixels } = inputs;\n    const { numChannels } = attrs;\n    const isVideo = typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement;\n    const isImage = typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement;\n    const [width, height] = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height];\n    const texShape = [height, width];\n    const outShape = [height, width, numChannels];\n    if (isImage || isVideo) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        pixels = fromPixels2DContext.canvas;\n    }\n    const tempPixelHandle = backend.makeTensorInfo(texShape, 'int32');\n    // This is a byte texture with pixels.\n    backend.texData.get(tempPixelHandle.dataId).usage = TextureUsage.PIXELS;\n    backend.gpgpu.uploadPixelDataToTexture(backend.getTexture(tempPixelHandle.dataId), pixels);\n    const program = env().getBool('WEBGL_PACK') ?\n        new FromPixelsPackedProgram(outShape) :\n        new FromPixelsProgram(outShape);\n    const res = backend.runWebGLProgram(program, [tempPixelHandle], 'int32');\n    backend.disposeData(tempPixelHandle.dataId);\n    return res;\n}\n//# sourceMappingURL=FromPixels.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { CropAndResize } from '@tensorflow/tfjs-core';\nimport { CropAndResizeProgram } from '../crop_and_resize_gpu';\nexport const cropAndResize = (args) => {\n    const { inputs, backend, attrs } = args;\n    const { image, boxes, boxInd } = inputs;\n    const { cropSize, method, extrapolationValue } = attrs;\n    const program = new CropAndResizeProgram(image.shape, boxes.shape, cropSize, method, extrapolationValue);\n    return backend.runWebGLProgram(program, [image, boxes, boxInd], 'float32');\n};\nexport const cropAndResizeConfig = {\n    kernelName: CropAndResize,\n    backendName: 'webgl',\n    kernelFunc: cropAndResize\n};\n//# sourceMappingURL=CropAndResize.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, MaxPoolGrad } from '@tensorflow/tfjs-core';\nimport { MaxPool2DBackpropProgram } from '../max_pool_backprop_gpu';\nimport { Pool2DProgram } from '../pool_gpu';\nimport { assertNotComplex } from '../webgl_util';\nexport function maxPoolGrad(args) {\n    const { inputs, backend, attrs } = args;\n    const { dy, input, output } = inputs;\n    const x = input;\n    assertNotComplex([input, output], 'maxPoolGrad');\n    const { filterSize, strides, pad, dimRoundingMode } = attrs;\n    const convInfo = backend_util.computePool2DInfo(x.shape, filterSize, strides, 1 /* dilations */, pad, dimRoundingMode);\n    const getPositions = true;\n    const maxPoolPositionsProgram = new Pool2DProgram(convInfo, 'max', getPositions);\n    const maxPoolPositions = backend.runWebGLProgram(maxPoolPositionsProgram, [x], x.dtype);\n    const maxPoolBackPropProgram = new MaxPool2DBackpropProgram(convInfo);\n    const result = backend.runWebGLProgram(maxPoolBackPropProgram, [dy, maxPoolPositions], x.dtype);\n    backend.disposeIntermediateTensorInfo(maxPoolPositions);\n    return result;\n}\nexport const maxPoolGradConfig = {\n    kernelName: MaxPoolGrad,\n    backendName: 'webgl',\n    kernelFunc: maxPoolGrad\n};\n//# sourceMappingURL=MaxPoolGrad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, MaxPool, util } from '@tensorflow/tfjs-core';\nimport { Pool2DProgram } from '../pool_gpu';\nimport { assertNotComplex } from '../webgl_util';\nimport { identity } from './Identity';\nexport function maxPool(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    assertNotComplex(x, 'maxPool');\n    const { filterSize, strides, pad, dimRoundingMode } = attrs;\n    const dilations = 1;\n    util.assert(backend_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const convInfo = backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n        util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n        return identity({ inputs: { x }, backend });\n    }\n    const maxPoolProgram = new Pool2DProgram(convInfo, 'max', false);\n    return backend.runWebGLProgram(maxPoolProgram, [x], x.dtype);\n}\nexport const maxPoolConfig = {\n    kernelName: MaxPool,\n    backendName: 'webgl',\n    kernelFunc: maxPool\n};\n//# sourceMappingURL=MaxPool.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Mod } from '@tensorflow/tfjs-core';\nimport { CHECK_NAN_SNIPPET } from '../binaryop_packed_gpu';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst MOD = `if (b == 0.0) return NAN;\n  return mod(a, b);`;\nconst MOD_PACKED = `\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  ` +\n    CHECK_NAN_SNIPPET + `\n  return result;\n`;\nexport const mod = binaryKernelFunc({\n    opSnippet: MOD,\n    packedOpSnippet: MOD_PACKED,\n});\nexport const modConfig = {\n    kernelName: Mod,\n    backendName: 'webgl',\n    kernelFunc: mod\n};\n//# sourceMappingURL=Mod.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LinSpace } from '@tensorflow/tfjs-core';\nimport { linSpaceImplCPU } from '../kernel_utils/shared';\nexport function linSpace(args) {\n    const { backend, attrs } = args;\n    const { start, stop, num } = attrs;\n    // TODO: Use CPU implementation due to the precision problem in Safari.\n    const outVals = linSpaceImplCPU(start, stop, num);\n    return backend.makeTensorInfo([outVals.length], 'float32', outVals);\n}\nexport const linSpaceConfig = {\n    kernelName: LinSpace,\n    backendName: 'webgl',\n    kernelFunc: linSpace\n};\n//# sourceMappingURL=LinSpace.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Maximum } from '@tensorflow/tfjs-core';\nimport { CHECK_NAN_SNIPPET } from '../binaryop_gpu';\nimport { CHECK_NAN_SNIPPET as CHECK_NAN_SNIPPET_PACKED } from '../binaryop_packed_gpu';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { maximumImplCPU } from '../kernel_utils/shared';\nconst MAXIMUM = CHECK_NAN_SNIPPET + `\n  return max(a, b);\n`;\nconst MAXIMUM_PACKED = `\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  ` +\n    CHECK_NAN_SNIPPET_PACKED + `\n  return result;\n`;\nexport const maximum = binaryKernelFunc({\n    opSnippet: MAXIMUM,\n    packedOpSnippet: MAXIMUM_PACKED,\n    cpuKernelImpl: maximumImplCPU\n});\nexport const maximumConfig = {\n    kernelName: Maximum,\n    backendName: 'webgl',\n    kernelFunc: maximum\n};\n//# sourceMappingURL=Maximum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, GatherV2, util } from '@tensorflow/tfjs-core';\nimport { GatherProgram } from '../gather_gpu';\nimport { gatherV2ImplCPU } from '../kernel_utils/shared';\nimport { reshape } from './Reshape';\nexport function gatherV2(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, indices } = inputs;\n    const { axis, batchDims } = attrs;\n    const parsedAxis = util.parseAxisParam(axis, x.shape)[0];\n    const shapeInfo = backend_util.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);\n    const indicesSize = util.sizeFromShape(indices.shape);\n    const toDispose = [];\n    const flattenX = reshape({\n        inputs: { x },\n        backend,\n        attrs: {\n            shape: [\n                shapeInfo.batchSize, shapeInfo.outerSize, shapeInfo.dimSize,\n                shapeInfo.sliceSize\n            ]\n        }\n    });\n    const flattenIndex = reshape({\n        inputs: { x: indices },\n        backend,\n        attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }\n    });\n    toDispose.push(flattenX);\n    toDispose.push(flattenIndex);\n    const flattenOutputShape = [\n        shapeInfo.batchSize, shapeInfo.outerSize, indicesSize / shapeInfo.batchSize,\n        shapeInfo.sliceSize\n    ];\n    if (backend.shouldExecuteOnCPU([x, indices]) || x.dtype === 'string') {\n        const indicesBuf = backend.bufferSync(flattenIndex);\n        const xBuf = backend.bufferSync(flattenX);\n        const outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);\n        toDispose.forEach(t => backend.disposeIntermediateTensorInfo(t));\n        return backend.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);\n    }\n    const program = new GatherProgram(flattenX.shape, flattenOutputShape);\n    const res = backend.runWebGLProgram(program, [flattenX, flattenIndex], flattenX.dtype);\n    toDispose.push(res);\n    const reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: shapeInfo.outputShape } });\n    toDispose.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return reshaped;\n}\nexport const gatherV2Config = {\n    kernelName: GatherV2,\n    backendName: 'webgl',\n    kernelFunc: gatherV2\n};\n//# sourceMappingURL=GatherV2.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Minimum } from '@tensorflow/tfjs-core';\nimport { CHECK_NAN_SNIPPET } from '../binaryop_gpu';\nimport { CHECK_NAN_SNIPPET as CHECK_NAN_SNIPPET_PACKED } from '../binaryop_packed_gpu';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { minimumImplCPU } from '../kernel_utils/shared';\nconst MINIMUM = CHECK_NAN_SNIPPET + `\n  return min(a, b);\n`;\nconst MINIMUM_PACKED = `\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  ` +\n    CHECK_NAN_SNIPPET_PACKED + `\n  return result;\n`;\nexport const minimum = binaryKernelFunc({\n    opSnippet: MINIMUM,\n    packedOpSnippet: MINIMUM_PACKED,\n    cpuKernelImpl: minimumImplCPU\n});\nexport const minimumConfig = {\n    kernelName: Minimum,\n    backendName: 'webgl',\n    kernelFunc: minimum\n};\n//# sourceMappingURL=Minimum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, Multiply } from '@tensorflow/tfjs-core';\nimport * as binaryop_complex_gpu from '../binaryop_complex_gpu';\nimport { BinaryOpComplexProgram } from '../binaryop_complex_gpu';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nimport { multiplyImplCPU as cpuMultiply } from '../kernel_utils/shared';\nimport { complex } from './Complex';\nconst MUL = 'return a * b;';\nexport function multiply(args) {\n    const { inputs, backend } = args;\n    const { a, b } = inputs;\n    const dtype = backend_util.upcastType(a.dtype, b.dtype);\n    if (a.dtype === 'complex64') {\n        const aData = backend.texData.get(a.dataId);\n        const bData = backend.texData.get(b.dataId);\n        const realProgram = new BinaryOpComplexProgram(binaryop_complex_gpu.COMPLEX_MULTIPLY.REAL, a.shape, b.shape);\n        const imagProgram = new BinaryOpComplexProgram(binaryop_complex_gpu.COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);\n        const inputs = [\n            {\n                dataId: aData.complexTensorInfos.real.dataId,\n                dtype: aData.complexTensorInfos.real.dtype,\n                shape: a.shape\n            },\n            {\n                dataId: aData.complexTensorInfos.imag.dataId,\n                dtype: aData.complexTensorInfos.imag.dtype,\n                shape: a.shape\n            },\n            {\n                dataId: bData.complexTensorInfos.real.dataId,\n                dtype: bData.complexTensorInfos.real.dtype,\n                shape: b.shape\n            },\n            {\n                dataId: bData.complexTensorInfos.imag.dataId,\n                dtype: bData.complexTensorInfos.imag.dtype,\n                shape: b.shape\n            }\n        ];\n        const realPart = backend.runWebGLProgram(realProgram, inputs, 'float32');\n        const imagPart = backend.runWebGLProgram(imagProgram, inputs, 'float32');\n        const complexOutput = complex({ inputs: { real: realPart, imag: imagPart }, backend });\n        backend.disposeIntermediateTensorInfo(realPart);\n        backend.disposeIntermediateTensorInfo(imagPart);\n        // TODO(annxingyuan): CPU forwarding for complex inputs.\n        return complexOutput;\n    }\n    if (backend.shouldExecuteOnCPU([a, b])) {\n        const aData = backend.texData.get(a.dataId);\n        const bData = backend.texData.get(b.dataId);\n        const [outValues, outShape] = cpuMultiply(a.shape, b.shape, aData.values, bData.values, dtype);\n        const out = backend.makeTensorInfo(outShape, dtype);\n        const outData = backend.texData.get(out.dataId);\n        outData.values = outValues;\n        return out;\n    }\n    let program;\n    if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        program = new BinaryOpPackedProgram(MUL, a.shape, b.shape);\n    }\n    else {\n        program = new BinaryOpProgram(MUL, a.shape, b.shape);\n    }\n    return backend.runWebGLProgram(program, [a, b], dtype);\n}\nexport const multiplyConfig = {\n    kernelName: Multiply,\n    backendName: 'webgl',\n    kernelFunc: multiply\n};\n//# sourceMappingURL=Multiply.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Less } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { lessImplCPU } from '../kernel_utils/shared';\nconst LESS = `return float(a < b);`;\nconst LESS_PACKED = `\n  return vec4(lessThan(a, b));\n`;\nexport const less = binaryKernelFunc({\n    opSnippet: LESS,\n    packedOpSnippet: LESS_PACKED,\n    cpuKernelImpl: lessImplCPU,\n    dtype: 'bool'\n});\nexport const lessConfig = {\n    kernelName: Less,\n    backendName: 'webgl',\n    kernelFunc: less\n};\n//# sourceMappingURL=Less.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Conv2DBackpropInput } from '@tensorflow/tfjs-core';\nimport { Conv2DDerInputProgram } from '../conv_backprop_gpu';\nexport function conv2DBackpropInput(args) {\n    const { inputs, backend, attrs } = args;\n    const { dy, filter } = inputs;\n    const { inputShape, strides, pad, dataFormat, dimRoundingMode } = attrs;\n    const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n    const convInfo = backend_util.computeConv2DInfo(inputShape, filter.shape, strides, 1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n    const program = new Conv2DDerInputProgram(convInfo);\n    return backend.runWebGLProgram(program, [dy, filter], 'float32');\n}\nexport const conv2DBackpropInputConfig = {\n    kernelName: Conv2DBackpropInput,\n    backendName: 'webgl',\n    kernelFunc: conv2DBackpropInput,\n};\n//# sourceMappingURL=Conv2DBackpropInput.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Exp } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { expImplCPU } from '../kernel_utils/shared';\nexport const EXP = `return exp(x);`;\nexport const exp = unaryKernelFunc({ opSnippet: EXP, packedOpSnippet: EXP, cpuKernelImpl: expImplCPU });\nexport const expConfig = {\n    kernelName: Exp,\n    backendName: 'webgl',\n    kernelFunc: exp\n};\n//# sourceMappingURL=Exp.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Dilation2D } from '@tensorflow/tfjs-core';\nimport { Dilation2DProgram } from '../dilation_gpu';\nimport { reshape } from './Reshape';\nexport function dilation2D(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter } = inputs;\n    const { strides, pad, dilations } = attrs;\n    const convInfo = backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations);\n    let out;\n    const program = new Dilation2DProgram(convInfo);\n    out = backend.runWebGLProgram(program, [x, filter], 'float32');\n    const outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: convInfo.outShape } });\n    backend.disposeIntermediateTensorInfo(out);\n    return outReshaped;\n}\nexport const dilation2DConfig = {\n    kernelName: Dilation2D,\n    backendName: 'webgl',\n    kernelFunc: dilation2D,\n};\n//# sourceMappingURL=Dilation2D.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Ceil } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { ceilImplCPU } from '../kernel_utils/shared';\nconst CEIL = `return ceil(x);`;\nexport const ceil = unaryKernelFunc({ opSnippet: CEIL, packedOpSnippet: CEIL, cpuKernelImpl: ceilImplCPU });\nexport const ceilConfig = {\n    kernelName: Ceil,\n    backendName: 'webgl',\n    kernelFunc: ceil\n};\n//# sourceMappingURL=Ceil.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport { Cast, util } from '@tensorflow/tfjs-core';\nimport { complex } from './Complex';\nimport { identity } from './Identity';\nimport { notEqual } from './NotEqual';\nimport { real } from './Real';\nimport { int } from '../kernel_utils/int';\nexport function cast(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { dtype } = attrs;\n    // Casting to complex64.\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return identity({ inputs: { x }, backend });\n        }\n        // TODO(annxingyuan): Import kernel function once zeros is modularized.\n        const zerosTensor = tf.zeros(x.shape);\n        const floatX = cast({ inputs: { x }, backend, attrs: { dtype: 'float32' } });\n        const result = complex({ inputs: { real: floatX, imag: zerosTensor }, backend });\n        zerosTensor.dispose();\n        backend.disposeIntermediateTensorInfo(floatX);\n        return result;\n    }\n    // Casting from complex64\n    if (x.dtype === 'complex64') {\n        const realPart = real({ inputs: { input: x }, backend });\n        const result = cast({ inputs: { x: realPart }, backend, attrs: { dtype } });\n        backend.disposeIntermediateTensorInfo(realPart);\n        return result;\n    }\n    if (!util.hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        const result = identity({ inputs: { x }, backend });\n        return { dataId: result.dataId, shape: result.shape, dtype };\n    }\n    if (dtype === 'int32') {\n        return int(x, backend);\n    }\n    if (dtype === 'bool') {\n        const zerosTensorInfo = backend.makeTensorInfo([], 'bool', util.getTypedArrayFromDType('bool', 1));\n        const binaryInputs = { a: x, b: zerosTensorInfo };\n        const result = notEqual({ inputs: binaryInputs, backend });\n        backend.disposeIntermediateTensorInfo(zerosTensorInfo);\n        return result;\n    }\n    throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\nexport const castConfig = {\n    kernelName: Cast,\n    backendName: 'webgl',\n    kernelFunc: cast\n};\n//# sourceMappingURL=Cast.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ComplexAbs } from '@tensorflow/tfjs-core';\nimport { ComplexAbsProgram } from '../complex_abs_gpu';\n// Returns a TensorInfo with the complex shape and the dataId of the\n// underlying part. We need to do this because a reshaped complex tensor is\n// not reflected in its parts.\nfunction makeComplexComponentTensorInfo(complexTensor, complexPart) {\n    return {\n        dataId: complexPart.dataId,\n        dtype: complexPart.dtype,\n        shape: complexTensor.shape\n    };\n}\nexport function complexAbs(args) {\n    const { inputs, backend } = args;\n    const { x } = inputs;\n    const xData = backend.texData.get(x.dataId);\n    const program = new ComplexAbsProgram(x.shape);\n    const programInputs = [\n        makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),\n        makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag),\n    ];\n    return backend.runWebGLProgram(program, programInputs, programInputs[0].dtype);\n}\nexport const complexAbsConfig = {\n    kernelName: ComplexAbs,\n    backendName: 'webgl',\n    kernelFunc: complexAbs\n};\n//# sourceMappingURL=ComplexAbs.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Fill, util } from '@tensorflow/tfjs-core';\nimport { FillProgram } from '../fill_gpu';\nexport function fill(args) {\n    const { backend, attrs } = args;\n    const { shape, value } = attrs;\n    let { dtype } = attrs;\n    dtype = dtype || util.inferDtype(value);\n    if (dtype === 'string') {\n        // String type should be handled in CPU memory.\n        const values = util.getArrayFromDType(dtype, util.sizeFromShape(shape));\n        values.fill(value);\n        return backend.makeTensorInfo(shape, dtype, values);\n    }\n    else {\n        const program = new FillProgram(shape, value);\n        const customSetup = program.getCustomSetupFunc(value);\n        return backend.runWebGLProgram(program, [], dtype, customSetup);\n    }\n}\nexport const fillConfig = {\n    kernelName: Fill,\n    backendName: 'webgl',\n    kernelFunc: fill\n};\n//# sourceMappingURL=Fill.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { MaxPoolWithArgmax } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxPoolWithArgmaxImpl } from './MaxPoolWithArgmax_impl';\nexport const maxPoolWithArgmaxConfig = {\n    kernelName: MaxPoolWithArgmax,\n    backendName: 'webgl',\n    kernelFunc: ({ inputs, attrs, backend }) => {\n        const { x } = inputs;\n        const { filterSize, strides, pad, includeBatchInIndex } = attrs;\n        const webglBackend = backend;\n        util.assert(x.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`);\n        const dilations = [1, 1];\n        util.assert(backend_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n            `Got strides ${strides} and dilations '${dilations}'`);\n        const convInfo = backend_util.computePool2DInfo(x.shape, filterSize, strides, dilations, pad);\n        const [result, indexes] = maxPoolWithArgmaxImpl(x, includeBatchInIndex, convInfo, webglBackend);\n        return [result, indexes];\n    }\n};\n//# sourceMappingURL=MaxPoolWithArgmax.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Pool2DProgram } from '../pool_gpu';\nexport function maxPoolWithArgmaxImpl(x, includeBatchInIndex, convInfo, backend) {\n    let program = new Pool2DProgram(convInfo, 'max', false);\n    const poolOutput = backend.runWebGLProgram(program, [x], 'float32');\n    program = new Pool2DProgram(convInfo, 'max', true, true, includeBatchInIndex);\n    const indexOutput = backend.runWebGLProgram(program, [x], 'float32');\n    return [poolOutput, indexOutput];\n}\n//# sourceMappingURL=MaxPoolWithArgmax_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Imag } from '@tensorflow/tfjs-core';\nimport { identity } from './Identity';\nexport function imag(args) {\n    const { inputs, backend } = args;\n    const { input } = inputs;\n    const inputData = backend.texData.get(input.dataId);\n    return identity({ inputs: { x: inputData.complexTensorInfos.imag }, backend });\n}\nexport const imagConfig = {\n    kernelName: Imag,\n    backendName: 'webgl',\n    kernelFunc: imag\n};\n//# sourceMappingURL=Imag.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedConv2D, util } from '@tensorflow/tfjs-core';\nimport { Conv2DProgram } from '../conv_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { conv2dByMatMul, conv2dWithIm2Row } from './Conv2D_impl';\nimport { reshape } from './Reshape';\nexport function fusedConv2d(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter, bias, preluActivationWeights } = inputs;\n    const { strides, pad, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;\n    const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n    const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n    let out;\n    const intermediates = [];\n    if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n        convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n        convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n        (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n        out = conv2dByMatMul({\n            x,\n            filter,\n            convInfo,\n            backend,\n            bias,\n            activation,\n            preluActivationWeights,\n            leakyreluAlpha\n        });\n    }\n    else if (env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n        out = conv2dWithIm2Row({\n            x,\n            filter,\n            convInfo,\n            backend,\n            bias,\n            activation,\n            preluActivationWeights,\n            leakyreluAlpha\n        });\n    }\n    else {\n        const hasBias = bias != null;\n        const hasPreluActivationWeights = preluActivationWeights != null;\n        const hasLeakyreluAlpha = activation === 'leakyrelu';\n        const fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n        const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n        const inputs = [x, filter];\n        if (bias) {\n            inputs.push(bias);\n        }\n        if (preluActivationWeights) {\n            inputs.push(preluActivationWeights);\n        }\n        if (hasLeakyreluAlpha) {\n            const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n            inputs.push($leakyreluAlpha);\n            intermediates.push($leakyreluAlpha);\n        }\n        out = backend.runWebGLProgram(program, inputs, 'float32');\n    }\n    const outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: convInfo.outShape } });\n    intermediates.push(out);\n    intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return outReshaped;\n}\nexport const fusedConv2DConfig = {\n    kernelName: FusedConv2D,\n    backendName: 'webgl',\n    kernelFunc: fusedConv2d,\n};\n//# sourceMappingURL=FusedConv2D.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, Neg } from '@tensorflow/tfjs-core';\nimport { negImplCPU } from '../kernel_utils/shared';\nimport { UnaryOpProgram } from '../unaryop_gpu';\nimport { UnaryOpPackedProgram } from '../unaryop_packed_gpu';\nconst NEG = `return -x;`;\n// This doesn't use unaryKernelFunc because negImplCPU is not of type\n// SimpleUnaryKernelImplCPU.\nexport function neg(args) {\n    const { inputs, backend } = args;\n    const { x } = inputs;\n    if (backend.shouldExecuteOnCPU([x])) {\n        const xData = backend.texData.get(x.dataId);\n        const [outValues, newShape] = negImplCPU(xData.values, x.shape, x.dtype);\n        return backend.makeTensorInfo(newShape, x.dtype, outValues);\n    }\n    let program;\n    if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        program = new UnaryOpPackedProgram(x.shape, NEG);\n    }\n    else {\n        program = new UnaryOpProgram(x.shape, NEG);\n    }\n    return backend.runWebGLProgram(program, [x], x.dtype);\n}\nexport const negConfig = {\n    kernelName: Neg,\n    backendName: 'webgl',\n    kernelFunc: neg\n};\n//# sourceMappingURL=Neg.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Elu } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst ELU = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;\nconst ELU_PACKED = `\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n`;\nconst elu = unaryKernelFunc({ opSnippet: ELU, packedOpSnippet: ELU_PACKED });\nexport const eluConfig = {\n    kernelName: Elu,\n    backendName: 'webgl',\n    kernelFunc: elu\n};\n//# sourceMappingURL=Elu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { DepthToSpace, util } from '@tensorflow/tfjs-core';\nimport { DepthToSpaceProgram } from '../depth_to_space_gpu';\nexport function depthToSpace(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { blockSize, dataFormat } = attrs;\n    util.assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n    const batchSize = x.shape[0];\n    const inputHeight = (dataFormat === 'NHWC') ? x.shape[1] : x.shape[2];\n    const inputWidth = (dataFormat === 'NHWC') ? x.shape[2] : x.shape[3];\n    const inputDepth = (dataFormat === 'NHWC') ? x.shape[3] : x.shape[1];\n    const outputHeight = inputHeight * blockSize;\n    const outputWidth = inputWidth * blockSize;\n    const outputDepth = inputDepth / (blockSize * blockSize);\n    const outputShape = (dataFormat === 'NHWC') ?\n        [batchSize, outputHeight, outputWidth, outputDepth] :\n        [batchSize, outputDepth, outputHeight, outputWidth];\n    const program = new DepthToSpaceProgram(outputShape, blockSize, dataFormat);\n    return backend.runWebGLProgram(program, [x], x.dtype);\n}\nexport const depthToSpaceConfig = {\n    kernelName: DepthToSpace,\n    backendName: 'webgl',\n    kernelFunc: depthToSpace\n};\n//# sourceMappingURL=DepthToSpace.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ClipByValue, env } from '@tensorflow/tfjs-core';\nimport { ClipProgram } from '../clip_gpu';\nimport { ClipPackedProgram } from '../clip_packed_gpu';\nexport function clipByValue(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { clipValueMin, clipValueMax } = attrs;\n    let program;\n    if (env().getBool('WEBGL_PACK_CLIP')) {\n        program = new ClipPackedProgram(x.shape);\n    }\n    else {\n        program = new ClipProgram(x.shape);\n    }\n    const customSetup = program.getCustomSetupFunc(clipValueMin, clipValueMax);\n    return backend.runWebGLProgram(program, [x], x.dtype, customSetup);\n}\nexport const clipByValueConfig = {\n    kernelName: ClipByValue,\n    backendName: 'webgl',\n    kernelFunc: clipByValue\n};\n//# sourceMappingURL=ClipByValue.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, DepthwiseConv2dNativeBackpropInput } from '@tensorflow/tfjs-core';\nimport { DepthwiseConv2DDerInputProgram } from '../conv_backprop_gpu_depthwise';\nexport function depthwiseConv2dNativeBackpropInput(args) {\n    const { inputs, backend, attrs } = args;\n    const { dy, filter } = inputs;\n    const { strides, dilations, pad, dimRoundingMode, inputShape } = attrs;\n    const convInfo = backend_util.computeConv2DInfo(inputShape, filter.shape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    const program = new DepthwiseConv2DDerInputProgram(convInfo);\n    return backend.runWebGLProgram(program, [dy, filter], 'float32');\n}\nexport const depthwiseConv2dNativeBackpropInputConfig = {\n    kernelName: DepthwiseConv2dNativeBackpropInput,\n    backendName: 'webgl',\n    kernelFunc: depthwiseConv2dNativeBackpropInput\n};\n//# sourceMappingURL=DepthwiseConv2dNativeBackpropInput.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Mean, util } from '@tensorflow/tfjs-core';\nimport { meanImpl } from './Mean_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport const meanConfig = {\n    kernelName: Mean,\n    backendName: 'webgl',\n    kernelFunc: ({ inputs, attrs, backend }) => {\n        const { x } = inputs;\n        const { keepDims, axis } = attrs;\n        const webglBackend = backend;\n        const xRank = x.shape.length;\n        const origAxes = util.parseAxisParam(axis, x.shape);\n        let axes = origAxes;\n        const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n        const meanInputIsTransposed = permutedAxes != null;\n        const shouldExecuteOnCPU = webglBackend.shouldExecuteOnCPU([x]);\n        const intermediates = [];\n        let meanInput = x;\n        if (meanInputIsTransposed) {\n            if (shouldExecuteOnCPU) {\n                const xTexData = webglBackend.texData.get(meanInput.dataId);\n                const values = xTexData.values;\n                const newShape = new Array(xRank);\n                for (let i = 0; i < newShape.length; i++) {\n                    newShape[i] = x.shape[permutedAxes[i]];\n                }\n                const meanInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n                meanInput = webglBackend.makeTensorInfo(newShape, x.dtype);\n                const meanInputData = webglBackend.texData.get(meanInput.dataId);\n                meanInputData.values = meanInputValues;\n            }\n            else {\n                meanInput = transposeImpl(x, permutedAxes, webglBackend);\n            }\n            intermediates.push(meanInput);\n            axes = backend_util.getInnerMostAxes(axes.length, xRank);\n        }\n        backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n        const [meanOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(meanInput.shape, axes);\n        let outShape = meanOutShape;\n        if (keepDims) {\n            // rather than reshape at the end, set the target shape here.\n            outShape = backend_util.expandShapeToKeepDim(meanOutShape, origAxes);\n        }\n        const out = meanImpl(meanInput, reduceShape, outShape, webglBackend);\n        for (const i of intermediates) {\n            webglBackend.disposeIntermediateTensorInfo(i);\n        }\n        return out;\n    }\n};\n//# sourceMappingURL=Mean.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from '../kernels/Reshape';\nexport function meanImpl(x, reduceShape, outShape, backend) {\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(x.shape);\n    const batchSize = xSize / inSize;\n    const reshapedInput = reshape({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend });\n    const reduced = reduce(reshapedInput, 'float32', 'mean', backend);\n    const reshapedOutput = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });\n    backend.disposeIntermediateTensorInfo(reshapedInput);\n    backend.disposeIntermediateTensorInfo(reduced);\n    return reshapedOutput;\n}\n//# sourceMappingURL=Mean_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { Im2ColPackedProgram } from '../im2col_packed_gpu';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { MatMulPackedProgram } from '../mulmat_packed_gpu';\nimport * as webgl_util from '../webgl_util';\nimport { batchMatMulImpl, MATMUL_SHARED_DIM_THRESHOLD } from './BatchMatMul_impl';\nimport { identity } from './Identity';\nimport { reshape } from './Reshape';\n// For 1x1 kernels that iterate through every point in the input, convolution\n// can be expressed as matrix multiplication (without need for memory\n// remapping).\nexport function conv2dByMatMul({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {\n    // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n    // result from 2D to 4D.\n    const xShape = x.shape;\n    const xTexData = backend.texData.get(x.dataId);\n    const sharedMatMulDim = convInfo.inChannels;\n    const outerShapeX = xShape[0] * xShape[1] * xShape[2];\n    const outerShapeFilter = convInfo.outChannels;\n    const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n    const transposeA = false;\n    const transposeB = false;\n    let out;\n    const intermediates = [];\n    // TODO: Once reduction ops are packed, batchMatMul will always be packed\n    // and we can remove this condition.\n    const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) &&\n        sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n    const reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n    if (batchMatMulWillBeUnpacked || !env().getBool('WEBGL_LAZILY_UNPACK') ||\n        !env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ||\n        !reshapeWillBeExpensive) {\n        const targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] :\n            xShape[0] * xShape[2] * xShape[3];\n        const xReshaped = reshape({\n            inputs: { x },\n            backend,\n            attrs: { shape: [1, targetShape, convInfo.inChannels] }\n        });\n        const filterReshaped = reshape({\n            inputs: { x: filter },\n            backend,\n            attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }\n        });\n        const result = batchMatMulImpl({\n            a: xReshaped,\n            b: filterReshaped,\n            transposeA,\n            transposeB,\n            backend,\n            bias,\n            activation,\n            preluActivationWeights,\n            leakyreluAlpha\n        });\n        out = reshape({ inputs: { x: result }, backend, attrs: { shape: convInfo.outShape } });\n        intermediates.push(xReshaped);\n        intermediates.push(filterReshaped);\n        intermediates.push(result);\n    }\n    else {\n        // Following optimization is specific to packed |x| with odd row count\n        // (For example, in channelLast mode, 'row count' refers to x.shape[2]):\n        // we avoid expensive packed 2x2 reshape by padding row count to next,\n        // even number. When x.shape[2] is odd, the result of packed batchMatMul is\n        // the same (has the same texture layout and and values in the texture) as\n        // it is for even x.shape[2] + 1. We make the odd-rows tensor to look like\n        // even-rows tensor before the operation and, after the batchMatMul,\n        // fix the even-rows result to have odd number of rows.\n        const targetShape = isChannelsLast ?\n            xShape[0] * xShape[1] * (xShape[2] + 1) :\n            xShape[0] * xShape[2] * (xShape[3] + 1);\n        const xReshaped = {\n            dataId: x.dataId,\n            shape: [1, targetShape, convInfo.inChannels],\n            dtype: x.dtype\n        };\n        // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n        // Decrementing row count, after batchMatMul->...->compileProgram leads to\n        // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n        // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n        // in compileProgram method, but that would affect compilation of all\n        // programs - instead, provide a copy here, with even row count, before\n        // calling batchMatMul->...->compileProgram and after that, the original\n        // xTexData.shape is restored.\n        const originalXTexDataShape = xTexData.shape;\n        xTexData.shape = xTexData.shape.slice();\n        xTexData.shape[xTexData.shape.length - 2]++;\n        util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);\n        const filterReshaped = reshape({\n            inputs: { x: filter },\n            backend,\n            attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }\n        });\n        intermediates.push(filterReshaped);\n        const pointwiseConv = batchMatMulImpl({\n            a: xReshaped,\n            b: filterReshaped,\n            backend,\n            transposeA,\n            transposeB,\n            bias,\n            activation,\n            preluActivationWeights,\n            leakyreluAlpha\n        });\n        const pointwiseConvTexData = backend.texData.get(pointwiseConv.dataId);\n        util.assert(pointwiseConvTexData.isPacked, () => 'batchMatMul result is expected to be packed');\n        // Restore the input shape to original.\n        xTexData.shape = originalXTexDataShape;\n        // Set the output shape - there is no need for expensive reshape as data\n        // layout is already correct.\n        pointwiseConvTexData.shape = convInfo.outShape;\n        out = identity({ inputs: { x: pointwiseConv }, backend });\n        out.shape = convInfo.outShape;\n        intermediates.push(pointwiseConv);\n    }\n    for (const i of intermediates) {\n        backend.disposeIntermediateTensorInfo(i);\n    }\n    return out;\n}\n// Implements the im2row algorithm as outlined in \"High Performance\n// Convolutional Neural Networks for Document Processing\" (Suvisoft, 2006)\nexport function conv2dWithIm2Row({ x, filter, convInfo, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {\n    // Rearranges conv2d input so each block to be convolved over forms the\n    // column of a new matrix with shape [filterWidth * filterHeight *\n    // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n    // output channel forms a row of a new matrix with shape [outChannels,\n    // filterWidth * filterHeight * inChannels]. The convolution is then\n    // computed by multiplying these matrices and reshaping the result.\n    const { filterWidth, filterHeight, inChannels, outWidth, outHeight, dataFormat } = convInfo;\n    const isChannelsLast = dataFormat === 'channelsLast';\n    const sharedDim = filterWidth * filterHeight * inChannels;\n    const numCols = outHeight * outWidth;\n    const x2ColShape = [sharedDim, numCols];\n    const transposeA = true;\n    const transposeB = false;\n    const intermediates = [];\n    const xSqueezed = reshape({ inputs: { x }, backend, attrs: { shape: x.shape.slice(1) } });\n    const w2Row = reshape({\n        inputs: { x: filter },\n        backend,\n        attrs: { shape: [1, sharedDim, util.sizeFromShape(filter.shape) / sharedDim] }\n    });\n    intermediates.push(xSqueezed);\n    intermediates.push(w2Row);\n    const im2ColProgram = new Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n    const im2Col = backend.runWebGLProgram(im2ColProgram, [xSqueezed], 'float32');\n    const im2ColReshaped = reshape({\n        inputs: { x: im2Col },\n        backend,\n        attrs: { shape: [1, x2ColShape[0], x2ColShape[1]] }\n    });\n    intermediates.push(im2Col);\n    intermediates.push(im2ColReshaped);\n    const hasBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    const hasLeakyreluAlpha = activation === 'leakyrelu';\n    const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n    const matmulProgram = new MatMulPackedProgram(im2ColReshaped.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    const inputs = [im2ColReshaped, w2Row];\n    if (bias) {\n        inputs.push(bias);\n    }\n    if (hasPreluActivationWeights) {\n        inputs.push(preluActivationWeights);\n    }\n    if (hasLeakyreluAlpha) {\n        const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n        inputs.push($leakyreluAlpha);\n        intermediates.push($leakyreluAlpha);\n    }\n    const product = backend.runWebGLProgram(matmulProgram, inputs, 'float32');\n    const outShape = isChannelsLast ?\n        [1, outHeight, outWidth, convInfo.outChannels] :\n        [1, convInfo.outChannels, outHeight, outWidth];\n    const out = reshape({ inputs: { x: product }, backend, attrs: { shape: outShape } });\n    intermediates.push(product);\n    for (const i of intermediates) {\n        backend.disposeIntermediateTensorInfo(i);\n    }\n    return out;\n}\n//# sourceMappingURL=Conv2D_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Floor } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { floorImplCPU } from '../kernel_utils/shared';\nconst FLOOR = `return floor(x);`;\nexport const floor = unaryKernelFunc({ opSnippet: FLOOR, packedOpSnippet: FLOOR, cpuKernelImpl: floorImplCPU });\nexport const floorConfig = {\n    kernelName: Floor,\n    backendName: 'webgl',\n    kernelFunc: floor,\n};\n//# sourceMappingURL=Floor.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Pack, util } from '@tensorflow/tfjs-core';\nimport { concat } from './Concat';\nimport { expandDims } from './ExpandDims';\nexport function pack(args) {\n    const { inputs, backend, attrs } = args;\n    const { axis } = attrs;\n    if (inputs.length === 1) {\n        return expandDims({ inputs: { input: inputs[0] }, backend, attrs: { dim: axis } });\n    }\n    const shape = inputs[0].shape;\n    const dtype = inputs[0].dtype;\n    inputs.forEach(t => {\n        util.assertShapesMatch(shape, t.shape, 'All tensors passed to stack must have matching shapes');\n        util.assert(dtype === t.dtype, () => 'All tensors passed to stack must have matching dtypes');\n    });\n    const intermediateTensorInfos = [];\n    const expandedTensors = inputs.map(t => {\n        const expandedT = expandDims({ inputs: { input: t }, backend, attrs: { dim: axis } });\n        intermediateTensorInfos.push(expandedT);\n        return expandedT;\n    });\n    const result = concat({ inputs: expandedTensors, backend, attrs: { axis } });\n    intermediateTensorInfos.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return result;\n}\nexport const packConfig = {\n    kernelName: Pack,\n    backendName: 'webgl',\n    kernelFunc: pack\n};\n//# sourceMappingURL=Pack.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LogicalAnd } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst LOGICAL_AND = `return float(a >= 1.0 && b >= 1.0);`;\nconst LOGICAL_AND_PACKED = `\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n`;\nexport const logicalAnd = binaryKernelFunc({\n    opSnippet: LOGICAL_AND,\n    packedOpSnippet: LOGICAL_AND_PACKED,\n    dtype: 'bool'\n});\nexport const logicalAndConfig = {\n    kernelName: LogicalAnd,\n    backendName: 'webgl',\n    kernelFunc: logicalAnd\n};\n//# sourceMappingURL=LogicalAnd.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { OneHot, util } from '@tensorflow/tfjs-core';\nimport { OneHotProgram } from '../onehot_gpu';\nimport { reshape } from './Reshape';\nexport const oneHot = (args) => {\n    const { inputs, backend, attrs } = args;\n    const { indices } = inputs;\n    const { depth, onValue, offValue } = attrs;\n    const indicesSize = util.sizeFromShape(indices.shape);\n    const program = new OneHotProgram(indicesSize, depth, onValue, offValue);\n    const reshaped = reshape({ inputs: { x: indices }, backend, attrs: { shape: [indicesSize] } });\n    const result = backend.runWebGLProgram(program, [reshaped], indices.dtype);\n    backend.disposeIntermediateTensorInfo(reshaped);\n    const outShape = [...indices.shape, depth];\n    const out = reshape({ inputs: { x: result }, backend, attrs: { shape: outShape } });\n    backend.disposeIntermediateTensorInfo(result);\n    return out;\n};\nexport const oneHotConfig = {\n    kernelName: OneHot,\n    backendName: 'webgl',\n    kernelFunc: oneHot\n};\n//# sourceMappingURL=OneHot.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { upcastType, util } from '@tensorflow/tfjs-core';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nimport { MatMulPackedProgram } from '../mulmat_packed_gpu';\nimport { multiply } from './Multiply';\nimport { reshape } from './Reshape';\nimport { sum } from './Sum';\nimport { transpose } from './Transpose';\n// Empirically determined minimal shared dimension in matmul before we forward\n// to a.mul(b).sum() in order to take advantage of GPU parallelism. See\n// https://github.com/tensorflow/tfjs-core/pull/1379 for benchmarks.\nexport const MATMUL_SHARED_DIM_THRESHOLD = 1000;\nexport function batchMatMulImpl({ a, b, transposeA, transposeB, backend, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {\n    const aRank = a.shape.length;\n    const bRank = b.shape.length;\n    const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n    const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n    const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n    const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n    const outerDimsA = a.shape.slice(0, -2);\n    const outerDimsB = b.shape.slice(0, -2);\n    const batchDimA = util.sizeFromShape(outerDimsA);\n    const batchDimB = util.sizeFromShape(outerDimsB);\n    const batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n    util.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, () => `Error in matMul: the input batch dimensions must either be the ` +\n        `same or at least one input batch dimension must be 1. Got input ` +\n        `batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);\n    const outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);\n    const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n    util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n        `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n        `${b.shape} and transposeA=${transposeA}` +\n        ` and transposeB=${transposeB} must match.`);\n    const a3dShape = transposeA ?\n        [batchDimA, innerShapeA, outerShapeA] :\n        [batchDimA, outerShapeA, innerShapeA];\n    const b3dShape = transposeB ?\n        [batchDimB, outerShapeB, innerShapeB] :\n        [batchDimB, innerShapeB, outerShapeB];\n    // The rest of the implementation is designed to operate on rank-3 tensors\n    const a3d = reshape({ inputs: { x: a }, backend, attrs: { shape: a3dShape } });\n    const b3d = reshape({ inputs: { x: b }, backend, attrs: { shape: b3dShape } });\n    const intermediates = [a3d, b3d];\n    const batchDim = Math.max(batchDimA, batchDimB);\n    const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n    const hasBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    const hasLeakyreluAlpha = activation === 'leakyrelu';\n    const fusedActivation = activation != null ?\n        mapActivationToShaderProgram(activation, true) :\n        null;\n    const containsFusedOps = hasBias || hasPreluActivationWeights ||\n        hasLeakyreluAlpha || fusedActivation != null;\n    let out;\n    // Since the matrices are vectors, it is faster to call mul().sum()\n    // because sum() is O(sqrt(N)) due to divide-and-conquer.\n    if ((outerShapeA === 1 || outerShapeB === 1) &&\n        sharedDim > MATMUL_SHARED_DIM_THRESHOLD && containsFusedOps === false) {\n        let aVec = a3d;\n        let bVec = b3d;\n        if (transposeA) {\n            aVec = transpose({ inputs: { x: a3d }, backend, attrs: { perm: [0, 2, 1] } });\n            intermediates.push(aVec);\n        }\n        if (transposeB) {\n            bVec = transpose({ inputs: { x: b3d }, backend, attrs: { perm: [0, 2, 1] } });\n            intermediates.push(bVec);\n        }\n        const shouldReshapeA = outerShapeB !== 1;\n        const shouldReshapeB = outerShapeB === 1;\n        let aVec3d = aVec;\n        if (shouldReshapeA) {\n            aVec3d = reshape({\n                inputs: { x: aVec },\n                backend,\n                attrs: { shape: [batchDim, sharedDim, 1] }\n            });\n            intermediates.push(aVec3d);\n        }\n        const axis = outerShapeB === 1 ? 2 : 1;\n        let bVec3d = bVec;\n        if (shouldReshapeB) {\n            bVec3d = reshape({\n                inputs: { x: bVec },\n                backend,\n                attrs: { shape: [batchDim, 1, sharedDim] }\n            });\n            intermediates.push(bVec3d);\n        }\n        const product = multiply({ inputs: { a: aVec3d, b: bVec3d }, backend });\n        out = sum({ inputs: { x: product }, backend, attrs: { axis, keepDims: true } });\n        intermediates.push(product);\n    }\n    else {\n        const dtype = upcastType(a.dtype, b.dtype);\n        const program = new MatMulPackedProgram(a3dShape, b3dShape, [batchDim, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n        const inputs = [a3d, b3d];\n        if (bias != null) {\n            inputs.push(bias);\n        }\n        if (hasPreluActivationWeights) {\n            inputs.push(preluActivationWeights);\n        }\n        if (hasLeakyreluAlpha) {\n            const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n            inputs.push($leakyreluAlpha);\n            intermediates.push($leakyreluAlpha);\n        }\n        out = backend.runWebGLProgram(program, inputs, dtype);\n    }\n    const outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: outShape } });\n    intermediates.push(out);\n    for (const i of intermediates) {\n        backend.disposeIntermediateTensorInfo(i);\n    }\n    return outReshaped;\n}\n//# sourceMappingURL=BatchMatMul_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { OnesLike } from '@tensorflow/tfjs-core';\nimport { complex } from './Complex';\nimport { fill } from './Fill';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { zerosLike } from './ZerosLike';\nexport function onesLike(args) {\n    const { inputs, backend } = args;\n    const { x } = inputs;\n    if (x.dtype === 'string') {\n        throw new Error('onesLike is not supported under string dtype');\n    }\n    else if (x.dtype === 'complex64') {\n        const realPart = real({ inputs: { input: x }, backend });\n        const r = onesLike({ inputs: { x: realPart }, backend });\n        const imagPart = imag({ inputs: { input: x }, backend });\n        const i = zerosLike({ inputs: { x: imagPart }, backend });\n        const result = complex({ inputs: { real: r, imag: i }, backend });\n        backend.disposeIntermediateTensorInfo(realPart);\n        backend.disposeIntermediateTensorInfo(r);\n        backend.disposeIntermediateTensorInfo(imagPart);\n        backend.disposeIntermediateTensorInfo(i);\n        return result;\n    }\n    else {\n        // TODO(cais, smilkov): Add WebGL shader for onesLike:\n        //   https://github.com/tensorflow/tfjs/issues/1293\n        return fill({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend });\n    }\n}\nexport const onesLikeConfig = {\n    kernelName: OnesLike,\n    backendName: 'webgl',\n    kernelFunc: onesLike\n};\n//# sourceMappingURL=OnesLike.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, FusedDepthwiseConv2D, util } from '@tensorflow/tfjs-core';\nimport { DepthwiseConv2DProgram } from '../conv_gpu_depthwise';\nimport { DepthwiseConvPacked2DProgram } from '../conv_packed_gpu_depthwise';\nimport { mapActivationToShaderProgram } from '../kernel_utils/kernel_funcs_utils';\nexport function fusedDepthwiseConv2D(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter, bias, preluActivationWeights } = inputs;\n    const { strides, pad, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;\n    const intermediates = [];\n    let $dilations = dilations;\n    if ($dilations == null) {\n        $dilations = [1, 1];\n    }\n    util.assert(backend_util.eitherStridesOrDilationsAreOne(strides, $dilations), () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n        `1. Got strides ${strides} and dilations '${$dilations}'`);\n    const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, $dilations, pad, dimRoundingMode, true /* depthwise */);\n    const shouldPackDepthwiseConv = env().getBool('WEBGL_PACK_DEPTHWISECONV') &&\n        convInfo.strideWidth <= 2 &&\n        convInfo.outChannels / convInfo.inChannels === 1;\n    const fusedActivation = activation ?\n        mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) :\n        null;\n    const programInputs = [x, filter];\n    const hasBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    const hasLeakyreluAlpha = activation === 'leakyrelu';\n    if (hasBias) {\n        programInputs.push(bias);\n    }\n    if (hasPreluActivationWeights) {\n        programInputs.push(preluActivationWeights);\n    }\n    if (hasLeakyreluAlpha) {\n        const $leakyreluAlpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(leakyreluAlpha, 'float32'));\n        programInputs.push($leakyreluAlpha);\n        intermediates.push($leakyreluAlpha);\n    }\n    let program;\n    if (shouldPackDepthwiseConv) {\n        program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    }\n    else {\n        program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);\n    }\n    const result = backend.runWebGLProgram(program, programInputs, 'float32');\n    intermediates.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return result;\n}\nexport const fusedDepthwiseConv2DConfig = {\n    kernelName: FusedDepthwiseConv2D,\n    backendName: 'webgl',\n    kernelFunc: fusedDepthwiseConv2D,\n};\n//# sourceMappingURL=FusedDepthwiseConv2D.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, BatchToSpaceND, util } from '@tensorflow/tfjs-core';\nimport { reshape } from './Reshape';\nimport { slice } from './Slice';\nimport { transpose } from './Transpose';\nexport const batchToSpaceND = (args) => {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { blockShape, crops } = attrs;\n    util.assert(x.shape.length <= 4, () => 'batchToSpaceND for rank > 4 with a WebGL backend not ' +\n        'implemented yet');\n    const prod = blockShape.reduce((a, b) => a * b);\n    const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n    const permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n    const reshapedPermuted = backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    const sliceBeginCoords = backend_util.getSliceBeginCoords(crops, blockShape.length);\n    const sliceSize = backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n    const toDispose = [];\n    const reshapedIntermediate = reshape({ inputs: { x }, backend, attrs: { shape: reshaped } });\n    const transposedIntermediate = transpose({ inputs: { x: reshapedIntermediate }, backend, attrs: { perm: permuted } });\n    const reshapedIntermediate2 = reshape({\n        inputs: { x: transposedIntermediate },\n        backend,\n        attrs: { shape: reshapedPermuted }\n    });\n    const sliced = slice({\n        inputs: { x: reshapedIntermediate2 },\n        backend,\n        attrs: { begin: sliceBeginCoords, size: sliceSize }\n    });\n    toDispose.push(reshapedIntermediate);\n    toDispose.push(transposedIntermediate);\n    toDispose.push(reshapedIntermediate2);\n    toDispose.forEach(t => backend.disposeIntermediateTensorInfo(t));\n    return sliced;\n};\nexport const batchToSpaceNDConfig = {\n    kernelName: BatchToSpaceND,\n    backendName: 'webgl',\n    kernelFunc: batchToSpaceND\n};\n//# sourceMappingURL=BatchToSpaceND.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, MaxPool3DGrad } from '@tensorflow/tfjs-core';\nimport { MaxPool3DBackpropProgram } from '../max_pool_backprop_gpu';\nimport { Pool3DProgram } from '../pool_gpu';\nexport function maxPool3DGrad(args) {\n    const { inputs, backend, attrs } = args;\n    const { dy, input } = inputs;\n    const x = input;\n    const { filterSize, strides, pad, dimRoundingMode } = attrs;\n    const dilations = [1, 1, 1];\n    const convInfo = backend_util.computePool3DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode);\n    const maxPool3dPositionsProgram = new Pool3DProgram(convInfo, 'max', true /* get positions */);\n    const maxPool3dPositions = backend.runWebGLProgram(maxPool3dPositionsProgram, [x], x.dtype);\n    const maxPoolBackpropProgram = new MaxPool3DBackpropProgram(convInfo);\n    const result = backend.runWebGLProgram(maxPoolBackpropProgram, [dy, maxPool3dPositions], x.dtype);\n    backend.disposeIntermediateTensorInfo(maxPool3dPositions);\n    return result;\n}\nexport const maxPoolGrad3DConfig = {\n    kernelName: MaxPool3DGrad,\n    backendName: 'webgl',\n    kernelFunc: maxPool3DGrad\n};\n//# sourceMappingURL=MaxPool3DGrad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Conv2D, env } from '@tensorflow/tfjs-core';\nimport { Conv2DProgram } from '../conv_gpu';\nimport { conv2dByMatMul, conv2dWithIm2Row } from './Conv2D_impl';\nimport { reshape } from './Reshape';\nexport function conv2d(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter } = inputs;\n    const { strides, pad, dataFormat, dilations, dimRoundingMode } = attrs;\n    const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n    const convInfo = backend_util.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n    let out;\n    if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 &&\n        convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 &&\n        convInfo.strideHeight === 1 && convInfo.strideWidth === 1 &&\n        (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n        out = conv2dByMatMul({ x, filter, convInfo, backend });\n    }\n    else if (env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n        out = conv2dWithIm2Row({ x, filter, convInfo, backend });\n    }\n    else {\n        const program = new Conv2DProgram(convInfo);\n        out = backend.runWebGLProgram(program, [x, filter], 'float32');\n    }\n    const outReshaped = reshape({ inputs: { x: out }, backend, attrs: { shape: convInfo.outShape } });\n    backend.disposeIntermediateTensorInfo(out);\n    return outReshaped;\n}\nexport const conv2DConfig = {\n    kernelName: Conv2D,\n    backendName: 'webgl',\n    kernelFunc: conv2d,\n};\n//# sourceMappingURL=Conv2D.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { IFFT } from '@tensorflow/tfjs-core';\nimport { fftImpl } from './FFT_impl';\nexport function ifft(args) {\n    const { inputs, backend } = args;\n    const { input } = inputs;\n    return fftImpl(input, true /* inverse */, backend);\n}\nexport const ifftConfig = {\n    kernelName: IFFT,\n    backendName: 'webgl',\n    kernelFunc: ifft\n};\n//# sourceMappingURL=IFFT.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, GatherNd, util } from '@tensorflow/tfjs-core';\nimport { GatherNDProgram } from '../gather_nd_gpu';\nimport { reshape } from './Reshape';\nexport function gatherNd(args) {\n    const { inputs, backend } = args;\n    const { params, indices } = inputs;\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n    const [resultShape, numSlices, sliceSize, strides] = backend_util.prepareAndValidate(params, indices);\n    const flattenIndices = reshape({ inputs: { x: indices }, backend, attrs: { shape: [numSlices, sliceRank] } });\n    const flattenX = reshape({\n        inputs: { x: params },\n        backend,\n        attrs: { shape: [(util.sizeFromShape(params.shape) / sliceSize), sliceSize] }\n    });\n    const program = new GatherNDProgram(sliceRank, strides, [numSlices, sliceSize]);\n    const res = backend.runWebGLProgram(program, [flattenX, flattenIndices], flattenX.dtype);\n    const reshaped = reshape({ inputs: { x: res }, backend, attrs: { shape: resultShape } });\n    backend.disposeIntermediateTensorInfo(flattenIndices);\n    backend.disposeIntermediateTensorInfo(flattenX);\n    backend.disposeIntermediateTensorInfo(res);\n    return reshaped;\n}\nexport const gatherNdConfig = {\n    kernelName: GatherNd,\n    backendName: 'webgl',\n    kernelFunc: gatherNd\n};\n//# sourceMappingURL=GatherNd.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, LeakyRelu, util } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nexport const LEAKYRELU = `return (a < 0.) ? b * a : a;`;\nexport const LEAKYRELU_PACKED = `\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n`;\nexport function leakyRelu(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { alpha } = attrs;\n    const $alpha = backend.makeTensorInfo([], 'float32', util.createScalarValue(alpha, 'float32'));\n    const program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n        new BinaryOpPackedProgram(LEAKYRELU_PACKED, x.shape, $alpha.shape) :\n        new BinaryOpProgram(LEAKYRELU, x.shape, $alpha.shape);\n    const result = backend.runWebGLProgram(program, [x, $alpha], x.dtype);\n    backend.disposeIntermediateTensorInfo($alpha);\n    return result;\n}\nexport const leakyReluConfig = {\n    kernelName: LeakyRelu,\n    backendName: 'webgl',\n    kernelFunc: leakyRelu\n};\n//# sourceMappingURL=LeakyRelu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Min, util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from './Reshape';\nimport { transpose } from './Transpose';\nexport function min(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { axis, keepDims } = attrs;\n    const xRank = x.shape.length;\n    const origAxes = util.parseAxisParam(axis, x.shape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    let permutedX = x;\n    if (permutedAxes != null) {\n        permutedX = transpose({ inputs: { x }, backend, attrs: { perm: permutedAxes } });\n        axes = backend_util.getInnerMostAxes(axes.length, x.shape.length);\n    }\n    backend_util.assertAxesAreInnerMostDims('min', axes, xRank);\n    const [outShape, reduceShape] = backend_util.computeOutAndReduceShapes(permutedX.shape, axes);\n    const inSize = util.sizeFromShape(reduceShape);\n    const a2D = reshape({ inputs: { x: permutedX }, backend, attrs: { shape: [-1, inSize] } });\n    const reduced = reduce(a2D, a2D.dtype, 'min', backend);\n    let res;\n    if (keepDims) {\n        const newShape = backend_util.expandShapeToKeepDim(outShape, origAxes);\n        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: newShape } });\n    }\n    else {\n        res = reshape({ inputs: { x: reduced }, backend, attrs: { shape: outShape } });\n    }\n    backend.disposeIntermediateTensorInfo(a2D);\n    backend.disposeIntermediateTensorInfo(reduced);\n    if (permutedAxes != null) {\n        backend.disposeIntermediateTensorInfo(permutedX);\n    }\n    return res;\n}\nexport const minConfig = {\n    kernelName: Min,\n    backendName: 'webgl',\n    kernelFunc: min\n};\n//# sourceMappingURL=Min.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, kernel_impls, NonMaxSuppressionV5 } from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nexport function nonMaxSuppressionV5(args) {\n    backend_util.warn('tf.nonMaxSuppression() in webgl locks the UI thread. ' +\n        'Call tf.nonMaxSuppressionAsync() instead');\n    const { inputs, backend, attrs } = args;\n    const { boxes, scores } = inputs;\n    const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;\n    const boxesVals = backend.readSync(boxes.dataId);\n    const scoresVals = backend.readSync(scores.dataId);\n    const maxOutputSizeVal = maxOutputSize;\n    const iouThresholdVal = iouThreshold;\n    const scoreThresholdVal = scoreThreshold;\n    const softNmsSigmaVal = softNmsSigma;\n    const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);\n    return [\n        backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices)),\n        backend.makeTensorInfo([selectedScores.length], 'float32', new Float32Array(selectedScores))\n    ];\n}\nexport const nonMaxSuppressionV5Config = {\n    kernelName: NonMaxSuppressionV5,\n    backendName: 'webgl',\n    kernelFunc: nonMaxSuppressionV5\n};\n//# sourceMappingURL=NonMaxSuppressionV5.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Expm1 } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { expm1ImplCPU } from '../kernel_utils/shared';\nconst EXPM1 = `return exp(x) - 1.0;`;\nexport const expm1 = unaryKernelFunc({ opSnippet: EXPM1, packedOpSnippet: EXPM1, cpuKernelImpl: expm1ImplCPU });\nexport const expm1Config = {\n    kernelName: Expm1,\n    backendName: 'webgl',\n    kernelFunc: expm1\n};\n//# sourceMappingURL=Expm1.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Log } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { logImplCPU } from '../kernel_utils/shared';\nconst LOG = `if (x < 0.0) return NAN;\n  return log(x);`;\nconst LOG_PACKED = `\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n`;\nexport const log = unaryKernelFunc({ opSnippet: LOG, packedOpSnippet: LOG_PACKED, cpuKernelImpl: logImplCPU });\nexport const logConfig = {\n    kernelName: Log,\n    backendName: 'webgl',\n    kernelFunc: log\n};\n//# sourceMappingURL=Log.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Bincount } from '@tensorflow/tfjs-core';\nimport { bincountImplCPU } from '../kernel_utils/shared';\nexport function bincount(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, weights } = inputs;\n    const { size } = attrs;\n    const xVals = backend.readSync(x.dataId);\n    const weightsVals = backend.readSync(weights.dataId);\n    const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);\n    return backend.makeTensorInfo([size], weights.dtype, outVals);\n}\nexport const bincountConfig = {\n    kernelName: Bincount,\n    backendName: 'webgl',\n    kernelFunc: bincount\n};\n//# sourceMappingURL=Bincount.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Einsum, util } from '@tensorflow/tfjs-core';\nimport { multiply } from './Multiply';\nimport { reshape } from './Reshape';\nimport { sum } from './Sum';\nimport { transpose } from './Transpose';\nexport function einsum(args) {\n    const { inputs, backend, attrs } = args;\n    const { equation } = attrs;\n    const tensors = inputs;\n    const { allDims, summedDims, idDims } = backend_util.decodeEinsumEquation(equation, tensors.length);\n    backend_util.checkEinsumDimSizes(allDims.length, idDims, tensors);\n    const { path, steps } = backend_util.getEinsumComputePath(summedDims, idDims);\n    const nSteps = steps.length;\n    let out = null;\n    let numDimsRemaining = allDims.length;\n    const tensorsToDispose = [];\n    for (let i = 0; i < nSteps; ++i) {\n        for (const idTerm of steps[i]) {\n            const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);\n            let x;\n            if (backend_util.isIdentityPermutation(perm)) {\n                x = tensors[idTerm];\n            }\n            else {\n                x = transpose({ inputs: { x: tensors[idTerm] }, backend, attrs: { perm } });\n                tensorsToDispose.push(x);\n            }\n            const targetShape = x.shape.slice();\n            for (let k = 0; k < dimsToExpand.length; ++k) {\n                targetShape.splice(dimsToExpand[k], 0, 1);\n            }\n            if (!util.arraysEqual(x.shape, targetShape)) {\n                x = reshape({ inputs: { x }, backend, attrs: { shape: targetShape } });\n                tensorsToDispose.push(x);\n            }\n            if (out === null) {\n                out = x;\n            }\n            else {\n                // tslint:disable-next-line: no-unnecessary-type-assertion\n                out = multiply({ inputs: { a: x, b: out }, backend });\n                tensorsToDispose.push(out);\n            }\n        }\n        if (i < nSteps - 1) {\n            if (path[i] >= 0) {\n                out = sum({\n                    inputs: { x: out },\n                    backend,\n                    attrs: {\n                        axis: path[i] - (allDims.length - numDimsRemaining),\n                        keepDims: false\n                    }\n                });\n                tensorsToDispose.push(out);\n            }\n            numDimsRemaining--;\n        }\n    }\n    // Clean up intermediate tensors.\n    for (const tensorInfo of tensorsToDispose) {\n        if (tensorInfo === out) {\n            continue;\n        }\n        backend.disposeIntermediateTensorInfo(tensorInfo);\n    }\n    return out;\n}\nexport const einsumConfig = {\n    kernelName: Einsum,\n    backendName: 'webgl',\n    kernelFunc: einsum\n};\n//# sourceMappingURL=Einsum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Equal } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst PACKED_EQUAL = `\n  return vec4(equal(a, b));\n`;\nconst EQUAL = `return float(a == b);`;\nexport const equal = binaryKernelFunc({ opSnippet: EQUAL, packedOpSnippet: PACKED_EQUAL, dtype: 'bool' });\nexport const equalConfig = {\n    kernelName: Equal,\n    backendName: 'webgl',\n    kernelFunc: equal\n};\n//# sourceMappingURL=Equal.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, kernel_impls, NonMaxSuppressionV3 } from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\nexport function nonMaxSuppressionV3(args) {\n    backend_util.warn('tf.nonMaxSuppression() in webgl locks the UI thread. ' +\n        'Call tf.nonMaxSuppressionAsync() instead');\n    const { inputs, backend, attrs } = args;\n    const { boxes, scores } = inputs;\n    const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;\n    const boxesVals = backend.readSync(boxes.dataId);\n    const scoresVals = backend.readSync(scores.dataId);\n    const { selectedIndices } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n    return backend.makeTensorInfo([selectedIndices.length], 'int32', new Int32Array(selectedIndices));\n}\nexport const nonMaxSuppressionV3Config = {\n    kernelName: NonMaxSuppressionV3,\n    backendName: 'webgl',\n    kernelFunc: nonMaxSuppressionV3\n};\n//# sourceMappingURL=NonMaxSuppressionV3.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Identity } from '@tensorflow/tfjs-core';\nexport function identity(args) {\n    const { inputs, backend } = args;\n    const { x } = inputs;\n    backend.incRef(x.dataId);\n    return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };\n}\nexport const identityConfig = {\n    kernelName: Identity,\n    backendName: 'webgl',\n    kernelFunc: identity\n};\n//# sourceMappingURL=Identity.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, FusedBatchNorm, util } from '@tensorflow/tfjs-core';\nimport { BatchNormProgram } from '../batchnorm_gpu';\nimport { BatchNormPackedProgram } from '../batchnorm_packed_gpu';\nexport const batchNorm = ({ inputs, backend, attrs }) => {\n    const { x, mean, variance, offset, scale } = inputs;\n    util.assert(mean.shape.length === variance.shape.length, () => 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.');\n    util.assert(offset == null || mean.shape.length === offset.shape.length, () => 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.');\n    util.assert(scale == null || mean.shape.length === scale.shape.length, () => 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.');\n    let { varianceEpsilon } = attrs;\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    const finalInputs = [x, mean, variance];\n    let offsetShape = null;\n    if (offset != null) {\n        offsetShape = offset.shape;\n        finalInputs.push(offset);\n    }\n    let scaleShape = null;\n    if (scale != null) {\n        scaleShape = scale.shape;\n        finalInputs.push(scale);\n    }\n    const program = env().getBool('WEBGL_PACK_NORMALIZATION') ?\n        new BatchNormPackedProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon) :\n        new BatchNormProgram(x.shape, mean.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);\n    const output = backend.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);\n    return output;\n};\nexport const batchNormConfig = {\n    kernelName: FusedBatchNorm,\n    backendName: 'webgl',\n    kernelFunc: batchNorm,\n};\n//# sourceMappingURL=BatchNorm.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { IsFinite } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst IS_FINITE = `return float(!isnan(x) && !isinf(x));`;\nexport const isFinite = unaryKernelFunc({ opSnippet: IS_FINITE, dtype: 'bool' });\nexport const isFiniteConfig = {\n    kernelName: IsFinite,\n    backendName: 'webgl',\n    kernelFunc: isFinite,\n};\n//# sourceMappingURL=IsFinite.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Erf } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst ERF = `\n  // Error function is calculated approximately with elementary function.\n  // See \"Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\n  float p = ${backend_util.ERF_P};\n  float a1 = ${backend_util.ERF_A1};\n  float a2 = ${backend_util.ERF_A2};\n  float a3 = ${backend_util.ERF_A3};\n  float a4 = ${backend_util.ERF_A4};\n  float a5 = ${backend_util.ERF_A5};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`;\nexport const erf = unaryKernelFunc({ opSnippet: ERF });\nexport const erfConfig = {\n    kernelName: Erf,\n    backendName: 'webgl',\n    kernelFunc: erf,\n};\n//# sourceMappingURL=Erf.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, DepthwiseConv2dNativeBackpropFilter } from '@tensorflow/tfjs-core';\nimport { DepthwiseConv2DDerFilterProgram } from '../conv_backprop_gpu_depthwise';\nexport function depthwiseConv2dNativeBackpropFilter(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, dy } = inputs;\n    const { strides, dilations, pad, dimRoundingMode, filterShape } = attrs;\n    const convInfo = backend_util.computeConv2DInfo(x.shape, filterShape, strides, dilations, pad, dimRoundingMode, true /* depthwise */);\n    const program = new DepthwiseConv2DDerFilterProgram(convInfo);\n    return backend.runWebGLProgram(program, [x, dy], 'float32');\n}\nexport const depthwiseConv2dNativeBackpropFilterConfig = {\n    kernelName: DepthwiseConv2dNativeBackpropFilter,\n    backendName: 'webgl',\n    kernelFunc: depthwiseConv2dNativeBackpropFilter\n};\n//# sourceMappingURL=DepthwiseConv2dNativeBackpropFilter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Cosh } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst COSH = `\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n`;\nexport const cosh = unaryKernelFunc({ opSnippet: COSH });\nexport const coshConfig = {\n    kernelName: Cosh,\n    backendName: 'webgl',\n    kernelFunc: cosh,\n};\n//# sourceMappingURL=Cosh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LRNGrad } from '@tensorflow/tfjs-core';\nimport { LRNGradProgram } from '../lrn_grad_gpu';\nexport const lrnGrad = (args) => {\n    const { inputs, backend, attrs } = args;\n    const { x, y, dy } = inputs;\n    const { depthRadius, bias, alpha, beta } = attrs;\n    const program = new LRNGradProgram(x.shape, depthRadius, bias, alpha, beta);\n    return backend.runWebGLProgram(program, [x, y, dy], x.dtype);\n};\n// tslint:disable-next-line: variable-name\nexport const LRNGradConfig = {\n    kernelName: LRNGrad,\n    backendName: 'webgl',\n    kernelFunc: lrnGrad\n};\n//# sourceMappingURL=LRNGrad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Multinomial } from '@tensorflow/tfjs-core';\nimport { MultinomialProgram } from '../multinomial_gpu';\nimport { softmax } from './Softmax';\nexport function multinomial(args) {\n    const { inputs, backend, attrs } = args;\n    const { logits } = inputs;\n    const { numSamples, seed, normalized } = attrs;\n    const probs = normalized ?\n        logits :\n        softmax({ inputs: { logits }, backend, attrs: { dim: logits.shape.length - 1 } });\n    const batchSize = probs.shape[0];\n    const numOutcomes = probs.shape[1];\n    const program = new MultinomialProgram(batchSize, numOutcomes, numSamples);\n    const customSetup = program.getCustomSetupFunc(seed);\n    const res = backend.runWebGLProgram(program, [probs], 'int32', customSetup);\n    if (!normalized) {\n        backend.disposeIntermediateTensorInfo(probs);\n    }\n    return res;\n}\nexport const multinomialConfig = {\n    kernelName: Multinomial,\n    backendName: 'webgl',\n    kernelFunc: multinomial\n};\n//# sourceMappingURL=Multinomial.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FFT } from '@tensorflow/tfjs-core';\nimport { fftImpl } from './FFT_impl';\nexport function fft(args) {\n    const { inputs, backend } = args;\n    const { input } = inputs;\n    return fftImpl(input, false /* inverse */, backend);\n}\nexport const fftConfig = {\n    kernelName: FFT,\n    backendName: 'webgl',\n    kernelFunc: fft\n};\n//# sourceMappingURL=FFT.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Conv2DBackpropFilter } from '@tensorflow/tfjs-core';\nimport { Conv2DDerFilterProgram } from '../conv_backprop_gpu';\nexport function conv2DBackpropFilter(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, dy } = inputs;\n    const { strides, pad, dataFormat, dimRoundingMode, filterShape } = attrs;\n    const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n    const convInfo = backend_util.computeConv2DInfo(x.shape, filterShape, strides, 1 /* dilations */, pad, dimRoundingMode, false /* depthwise */, $dataFormat);\n    const program = new Conv2DDerFilterProgram(convInfo);\n    return backend.runWebGLProgram(program, [x, dy], 'float32');\n}\nexport const conv2DBackpropFilterConfig = {\n    kernelName: Conv2DBackpropFilter,\n    backendName: 'webgl',\n    kernelFunc: conv2DBackpropFilter,\n};\n//# sourceMappingURL=Conv2DBackpropFilter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, PadV2 } from '@tensorflow/tfjs-core';\nimport { PadProgram } from '../pad_gpu';\nimport { PadPackedProgram } from '../pad_packed_gpu';\nexport const padV2 = (args) => {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { paddings, constantValue } = attrs;\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n        new PadPackedProgram(x.shape, paddings, constantValue) :\n        new PadProgram(x.shape, paddings, constantValue);\n    const customSetup = program.getCustomSetupFunc(constantValue);\n    return backend.runWebGLProgram(program, [x], x.dtype, customSetup);\n};\nexport const padV2Config = {\n    kernelName: PadV2,\n    backendName: 'webgl',\n    kernelFunc: padV2\n};\n//# sourceMappingURL=PadV2.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, MaxPool3D } from '@tensorflow/tfjs-core';\nimport { Pool3DProgram } from '../pool_gpu';\nexport function maxPool3d(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { filterSize, strides, pad, dataFormat, dimRoundingMode } = attrs;\n    const dilations = [1, 1, 1];\n    const convInfo = backend_util.computePool3DInfo(x.shape, filterSize, strides, dilations, pad, dimRoundingMode, dataFormat);\n    const maxPoolProgram = new Pool3DProgram(convInfo, 'max', false);\n    return backend.runWebGLProgram(maxPoolProgram, [x], x.dtype);\n}\nexport const maxPool3DConfig = {\n    kernelName: MaxPool3D,\n    backendName: 'webgl',\n    kernelFunc: maxPool3d\n};\n//# sourceMappingURL=MaxPool3D.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { EluGrad, env } from '@tensorflow/tfjs-core';\nimport { BinaryOpProgram } from '../binaryop_gpu';\nimport { BinaryOpPackedProgram } from '../binaryop_packed_gpu';\nconst ELU_DER = `return (b >= 1.0) ? a : a * (b + 1.0);`;\nconst ELU_DER_PACKED = `\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n`;\nexport const eluGrad = (args) => {\n    const { inputs, backend } = args;\n    const { dy, y } = inputs;\n    const program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ?\n        new BinaryOpPackedProgram(ELU_DER_PACKED, dy.shape, y.shape) :\n        new BinaryOpProgram(ELU_DER, dy.shape, y.shape);\n    return backend.runWebGLProgram(program, [dy, y], dy.dtype);\n};\nexport const eluGradConfig = {\n    kernelName: EluGrad,\n    backendName: 'webgl',\n    kernelFunc: eluGrad\n};\n//# sourceMappingURL=EluGrad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, env, util } from '@tensorflow/tfjs-core';\nimport { ConcatProgram } from '../concat_gpu';\nimport { ConcatPackedProgram } from '../concat_packed_gpu';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { complex } from './Complex';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concatImpl(inputs, axis, backend) {\n    const dtype = inputs[0].dtype;\n    if (dtype === 'complex64') {\n        const reals = inputs.map((t) => real({ inputs: { input: t }, backend }));\n        const imags = inputs.map((t) => imag({ inputs: { input: t }, backend }));\n        const realConcated = concatImpl(reals, axis, backend);\n        const imagConcated = concatImpl(imags, axis, backend);\n        const result = complex({ inputs: { real: realConcated, imag: imagConcated }, backend });\n        reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n        imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n        backend.disposeIntermediateTensorInfo(realConcated);\n        backend.disposeIntermediateTensorInfo(imagConcated);\n        return result;\n    }\n    let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n    // Run on cpu if dtype is string. For string, the backend represents it\n    // as Uint8Array[], where each Uint8Array is a character. Given that the\n    // computation is only on the outer array, uploading the whole data onto\n    // gpu is wasteful. Also, currently webgl doesn't have a design to\n    // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n    // just run the kernel on cpu if dtype is string.\n    if (dtype === 'string') {\n        runOnCpu = true;\n    }\n    if (runOnCpu) {\n        // Any concat of n-dimensional tensors across any axis can be reduced to\n        // a concatenation of two-dimensional tensors across the axis 1 by first\n        // partitioning the axes of the original tensors into those less than the\n        // axis to be concatenated and the rest. Then reshape the tensors\n        // into a two-dimensional tensor by collapsing these two sets of axes and\n        // concatenate the resulting matrices across the axis 1, finally reshaping\n        // the result to have the proper shape.\n        const tensors2D = inputs.map(t => {\n            const innerSize = util.sizeFromShape(t.shape.slice(axis));\n            const shape = [-1, innerSize];\n            return reshape({ inputs: { x: t }, backend, attrs: { shape } });\n        });\n        const inputsValShapes = tensors2D.map(t => {\n            return { vals: backend.readSync(t.dataId), shape: t.shape };\n        });\n        // Concats 2d tensors along axis=1.\n        const outShape = backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n        const simplyConcat = tensors2D[0].shape[0] === 1;\n        const outVals = concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n        const finalOutShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n        const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n        tensors2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n        return outInfo;\n    }\n    if (inputs.length > env().getNumber('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n        const midIndex = Math.floor(inputs.length / 2);\n        const leftSide = concatImpl(inputs.slice(0, midIndex), axis, backend);\n        const rightSide = concatImpl(inputs.slice(midIndex), axis, backend);\n        const result = concatImpl([leftSide, rightSide], axis, backend);\n        backend.disposeIntermediateTensorInfo(leftSide);\n        backend.disposeIntermediateTensorInfo(rightSide);\n        return result;\n    }\n    if (env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') &&\n        inputs[0].shape.length > 1) {\n        const program = new ConcatPackedProgram(inputs.map(t => t.shape), axis);\n        return backend.runWebGLProgram(program, inputs, dtype);\n    }\n    const { tensors2D, outShape } = computeTensors2D(inputs, axis, backend);\n    const program = new ConcatProgram(tensors2D.map(t => t.shape));\n    const result = backend.runWebGLProgram(program, tensors2D, dtype);\n    tensors2D.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    const reshapedResult = reshape({ inputs: { x: result }, attrs: { shape: outShape }, backend });\n    backend.disposeIntermediateTensorInfo(result);\n    return reshapedResult;\n}\nfunction computeTensors2D(inputs, axis, backend) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n    const tensors2D = inputs.map(x => reshape({\n        inputs: { x },\n        attrs: { shape: [-1, util.sizeFromShape(x.shape.slice(axis))] },\n        backend\n    }));\n    return { tensors2D, outShape };\n}\n//# sourceMappingURL=Concat_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Concat, util } from '@tensorflow/tfjs-core';\nimport { concatImpl } from './Concat_impl';\nimport { identity } from './Identity';\nexport function concat(args) {\n    const { inputs, backend, attrs } = args;\n    const { axis } = attrs;\n    const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n    const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n    if (util.sizeFromShape(outShape) === 0) {\n        return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n    }\n    // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n    const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n    if ($inputs.length === 1) {\n        return identity({ inputs: { x: $inputs[0] }, backend });\n    }\n    const shapes = $inputs.map(t => t.shape);\n    backend_util.assertParamsConsistent(shapes, $axis);\n    return concatImpl($inputs, $axis, backend);\n}\nexport const concatConfig = {\n    kernelName: Concat,\n    backendName: 'webgl',\n    kernelFunc: concat\n};\n//# sourceMappingURL=Concat.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, MirrorPad } from '@tensorflow/tfjs-core';\nimport { MirrorPadProgram } from '../mirror_pad_gpu';\nimport { MirrorPadPackedProgram } from '../mirror_pad_packed_gpu';\nexport const mirrorPadKernelFunc = ({ inputs, backend, attrs }) => {\n    const { x } = inputs;\n    const { paddings, mode } = attrs;\n    const program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ?\n        new MirrorPadPackedProgram(x.shape, paddings, mode) :\n        new MirrorPadProgram(x.shape, paddings, mode);\n    const output = backend.runWebGLProgram(program, [x], x.dtype);\n    return output;\n};\nexport const mirrorPadConfig = {\n    kernelName: MirrorPad,\n    backendName: 'webgl',\n    kernelFunc: mirrorPadKernelFunc,\n};\n//# sourceMappingURL=MirrorPad.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Conv3DBackpropInputV2 } from '@tensorflow/tfjs-core';\nimport { Conv3DDerInputProgram } from '../conv_backprop_gpu';\nexport function conv3DBackpropInput(args) {\n    const { inputs, backend, attrs } = args;\n    const { dy, filter } = inputs;\n    const { pad, strides, inputShape } = attrs;\n    const convInfo = backend_util.computeConv3DInfo(inputShape, filter.shape, strides, 1 /* dilations */, pad);\n    const program = new Conv3DDerInputProgram(convInfo);\n    return backend.runWebGLProgram(program, [dy, filter], 'float32');\n}\nexport const conv3DBackpropInputConfig = {\n    kernelName: Conv3DBackpropInputV2,\n    backendName: 'webgl',\n    kernelFunc: conv3DBackpropInput,\n};\n//# sourceMappingURL=Conv3DBackpropInputV2.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Greater } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nimport { greaterImplCPU } from '../kernel_utils/shared';\nconst GREATER = `return float(a > b);`;\nconst GREATER_PACKED = `\n  return vec4(greaterThan(a, b));\n`;\nexport const greater = binaryKernelFunc({\n    opSnippet: GREATER,\n    packedOpSnippet: GREATER_PACKED,\n    cpuKernelImpl: greaterImplCPU,\n    dtype: 'bool'\n});\nexport const greaterConfig = {\n    kernelName: Greater,\n    backendName: 'webgl',\n    kernelFunc: greater\n};\n//# sourceMappingURL=Greater.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { IsInf } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst IS_INF = `return float(isinf(x));`;\nexport const isInf = unaryKernelFunc({ opSnippet: IS_INF, dtype: 'bool' });\nexport const isInfConfig = {\n    kernelName: IsInf,\n    backendName: 'webgl',\n    kernelFunc: isInf,\n};\n//# sourceMappingURL=IsInf.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { FFTProgram } from '../fft_gpu';\nimport { complex } from './Complex';\nimport { reshape } from './Reshape';\nexport function fftImpl(x, inverse, backend) {\n    const xData = backend.texData.get(x.dataId);\n    const inputSize = util.sizeFromShape(x.shape);\n    // Collapse all outer dimensions to a single batch dimension.\n    const innerDimensionSize = x.shape[x.shape.length - 1];\n    const batch = inputSize / innerDimensionSize;\n    const input2D = reshape({ inputs: { x }, backend, attrs: { shape: [batch, innerDimensionSize] } });\n    const xShape = input2D.shape;\n    const realProgram = new FFTProgram('real', xShape, inverse);\n    const imagProgram = new FFTProgram('imag', xShape, inverse);\n    const inputs = [\n        {\n            dataId: xData.complexTensorInfos.real.dataId,\n            dtype: xData.complexTensorInfos.real.dtype,\n            shape: xShape\n        },\n        {\n            dataId: xData.complexTensorInfos.imag.dataId,\n            dtype: xData.complexTensorInfos.imag.dtype,\n            shape: xShape\n        }\n    ];\n    const realPart = backend.runWebGLProgram(realProgram, inputs, 'float32');\n    const imagPart = backend.runWebGLProgram(imagProgram, inputs, 'float32');\n    const complexOutput = complex({ inputs: { real: realPart, imag: imagPart }, backend });\n    backend.disposeIntermediateTensorInfo(realPart);\n    backend.disposeIntermediateTensorInfo(imagPart);\n    const complexOutputReshaped = reshape({ inputs: { x: complexOutput }, backend, attrs: { shape: x.shape } });\n    backend.disposeIntermediateTensorInfo(input2D);\n    backend.disposeIntermediateTensorInfo(complexOutput);\n    return complexOutputReshaped;\n}\n//# sourceMappingURL=FFT_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ExpandDims, util } from '@tensorflow/tfjs-core';\nimport { reshape } from './Reshape';\nexport function expandDims(args) {\n    const { inputs, attrs, backend } = args;\n    const { dim } = attrs;\n    const { input } = inputs;\n    const inputRank = input.shape.length;\n    const newShape = input.shape.slice();\n    let $dim = dim;\n    if (dim < 0) {\n        // Negative value is counted from the tail of rank.\n        util.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);\n        $dim = inputRank + dim + 1;\n    }\n    newShape.splice($dim, 0, 1);\n    return reshape({ inputs: { x: input }, backend, attrs: { shape: newShape } });\n}\nexport const expandDimsConfig = {\n    kernelName: ExpandDims,\n    backendName: 'webgl',\n    kernelFunc: expandDims,\n};\n//# sourceMappingURL=ExpandDims.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { NotEqual } from '@tensorflow/tfjs-core';\nimport { binaryKernelFunc } from '../kernel_utils/kernel_funcs_utils';\nconst NOT_EQUAL = `return float(a != b);`;\nexport const notEqual = binaryKernelFunc({ opSnippet: NOT_EQUAL, dtype: 'bool' });\nexport const notEqualConfig = {\n    kernelName: NotEqual,\n    backendName: 'webgl',\n    kernelFunc: notEqual,\n};\n//# sourceMappingURL=NotEqual.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Max } from '@tensorflow/tfjs-core';\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { maxImplCPU } from '../kernel_utils/shared';\nimport { maxImpl } from './Max_impl';\nimport { transposeImpl, transposeImplCPU } from './Transpose_impl';\nexport function max(args) {\n    const { inputs, backend, attrs } = args;\n    const { x } = inputs;\n    const { reductionIndices, keepDims } = attrs;\n    const xRank = x.shape.length;\n    const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    const maxInputIsTransposed = permutedAxes != null;\n    const shouldExecuteOnCPU = backend.shouldExecuteOnCPU([x]);\n    let maxInput = x;\n    if (maxInputIsTransposed) {\n        if (shouldExecuteOnCPU) {\n            const xTexData = backend.texData.get(maxInput.dataId);\n            const values = xTexData.values;\n            const newShape = new Array(xRank);\n            for (let i = 0; i < newShape.length; i++) {\n                newShape[i] = x.shape[permutedAxes[i]];\n            }\n            const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);\n            maxInput = backend.makeTensorInfo(newShape, x.dtype);\n            const maxInputData = backend.texData.get(maxInput.dataId);\n            maxInputData.values = maxInputValues;\n        }\n        else {\n            maxInput = transposeImpl(x, permutedAxes, backend);\n        }\n        axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    }\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(maxInput.shape, axes);\n    let outShape = maxOutShape;\n    if (keepDims) {\n        // rather than reshape at the end, set the target shape here.\n        outShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n    }\n    let out;\n    if (shouldExecuteOnCPU) {\n        const xTexData = backend.texData.get(maxInput.dataId);\n        const values = xTexData.values;\n        const outValues = maxImplCPU(values, util.sizeFromShape(reduceShape), outShape, x.dtype);\n        out = backend.makeTensorInfo(outShape, x.dtype);\n        const outData = backend.texData.get(out.dataId);\n        outData.values = outValues;\n    }\n    else {\n        out = maxImpl(maxInput, reduceShape, outShape, backend);\n    }\n    if (maxInputIsTransposed) {\n        backend.disposeIntermediateTensorInfo(maxInput);\n    }\n    return out;\n}\nexport const maxConfig = {\n    kernelName: Max,\n    backendName: 'webgl',\n    kernelFunc: max\n};\n//# sourceMappingURL=Max.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from '../kernels/Reshape';\nexport function maxImpl(x, reduceShape, outShape, backend) {\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(x.shape);\n    const batchSize = xSize / inSize;\n    const reshapedInput = reshape({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend });\n    const reduced = reduce(reshapedInput, x.dtype, 'max', backend);\n    const reshapedOutput = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });\n    backend.disposeIntermediateTensorInfo(reshapedInput);\n    backend.disposeIntermediateTensorInfo(reduced);\n    return reshapedOutput;\n}\n//# sourceMappingURL=Max_impl.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { DenseBincount } from '@tensorflow/tfjs-core';\nimport { bincountImplCPU, bincountReduceImplCPU } from '../kernel_utils/shared';\nexport function denseBincount(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, weights } = inputs;\n    const { size, binaryOutput } = attrs;\n    if (x.shape.length === 1) {\n        const xVals = backend.readSync(x.dataId);\n        const weightsVals = backend.readSync(weights.dataId);\n        const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);\n        return backend.makeTensorInfo([size], weights.dtype, outVals);\n    }\n    else if (x.shape.length === 2) {\n        const xBuf = backend.bufferSync(x);\n        const weightsBuf = backend.bufferSync(weights);\n        const outBuf = bincountReduceImplCPU(xBuf, weightsBuf, size, binaryOutput);\n        return backend.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);\n    }\n    throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank` +\n        `${x.shape.length}.`);\n}\nexport const denseBincountConfig = {\n    kernelName: DenseBincount,\n    backendName: 'webgl',\n    kernelFunc: denseBincount\n};\n//# sourceMappingURL=DenseBincount.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FlipLeftRight } from '@tensorflow/tfjs-core';\nimport { FlipLeftRightProgram } from '../flip_left_right_gpu';\nexport const flipLeftRightConfig = {\n    kernelName: FlipLeftRight,\n    backendName: 'webgl',\n    kernelFunc: ({ inputs, backend }) => {\n        const { image } = inputs;\n        const webglBackend = backend;\n        const program = new FlipLeftRightProgram(image.shape);\n        const output = webglBackend.runWebGLProgram(program, [image], image.dtype);\n        return output;\n    }\n};\n//# sourceMappingURL=FlipLeftRight.js.map"],"names":["greaterEqual","opSnippet","packedOpSnippet","dtype","greaterEqualConfig","kernelName","GreaterEqual","backendName","kernelFunc","isNaN","isNaNConfig","IsNan","lessEqual","lessEqualConfig","LessEqual","logicalNot","logicalNotConfig","LogicalNot","cumsumConfig","Cumsum","args","inputs","backend","attrs","x","axis","exclusive","reverse","xRank","shape","length","permutation","backend_util","permutedX","perm","permutedAxis","Error","size","result","i","Math","ceil","log2","program","customSetup","getCustomSetupFunc","prevResult","runWebGLProgram","disposeIntermediateTensorInfo","reversePermutation","reverseTransposedResult","LRNConfig","LRN","depthRadius","bias","alpha","beta","env","getBool","diagConfig","Diag","outShape","xSize","util","flat","res","out","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","dy","strides","pad","filterShape","convInfo","batchMatMulConfig","BatchMatMul","a","b","transposeA","transposeB","complex","real","imag","complexInfo","makeTensorInfo","texData","get","dataId","realTensorInfo","imagTensorInfo","complexTensorInfos","complexConfig","Complex","logicalOr","logicalOrConfig","LogicalOr","log1p","log1pConfig","Log1p","nonMaxSuppressionV4Impl","kernel_impls","nonMaxSuppressionV4Config","NonMaxSuppressionV4","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","padToMaxOutputSize","boxesVals","readSync","scoresVals","selectedIndices","validOutputs","Int32Array","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","filter","dilations","dimRoundingMode","$dilations","strideWidth","outChannels","inChannels","conv3DConfig","Conv3D","floorDiv","floorDivConfig","FloorDiv","COS","cos","cosConfig","Cos","FromPixelsProgram","constructor","outputShape","this","variableNames","glsl","height","width","userCode","texture2D","FromPixelsPackedProgram","packedInputs","packedOutput","output","fromPixelsConfig","FromPixels","pixels","numChannels","isVideo","HTMLVideoElement","isImage","HTMLImageElement","videoWidth","videoHeight","texShape","fromPixels2DContext","document","createElement","getContext","canvas","drawImage","tempPixelHandle","usage","PIXELS","gpgpu","uploadPixelDataToTexture","getTexture","disposeData","cropAndResizeConfig","CropAndResize","image","boxInd","cropSize","method","extrapolationValue","maxPoolGradConfig","MaxPoolGrad","input","filterSize","maxPoolPositionsProgram","maxPoolPositions","maxPoolBackPropProgram","maxPoolConfig","MaxPool","filterWidth","filterHeight","inShape","maxPoolProgram","MOD_PACKED","mod","modConfig","Mod","linSpaceConfig","LinSpace","start","stop","num","outVals","MAXIMUM","MAXIMUM_PACKED","maximum","cpuKernelImpl","maximumConfig","Maximum","gatherV2Config","GatherV2","indices","batchDims","parsedAxis","shapeInfo","indicesSize","toDispose","flattenX","batchSize","outerSize","dimSize","sliceSize","flattenIndex","push","flattenOutputShape","shouldExecuteOnCPU","indicesBuf","bufferSync","xBuf","outBuf","forEach","t","values","reshaped","MINIMUM","MINIMUM_PACKED","minimum","minimumConfig","Minimum","MUL","multiply","aData","bData","realProgram","REAL","imagProgram","IMAG","realPart","imagPart","complexOutput","outValues","multiplyConfig","Multiply","less","lessConfig","Less","conv2DBackpropInputConfig","Conv2DBackpropInput","inputShape","dataFormat","$dataFormat","EXP","exp","expConfig","Exp","dilation2DConfig","Dilation2D","outReshaped","CEIL","ceilConfig","Ceil","castConfig","Cast","cast","zerosTensor","floatX","dispose","zerosTensorInfo","binaryInputs","makeComplexComponentTensorInfo","complexTensor","complexPart","complexAbsConfig","ComplexAbs","xData","programInputs","fill","value","fillConfig","Fill","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","includeBatchInIndex","webglBackend","indexes","poolOutput","maxPoolWithArgmaxImpl","inputData","imagConfig","Imag","fusedConv2DConfig","FusedConv2D","preluActivationWeights","activation","leakyreluAlpha","intermediates","dilationHeight","dilationWidth","strideHeight","padInfo","type","hasBias","hasPreluActivationWeights","hasLeakyreluAlpha","fusedActivation","$leakyreluAlpha","NEG","negConfig","Neg","newShape","elu","eluConfig","Elu","depthToSpaceConfig","DepthToSpace","blockSize","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","clipByValueConfig","ClipByValue","clipValueMin","clipValueMax","depthwiseConv2dNativeBackpropInputConfig","DepthwiseConv2dNativeBackpropInput","meanConfig","Mean","keepDims","origAxes","axes","permutedAxes","meanInputIsTransposed","meanInput","Array","meanInputValues","meanOutShape","reduceShape","inSize","reshapedInput","reduced","reduce","reshapedOutput","meanImpl","conv2dByMatMul","xShape","xTexData","sharedMatMulDim","outerShapeX","outerShapeFilter","isChannelsLast","batchMatMulWillBeUnpacked","reshapeWillBeExpensive","isPacked","targetShape","xReshaped","originalXTexDataShape","slice","filterReshaped","pointwiseConv","pointwiseConvTexData","conv2dWithIm2Row","outWidth","outHeight","sharedDim","numCols","x2ColShape","xSqueezed","w2Row","im2ColProgram","im2Col","im2ColReshaped","matmulProgram","product","FLOOR","floor","floorConfig","Floor","packConfig","Pack","dim","intermediateTensorInfos","expandedTensors","map","expandedT","logicalAnd","logicalAndConfig","LogicalAnd","oneHotConfig","OneHot","depth","onValue","offValue","MATMUL_SHARED_DIM_THRESHOLD","batchMatMulImpl","aRank","bRank","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","batchDimsCompatible","concat","a3dShape","b3dShape","a3d","b3d","batchDim","max","aVec","bVec","shouldReshapeB","aVec3d","bVec3d","upcastType","onesLikeConfig","OnesLike","onesLike","r","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","shouldPackDepthwiseConv","batchToSpaceNDConfig","BatchToSpaceND","blockShape","crops","prod","permuted","reshapedPermuted","sliceBeginCoords","reshapedIntermediate","transposedIntermediate","reshapedIntermediate2","sliced","begin","maxPoolGrad3DConfig","MaxPool3DGrad","maxPool3dPositionsProgram","maxPool3dPositions","maxPoolBackpropProgram","conv2DConfig","Conv2D","ifftConfig","IFFT","gatherNdConfig","GatherNd","params","indicesShape","sliceRank","resultShape","numSlices","flattenIndices","LEAKYRELU","LEAKYRELU_PACKED","leakyReluConfig","LeakyRelu","$alpha","minConfig","Min","a2D","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","maxOutputSizeVal","iouThresholdVal","scoreThresholdVal","softNmsSigmaVal","selectedScores","Float32Array","EXPM1","expm1","expm1Config","Expm1","log","logConfig","Log","bincountConfig","Bincount","weights","xVals","weightsVals","einsumConfig","Einsum","equation","tensors","allDims","summedDims","idDims","path","steps","nSteps","numDimsRemaining","tensorsToDispose","idTerm","permutationIndices","expandDims","dimsToExpand","k","splice","tensorInfo","equal","equalConfig","Equal","nonMaxSuppressionV3Impl","nonMaxSuppressionV3Config","NonMaxSuppressionV3","identity","incRef","identityConfig","Identity","batchNormConfig","FusedBatchNorm","mean","variance","offset","scale","varianceEpsilon","finalInputs","offsetShape","scaleShape","isFinite","isFiniteConfig","IsFinite","ERF","erf","erfConfig","Erf","depthwiseConv2dNativeBackpropFilterConfig","DepthwiseConv2dNativeBackpropFilter","cosh","coshConfig","Cosh","LRNGradConfig","LRNGrad","y","multinomialConfig","Multinomial","logits","numSamples","seed","normalized","probs","numOutcomes","fftConfig","FFT","conv2DBackpropFilterConfig","Conv2DBackpropFilter","padV2","paddings","constantValue","padV2Config","PadV2","maxPool3DConfig","MaxPool3D","eluGradConfig","EluGrad","concatImpl","reals","imags","realConcated","imagConcated","runOnCpu","tensors2D","inputsValShapes","vals","simplyConcat","finalOutShape","outInfo","getNumber","midIndex","leftSide","rightSide","computeTensors2D","reshapedResult","$axis","$inputs","shapes","concatConfig","Concat","mirrorPadConfig","MirrorPad","mode","conv3DBackpropInputConfig","Conv3DBackpropInputV2","greater","greaterConfig","Greater","isInf","isInfConfig","IsInf","fftImpl","inverse","inputSize","innerDimensionSize","batch","input2D","complexOutputReshaped","inputRank","$dim","expandDimsConfig","ExpandDims","notEqual","notEqualConfig","NotEqual","reductionIndices","maxInputIsTransposed","maxInput","maxInputValues","maxOutShape","maxImpl","maxConfig","Max","denseBincountConfig","DenseBincount","binaryOutput","weightsBuf","flipLeftRightConfig","FlipLeftRight"],"sourceRoot":""}