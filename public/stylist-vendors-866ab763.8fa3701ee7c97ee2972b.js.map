{"version":3,"file":"stylist-vendors-866ab763.8fa3701ee7c97ee2972b.js","mappings":"mKAyBO,SAASA,EAAaC,EAAOC,EAAYC,EAEhDC,EAAUC,QAAQC,KACd,MAAMC,EA2DV,SAA+BN,GAC3B,IAAIM,GAAiB,EACrB,MAAMC,EAAe,GACfC,EAAQ,GACd,IAAK,MAAMC,KAAST,EAAMO,aACtBA,EAAaG,KAAKV,EAAMO,aAAaE,IAEzC,IAAK,MAAME,KAAcJ,EAAc,CACnC,GAAII,EAAWC,OAAS,GACE,IAAtBD,EAAWC,QAAgBD,EAAW,GAAGE,cAAcD,OAAS,EAAG,CACnEN,GAAiB,EACjB,KACJ,CACAE,EAAME,QAAQC,EAClB,CACA,GAAIL,EAEA,IAAK,MAAMQ,KAASd,EAAMe,OAAQ,CAC9B,IAAIC,GAAO,EACX,IAAK,MAAMC,KAAQH,EAAMI,aACrB,IAA6B,IAAzBV,EAAMW,QAAQF,GAAc,CAC5B,GAAID,EAAM,CACNV,GAAiB,EACjB,KACJ,CAEIU,GAAO,CAEf,CAEJ,IAAKV,EACD,KAER,CAEJ,OAAOA,CACX,CA/F2Bc,CAAsBpB,GAEvCqB,EAAY,CAAC,eAAgB,eAAgB,WAcnD,IAAIC,EACJ,GAdIhB,GACAL,EAAaA,GAAc,GAC3BC,EAAYA,GAAa,CAAC,IAAM,IAAM,KAGtCD,EAAaA,GAAc,GAC3BC,EAAYA,GAAa,CAAC,IAAM,IAAM,IAAM,IAG5CA,EAAUA,EAAUU,OAAS,IAAM,IAEnCV,EAAYA,EAAUqB,KAAIC,GAAKC,KAAKC,MAAMzB,EAAauB,OAGtDlB,EAAgB,CACjBe,EAAUX,KAAK,mBACfY,EAAgB,GAChB,IAAK,MAAMb,KAAST,EAAMO,aACtBe,EAAcZ,QAAQV,EAAMO,aAAaE,GAEjD,CACAN,EAAQ,IAAIwB,OAAO1B,IACnB2B,EAASP,EAAWnB,EAAWC,GAC/BA,EAAQ,IAAIwB,OAAO1B,IACnB,MAAMc,EAASf,EAAMe,OACrB,IAAK,IAAIc,EAAI,EAAGA,EAAId,EAAOH,SAAUiB,EAC7BvB,EACAwB,EAAkBf,EAAOc,GAAI3B,EAAWC,GAGxC4B,EAAiChB,EAAOc,GAAI3B,EAAWoB,EAAenB,GAE1EA,GAAS0B,IAAMd,EAAOH,OAAS,EAAI,IAAM,KAAKe,OAAO1B,IAGzDD,EAAMgC,mCACN,MAAMC,EAOV,SAA8BjC,GAC1B,IAAIiC,EAGAA,EADmC,MAAnCjC,EAAMkC,2BAEF,OAAqBlC,EAAMkC,4BAGd,OAAqBlC,EAAMmC,kBAGhD,OAAOF,CACX,CAnB2BG,CAAqBpC,GACtCqC,GAAoB,OAAqBrC,EAAMsC,qBACrDnC,EAAQ,iBAAiB8B,EAAiBI,KAC1ClC,EAAQ,qBAAqB8B,KAC7B9B,EAAQ,yBAAyBkC,KACjClC,EAAQ,IAAIwB,OAAO1B,GACvB,CAmDA,SAAS2B,EAASW,EAAQrC,EAE1BC,EAAUC,QAAQC,KACd,IAAImC,EAAO,GACX,IAAK,IAAIX,EAAI,EAAGA,EAAIU,EAAO3B,SAAUiB,EAC7BA,EAAI,IACJW,EAAOA,EAAKC,MAAM,EAAGD,EAAK5B,OAAS,GAAK,KAE5C4B,GAAQD,EAAOV,GACfW,EAAOA,EAAKC,MAAM,EAAGvC,EAAU2B,IAC/BW,GAAQ,IAAIb,OAAOzB,EAAU2B,GAAKW,EAAK5B,QAE3CT,EAAQqC,EACZ,CAMA,SAASV,EAAkBhB,EAAOZ,EAElCC,GACI,IAAIuC,EACJ,IACIA,EAAcC,KAAKC,UAAU9B,EAAM4B,YACvC,CACA,MAAOG,GACHH,EAAc,UAClB,CAIAd,EADe,CAAC,GAFHd,EAAMgC,SACDhC,EAAMiC,kBACkBL,EAAa5B,EAAMkC,cAAcC,YAC1D/C,EAAWC,EAChC,CAIA,SAAS4B,EAAiCjB,EAAOZ,EAAWoB,EAE5DnB,GACI,IAAIuC,EACJ,IACIA,EAAcC,KAAKC,UAAU9B,EAAM4B,YACvC,CACA,MAAOG,GACHH,EAAc,UAClB,CACA,MAAMQ,EAAc,GACpB,IAAK,MAAMjC,KAAQH,EAAMI,aACrB,KAAqB,MAAjBI,GAAyBA,EAAcV,OAAS,IACf,IAAjCU,EAAcH,QAAQF,IAG1B,IAAK,IAAIY,EAAI,EAAGA,EAAIZ,EAAKJ,cAAcD,SAAUiB,EAAG,CAChD,MAAMsB,EAAelC,EAAKJ,cAAcgB,GAAGiB,KACrCM,EAAoBnC,EAAKoC,YAAYxB,GACrCyB,EAAqBrC,EAAKsC,cAAc1B,GAC9CqB,EAAYxC,KAAK,GAAGyC,KAAgBC,MAAsBE,KAC9D,CAEJ,MAAMR,EAAOhC,EAAMgC,KACbU,EAAY1C,EAAMiC,eAClBU,EAAyC,IAAvBP,EAAYtC,OAAe,GAAKsC,EAAY,GAKpEtB,EAJe,CACX,GAAGkB,MAASU,KAAcd,EAAa5B,EAAMkC,cAAcC,WAC3DQ,GAEavD,EAAWC,GAC5B,IAAK,IAAI0B,EAAI,EAAGA,EAAIqB,EAAYtC,SAAUiB,EACtCD,EAAS,CAAC,GAAI,GAAI,GAAIsB,EAAYrB,IAAK3B,EAAWC,EAE1D,C,yIC4FO,MAAMuD,UAAmB,KAC5B,WAAAC,CAAYC,GAQR,GAPAC,MAAM,CAAEC,OAAQ,GAAIC,QAAS,KAC7BH,EAAOA,GAAQ,CAAC,EAChBI,KAAKC,WAAY,EACjBD,KAAKE,OAAQ,EAEbF,KAAKlB,KAAqB,MAAbc,EAAKd,KAAgBc,EAAKd,MAAO,OAAO,eAElC,MAAfc,EAAK7C,OACL,IAAK,MAAMD,KAAS8C,EAAK7C,OACrBiD,KAAKG,IAAIrD,EAGrB,CAGA,UAAAsD,CAAWtD,GAEP,GADcA,EAAMI,aAAa,GAAGmD,cAAc,GAAGC,MAC3CC,MAAKC,GAAKA,EAAI,IACpB,MAAM,IAAI,KACN,kDAAG1D,EAAMgC,0BACNhC,EAAMI,aAAa,GAAGuD,aAAa,GAAGH,SAErD,CAsBA,GAAAH,CAAIrD,GACA,MAAM4D,EAAuB5D,aAAiB4C,GAAc5C,aAAiB,KAC7E,IAAI6D,EACJ,GAAID,EAAsB,CAEtB,GADAC,EAAa7D,EACqB,IAA9B6D,EAAWZ,QAAQnD,OACnB,MAAM,IAAI,KAAW,yHAKzB,GAAiC,IAA7B+D,EAAWb,OAAOlD,OAClB,MAAM,IAAI,KAAW,sHAK7B,CACA,GAA4B,IAAxBoD,KAAKD,QAAQnD,OAAc,CAE3B,GAAkC,IAA9BE,EAAMI,aAAaN,OAAc,CAEjC,GAA6B,MAAzBE,EAAM8D,gBACN,MAAM,IAAI,KAAW,iGAIzB,MAAMJ,GAAI,OAAM,CACZK,WAAY/D,EAAM8D,gBAClBE,MAAOhE,EAAMgE,MACbhC,KAAMhC,EAAMgC,KAAO,WAIvBhC,EAAMiE,MAAMP,EAChB,CACA,GAAIE,EACAV,KAAKD,QAAUY,EAAWZ,QAC1BC,KAAKF,OAASa,EAAWb,WAExB,CACD,GAAkC,IAA9BhD,EAAMI,aAAaN,OACnB,MAAM,IAAI,KACN,gHAAwDE,EAAMgC,kBACjDhC,EAAMI,aAAaN,4CAGxC,GAAmD,IAA/CE,EAAMI,aAAa,GAAGmD,cAAczD,OACpC,MAAM,IAAI,KAAW,yHAKzBoD,KAAKI,WAAWtD,GAChBkD,KAAKD,QAAU,CAACjD,EAAMI,aAAa,GAAGmD,cAAc,IACpDL,KAAKF,QAAS,QAAgBE,KAAKD,QAAQ,GAC/C,CACAC,KAAK9C,aAAe,GAKpB,IAAI,KAAK,CACL8D,cAAehB,KACfnD,cAAe,GACfwC,YAAa,GACbE,cAAe,GACfkB,aAAcT,KAAKF,OACnBO,cAAeL,KAAKD,QAEpBkB,WAAY,KAA2B,KAAMjB,KAAKF,OAAOlD,QACzDsE,YAAa,CAAC,MACdC,YAAanB,KAAKF,OAAOvC,KAAIiD,GAAKA,EAAEF,QACpCc,aAAcpB,KAAKD,QAAQ,GAAGO,OAEtC,KACK,CACD,MAAMe,EAAevE,EAAMiE,MAAMf,KAAKD,QAAQ,IAC9C,GAAIuB,MAAMC,QAAQF,GACd,MAAM,IAAIG,UAAU,yHAKxBxB,KAAKI,WAAWtD,GAChBkD,KAAKD,QAAU,CAACsB,GAEhBrB,KAAK9C,aAAa,GAAGmD,cAAgBL,KAAKD,QAC1CC,KAAK9C,aAAa,GAAGkE,aAAe,CAACpB,KAAKD,QAAQ,GAAGO,MACzD,CACAN,KAAKjD,OAAOL,KAAKI,GACjBkD,KAAKE,OAAQ,CACjB,CAMA,GAAAuB,GACI,GAA2B,IAAvBzB,KAAKjD,OAAOH,OACZ,MAAM,IAAI4E,UAAU,qCAGxB,GADAxB,KAAKjD,OAAO0E,MACe,IAAvBzB,KAAKjD,OAAOH,OACZoD,KAAKD,QAAU,GACfC,KAAK9C,aAAe,GACpB8C,KAAK0B,cAAgB,OAEpB,CACD,MAAMC,EAAiB3B,KAAKjD,OAAOH,OAAS,EAC5CoD,KAAKjD,OAAO4E,GAAgBD,cAAgB,GAC5C1B,KAAKD,QAAU,CAACC,KAAKjD,OAAO4E,GAAgBC,QAE5C5B,KAAK9C,aAAa,GAAGmD,cAAgBL,KAAKD,QAC1CC,KAAK9C,aAAa,GAAGkE,aAAe,CAACpB,KAAKD,QAAQ,GAAGO,MACzD,CACJ,CACA,IAAAuB,CAAK/B,EAAQgC,GAIT,OAHkB,MAAd9B,KAAKhE,OACLgE,KAAK+B,QAEF/B,KAAKhE,MAAM6F,KAAK/B,EAAQgC,EACnC,CACA,KAAAC,CAAMC,GAIF,IADA,QAAmBA,GACQ,IAAvBhC,KAAKF,OAAOlD,QAAwC,IAAxBoD,KAAKD,QAAQnD,OACzC,MAAM,IAAI4E,UAAU,4EAIxBxB,KAAKhE,MAAQ,IAAI,KAAY,CACzB8D,OAAQE,KAAKF,OACbC,QAASC,KAAKD,QAAQ,GACtBjB,KAAMkB,KAAKlB,KAAO,WAEtBkB,KAAKhE,MAAMiE,UAAYD,KAAKC,UAE5BD,KAAKiC,gBAAkBjC,KAAKhE,MAAMiG,gBAElCjC,KAAKkC,YAAclC,KAAKhE,MAAMkG,YAC9BlC,KAAKmC,uBAAyBnC,KAAKhE,MAAMmG,uBACzCnC,KAAKoC,yBAA2BpC,KAAKhE,MAAMoG,yBAC3CpC,KAAKqC,aAAerC,KAAKhE,MAAMqG,aAC/BrC,KAAKsC,wBAA0BtC,KAAKhE,MAAMsG,wBAC1CtC,KAAKuC,0BAA4BvC,KAAKhE,MAAMuG,0BAC5CvC,KAAKzD,aAAeyD,KAAKhE,MAAMO,aAC/ByD,KAAKwC,eAAiBxC,KAAKhE,MAAMwG,eACjCxC,KAAKyC,YAAczC,KAAKhE,MAAMyG,YAC9BzC,KAAK0C,WAAa1C,KAAKhE,MAAM0G,WAG7B1C,KAAKE,OAAQ,CACjB,CACA,WAAAlB,GAII,OAHKgB,KAAKE,OACNF,KAAK+B,QAEFlC,MAAMb,aACjB,CA+BA,OAAA2D,CAAQ1G,EAAYC,EAAWC,EAAUC,QAAQC,KACxC2D,KAAKE,OACNF,KAAK+B,QAETlC,MAAM8C,QAAQ1G,EAAYC,EAAWC,EACzC,CAOA,UAAAyG,CAAWC,GACW,MAAd7C,KAAKhE,OACLgE,KAAK+B,QAET/B,KAAKhE,MAAM4G,WAAWC,EAC1B,CAiCA,QAAAC,CAAStC,EAAGuC,EAAGnD,EAAO,CAAC,GACnB,IAAKI,KAAKE,MACN,MAAM,IAAI,KAAa,qDAE3B,OAAOF,KAAKhE,MAAM8G,SAAStC,EAAGuC,EAAGnD,EACrC,CAuBA,qBAAMoD,CAAgBC,EAASrD,GAC3B,IAAKI,KAAKE,MACN,MAAM,IAAI,KAAa,qDAE3B,OAAOF,KAAKhE,MAAMgH,gBAAgBC,EAASrD,EAC/C,CA4BA,OAAAsD,CAAQ1C,EAAGZ,EAAO,CAAC,GAIf,OAHkB,MAAdI,KAAKhE,OACLgE,KAAK+B,QAEF/B,KAAKhE,MAAMkH,QAAQ1C,EAAGZ,EACjC,CAQA,cAAAuD,CAAe3C,GAIX,OAHkB,MAAdR,KAAKhE,OACLgE,KAAK+B,QAEF/B,KAAKhE,MAAMmH,eAAe3C,EACrC,CAMA,OAAA4C,CAAQxD,GACJI,KAAK+B,QACL/B,KAAKhE,MAAMoH,QAAQxD,GACnBI,KAAKqD,WAAarD,KAAKhE,MAAMsH,UAE7BtD,KAAKuD,iBAAmBvD,KAAKhE,MAAMuH,iBACnCvD,KAAKwD,KAAOxD,KAAKhE,MAAMwH,KACvBxD,KAAKyD,QAAUzD,KAAKhE,MAAMyH,QAG1BzD,KAAK0D,eAAiB1D,KAAKhE,MAAM0H,eACjC1D,KAAK2D,aAAe3D,KAAKhE,MAAM2H,YAEnC,CACA,aAAIL,GACA,OAAqB,MAAdtD,KAAKhE,WAAgB4H,EAAY5D,KAAKhE,MAAMsH,SACvD,CACA,aAAIA,CAAUA,GACVtD,KAAKhE,MAAMsH,UAAYA,CAC3B,CAgCA,SAAMO,CAAIrD,EAAGuC,EAAGnD,EAAO,CAAC,GACpB,IAAKI,KAAKE,MACN,MAAM,IAAI,KAAa,qDAG3B,OAAOF,KAAKhE,MAAM6H,IAAIrD,EAAGuC,EAAGnD,EAChC,CAsFA,gBAAMkE,CAAWb,EAASrD,GACtB,IAAKI,KAAKE,MACN,MAAM,IAAI,KAAa,qDAG3B,OAAOF,KAAKhE,MAAM8H,WAAWb,EAASrD,EAC1C,CAwBA,kBAAMmE,CAAavD,EAAGuC,GAClB,OAAO/C,KAAKhE,MAAM+H,aAAavD,EAAGuC,EACtC,CAGA,iBAAOiB,CAAWC,EAAKC,EAAQC,EAAgB,CAAC,EAAGC,GAAiB,GAChE,IAAIC,EACAC,EAAmB,CAAC,EACxB,GAAIJ,aAAkB5C,MAAO,CACzB,GAA6B,MAAvB4C,EAAO,GAAG1E,WACe,UAA3B0E,EAAO,GAAc,UACrB,MAAM,IAAI,KAAW,kDAEzBG,EAAcH,CAClB,MAEI,EAAAK,KAAA,OAAgC,MAApBL,EAAe,QAAW,IAAM,wHAE5CG,EAAcH,EAAe,cACtBA,EAAe,OACtBI,EAAmBJ,EAEvB,MAAMlI,EAAQ,IAAIiI,EAAIK,GACtB,KAAMtI,aAAiB0D,GACnB,MAAM,IAAI,KAAoB,yDAAyD1D,KAE3F,IAAK,MAAMwI,KAAQH,EAAa,CAC5B,MAAMF,OAAgBP,EAChB9G,GAAQ,OAAY0H,EAAML,EAAeC,GAC3CA,GACAtH,EAAM2H,8BAA6B,GAEvCzI,EAAMmE,IAAIrD,EACd,CACA,OAAOd,CACX,CA6BA,gBAAI0I,CAAaC,GAGb,GAAkB,MAAd3E,KAAKhE,MACL,MAAM,IAAI,KAAW,qFAGzBgE,KAAKhE,MAAM0I,aAAeC,CAC9B,CACA,gBAAID,GACA,GAAkB,MAAd1E,KAAKhE,MACL,MAAM,IAAI,KAAW,qFAGzB,OAAOgE,KAAKhE,MAAM0I,YACtB,CAGA,SAAAE,GAKI,MAAM7H,EAAS,GACf,IAAK,MAAMD,KAASkD,KAAKjD,OAAQ,CAC7B,MAAM8H,EAAO,CAAC,EACdA,EAAgB,UAAI/H,EAAMiC,eAC1B8F,EAAa,OAAI/H,EAAM8H,YACvB7H,EAAOL,KAAKmI,EAChB,CACA,MAAO,CAAE/F,KAAMkB,KAAKlB,KAAM/B,SAC9B,EAGJ2C,EAAWF,UAAY,aACvB,EAAAsF,cAAA,cAA4BpF,E,wBCh6B1BqF,EAAOC,QAAU,EAAjB,M,wBCQF,IAAIC,EAAQ,EAAQ,OAClBC,EAAO,EAAQ,OAIjB,IAAIC,EAAW,oBAAsBC,OAAOC,GAAKD,OAAOC,GAHxD,SAAY7E,EAAGuC,GACb,OAAQvC,IAAMuC,IAAM,IAAMvC,GAAK,EAAIA,IAAM,EAAIuC,IAAQvC,IAAMA,GAAKuC,IAAMA,CACxE,EAEEuC,EAAuBJ,EAAKI,qBAC5BC,EAASN,EAAMM,OACfC,EAAYP,EAAMO,UAClBC,EAAUR,EAAMQ,QAChBC,EAAgBT,EAAMS,cACxBV,EAAQW,iCAAmC,SACzCC,EACAC,EACAC,EACAC,EACAC,GAEA,IAAIC,EAAUV,EAAO,MACrB,GAAI,OAASU,EAAQC,QAAS,CAC5B,IAAIC,EAAO,CAAEC,UAAU,EAAIC,MAAO,MAClCJ,EAAQC,QAAUC,CACpB,MAAOA,EAAOF,EAAQC,QACtBD,EAAUR,GACR,WACE,SAASa,EAAiBC,GACxB,IAAKC,EAAS,CAIZ,GAHAA,GAAU,EACVC,EAAmBF,EACnBA,EAAeR,EAASQ,QACpB,IAAWP,GAAWG,EAAKC,SAAU,CACvC,IAAIM,EAAmBP,EAAKE,MAC5B,GAAIL,EAAQU,EAAkBH,GAC5B,OAAQI,EAAoBD,CAChC,CACA,OAAQC,EAAoBJ,CAC9B,CAEA,GADAG,EAAmBC,EACfxB,EAASsB,EAAkBF,GAAe,OAAOG,EACrD,IAAIE,EAAgBb,EAASQ,GAC7B,YAAI,IAAWP,GAAWA,EAAQU,EAAkBE,IAC1CH,EAAmBF,EAAeG,IAC5CD,EAAmBF,EACXI,EAAoBC,EAC9B,CACA,IACEH,EACAE,EAFEH,GAAU,EAGZK,OACE,IAAWf,EAAoB,KAAOA,EAC1C,MAAO,CACL,WACE,OAAOQ,EAAiBT,IAC1B,EACA,OAASgB,OACL,EACA,WACE,OAAOP,EAAiBO,IAC1B,EAER,GACA,CAAChB,EAAaC,EAAmBC,EAAUC,IAE7C,IAAIK,EAAQf,EAAqBM,EAAWK,EAAQ,GAAIA,EAAQ,IAShE,OARAT,GACE,WACEW,EAAKC,UAAW,EAChBD,EAAKE,MAAQA,CACf,GACA,CAACA,IAEHX,EAAcW,GACPA,CACT,C,2FClEO,SAASS,EAAaC,GACzB,MAAMC,EAAe,CACjB,QAAW,IAAM,EAAAC,MAAMC,QAAQ,KAC/B,SAAY,IAAM,EAAAD,MAAME,SAAS,EAAG,KAAM,WAC1C,KAAQ,IAAM,EAAAF,MAAMG,KAAK,KAAO,GAAK,MAAO,WAC5C,OAAU,IAAM,EAAAH,MAAMI,OAAO,KAAO,GAAK,MAAO,UAAW,GAC3D,QAAW,IAAM,EAAAJ,MAAMK,QAAQ,KAAO,GAAK,GAAG,WAC9C,IAAO,IAAM,EAAAL,MAAMM,IAAI,MAQ3B,GANAP,EAAsB,QAAIA,EAAsB,QAChDA,EAAuB,SAAIA,EAAuB,SAClDA,EAAmB,KAAIA,EAAmB,KAC1CA,EAAqB,OAAIA,EAAqB,OAC9CA,EAAsB,QAAIA,EAAsB,QAChDA,EAAkB,IAAIA,EAAkB,IACpCD,KAAcC,EACd,OAAOA,EAAaD,KAExB,MAAM,IAAI,KAAW,qBAAqBA,IAC9C,C,qUCEiB,EAAAS,aACO,KACE,KACT,KACE,KACG,I,2RCxBf,SAASC,EAAeC,EAAOC,GAClC,OAAO,IAAAC,OAAK,KACR,MAAMC,EAAY,MAAQ,GAAI,WAAaF,IACrCG,EAAmB,KAAO,UAAYH,EAAOE,GAAYH,EAAM5G,OACrE,OAAO,OAAS,QAAU4G,EAAOI,IAAoB,EAAE,GAE/D,CACO,SAASC,EAAoBL,EAAOC,GACvC,OAAO,IAAAC,OAAK,IAAM,KAAO,QAAU,SAAWF,GAAQ,GAAI,SAAWC,GAAQ,IAAK,YACtF,CACA,SAASK,EAAcN,EAAOC,GAC1B,OAAO,IAAAC,OAAK,IACD,aAAeF,EAAMO,MAAM,GAAIN,EAAMM,MAAM,IAAIC,MAAMC,KAAK,YAEzE,CA6BO,SAASC,EAAmBV,EAAOC,GACtC,OAAO,QAAuBD,EAAOC,EACzC,CACO,SAASU,EAA0BX,EAAOC,GAQ7C,OAPID,EAAMY,OAASX,EAAMW,OACrBZ,EAAQA,EAAMa,QAAQ,CAACb,EAAMY,KAAO,MAExCX,EAAQA,EAAMa,QAAQ,IACZ1H,QAAU4G,EAAM5G,QACtB6G,EAAQA,EAAMc,OAAOf,EAAM5G,QAExB,QAAU4G,EAAOC,GAAOc,OAAO,UAC1C,CAQO,MAAMC,EAAM,KACNC,EAAM,KACNC,EAAM,KACNC,EAAM,KACNC,EAAO,KACPC,EAAO,KACPC,EAA0B,KAC1BC,EAAS,KACTC,EAAgC,KAEhCC,EAAa,CACtB1B,iBACAM,sBACAqB,UAnDG,SAAmB1B,EAAOC,GAC7B,OAAO,IAAAC,OAAK,KACR,MAAMyB,EAAKrB,EAAcN,EAAOC,GAC1B2B,EARd,SAAwB5B,EAAOC,GAC3B,OAAO,IAAAC,OAAK,IACD,aAAeF,EAAMO,MAAM,GAAIN,EAAMM,MAAM,IAAIC,MAAMC,KAAK,YAEzE,CAImBoB,CAAe7B,EAAOC,GAC3B6B,EAAcH,EAAGlJ,IAAImJ,GAC3B,OAAO,QAAU,UAAYE,EAAa,GAAIH,EAAGI,IAAID,GAAc,GAC9DrB,KAAK,UAAU,GAE5B,EA4CIa,0BACAE,gCACAR,MACAC,MACAC,MACAC,MACAC,OACAC,OACAE,UAEG,SAASS,EAAI3C,GAChB,GAA0B,kBAAfA,GAA2BA,KAAcoC,EAChD,OAAOA,EAAWpC,GAEjB,GAA0B,kBAAfA,GAAyC,MAAdA,EACvC,OAAOA,EAGP,MAAM,IAAI,KAAW,kBAAkBA,IAE/C,CAkBO,SAAS4C,EAAoBC,GAEhC,GADA,KAAmB,OAAPA,EAAa,0BAA0BA,KACjC,kBAAPA,EACP,OAAOA,EAEN,CACD,IAAIC,EACJ,IAAK,MAAMC,KAAO1E,OAAO2E,KAAK,MAC1B,GAAI,KAAUD,KAASF,EAAI,CACvBC,EAASC,EACT,KACJ,CAEJ,QAAelG,IAAXiG,EACA,OAAOA,EAEX,IAAK,MAAMC,KAAO1E,OAAO2E,KAAKZ,GAC1B,GAAIA,EAAWW,KAASF,EAAI,CACxBC,EAASC,EACT,KACJ,CAEJ,YAAelG,IAAXiG,EACOA,EAEJD,EAAG9K,IACd,CACJ,C,kdChJO,SAASkL,EAAa3D,EAAO4D,GAChC,GAAI3I,MAAMC,QAAQ8E,GAAQ,CAEtB,IAAI6D,EAAW,GACf,IAAK,IAAIrM,EAAI,EAAGA,EAAIoM,EAAWpM,IAC3BqM,EAAWA,EAASC,OAAO9D,GAE/B,OAAO6D,CACX,CACK,CACD,MAAMA,EAAW,IAAI5I,MAAM2I,GAE3B,OADAC,EAASE,KAAK/D,GACP6D,CACX,CACJ,CACO,SAASG,EAAOC,EAAKC,GACxB,IAAKD,EACD,MAAM,IAAI,KAAeC,EAEjC,CAIO,SAASC,EAAMC,EAAOC,GACzB,IAAIC,EAAU,EACd,IAAK,MAAMC,KAAQH,EACXG,IAASF,GACTC,IAGR,OAAOA,CACX,CAMO,SAASE,EAAiBC,GAC7B,OAAkB,IAAdA,EAAGlO,OACIkO,EAAG,GAEPA,CACX,CAUO,SAASC,EAAOvK,GACnB,OAAIc,MAAMC,QAAQf,GACPA,EAEJ,CAACA,EACZ,CAuBO,SAASwK,EAAYlM,GACxB,MACMmM,EADenM,EAAKoM,QAAQ,uBAAwB,SAC5BA,QAAQ,kBAAmB,SAASC,cAKlE,MAAoB,MAAhBF,EAAS,GACFA,EAEJ,UAAYA,CACvB,CACO,SAASG,EAAYrE,GAExB,OAAIA,EAAWnK,QAAU,IAIQ,IAA7BmK,EAAW5J,QAAQ,KAHZ4J,EAMJA,EAAWmE,QAAQ,eAAe,CAACG,EAAGC,IAAOA,EAAGC,eAC3D,CAEA,IAAIC,EAAyB,CAAC,EACvB,SAASC,EAAqBC,GACjC,GAAiB,OAAbA,QAAkC9H,IAAb8H,EACrB,OAAO,KAEX,MAAM7G,EAAO,CAAC,EAGd,OAFAA,EAAgB,UAAI6G,EAAS3M,eAC7B8F,EAAa,OAAI6G,EAAS9G,YACnBC,CACX,CAYA,SAAS8G,EAA8BzH,GACnC,GAAc,MAAVA,GAAoC,kBAAXA,EAGxB,GAAI5C,MAAMC,QAAQ2C,GACnBA,EAAO0H,SAAQC,GAAcF,EAA8BE,SAE1D,CACD,MAAMtN,EAAS6G,OAAO2E,KAAK7F,GAC3B,IAAK,MAAM4H,KAASvN,EAAQ,CACxB,MAAM8H,EAAQnC,EAAO4H,GACR,MAATzF,GAAkC,kBAAVA,IACnB/E,MAAMC,QAAQ8E,IAA4B,YAAlBA,EAAY,MACX,kBAAnBA,EAAa,MAIpBsF,EAA8BtF,GAH9BnC,EAAO4H,GAASzF,EAAa,MAMzC,CACJ,CACJ,CAcO,SAAS0F,EAAuBhF,EAAYiF,EAAgB,CAAC,EAAG7H,EAAgB,CAAC,EAAG8H,EAAsB,SAAU7H,GAAiB,GAExI,GAA0B,kBAAf2C,EAAyB,CAChC,MAAMmF,EAAenF,EACrB,IAAI6C,EACJ,GAAIsC,KAAgB/H,EAChByF,EAAKzF,EAAc+H,QAElB,GAAIA,KAAgBV,EACrB5B,EAAK4B,EAAuBU,QAI5B,GADAtC,EAAKoC,EAAcE,GACT,MAANtC,EACA,MAAM,IAAI,KAAW,WAAWqC,MAAwBlF,+DAE1CkF,wHAGOA,qGAM7B,OAAOrC,CACX,CACK,CAED,MAAM1F,EAAS6C,EACf,GAA2B,MAAvB7C,EAAkB,WAAiC,MAApBA,EAAe,OAC9C,MAAM,IAAI,KAAW,GAAG+H,8BACjBtN,KAAKC,UAAUsF,2CAG1B,MAAM1E,EAAY0E,EAAkB,UACpC,IAAID,EAAKD,EAUT,GATIxE,KAAa2E,GACZF,EAAKD,GAAcG,EAAc3E,GAE7BA,KAAagM,GACjBvH,EAAKD,GAAcwH,EAAkC,UAEjDhM,KAAawM,KACjB/H,EAAKD,GAAcgI,EAAcxM,IAE3B,MAAPyE,EACA,MAAM,IAAI,KAAW,WAAWgI,MAAwBzM,+DAE1CyM,wHAGOA,qGAKzB,GAAkB,MAAdjI,EAAoB,CAMpB,MAAMmI,EAAwB,CAAC,EAC/B,IAAK,MAAMrC,KAAO1E,OAAO2E,KAAKyB,GAC1BW,EAAsBrC,GAAO0B,EAAuB1B,GAExD,IAAK,MAAMA,KAAO1E,OAAO2E,KAAK5F,GAC1BgI,EAAsBrC,GAAO3F,EAAc2F,GAG1B5F,EAAe,OACR,cAAIiI,EAChC,MAAMC,EAAsBhH,OAAOiH,OAAO,CAAC,EAAGb,GAC9C,IAAK,MAAM1B,KAAO1E,OAAO2E,KAAK5F,GAC1BqH,EAAuB1B,GAAO3F,EAAc2F,GAEhD6B,EAA8BzH,EAAe,QAC7C,MAAMoI,EAAYtI,EAAWC,EAAKC,EAAe,OAAGC,EAAeC,GAEnE,OADAoH,EAAyBpG,OAAOiH,OAAO,CAAC,EAAGD,GACpCE,CACX,CACK,CAID,MAAMF,EAAsBhH,OAAOiH,OAAO,CAAC,EAAGb,GAC9C,IAAK,MAAM1B,KAAO1E,OAAO2E,KAAK5F,GAC1BqH,EAAuB1B,GAAO3F,EAAc2F,GAKhD,MAAMwC,EAAY,IAAIrI,EAAIC,EAAe,QAEzC,OADAsH,EAAyBpG,OAAOiH,OAAO,CAAC,EAAGD,GACpCE,CACX,CACJ,CACJ,CAcO,SAASC,EAAqBC,EAAGC,GACpC,OAAQ,EATL,SAAuBD,EAAGC,GAC7B,OAAQD,EAAIC,GAAM,EAAMD,EAAIC,EAAK,EAAI,CACzC,CAOgBC,CAAcF,EAAGC,EACjC,CAuCO,SAASE,EAAO7B,GACnB,GAAU,MAANA,EACA,OAAOA,EAEX,MAAM8B,EAAM,GAEZ,IAAK,MAAMpM,KAAKsK,GACY,IAApB8B,EAAIzP,QAAQqD,IACZoM,EAAIlQ,KAAK8D,GAGjB,OAAOoM,CACX,CAOO,SAASC,EAAcC,GAC1B,GAAW,MAAPA,EACA,MAAM,IAAI,KAAW,yBAAyBnO,KAAKC,UAAUkO,MAEjE,IAAK,MAAMhD,KAAOgD,EACd,GAAIA,EAAIC,eAAejD,GACnB,OAAO,EAGf,OAAO,CACX,CAQO,SAASkD,EAA0BC,EAAQC,EAAO7G,GACrD,GAAa,MAATA,GAGA4G,EAAO9P,QAAQkJ,GAAS,EACxB,MAAM,IAAI,KAAW,GAAGA,oBAAwB6G,wBAA4BD,uBAEpF,CAgBO,SAASE,EAAwB3M,EAAG4M,EAAcC,EAAY,EAAGC,EAAYC,KAGhF,OAFAlD,EAAOgD,GAAa,GACpBhD,EAAOiD,GAAaD,GACZ/L,MAAMC,QAAQf,IAAMA,EAAE5D,QAAUyQ,GAAa7M,EAAE5D,QAAU0Q,GAC7D9M,EAAEgN,OAAMC,UAAYA,IAAML,GAClC,CASO,SAASM,EAAsBrH,EAAOvH,GACrCwC,MAAMC,QAAQ8E,IACd,EAAA9B,KAAA,OAAY8B,EAAMzJ,OAAS,GAAG,IAAM,GAAGkC,sCACvCuH,EAAMuF,SAAQ,CAAC+B,EAAG9P,IAAM6P,EAAsBC,EAAG,WAAW9P,EAAI,QAAQiB,QAGxE,EAAAyF,KAAA,OAAYqJ,OAAOC,UAAUxH,IAAUA,EAAQ,GAAG,IAAM,YAAYvH,uCAC7DgP,EAAuBzH,OAEtC,CAYO,SAASyH,EAAuBzH,GACnC,OAAc,OAAVA,EACO,OAEF/E,MAAMC,QAAQ8E,GACZ,IAAMA,EAAM9I,KAAIoQ,GAAKG,EAAuBH,KAAII,KAAK,KAAO,IAE7C,kBAAV1H,EACL,IAAIA,KAGJ,GAAGA,GAElB,CAUO,SAAS2H,EAASC,EAAGC,GACxB,IACIC,EADAC,EAAW,EAAA7J,KAAA,MAWf,MATW,IAAI3E,KACX,MAAMyO,EAAM,EAAA9J,KAAA,MACZ,OAAI8J,EAAMD,EAAWF,IAGrBE,EAAWC,EACXF,EAAaF,KAAKrO,IAHPuO,CAIM,CAGzB,CAOO,SAASG,EAA2BC,GACvC,MAAuB,SAAnBA,EACO,OAEY,WAAnBA,EACO,SAEY,QAAnBA,EACO,MAEJ,IACX,C,+TC7cO,SAASC,EAAYhO,EAAGiO,GAC3B,OAAO,IAAA7G,OAAK,KACQ,YAAZpH,EAAEM,QACFN,EAAIA,EAAEiI,OAAO,YAEjB,MAAMiG,EAAY,MAAQ,KAASlO,GAAIiO,GAAM,GACvCE,EAAgB,OAASD,EAAUpO,OAAO,WAC1CsO,EAAO,OAAS,UAAYF,EAAWC,IAC7C,OAAO,MAAQnO,EAAGoO,EAAK,GAE/B,CACO,SAASC,EAAiBnH,EAAOC,GACpC,OAAO,IAAAC,OAAK,IAAM,OAAS,KAAS,MAAQD,EAAOD,KAAU,IACjE,CACO,SAASoH,EAAkBpH,EAAOC,GACrC,OAAO,IAAAC,OAAK,IAAM,OAAS,MAAQ,MAAQD,EAAOD,KAAU,IAChE,CACO,SAASqH,EAA4BrH,EAAOC,GAC/C,OAAO,IAAAC,OAAK,KACR,MAAMoH,EAAO,MAAQtH,EAAOC,GACtBsH,EAAc,cAAgB,MAAQvH,IAAQ,UAAWkG,OAAOsB,WAChEC,EAAY,MAAQ,MAAQH,EAAMC,IACxC,OAAO,MAAQ,IAAK,OAASE,GAAY,GAAG,GAEpD,CACO,SAASC,EAA4B1H,EAAOC,GAC/C,OAAO,IAAAC,OAAK,KACR,MAAMyH,EAAc,cAAgB1H,GAAO,UAAWiG,OAAOsB,WACvDI,EAAW,MAAQ,MAAQ,EAAGD,IAC9BJ,EAAc,cAAgBvH,GAAO,UAAWkG,OAAOsB,WACvDK,EAAY,MAAQ,MAAQ,EAAGN,IACrC,OAAO,OAAS,KAAS,MAAQK,EAAUC,KAAc,EAAE,GAEnE,CAoCO,SAASvG,EAAwBwG,EAAQ5N,EAAQ6N,GAAa,GACjE,OAAO,IAAA7H,OAAK,KACR,GAAI6H,EACA7N,EAAS,UAAYA,OAEpB,CAED,MAAM8N,EAAY,MAAQ9N,EAAQA,EAAOtB,MAAM1D,OAAS,GAAG,GAC3DgF,EAAS,MAAQA,EAAQ8N,EAC7B,CAEA,OADA9N,EAAS,cAAgBA,GAAQ,UAAW,GAAI,WACzC,MAAQ,MAAQ,MAAQ4N,EAAOG,UAAW,MAAQ/N,IAAUA,EAAOtB,MAAM1D,OAAS,GAAG,GAEpG,CAUO,SAASsM,EAA8BsG,EAAQ5N,EAAQ6N,GAAa,GACvE,OAAO,IAAA7H,OAAK,KACR,MAAMgI,EAAa,QAAU,KAAUJ,IAASK,QAE1CnR,GADNkD,EAAS,cAAgBA,GAAQ,UAAW,GAAI,YACrBtB,MAG3B,OAAO0I,EAFc,SAAW4G,EAAYlR,EAAYA,EAAY9B,OAAS,IACxEkT,QAAQpR,GACgCkD,EAAQ6N,EAAW,GAExE,CAuCO,SAASrH,EAAmBV,EAAOC,GACtC,OAAO,IAAAC,OAAK,KACR,IAAI7E,EAGJ,OAFAA,EAAI,cAAgB4E,GAAO,UAAW,GAAI,WAC1C5E,EAAI,MAAQ,MAAQA,EAAG,MAAQ,EAAGA,KAC3B,OAtBR,SAAuCgN,EAAQC,GAClD,IAAK,EAAAzL,KAAA,YAAiBwL,EAAOzP,MAAO0P,EAAO1P,OACvC,MAAM,IAAI,KACN,8DAAG3B,KAAKC,UAAUmR,EAAOzP,cAAc3B,KAAKC,UAAUoR,EAAO1P,UAErE,OAAO,IAAAsH,OAAK,KAOR,MAAMqI,EAAaD,EAAOE,OACpBC,EAAeH,EAAOI,MAAMC,MAClC,OAAOJ,EAAWK,IAAIN,EAAOO,IAAIR,IAAS5P,IAAIgQ,EAAaK,MAAMC,QAAQ,GAEjF,CAMwBC,CAA8BhJ,EAAO3E,IAAK,EAAE,GAEpE,CACO,SAAS4N,EAA0BjJ,EAAOC,GAC7C,OAAO,IAAAC,OAAK,KACR,MAAMqH,EAAc,cAAgBvH,GAAO,UAAW,GAChD2H,EAAc,cAAgB1H,GAAO,UAAW,GACtD,OAAO,MAAQ,MAAQD,EAAO,MAAQ,MAAQuH,EAAaI,MAAiB,EAAE,GAEtF,CAOO,SAASuB,EAAgBlJ,EAAOC,GACnC,OAAO,IAAAC,OAAK,KACR,MAAMiJ,EAAiBrC,EAAY9G,GAAQ,GACrCoJ,EAAiBtC,EAAY7G,GAAQ,GACrCoJ,EAAY,MAAQF,EAAgBC,GAC1C,OAAO,MAAQ,MAAQC,GAAY,GAAG,GAE9C,CACO,MAYMC,EAAY,CACrBnC,mBACAC,oBACAC,8BACAK,8BACA6B,aAxJG,SAAsBvJ,EAAOC,GAChC,OAAO,IAAAC,OAAK,KACR,MAAMsJ,EAAY,UAAY,EAAG,MAAQ,EAAG,MAAQxJ,EAAOC,KAC3D,OAAO,OAAS,KAASuJ,IAAa,EAAE,GAEhD,EAoJIC,MAnJG,SAAezJ,EAAOC,GACzB,OAAO,IAAAC,OAAK,KACR,MAAMsJ,EAAY,UAAY,EAAG,MAAQ,EAAG,MAAQxJ,EAAOC,KAC3D,OAAO,OAASuJ,GAAY,EAAE,GAEtC,EA+IIE,iBA9IG,SAA0B1J,EAAOC,GACpC,OAAO,IAAAC,OAAK,KACR,MAAMyJ,EAAM,MAAQ,MAAQ3J,EAAOC,IAAS,GACtC0I,EAAM,MAAQ,MAAQ,MAAQ,EAAG3I,GAAQC,IAAS,GACxD,OAAO,UAAY,EAAG,MAAQ,EAAG,MAAQ0I,EAAKgB,IAAM,GAE5D,EAyIIC,QAhIG,SAAiB5J,EAAOC,GAC3B,OAAO,IAAAC,OAAK,KACR,MAAM2J,EAAO9T,KAAKpB,IAAI,GAChBmV,EAAiB,MAAQ7J,EAAOD,GAChC+J,EAAgB,MAAQ,MAAQD,EAAgB,WAAa,OAAS,EAAGA,KAAmBD,GAClG,OAAO,OAASE,GAAgB,EAAE,GAE1C,EA0HIzI,0BACAE,gCACAd,qBACAuI,4BACAe,QAvCG,SAAiBhK,EAAOC,GAC3B,OAAO,IAAAC,OAAK,KACR,MAAM+J,EAAU,MAAQ,OAAQ,UAAWhK,IAC3C,OAAO,OAAS,MAAQA,EAAO,MAAQD,EAAOiK,KAAY,EAAE,GAEpE,EAmCIf,mBAIG,SAASlH,EAAIkI,GAChB,GAA8B,kBAAnBA,EAA6B,CACpC,GAAIA,KAAkBZ,EAClB,OAAOA,EAAUY,GAErB,IAAIC,EAAS,gBAAgBD,IAM7B,MALIA,EAAezG,cAAc2G,SAAS,yBACtCD,EAAS,gBAAgBD,yFAIvB,IAAI,KAAWC,EACzB,CAEI,OAAOD,CAEf,C,wDCzOA,MAAMG,EAAU,O,wBCcT,SAASC,EAAqBnP,GACjC,IAAI2H,EAAQ,EACZ,IAAK,MAAMyH,KAAUpP,EACW,IAAxBoP,EAAO3R,MAAM1D,OACb4N,GAAS,EAGTA,GAASyH,EAAO3R,MAAM4R,QAAO,CAAC1F,EAAGC,IAAMD,EAAIC,IAGnD,OAAOjC,CACX,C,uDChBA,IAAIvF,EAAQ,EAAQ,OAIpB,IAAIE,EAAW,oBAAsBC,OAAOC,GAAKD,OAAOC,GAHxD,SAAY7E,EAAGuC,GACb,OAAQvC,IAAMuC,IAAM,IAAMvC,GAAK,EAAIA,IAAM,EAAIuC,IAAQvC,IAAMA,GAAKuC,IAAMA,CACxE,EAEEoP,EAAWlN,EAAMkN,SACjB3M,EAAYP,EAAMO,UAClB4M,EAAkBnN,EAAMmN,gBACxB1M,EAAgBT,EAAMS,cA0BxB,SAAS2M,EAAuBlM,GAC9B,IAAImM,EAAoBnM,EAAKN,YAC7BM,EAAOA,EAAKE,MACZ,IACE,IAAIkM,EAAYD,IAChB,OAAQnN,EAASgB,EAAMoM,EACzB,CAAE,MAAOC,GACP,OAAO,CACT,CACF,CAIA,IAAItN,EACF,qBAAuBuN,QACvB,qBAAuBA,OAAOC,UAC9B,qBAAuBD,OAAOC,SAASC,cANzC,SAAgC/M,EAAWC,GACzC,OAAOA,GACT,EArCA,SAAgCD,EAAWC,GACzC,IAAIQ,EAAQR,IACV+M,EAAYT,EAAS,CAAEhM,KAAM,CAAEE,MAAOA,EAAOR,YAAaA,KAC1DM,EAAOyM,EAAU,GAAGzM,KACpB0M,EAAcD,EAAU,GAmB1B,OAlBAR,GACE,WACEjM,EAAKE,MAAQA,EACbF,EAAKN,YAAcA,EACnBwM,EAAuBlM,IAAS0M,EAAY,CAAE1M,KAAMA,GACtD,GACA,CAACP,EAAWS,EAAOR,IAErBL,GACE,WAEE,OADA6M,EAAuBlM,IAAS0M,EAAY,CAAE1M,KAAMA,IAC7CP,GAAU,WACfyM,EAAuBlM,IAAS0M,EAAY,CAAE1M,KAAMA,GACtD,GACF,GACA,CAACP,IAEHF,EAAcW,GACPA,CACT,EAoBArB,EAAQM,0BACN,IAAWL,EAAMK,qBAAuBL,EAAMK,qBAAuBJ,C,gJCnDhE,SAAS4N,EAAgBtS,GAC5B,OAAOc,MAAMC,QAAQf,IAAMc,MAAMC,QAAQf,EAAE,GAC/C,CAOO,SAASuS,EAAmBvS,GAC/B,OAAiB,IAAbA,EAAE5D,OACK,GAEN0E,MAAMC,QAAQf,EAAE,IAGdA,EAFI,CAACA,EAGhB,CAOO,SAASwS,EAAoBlI,GAChC,IAAItK,EACJ,GAAIc,MAAMC,QAAQuJ,GAAK,CACnB,GAAkB,IAAdA,EAAGlO,OACH,MAAM,IAAI,KAAW,uCAAuCkO,EAAGlO,UAEnE4D,EAAIsK,EAAG,EACX,MAEItK,EAAIsK,EAER,OAAOtK,CACX,CAWO,SAASyS,EAAmBC,GAC/B,GAAI5R,MAAMC,QAAQ2R,IAAW5R,MAAMC,QAAQ2R,EAAO,IAAK,CACnD,GAAsB,IAAlBA,EAAOtW,OAEP,OAAOsW,EAAO,GAGd,MAAM,IAAI,KAAW,iCAAiCA,EAAOtW,SAErE,CAEI,OAAOsW,CAEf,C,6ICvDO,SAASC,EAAe9M,EAAO+M,EAAGtU,GACrC,GAAqB,kBAAVuH,EACP,OAAO,QAAaA,EAAO+M,GAG3B,GAAI/M,EAAMzJ,SAAWwW,EACjB,MAAM,IAAI,KAAW,OAAOtU,6CAAgDsU,yBAC1D/M,EAAMzJ,oBAE5B,IAAK,IAAIiB,EAAI,EAAGA,EAAIuV,IAAKvV,EAAG,CACxB,MAAMwV,EAAchN,EAAMxI,GAC1B,KAAK,QAAUwV,GACX,MAAM,IAAI,KAAW,OAAOvU,6CAAgDsU,yBAChDzU,KAAKC,UAAUyH,qCAChBgN,IAEnC,CACA,OAAOhN,CAEf,CASO,SAASiN,EAAiBC,EAAaC,EAAYC,EAASC,EAAQC,EAAW,GAClF,GAAmB,MAAfJ,EACA,OAAOA,EAGX,IAAIK,EAOJ,OALIA,EADY,SAAZH,EACeF,EAGAA,GANOC,GAAcA,EAAa,IAAMG,EAAW,IAMjB,EAE9ClW,KAAKC,OAAOkW,EAAeF,EAAS,GAAKA,EACpD,CACO,SAASG,EAAaC,EAASC,EAAYC,EAAYP,GAC1D,GAAe,MAAXK,EACA,OAAO,KAEX,GAAgB,UAAZL,EACAK,EAAUA,EAAUC,GAAa,QAAI,CAACC,EAAaD,EAAY,QAE9D,IAAgB,SAAZN,EAIL,MAAM,IAAI,KAAW,2BAA2BA,MAHhDK,GAAoBC,CAIxB,CACA,OAAOD,CACX,C,wBCxEE/O,EAAOC,QAAU,EAAjB,M,sJCWF,MAAMiP,EAA+B,WAO9B,MAAMC,EAeT,WAAAvU,CAAY2K,EAAKxJ,EAAQ,UAAWhC,EAAOmV,EAA8BhU,GAAY,EAAMkU,EAAa,MACpGnU,KAAKc,MAAiB,MAATA,EAAgB,UAAYA,EACzCd,KAAKM,MAAQgK,EAAIhK,MACjBN,KAAKoU,IAAK,SACVtV,EAAe,MAARA,EAAemV,EAA+BnV,EACrDkB,KAAKqU,cAAe,QAAoBvV,GACxCkB,KAAKlB,MAAO,QAAoBkB,KAAKqU,cACrCrU,KAAKsU,WAAarU,EAClBD,KAAKmU,WAAaA,EAClBnU,KAAKsK,IAAM,WAAaA,EAAKtK,KAAKsU,WAAYtU,KAAKlB,KAAMkB,KAAKc,MAClE,CAQA,IAAAyT,GAEI,OADAvU,KAAKwU,oBACExU,KAAKsK,GAChB,CAQA,KAAAmK,CAAMC,GAWF,OATA1U,KAAKwU,oBA+Bb,SAA0BhU,EAAGuC,GACzB,GAAIvC,EAAEF,MAAMrB,aAAe8D,EAAEzC,MAAMrB,WAC/B,MAAM,IAAI0V,MAAM,mBAAqBhW,KAAKC,UAAU4B,EAAEF,OAAS,QAC3D3B,KAAKC,UAAUmE,EAAEzC,OAE7B,CAnCQsU,CAAiB5U,KAAKsK,IAAKoK,GAEvB1U,KAAKsK,IAAI8J,KAAOM,EAAON,KACvBpU,KAAKsK,IAAI+B,OAAOqI,GACO,MAAnB1U,KAAKmU,YACLnU,KAAKsK,IAAI+B,OAAOrM,KAAKmU,WAAWpT,MAAMf,KAAKsK,OAG5CtK,IACX,CAIA,OAAA6U,GACI7U,KAAKwU,oBACLxU,KAAKsK,IAAIuK,SACb,CACA,iBAAAL,GACI,GAAIxU,KAAKsK,IAAIwK,WACT,MAAM,IAAIH,MAAM,kBAAkB3U,KAAKlB,4BAE/C,CACA,aAAImB,GACA,OAAOD,KAAKsU,UAChB,CACA,aAAIrU,CAAUA,GACVD,KAAKsU,WAAarU,EAClBD,KAAKsK,IAAIrK,UAAYA,CACzB,EAiKG,SAAS8U,EAAcjK,GAC1B,OAAOA,EAAGvN,KAAIiD,GAAKA,EAAE+T,QACzB,CASO,SAASS,EAAcC,GAC1BA,EAAmBrJ,SAAQsJ,IACNA,EAAiB,GACzBT,MAAMS,EAAiB,GAAG,GAE3C,C,kLCxPO,SAASrH,EAAUrN,GACtB,OAAOA,IAAM2U,SAAS3U,EAAEvB,WAAY,GACxC,CAQO,SAASmW,EAAU3K,EAAO4K,EAAOC,GACvB,MAATD,IACAA,EAAQ,GAED,MAAPC,IACAA,EAAM7K,EAAM7N,QAEhB,IAAI2Y,EAAO,EACX,IAAK,IAAI1X,EAAIwX,EAAOxX,EAAIyX,IAAOzX,EAC3B0X,GAAQ9K,EAAM5M,GAElB,OAAO0X,CACX,CAMA,SAASC,EAAU/K,GAEf,OADAA,EAAQnJ,MAAMC,QAAQkJ,GAAS,IAAIgL,aAAahL,GAASA,GAClD,IAAAiL,UAASjL,EACpB,CAMO,SAASkL,EAAIlL,GAChB,OAAO,MAAQ+K,EAAU/K,IAAQmL,WAAW,EAChD,CAMO,SAASC,EAAIpL,GAChB,OAAO,MAAQ+K,EAAU/K,IAAQmL,WAAW,EAChD,CAgDO,SAASE,EAAMT,EAAOC,GACzB,GAAIA,EAAMD,EACN,MAAM,IAAI,KAAW,QAAQC,eAAiBD,oBAElD,MAAMzI,EAAM,GACZ,IAAK,IAAI/O,EAAIwX,EAAOxX,EAAIyX,IAAOzX,EAC3B+O,EAAIlQ,KAAKmB,GAEb,OAAO+O,CACX,C,qHCnHA,SAASmJ,EAAiBnW,GACtB,GAAY,MAARA,GAAgC,kBAATA,EACvB,MAAM,IAAI+U,MACN,yFAAyB/U,IAErC,CAIO,MAAMoW,UAAoB,EAAAlR,cAAA,cAE1B,MAAMmR,UAAaD,EACtB,WAAArW,CAAYC,GACRC,QACAkW,EAAiBnW,GACjBI,KAAKkW,GAAa,MAARtW,GAA2B,MAAXA,EAAKsW,GAAa,IAAOtW,EAAKsW,GACxDlW,KAAKmW,GAAa,MAARvW,GAA2B,MAAXA,EAAKuW,GAAa,IAAOvW,EAAKuW,GACxDnW,KAAKoW,MAAoB,IAAZpW,KAAKkW,GAClBlW,KAAKqW,MAAoB,IAAZrW,KAAKmW,EACtB,CAKA,KAAApV,CAAMP,GACF,OAAO,IAAAoH,OAAK,KACR,IAAI0O,GAAiB,IAAAC,OAAM,CAAC,IAQ5B,OAPIvW,KAAKoW,QACLE,GAAiB,IAAAnW,KAAImW,GAAgB,IAAApO,KAAI,MAAQlI,KAAKkW,IAAI,IAAA9F,KAAI5P,OAE9DR,KAAKqW,QACLC,GACI,IAAAnW,KAAImW,GAAgB,IAAApO,KAAI,MAAQlI,KAAKmW,GAAI,KAAS3V,OAEnD8V,EAAeE,UAAU,GAExC,CACA,SAAA5R,GACI,MAAO,CAAE,GAAM5E,KAAKkW,GAAI,GAAMlW,KAAKmW,GACvC,CAEA,iBAAOnS,CAAWC,EAAKC,GACnB,OAAO,IAAID,EAAI,CAAEiS,GAAIhS,EAAW,GAAGiS,GAAIjS,EAAW,IACtD,EAGJ+R,EAAKzW,UAAY,OACjB,EAAAsF,cAAA,cAA4BmR,GAUrB,MAAMQ,EAA6C,CACtD,KAAQ,QAEL,SAASC,EAAqBvC,GACjC,OAAO,QAAqBA,EAChC,CACO,SAASwC,EAAuBzS,EAAQC,EAAgB,CAAC,GAC5D,OAAO,QAAuBD,EAAQ,EAAAY,cAAA,iBAA+B8R,SAASC,aAAc1S,EAAe,cAC/G,CACO,SAAS2S,EAAe/P,GAC3B,GAAkB,MAAdA,EACA,OAAO,KAEX,GAA0B,kBAAfA,EAAyB,CAKhC,OAAO4P,EADQ,CAAEnX,UAHCuH,KAAc0P,EAC5BA,EAA2C1P,GAC3CA,EACwB7C,OAAQ,CAAC,GAEzC,CACK,OAAI6C,aAAsBiP,EACpBjP,EAGA4P,EAAuB5P,EAEtC,C,8FC7EA,SAASgQ,EAA6BjN,EAAKkN,EAAO3Q,GAC9C,OAAgB,iBAARyD,GAAkC,iBAARA,GACtB,gBAARA,IACU,IAAVkN,GAAgC,kBAAV3Q,CAC9B,CAOO,SAAS4Q,EAAoBC,EAAgBpN,GAChD,GAAuB,OAAnBoN,EACA,OAAO,KAEN,GAA8B,kBAAnBA,EACZ,OAAO,KAA0BA,GAEhC,GAA+B,kBAAnBA,GACc,mBAAnBA,EACR,OAAOA,EAEN,GAAIA,aAA0B5V,MAAO,CACtC,MAAM6V,EAAU,GACVC,EAAcF,EAAeta,OACnC,IAAK,IAAIiB,EAAI,EAAGA,EAAIuZ,IAAevZ,EAAG,CAClC,MAAM+M,EAAOsM,EAAerZ,GACxBkZ,EAA6BjN,EAAKjM,EAAG+M,GACrCuM,EAAQza,KAAKkO,GAGbuM,EAAQza,KAAKua,EAAoBrM,EAAMd,GAE/C,CACA,OAAOqN,CACX,CACK,CACD,MAAME,EAAS,CAAC,EAChB,IAAK,MAAMC,KAAelS,OAAO2E,KAAKmN,GAAiB,CACnD,MAAMK,EAAgBL,EAAeI,GACrC,GAAoB,SAAhBA,GAAmD,kBAAlBC,EAIjCF,EAAOC,GAAeC,MAErB,CACD,MAAMC,EAAQ,KAA0BF,GACxCD,EAAOG,GAASP,EAAoBM,EAAeC,EACvD,CACJ,CACA,OAAOH,CACX,CACJ,CAOO,SAASI,EAAoBC,EAAU5N,GAC1C,GAAiB,OAAb4N,QAAkC9T,IAAb8T,EACrB,OAAO,KAEN,GAAwB,kBAAbA,EACZ,OAAO,KAA0BA,GAEhC,GAAyB,kBAAbA,GAA+C,mBAAbA,EAC/C,OAAOA,EAEN,GAAIA,aAAoBpW,MAAO,CAChC,MAAMqW,EAAU,GACVP,EAAcM,EAAS9a,OAC7B,IAAK,IAAIiB,EAAI,EAAGA,EAAIuZ,IAAevZ,EAAG,CAClC,MAAM+M,EAAO8M,EAAS7Z,GAClBkZ,EAA6BjN,EAAKjM,EAAG+M,GACrC+M,EAAQjb,KAAKkO,GAGb+M,EAAQjb,KAAK+a,EAAoB7M,EAAMd,GAE/C,CACA,OAAO6N,CACX,CACK,CACD,MAAMC,EAAS,CAAC,EAChB,IAAK,MAAMJ,KAASpS,OAAO2E,KAAK2N,GAAW,CACvC,MAAMG,EAAUH,EAASF,GACnBM,EAAQ,KAA0BN,GASpCI,EAAOE,GARI,SAAVN,GAA8B,cAAVA,GACF,kBAAZK,EAOSJ,EAAoBI,EAASL,GAH7BK,CAKxB,CACA,OAAOD,CACX,CACJ,C,yDChGO,SAASG,EAAyBC,EAAqBC,EAAWC,GAAY,GACjF,GAA2B,MAAvBF,GAC+B,kBAAxBA,GACP5S,OAAO+S,eAAeH,KAAyB5S,OAAOgT,YACrDC,EAAiBL,GAClB,MAAM,IAAIrD,MAAM,sEAEpB,GAAIuD,EAAW,CACCvZ,KAAKC,UAAUoZ,GACnBpb,MAOZ,CACJ,CAYO,SAASyb,EAAiB7X,GAC7B,GAAU,OAANA,EAEA,OAAO,EAEN,GAAiB,kBAANA,EAAgB,CAC5B,GAAI4E,OAAO+S,eAAe3X,KAAO4E,OAAOgT,UAAW,CAE/C,MAAMrO,EAAO3E,OAAO2E,KAAKvJ,GACzB,IAAK,MAAMsJ,KAAOC,EAAM,CACpB,GAAmB,kBAARD,EAEP,OAAO,EAEX,IAAKuO,EAAiB7X,EAAEsJ,IACpB,OAAO,CAEf,CACA,OAAO,CACX,CAGI,GAAIxI,MAAMC,QAAQf,GAAI,CAElB,IAAK,MAAMoK,KAAQpK,EACf,IAAK6X,EAAiBzN,GAClB,OAAO,EAGf,OAAO,CACX,CAKI,OAAO,CAGnB,CACK,CAED,MAAM0N,SAAe9X,EACrB,MAAiB,WAAV8X,GAAgC,WAAVA,GAAgC,YAAVA,CACvD,CACJ,C,6FCpFOC,eAAeC,EAAqBC,GACvC,GAAY,MAARA,EACA,OAEJ,MAAMC,EAAW,GACX3O,EAAO,GACP4O,EAAmB,GACzB,IAAK,MAAM7O,KAAO2O,EAAM,CACpB,MAAMpS,EAAQoS,EAAK3O,GACnB,GAAqB,kBAAVzD,EAAoB,CAC3B,MAAMuS,EAAcvS,EACpBqS,EAAShc,KAAKkc,EAAYC,QAC1B9O,EAAKrN,KAAKoN,GACV6O,EAAiBjc,KAAKkc,EAC1B,CACJ,CACA,GAAIF,EAAS9b,OAAS,EAAG,CACrB,MAAMqQ,QAAe6L,QAAQC,IAAIL,GACjC,IAAK,IAAI7a,EAAI,EAAGA,EAAIoP,EAAOrQ,SAAUiB,EACjC4a,EAAK1O,EAAKlM,IAAMoP,EAAOpP,GAAG,IAG9B,IAAAgX,SAAQ8D,EACZ,CACJ,CAOO,SAASK,EAAqBP,GACjC,GAAY,MAARA,EAGJ,IAAK,MAAM3O,KAAO2O,EAAM,CACpB,MAAMpS,EAAQoS,EAAK3O,GACE,kBAAVzD,GACPA,EAAMwO,SAEd,CACJ,C","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/layer_utils.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/models.js","webpack://StylistWidget/./node_modules/use-sync-external-store/shim/index.js","webpack://StylistWidget/./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim/with-selector.production.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/optimizers.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs/dist/index.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/metrics.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/losses.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/version.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/variable_utils.js","webpack://StylistWidget/./node_modules/use-sync-external-store/cjs/use-sync-external-store-shim.production.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/conv_utils.js","webpack://StylistWidget/./node_modules/use-sync-external-store/shim/with-selector.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/variables.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/math_utils.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/regularizers.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/utils/serialization_utils.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/user_defined_metadata.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-layers/dist/logs.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { countParamsInWeights } from './variable_utils';\n/**\n * Print the summary of a LayersModel object.\n *\n * @param model tf.LayersModel instance.\n * @param lineLength Total length of printed lines. Set this to adapt to the\n *   display to different terminal or console sizes.\n * @param positions Relative or absolute positions of log elements in each\n *   line. Each number corresponds to right-most (i.e., ending) position of a\n *   column.\n *   If not provided, defaults to `[0.45, 0.85, 1]` for sequential-like\n *   models and `[0.33, 0.55, 0.67, 1]` for non-sequential like models.\n * @param printFn Print function to use.\n *   It will be called on each line of the summary. You can provide a custom\n *   function in order to capture the string summary. Defaults to `console.log`.\n */\nexport function printSummary(model, lineLength, positions, \n// tslint:disable-next-line:no-any\nprintFn = console.log) {\n    const sequentialLike = isModelSequentialLike(model);\n    // Header names for different log elements.\n    const toDisplay = ['Layer (type)', 'Output shape', 'Param #'];\n    if (sequentialLike) {\n        lineLength = lineLength || 65;\n        positions = positions || [0.45, 0.85, 1];\n    }\n    else {\n        lineLength = lineLength || 98;\n        positions = positions || [0.33, 0.55, 0.67, 1];\n        // Header names for different log elements.\n    }\n    if (positions[positions.length - 1] <= 1) {\n        // `positions` is relative. Convert it to absolute positioning.\n        positions = positions.map(p => Math.floor(lineLength * p));\n    }\n    let relevantNodes;\n    if (!sequentialLike) {\n        toDisplay.push('Receives inputs');\n        relevantNodes = [];\n        for (const depth in model.nodesByDepth) {\n            relevantNodes.push(...model.nodesByDepth[depth]);\n        }\n    }\n    printFn('_'.repeat(lineLength));\n    printRow(toDisplay, positions, printFn);\n    printFn('='.repeat(lineLength));\n    const layers = model.layers;\n    for (let i = 0; i < layers.length; ++i) {\n        if (sequentialLike) {\n            printLayerSummary(layers[i], positions, printFn);\n        }\n        else {\n            printLayerSummaryWithConnections(layers[i], positions, relevantNodes, printFn);\n        }\n        printFn((i === layers.length - 1 ? '=' : '_').repeat(lineLength));\n    }\n    // tslint:disable-next-line:no-any\n    model.checkTrainableWeightsConsistency();\n    const trainableCount = countTrainableParams(model);\n    const nonTrainableCount = countParamsInWeights(model.nonTrainableWeights);\n    printFn(`Total params: ${trainableCount + nonTrainableCount}`);\n    printFn(`Trainable params: ${trainableCount}`);\n    printFn(`Non-trainable params: ${nonTrainableCount}`);\n    printFn('_'.repeat(lineLength));\n}\nfunction countTrainableParams(model) {\n    let trainableCount;\n    // tslint:disable:no-any\n    if (model.collectedTrainableWeights != null) {\n        trainableCount =\n            countParamsInWeights(model.collectedTrainableWeights);\n    }\n    else {\n        trainableCount = countParamsInWeights(model.trainableWeights);\n    }\n    // tslint:enable:no-any\n    return trainableCount;\n}\nfunction isModelSequentialLike(model) {\n    let sequentialLike = true;\n    const nodesByDepth = [];\n    const nodes = [];\n    for (const depth in model.nodesByDepth) {\n        nodesByDepth.push(model.nodesByDepth[depth]);\n    }\n    for (const depthNodes of nodesByDepth) {\n        if (depthNodes.length > 1 ||\n            depthNodes.length === 1 && depthNodes[0].inboundLayers.length > 1) {\n            sequentialLike = false;\n            break;\n        }\n        nodes.push(...depthNodes);\n    }\n    if (sequentialLike) {\n        // Search for shared layers.\n        for (const layer of model.layers) {\n            let flag = false;\n            for (const node of layer.inboundNodes) {\n                if (nodes.indexOf(node) !== -1) {\n                    if (flag) {\n                        sequentialLike = false;\n                        break;\n                    }\n                    else {\n                        flag = true;\n                    }\n                }\n            }\n            if (!sequentialLike) {\n                break;\n            }\n        }\n    }\n    return sequentialLike;\n}\nfunction printRow(fields, positions, \n// tslint:disable-next-line:no-any\nprintFn = console.log) {\n    let line = '';\n    for (let i = 0; i < fields.length; ++i) {\n        if (i > 0) {\n            line = line.slice(0, line.length - 1) + ' ';\n        }\n        line += fields[i];\n        line = line.slice(0, positions[i]);\n        line += ' '.repeat(positions[i] - line.length);\n    }\n    printFn(line);\n}\n/**\n * Prints a summary for a single Layer, without connectivity information.\n *\n * @param layer: Layer instance to print.\n */\nfunction printLayerSummary(layer, positions, \n// tslint:disable-next-line:no-any\nprintFn) {\n    let outputShape;\n    try {\n        outputShape = JSON.stringify(layer.outputShape);\n    }\n    catch (err) {\n        outputShape = 'multiple';\n    }\n    const name = layer.name;\n    const className = layer.getClassName();\n    const fields = [`${name} (${className})`, outputShape, layer.countParams().toString()];\n    printRow(fields, positions, printFn);\n}\n/**\n * Prints a summary for a single Layer, with connectivity information.\n */\nfunction printLayerSummaryWithConnections(layer, positions, relevantNodes, \n// tslint:disable-next-line:no-any\nprintFn) {\n    let outputShape;\n    try {\n        outputShape = JSON.stringify(layer.outputShape);\n    }\n    catch (err) {\n        outputShape = 'multiple';\n    }\n    const connections = [];\n    for (const node of layer.inboundNodes) {\n        if (relevantNodes != null && relevantNodes.length > 0 &&\n            relevantNodes.indexOf(node) === -1) {\n            continue;\n        }\n        for (let i = 0; i < node.inboundLayers.length; ++i) {\n            const inboundLayer = node.inboundLayers[i].name;\n            const inboundLayerIndex = node.nodeIndices[i];\n            const inboundTensorIndex = node.tensorIndices[i];\n            connections.push(`${inboundLayer}[${inboundLayerIndex}][${inboundTensorIndex}]`);\n        }\n    }\n    const name = layer.name;\n    const className = layer.getClassName();\n    const firstConnection = connections.length === 0 ? '' : connections[0];\n    const fields = [\n        `${name} (${className})`, outputShape, layer.countParams().toString(),\n        firstConnection\n    ];\n    printRow(fields, positions, printFn);\n    for (let i = 1; i < connections.length; ++i) {\n        printRow(['', '', '', connections[i]], positions, printFn);\n    }\n}\n//# sourceMappingURL=layer_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original source keras/models.py */\nimport { dispose, io, serialization, util } from '@tensorflow/tfjs-core';\nimport { getUid } from './backend/state';\nimport { Input } from './engine/input_layer';\nimport { getSourceInputs, Node } from './engine/topology';\nimport { LayersModel } from './engine/training';\nimport { NotImplementedError, RuntimeError, ValueError } from './errors';\nimport { deserialize } from './layers/serialization';\nimport * as generic_utils from './utils/generic_utils';\nimport { convertPythonicToTs } from './utils/serialization_utils';\nimport { getExactlyOneShape } from './utils/types_utils';\n/**\n * Parses a JSON model configuration file and returns a model instance.\n *\n * ```js\n * // This example shows how to serialize a model using `toJSON()` and\n * // deserialize it as another model using `tf.models.modelFromJSON()`.\n * // Note: this example serializes and deserializes only the topology\n * // of the model; the weights of the loaded model will be different\n * // from those of the the original model, due to random weight\n * // initialization.\n * // To load the topology and weights of a model, use `tf.loadLayersModel()`.\n * const model1 = tf.sequential();\n * model1.add(tf.layers.repeatVector({inputShape: [2], n: 4}));\n * // Serialize `model1` as a JSON object.\n * const model1JSON = model1.toJSON(null, false);\n * model1.summary();\n *\n * const model2 = await tf.models.modelFromJSON(model1JSON);\n * model2.summary();\n * ```\n *\n *  @param modelAndWeightsConfig JSON object or string encoding a model and\n *       weights configuration. It can also be only the topology JSON of the\n *       model, in which case the weights will not be loaded.\n *  @param custom_objects Optional dictionary mapping names\n *       (strings) to custom classes or functions to be\n *       considered during deserialization.\n * @returns A TensorFlow.js Layers `tf.LayersModel` instance (uncompiled).\n */\nexport async function modelFromJSON(modelAndWeightsConfig, customObjects) {\n    if (!('modelTopology' in modelAndWeightsConfig)) {\n        modelAndWeightsConfig = { modelTopology: modelAndWeightsConfig };\n    }\n    modelAndWeightsConfig = modelAndWeightsConfig;\n    let modelTopology = modelAndWeightsConfig.modelTopology;\n    if (modelTopology['model_config'] != null) {\n        // If the model-topology JSON contains a 'model_config' field, then it is\n        // a full model JSON (e.g., from `keras.Model.save()`), which contains\n        // not only the model's architecture in its 'model_config' field, but\n        // additional information such as the model's optimizer. We use only the\n        // 'model_config' field currently.\n        modelTopology = modelTopology['model_config'];\n    }\n    const tsConfig = convertPythonicToTs(modelTopology);\n    const model = deserialize(tsConfig, customObjects);\n    if (modelAndWeightsConfig.weightsManifest != null) {\n        // Load the weight values keyed by the original tensor names in the model\n        // file that was loaded.  These should match the keys of the weight\n        // manifest.\n        const weightValues = await io.loadWeights(modelAndWeightsConfig.weightsManifest, modelAndWeightsConfig.pathPrefix, model.weights.map(weight => weight.originalName));\n        // Map the weights to the unique tensor names generated during model loading\n        const uniqueWeightValues = {};\n        for (const weight of model.weights) {\n            uniqueWeightValues[weight.originalName] =\n                weightValues[weight.originalName];\n        }\n        model.loadWeights(uniqueWeightValues);\n        // Dispose temporary weight values.\n        dispose(weightValues);\n    }\n    return model;\n}\n/**\n * Load a model, including its topology and optionally weights.  See the\n * Tutorial named \"How to import a Keras Model\" for usage examples.\n *\n * Example 1: Save `model`'s topology and weights to browser [local\n * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n * then load it back.\n *\n * ```js\n * const model = tf.sequential(\n *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n * console.log('Prediction from original model:');\n * model.predict(tf.ones([1, 3])).print();\n *\n * const saveResults = await model.save('localstorage://my-model-1');\n *\n * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\n * console.log('Prediction from loaded model:');\n * loadedModel.predict(tf.ones([1, 3])).print();\n * ```\n *\n * Example 2. Saving `model`'s topology and weights to browser\n * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\n * then load it back.\n *\n * ```js\n * const model = tf.sequential(\n *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n * console.log('Prediction from original model:');\n * model.predict(tf.ones([1, 3])).print();\n *\n * const saveResults = await model.save('indexeddb://my-model-1');\n *\n * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\n * console.log('Prediction from loaded model:');\n * loadedModel.predict(tf.ones([1, 3])).print();\n * ```\n *\n * Example 3. Load a model from user-selected files from HTML\n * [file input\n * elements](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input/file).\n *\n * ```js\n * // Note: this code snippet will not work without the HTML elements in the\n * //   page\n * const jsonUpload = document.getElementById('json-upload');\n * const weightsUpload = document.getElementById('weights-upload');\n *\n * const model = await tf.loadLayersModel(\n *     tf.io.browserFiles([jsonUpload.files[0], weightsUpload.files[0]]));\n * ```\n *\n * Example 4. Load a model from an HTTP server.\n *\n * ```js\n * const model = await\n *     tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/iris_v1/model.json');\n * model.summary();\n * ```\n *\n * @param pathOrIOHandler Can be either of the two formats\n *   1. A string path to the `ModelAndWeightsConfig` JSON describing\n *      the model in the canonical TensorFlow.js format. This path will be\n *      interpreted as a relative HTTP path, to which `fetch` will be used to\n *      request the model topology and weight manifest JSON.\n *      The content of the JSON file is assumed to be a JSON object with the\n *      following fields and values:\n *      - 'modelTopology': A JSON object that can be either of:\n *        1. a model architecture JSON consistent with the format of the return\n *            value of `keras.Model.to_json()`\n *        2. a full model JSON in the format of `keras.models.save_model()`.\n *      - 'weightsManifest': A TensorFlow.js weights manifest.\n *      See the Python converter function `save_model()` for more details.\n *      It is also assumed that model weights can be accessed from relative\n *      paths described by the `paths` fields in weights manifest.\n *   2. An `tf.io.IOHandler` object that loads model artifacts with its `load`\n *      method.\n * @param options Optional configuration arguments for the model loading,\n *   including:\n *   - `strict`: Require that the provided weights exactly match those required\n *     by the layers.  Default true.  Passing false means that both extra\n *     weights and missing weights will be silently ignored.\n *   - `onProgress`: A progress callback of the form:\n *     `(fraction: number) => void`. This callback can be used to monitor the\n *     model-loading process.\n * @returns A `Promise` of `tf.LayersModel`, with the topology and weights\n *     loaded.\n */\nexport async function loadLayersModelInternal(pathOrIOHandler, options) {\n    if (options == null) {\n        options = {};\n    }\n    if (typeof pathOrIOHandler === 'string') {\n        const handlers = io.getLoadHandlers(pathOrIOHandler, options);\n        if (handlers.length === 0) {\n            // For backward compatibility: if no load handler can be found,\n            // assume it is a relative http path.\n            // TODO(cais): Reformat the args into a single `LoadOptions` once the core\n            // is refactored.\n            handlers.push(io.browserHTTPRequest(pathOrIOHandler, options));\n        }\n        else if (handlers.length > 1) {\n            throw new ValueError(`Found more than one (${handlers.length}) load handlers for ` +\n                `URL '${pathOrIOHandler}'`);\n        }\n        pathOrIOHandler = handlers[0];\n    }\n    return loadLayersModelFromIOHandler(pathOrIOHandler, undefined, options);\n}\n/**\n * Load a model and optionally its weights, using an IOHandler object.\n *\n * @param handler The instance of `IOHandler` to be used during the model\n *   loading.\n * @param customObjects Any optional custom objects to be used during model\n *   loading.\n * @param strict Whether the weight loading will be done in strict mode.\n *   Default: `true`.\n */\nexport async function loadLayersModelFromIOHandler(handler, customObjects, options) {\n    if (options == null) {\n        options = {};\n    }\n    if (handler.load == null) {\n        throw new ValueError('Cannot proceed with model loading because the IOHandler provided ' +\n            'does not have the `load` method implemented.');\n    }\n    const artifacts = await handler.load();\n    let modelTopology = artifacts.modelTopology;\n    if (modelTopology['model_config'] != null) {\n        modelTopology = modelTopology['model_config'];\n    }\n    const strict = options.strict == null ? true : options.strict;\n    // If weights are provided and the weight-loading mode is strict, use\n    // fast weight initialization. This skips costly initializers such as\n    // 'orthogonal' and saves unnecessary computation in cases where\n    // the initialized weight values will immediately be overwritten by\n    // loaded weight values.\n    const fastWeightInit = artifacts.weightData != null && artifacts.weightSpecs != null && strict;\n    const model = deserialize(convertPythonicToTs(modelTopology), customObjects, fastWeightInit);\n    const trainingConfig = artifacts.trainingConfig;\n    if (trainingConfig != null) {\n        model.loadTrainingConfig(trainingConfig);\n    }\n    if (artifacts.userDefinedMetadata != null) {\n        model.setUserDefinedMetadata(artifacts.userDefinedMetadata);\n    }\n    // If weightData is present, load the weights into the model.\n    if (artifacts.weightData != null) {\n        // Loading weights requires weightSpecs.\n        if (artifacts.weightSpecs == null) {\n            throw new ValueError('LayersModel artifacts contains weight data, but not weight specs. ' +\n                'Therefore loading of weights cannot proceed.');\n        }\n        const { modelWeights, optimizerWeights } = decodeModelAndOptimizerWeights(artifacts.weightData, artifacts.weightSpecs);\n        model.loadWeights(modelWeights, strict);\n        if (model.optimizer != null && optimizerWeights.length > 0) {\n            await model.optimizer.setWeights(optimizerWeights);\n        }\n        // Dispose temporary weight values.\n        dispose(modelWeights);\n        dispose(optimizerWeights.map(w => w.tensor));\n    }\n    return model;\n}\nfunction decodeModelAndOptimizerWeights(buffer, specs) {\n    const name2Tensor = io.decodeWeights(buffer, specs);\n    const modelWeights = {};\n    const optimizerWeights = [];\n    specs.forEach(spec => {\n        if (spec.group === 'optimizer') {\n            optimizerWeights.push({ name: spec.name, tensor: name2Tensor[spec.name] });\n        }\n        else {\n            modelWeights[spec.name] = name2Tensor[spec.name];\n        }\n    });\n    return { modelWeights, optimizerWeights };\n}\n/**\n * A model with a stack of layers, feeding linearly from one to the next.\n *\n * `tf.sequential` is a factory function that creates an instance of\n * `tf.Sequential`.\n *\n * ```js\n *  // Define a model for linear regression.\n *  const model = tf.sequential();\n *  model.add(tf.layers.dense({units: 1, inputShape: [1]}));\n *\n *  // Prepare the model for training: Specify the loss and the optimizer.\n *  model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n *\n *  // Generate some synthetic data for training.\n *  const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);\n *  const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);\n *\n *  // Train the model using the data then do inference on a data point the\n *  // model hasn't seen:\n *  await model.fit(xs, ys);\n *  model.predict(tf.tensor2d([5], [1, 1])).print();\n * ```\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class Sequential extends LayersModel {\n    constructor(args) {\n        super({ inputs: [], outputs: [] });\n        args = args || {};\n        this.trainable = true;\n        this.built = false;\n        // Set model name.\n        this.name = (args.name != null) ? args.name : getUid('sequential_');\n        // Add to the model any layers passed to the constructor.\n        if (args.layers != null) {\n            for (const layer of args.layers) {\n                this.add(layer);\n            }\n        }\n    }\n    // Helper function to Sequential.add  Throws if the new output shape will be\n    // invalid.\n    checkShape(layer) {\n        const shape = layer.inboundNodes[0].outputTensors[0].shape;\n        if (shape.some(x => x < 0)) {\n            throw new ValueError('Negative dimension size caused by adding layer ' +\n                `${layer.name} with input shape [` +\n                `${layer.inboundNodes[0].inputTensors[0].shape}]`);\n        }\n    }\n    /**\n     * Adds a layer instance on top of the layer stack.\n     *\n     * ```js\n     *  const model = tf.sequential();\n     *  model.add(tf.layers.dense({units: 8, inputShape: [1]}));\n     *  model.add(tf.layers.dense({units: 4, activation: 'relu6'}));\n     *  model.add(tf.layers.dense({units: 1, activation: 'relu6'}));\n     *  // Note that the untrained model is random at this point.\n     *  model.predict(tf.randomNormal([10, 1])).print();\n     * ```\n     * @param layer Layer instance.\n     *\n     * @exception ValueError In case the `layer` argument does not know its\n     * input shape.\n     * @exception ValueError In case the `layer` argument has multiple output\n     *   tensors, or is already connected somewhere else (forbidden in\n     *   `Sequential` models).\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    add(layer) {\n        const isLayerModelInstance = layer instanceof Sequential || layer instanceof LayersModel;\n        let modelLayer;\n        if (isLayerModelInstance) {\n            modelLayer = layer;\n            if (modelLayer.outputs.length !== 1) {\n                throw new ValueError('All layers in a Sequential model ' +\n                    'should have a single output tensor. ' +\n                    'For multi-output layers, ' +\n                    'use the functional API.');\n            }\n            if (modelLayer.inputs.length !== 1) {\n                throw new ValueError('All layers in a Sequential model ' +\n                    'should have a single input tensor. ' +\n                    'For multi-input layers, ' +\n                    'use the functional API.');\n            }\n        }\n        if (this.outputs.length === 0) {\n            // first layer in model: check that it is an input layer\n            if (layer.inboundNodes.length === 0) {\n                // create an input layer\n                if (layer.batchInputShape == null) {\n                    throw new ValueError('The first layer in a Sequential model must ' +\n                        'get an `inputShape` or `batchInputShape` argument.');\n                }\n                // Instantiate the input layer.\n                const x = Input({\n                    batchShape: layer.batchInputShape,\n                    dtype: layer.dtype,\n                    name: layer.name + '_input'\n                });\n                // This will build the current layer and create the node connecting\n                // the current layer to the input layer we just created.\n                layer.apply(x);\n            }\n            if (isLayerModelInstance) {\n                this.outputs = modelLayer.outputs;\n                this.inputs = modelLayer.inputs;\n            }\n            else {\n                if (layer.inboundNodes.length !== 1) {\n                    throw new ValueError('A layer added to a Sequential model must not already be ' +\n                        `connected somewhere else. LayersModel received layer ${layer.name} ` +\n                        `which has ${layer.inboundNodes.length} pre-existing inbound ` +\n                        'connections.');\n                }\n                if (layer.inboundNodes[0].outputTensors.length !== 1) {\n                    throw new ValueError('All layers in a Sequential model ' +\n                        'should have a single output tensor. ' +\n                        'For multi-output layers, ' +\n                        'use the functional API.');\n                }\n                this.checkShape(layer);\n                this.outputs = [layer.inboundNodes[0].outputTensors[0]];\n                this.inputs = getSourceInputs(this.outputs[0]);\n            }\n            this.inboundNodes = [];\n            // We create an input node, which we will keep updated\n            // as we add more layers.\n            // (This call has side effects.)\n            // tslint:disable-next-line:no-unused-expression\n            new Node({\n                outboundLayer: this,\n                inboundLayers: [],\n                nodeIndices: [],\n                tensorIndices: [],\n                inputTensors: this.inputs,\n                outputTensors: this.outputs,\n                // no model-level masking for now\n                inputMasks: generic_utils.pyListRepeat(null, this.inputs.length),\n                outputMasks: [null],\n                inputShapes: this.inputs.map(x => x.shape),\n                outputShapes: this.outputs[0].shape\n            });\n        }\n        else {\n            const outputTensor = layer.apply(this.outputs[0]);\n            if (Array.isArray(outputTensor)) {\n                throw new TypeError('All layers in a Sequential model ' +\n                    'should have a single output tensor. ' +\n                    'For multi-output layers, ' +\n                    'use the functional API.');\n            }\n            this.checkShape(layer);\n            this.outputs = [outputTensor];\n            // update self.inbound_nodes\n            this.inboundNodes[0].outputTensors = this.outputs;\n            this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n        }\n        this.layers.push(layer);\n        this.built = false;\n    }\n    /**\n     * Removes the last layer in the model.\n     *\n     * @exception TypeError if there are no layers in the model.\n     */\n    pop() {\n        if (this.layers.length === 0) {\n            throw new TypeError('There are no layers in the model.');\n        }\n        this.layers.pop();\n        if (this.layers.length === 0) {\n            this.outputs = [];\n            this.inboundNodes = [];\n            this.outboundNodes = [];\n        }\n        else {\n            const lastLayerIndex = this.layers.length - 1;\n            this.layers[lastLayerIndex].outboundNodes = [];\n            this.outputs = [this.layers[lastLayerIndex].output];\n            // update self.inbound_nodes\n            this.inboundNodes[0].outputTensors = this.outputs;\n            this.inboundNodes[0].outputShapes = [this.outputs[0].shape];\n        }\n    }\n    call(inputs, kwargs) {\n        if (this.model == null) {\n            this.build();\n        }\n        return this.model.call(inputs, kwargs);\n    }\n    build(inputShape) {\n        // Call `getExactlyOneShape` without using its return value,\n        // to verify that exactly one input shape is provided.\n        getExactlyOneShape(inputShape);\n        if (this.inputs.length === 0 || this.outputs.length === 0) {\n            throw new TypeError('Sequential model cannot be built: model is empty.' +\n                ' Add some layers first.');\n        }\n        // actually create the model\n        this.model = new LayersModel({\n            inputs: this.inputs,\n            outputs: this.outputs[0],\n            name: this.name + '_model'\n        });\n        this.model.trainable = this.trainable;\n        // mirror model attributes\n        this.supportsMasking = this.model.supportsMasking;\n        // TODO(michaelterry): Add caches\n        this.inputLayers = this.model.inputLayers;\n        this.inputLayersNodeIndices = this.model.inputLayersNodeIndices;\n        this.inputLayersTensorIndices = this.model.inputLayersTensorIndices;\n        this.outputLayers = this.model.outputLayers;\n        this.outputLayersNodeIndices = this.model.outputLayersNodeIndices;\n        this.outputLayersTensorIndices = this.model.outputLayersTensorIndices;\n        this.nodesByDepth = this.model.nodesByDepth;\n        this.containerNodes = this.model.containerNodes;\n        this.outputNames = this.model.outputNames;\n        this.inputNames = this.model.inputNames;\n        // TODO(michaelterry): Add feedInputNames, feedInputs, if needed.\n        // TODO(michaelterry): Add callbackModel if needed.\n        this.built = true;\n    }\n    countParams() {\n        if (!this.built) {\n            this.build();\n        }\n        return super.countParams();\n    }\n    /**\n     * Print a text summary of the Sequential model's layers.\n     *\n     * The summary includes\n     * - Name and type of all layers that comprise the model.\n     * - Output shape(s) of the layers\n     * - Number of weight parameters of each layer\n     * - The total number of trainable and non-trainable parameters of the\n     * model.\n     *\n     * ```js\n     * const model = tf.sequential();\n     * model.add(\n     *     tf.layers.dense({units: 100, inputShape: [10], activation: 'relu'}));\n     * model.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));\n     *\n     * model.summary();\n     * ```\n     *\n     * @param lineLength Custom line length, in number of characters.\n     * @param positions Custom widths of each of the columns, as either\n     *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\n     *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\n     *   right-most (i.e., ending) position of a column.\n     * @param printFn Custom print function. Can be used to replace the default\n     *   `console.log`. For example, you can use `x => {}` to mute the printed\n     *   messages in the console.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    summary(lineLength, positions, printFn = console.log) {\n        if (!this.built) {\n            this.build();\n        }\n        super.summary(lineLength, positions, printFn);\n    }\n    /**\n     * Sets the weights of the model.\n     *\n     * @param weights Should be a list of Tensors with shapes and types matching\n     *   the output of `model.getWeights()`.\n     */\n    setWeights(weights) {\n        if (this.model == null) {\n            this.build();\n        }\n        this.model.setWeights(weights);\n    }\n    /**\n     * Returns the loss value & metrics values for the model in test mode.\n     *\n     * Loss and metrics are specified during `compile()`, which needs to happen\n     * before calls to `evaluate()`.\n     *\n     * Computation is done in batches.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * const result = model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]), {\n     *   batchSize: 4,\n     * });\n     * result.print();\n     * ```\n     *\n     * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple inputs.\n     * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple outputs.\n     * @param args A `ModelEvaluateConfig`, containing optional fields.\n     *\n     * @return `Scalar` test loss (if the model has a single output and no\n     *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\n     *   and/or metrics). The attribute `model.metricsNames`\n     *   will give you the display labels for the scalar outputs.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    evaluate(x, y, args = {}) {\n        if (!this.built) {\n            throw new RuntimeError('The model needs to be compiled before being used.');\n        }\n        return this.model.evaluate(x, y, args);\n    }\n    // TODO(cais): Add code snippet below once real dataset objects are\n    //   available.\n    /**\n     * Evaluate model using a dataset object.\n     *\n     * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for evaluation. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs. Of the two items in the array, the\n     *   first is the input feature(s) and the second is the output target(s).\n     * @param args A configuration object for the dataset-based evaluation.\n     * @returns Loss and metric values as an Array of `Scalar` objects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async evaluateDataset(dataset, args) {\n        if (!this.built) {\n            throw new RuntimeError('The model needs to be compiled before being used.');\n        }\n        return this.model.evaluateDataset(dataset, args);\n    }\n    /**\n     * Generates output predictions for the input samples.\n     *\n     * Computation is done in batches.\n     *\n     * Note: the \"step\" mode of predict() is currently not supported.\n     *   This is because the TensorFow.js core backend is imperative only.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predict(tf.ones([2, 10])).print();\n     * ```\n     *\n     * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\n     *   the model has multiple inputs.\n     * @param conifg A `ModelPredictConfig` object containing optional fields.\n     *\n     * @return `tf.Tensor`(s) of predictions.\n     *\n     * @exception ValueError In case of mismatch between the provided input data\n     *   and the model's expectations, or in case a stateful model receives a\n     *   number of samples that is not a multiple of the batch size.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    predict(x, args = {}) {\n        if (this.model == null) {\n            this.build();\n        }\n        return this.model.predict(x, args);\n    }\n    /**\n     * Returns predictions for a single batch of samples.\n     *\n     * @param x: Input samples, as a Tensor, or list of Tensors (if the model\n     *   has multiple inputs).\n     * @return Tensor(s) of predictions\n     */\n    predictOnBatch(x) {\n        if (this.model == null) {\n            this.build();\n        }\n        return this.model.predictOnBatch(x);\n    }\n    /**\n     * See `LayersModel.compile`.\n     *\n     * @param args\n     */\n    compile(args) {\n        this.build();\n        this.model.compile(args);\n        this.optimizer_ = this.model.optimizer;\n        // tslint:disable-next-line:no-any\n        this.isOptimizerOwned = this.model.isOptimizerOwned;\n        this.loss = this.model.loss;\n        this.metrics = this.model.metrics;\n        // TODO(cais): Add this.lossWeights, this.sampleWeightMode,\n        //   this.weightedMetrics, this.targets.\n        this.metricsTensors = this.model.metricsTensors;\n        this.metricsNames = this.model.metricsNames;\n        // TODO(cais): Add sampleWeights.\n    }\n    get optimizer() {\n        return this.model == null ? undefined : this.model.optimizer;\n    }\n    set optimizer(optimizer) {\n        this.model.optimizer = optimizer;\n    }\n    /**\n     * Trains the model for a fixed number of epochs (iterations on a dataset).\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * const history = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\n     *   batchSize: 4,\n     *   epochs: 3\n     * });\n     * console.log(history.history.loss[0]);\n     * ```\n     *\n     * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\n     * model has multiple inputs. If all inputs in the model are named, you can\n     * also pass a dictionary mapping input names to `tf.Tensor`s.\n     * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\n     * the model has multiple outputs. If all outputs in the model are named, you\n     *  can also pass a dictionary mapping output names to `tf.Tensor`s.\n     * @param args  A `ModelFitConfig`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @exception ValueError In case of mismatch between the provided input data\n     *   and what the model expects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async fit(x, y, args = {}) {\n        if (!this.built) {\n            throw new RuntimeError('The model needs to be compiled before ' +\n                'being used.');\n        }\n        return this.model.fit(x, y, args);\n    }\n    /**\n     * Trains the model using a dataset object.\n     *\n     * ```js\n     * const xArray = [\n     *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\n     *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\n     *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\n     *   [1, 1, 1, 1, 1, 1, 1, 1, 1],\n     * ];\n     * const yArray = [1, 1, 1, 1];\n     * // Create a dataset from the JavaScript array.\n     * const xDataset = tf.data.array(xArray);\n     * const yDataset = tf.data.array(yArray);\n     * // Zip combines the `x` and `y` Datasets into a single Dataset, the\n     * // iterator of which will return an object containing of two tensors,\n     * // corresponding to `x` and `y`.  The call to `batch(4)` will bundle\n     * // four such samples into a single object, with the same keys now pointing\n     * // to tensors that hold 4 examples, organized along the batch dimension.\n     * // The call to `shuffle(4)` causes each iteration through the dataset to\n     * // happen in a different order.  The size of the shuffle window is 4.\n     * const xyDataset = tf.data.zip({xs: xDataset, ys: yDataset})\n     *     .batch(4)\n     *     .shuffle(4);\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [9]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * const history = await model.fitDataset(xyDataset, {\n     *   epochs: 4,\n     *   callbacks: {onEpochEnd: (epoch, logs) => console.log(logs.loss)}\n     * });\n     * ```\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected to\n     *   generate a dataset iterator object, the `next()` method of which is\n     *   expected to produce data batches for evaluation. The return value of the\n     *   `next()` call ought to contain a boolean `done` field and a `value`\n     *   field.\n     *\n     *   The `value` field is expected to be an object of with fields\n     *   `xs` and `ys`, which point to the feature tensor and the target tensor,\n     *   respectively. This case is for models with exactly one input and one\n     *   output (e.g.. a sequential model). For example:\n     *   ```js\n     *   {value: {xs: xsTensor, ys: ysTensor}, done: false}\n     *   ```\n     *\n     *   If the model has multiple inputs, the `xs` field of `value` should\n     *   be an object mapping input names to their respective feature tensors.\n     *   For example:\n     *   ```js\n     *   {\n     *     value: {\n     *       xs: {\n     *         input_1: xsTensor1,\n     *         input_2: xsTensor2\n     *       },\n     *       ys: ysTensor\n     *     },\n     *     done: false\n     *   }\n     *   ```\n     *   If the model has multiple outputs, the `ys` field of `value` should\n     *   be an object mapping output names to their respective target tensors.\n     *   For example:\n     *   ```js\n     *   {\n     *     value: {\n     *       xs: xsTensor,\n     *       ys: {\n     *         output_1: ysTensor1,\n     *         output_2: ysTensor2\n     *       },\n     *     },\n     *     done: false\n     *   }\n     *   ```\n     * @param args A `ModelFitDatasetArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n     */\n    async fitDataset(dataset, args) {\n        if (!this.built) {\n            throw new RuntimeError('The model needs to be compiled before ' +\n                'being used.');\n        }\n        return this.model.fitDataset(dataset, args);\n    }\n    /**\n     * Runs a single gradient update on a single batch of data.\n     *\n     * This method differs from `fit()` and `fitDataset()` in the following\n     * regards:\n     *   - It operates on exactly one batch of data.\n     *   - It returns only the loss and matric values, instead of\n     *     returning the batch-by-batch loss and metric values.\n     *   - It doesn't support fine-grained options such as verbosity and\n     *     callbacks.\n     *\n     * @param x Input data. It could be one of the following:\n     *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\n     *     multiple inputs).\n     *   - An Object mapping input names to corresponding `tf.Tensor` (if the\n     *     model has named inputs).\n     * @param y Target darta. It could be either a `tf.Tensor` a multiple\n     *   `tf.Tensor`s. It should be consistent with `x`.\n     * @returns Training loss or losses (in case the model has\n     *   multiple outputs), along with metrics (if any), as numbers.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async trainOnBatch(x, y) {\n        return this.model.trainOnBatch(x, y);\n    }\n    /* See parent class for JsDoc */\n    /** @nocollapse */\n    static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {\n        let configArray;\n        let extraModelConfig = {};\n        if (config instanceof Array) {\n            if (!(config[0].className != null) ||\n                config[0]['className'] === 'Merge') {\n                throw new ValueError('Legacy serialization format not supported yet.');\n            }\n            configArray = config;\n        }\n        else {\n            util.assert(config['layers'] != null, () => `When the config data for a Sequential model is not an Array, ` +\n                `it must be an Object that contains the 'layers' field.`);\n            configArray = config['layers'];\n            delete config['layers'];\n            extraModelConfig = config;\n        }\n        const model = new cls(extraModelConfig);\n        if (!(model instanceof Sequential)) {\n            throw new NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${model}`);\n        }\n        for (const conf of configArray) {\n            const customObjects = undefined;\n            const layer = deserialize(conf, customObjects, fastWeightInit);\n            if (fastWeightInit) {\n                layer.setFastWeightInitDuringBuild(true);\n            }\n            model.add(layer);\n        }\n        return model;\n    }\n    /**\n     * Setter used for force stopping of LayersModel.fit() (i.e., training).\n     *\n     * Example:\n     *\n     * ```js\n     * const model = tf.sequential();\n     * model.add(tf.layers.dense({units: 1, inputShape: [10]}));\n     * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n     * const xs = tf.ones([8, 10]);\n     * const ys = tf.zeros([8, 1]);\n     *\n     * const history = await model.fit(xs, ys, {\n     *   epochs: 10,\n     *   callbacks: {\n     *     onEpochEnd: async (epoch, logs) => {\n     *       if (epoch === 2) {\n     *         model.stopTraining = true;\n     *       }\n     *     }\n     *   }\n     * });\n     *\n     * // There should be only 3 values in the loss array, instead of 10 values,\n     * // due to the stopping after 3 epochs.\n     * console.log(history.history.loss);\n     * ```\n     */\n    set stopTraining(stop) {\n        // TODO(cais): When refactoring to remove the composition pattern happens,\n        // remove this method overriding.\n        if (this.model == null) {\n            throw new ValueError('Cannot set the stopTraining property of a sequential model before ' +\n                'it is compiled.');\n        }\n        this.model.stopTraining = stop;\n    }\n    get stopTraining() {\n        if (this.model == null) {\n            throw new ValueError('Cannot get the stopTraining property of a sequential model before ' +\n                'it is compiled.');\n        }\n        return this.model.stopTraining;\n    }\n    // TODO(cais): Override get trainableWeights() here\n    // tslint:disable-next-line:no-any\n    getConfig() {\n        // NOTE(cais): We override the return type of getConfig() to `any` here,\n        //   because the `Sequential` class is a special case among `Container`\n        //   subtypes in that its getConfig() method returns an Array (not a\n        //   dict).\n        const layers = [];\n        for (const layer of this.layers) {\n            const dict = {};\n            dict['className'] = layer.getClassName();\n            dict['config'] = layer.getConfig();\n            layers.push(dict);\n        }\n        return { name: this.name, layers };\n    }\n}\n/** @nocollapse */\nSequential.className = 'Sequential';\nserialization.registerClass(Sequential);\n//# sourceMappingURL=models.js.map","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('../cjs/use-sync-external-store-shim.production.js');\n} else {\n  module.exports = require('../cjs/use-sync-external-store-shim.development.js');\n}\n","/**\n * @license React\n * use-sync-external-store-shim/with-selector.production.js\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\"use strict\";\nvar React = require(\"react\"),\n  shim = require(\"use-sync-external-store/shim\");\nfunction is(x, y) {\n  return (x === y && (0 !== x || 1 / x === 1 / y)) || (x !== x && y !== y);\n}\nvar objectIs = \"function\" === typeof Object.is ? Object.is : is,\n  useSyncExternalStore = shim.useSyncExternalStore,\n  useRef = React.useRef,\n  useEffect = React.useEffect,\n  useMemo = React.useMemo,\n  useDebugValue = React.useDebugValue;\nexports.useSyncExternalStoreWithSelector = function (\n  subscribe,\n  getSnapshot,\n  getServerSnapshot,\n  selector,\n  isEqual\n) {\n  var instRef = useRef(null);\n  if (null === instRef.current) {\n    var inst = { hasValue: !1, value: null };\n    instRef.current = inst;\n  } else inst = instRef.current;\n  instRef = useMemo(\n    function () {\n      function memoizedSelector(nextSnapshot) {\n        if (!hasMemo) {\n          hasMemo = !0;\n          memoizedSnapshot = nextSnapshot;\n          nextSnapshot = selector(nextSnapshot);\n          if (void 0 !== isEqual && inst.hasValue) {\n            var currentSelection = inst.value;\n            if (isEqual(currentSelection, nextSnapshot))\n              return (memoizedSelection = currentSelection);\n          }\n          return (memoizedSelection = nextSnapshot);\n        }\n        currentSelection = memoizedSelection;\n        if (objectIs(memoizedSnapshot, nextSnapshot)) return currentSelection;\n        var nextSelection = selector(nextSnapshot);\n        if (void 0 !== isEqual && isEqual(currentSelection, nextSelection))\n          return (memoizedSnapshot = nextSnapshot), currentSelection;\n        memoizedSnapshot = nextSnapshot;\n        return (memoizedSelection = nextSelection);\n      }\n      var hasMemo = !1,\n        memoizedSnapshot,\n        memoizedSelection,\n        maybeGetServerSnapshot =\n          void 0 === getServerSnapshot ? null : getServerSnapshot;\n      return [\n        function () {\n          return memoizedSelector(getSnapshot());\n        },\n        null === maybeGetServerSnapshot\n          ? void 0\n          : function () {\n              return memoizedSelector(maybeGetServerSnapshot());\n            }\n      ];\n    },\n    [getSnapshot, getServerSnapshot, selector, isEqual]\n  );\n  var value = useSyncExternalStore(subscribe, instRef[0], instRef[1]);\n  useEffect(\n    function () {\n      inst.hasValue = !0;\n      inst.value = value;\n    },\n    [value]\n  );\n  useDebugValue(value);\n  return value;\n};\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Optimizers.\n */\nimport { train } from '@tensorflow/tfjs-core';\nimport { epsilon } from './backend/common';\nimport { ValueError } from './errors';\n// Add (de)serialize()\n// Porting note: This diverges from the PyKeras implementation and may need to\n// change based on (de)serialization requirements.\nexport function getOptimizer(identifier) {\n    const optimizerMap = {\n        'Adagrad': () => train.adagrad(0.01),\n        'Adadelta': () => train.adadelta(1, 0.95, epsilon()),\n        'Adam': () => train.adam(0.001, 0.9, 0.999, epsilon()),\n        'Adamax': () => train.adamax(0.002, 0.9, 0.999, epsilon(), 0),\n        'RMSProp': () => train.rmsprop(0.001, 0.9, 0, epsilon()),\n        'SGD': () => train.sgd(0.01)\n    };\n    optimizerMap['adagrad'] = optimizerMap['Adagrad'];\n    optimizerMap['adadelta'] = optimizerMap['Adadelta'];\n    optimizerMap['adam'] = optimizerMap['Adam'];\n    optimizerMap['adamax'] = optimizerMap['Adamax'];\n    optimizerMap['rmsprop'] = optimizerMap['RMSProp'];\n    optimizerMap['sgd'] = optimizerMap['SGD'];\n    if (identifier in optimizerMap) {\n        return optimizerMap[identifier]();\n    }\n    throw new ValueError(`Unknown Optimizer ${identifier}`);\n}\n//# sourceMappingURL=optimizers.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport '@tensorflow/tfjs-core/dist/register_all_gradients';\n// tslint:disable-next-line: no-imports-from-dist\nimport '@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops';\nexport * from '@tensorflow/tfjs-core';\nexport * from '@tensorflow/tfjs-layers';\nexport * from '@tensorflow/tfjs-converter';\n// Export data api as tf.data\nimport * as data from '@tensorflow/tfjs-data';\nexport { data };\n// Import and register backends.\nimport '@tensorflow/tfjs-backend-cpu';\nimport '@tensorflow/tfjs-backend-webgl';\n// Import versions of all sub-packages.\nimport { version_core } from '@tensorflow/tfjs-core';\nimport { version_cpu } from '@tensorflow/tfjs-backend-cpu';\nimport { version_webgl } from '@tensorflow/tfjs-backend-webgl';\nimport { version_data } from '@tensorflow/tfjs-data';\nimport { version_layers } from '@tensorflow/tfjs-layers';\nimport { version_converter } from '@tensorflow/tfjs-converter';\nimport { version as version_union } from './version';\nexport const version = {\n    'tfjs-core': version_core,\n    'tfjs-backend-cpu': version_cpu,\n    'tfjs-backend-webgl': version_webgl,\n    'tfjs-data': version_data,\n    'tfjs-layers': version_layers,\n    'tfjs-converter': version_converter,\n    'tfjs': version_union\n};\n//# sourceMappingURL=index.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Built-in metrics.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { tidy } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { NotImplementedError, ValueError } from './errors';\nimport { categoricalCrossentropy as categoricalCrossentropyLoss, cosineProximity, meanAbsoluteError, meanAbsolutePercentageError, meanSquaredError, sparseCategoricalCrossentropy as sparseCategoricalCrossentropyLoss } from './losses';\nimport { binaryCrossentropy as lossBinaryCrossentropy } from './losses';\nimport { lossesMap } from './losses';\nimport * as util from './utils/generic_utils';\nexport function binaryAccuracy(yTrue, yPred) {\n    return tidy(() => {\n        const threshold = tfc.mul(.5, tfc.onesLike(yPred));\n        const yPredThresholded = K.cast(tfc.greater(yPred, threshold), yTrue.dtype);\n        return tfc.mean(tfc.equal(yTrue, yPredThresholded), -1);\n    });\n}\nexport function categoricalAccuracy(yTrue, yPred) {\n    return tidy(() => K.cast(tfc.equal(tfc.argMax(yTrue, -1), tfc.argMax(yPred, -1)), 'float32'));\n}\nfunction truePositives(yTrue, yPred) {\n    return tidy(() => {\n        return tfc.logicalAnd(yTrue.equal(1), yPred.equal(1)).sum().cast('float32');\n    });\n}\nfunction falseNegatives(yTrue, yPred) {\n    return tidy(() => {\n        return tfc.logicalAnd(yTrue.equal(1), yPred.equal(0)).sum().cast('float32');\n    });\n}\nfunction falsePositives(yTrue, yPred) {\n    return tidy(() => {\n        return tfc.logicalAnd(yTrue.equal(0), yPred.equal(1)).sum().cast('float32');\n    });\n}\nexport function precision(yTrue, yPred) {\n    return tidy(() => {\n        const tp = truePositives(yTrue, yPred);\n        const fp = falsePositives(yTrue, yPred);\n        const denominator = tp.add(fp);\n        return tfc.where(tfc.greater(denominator, 0), tp.div(denominator), 0)\n            .cast('float32');\n    });\n}\nexport function recall(yTrue, yPred) {\n    return tidy(() => {\n        const tp = truePositives(yTrue, yPred);\n        const fn = falseNegatives(yTrue, yPred);\n        const denominator = tp.add(fn);\n        return tfc.where(tfc.greater(denominator, 0), tp.div(denominator), 0)\n            .cast('float32');\n    });\n}\nexport function binaryCrossentropy(yTrue, yPred) {\n    return lossBinaryCrossentropy(yTrue, yPred);\n}\nexport function sparseCategoricalAccuracy(yTrue, yPred) {\n    if (yTrue.rank === yPred.rank) {\n        yTrue = yTrue.squeeze([yTrue.rank - 1]);\n    }\n    yPred = yPred.argMax(-1);\n    if (yPred.dtype !== yTrue.dtype) {\n        yPred = yPred.asType(yTrue.dtype);\n    }\n    return tfc.equal(yTrue, yPred).asType('float32');\n}\nexport function topKCategoricalAccuracy(yTrue, yPred) {\n    throw new NotImplementedError();\n}\nexport function sparseTopKCategoricalAccuracy(yTrue, yPred) {\n    throw new NotImplementedError();\n}\n// Aliases.\nexport const mse = meanSquaredError;\nexport const MSE = meanSquaredError;\nexport const mae = meanAbsoluteError;\nexport const MAE = meanAbsoluteError;\nexport const mape = meanAbsolutePercentageError;\nexport const MAPE = meanAbsolutePercentageError;\nexport const categoricalCrossentropy = categoricalCrossentropyLoss;\nexport const cosine = cosineProximity;\nexport const sparseCategoricalCrossentropy = sparseCategoricalCrossentropyLoss;\n// TODO(cais, nielsene): Add serialize().\nexport const metricsMap = {\n    binaryAccuracy,\n    categoricalAccuracy,\n    precision,\n    categoricalCrossentropy,\n    sparseCategoricalCrossentropy,\n    mse,\n    MSE,\n    mae,\n    MAE,\n    mape,\n    MAPE,\n    cosine\n};\nexport function get(identifier) {\n    if (typeof identifier === 'string' && identifier in metricsMap) {\n        return metricsMap[identifier];\n    }\n    else if (typeof identifier !== 'string' && identifier != null) {\n        return identifier;\n    }\n    else {\n        throw new ValueError(`Unknown metric ${identifier}`);\n    }\n}\n/**\n * Get the shortcut function name.\n *\n * If the fn name is a string,\n *   directly return the string name.\n * If the function is included in metricsMap or lossesMap,\n *   return key of the map.\n *   - If the function relative to multiple keys,\n *     return the first found key as the function name.\n *   - If the function exists in both lossesMap and metricsMap,\n *     search lossesMap first.\n * If the function is not included in metricsMap or lossesMap,\n *   return the function name.\n *\n * @param fn loss function, metric function, or short cut name.\n * @returns Loss or Metric name in string.\n */\nexport function getLossOrMetricName(fn) {\n    util.assert(fn !== null, `Unknown LossOrMetricFn ${fn}`);\n    if (typeof fn === 'string') {\n        return fn;\n    }\n    else {\n        let fnName;\n        for (const key of Object.keys(lossesMap)) {\n            if (lossesMap[key] === fn) {\n                fnName = key;\n                break;\n            }\n        }\n        if (fnName !== undefined) {\n            return fnName;\n        }\n        for (const key of Object.keys(metricsMap)) {\n            if (metricsMap[key] === fn) {\n                fnName = key;\n                break;\n            }\n        }\n        if (fnName !== undefined) {\n            return fnName;\n        }\n        return fn.name;\n    }\n}\n//# sourceMappingURL=metrics.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original source: utils/generic_utils.py */\nimport { util } from '@tensorflow/tfjs-core';\nimport { AssertionError, ValueError } from '../errors';\n// tslint:enable\n/**\n * If `value` is an Array, equivalent to Python's `value * numValues`.\n * If `value` is not an Array, equivalent to Python's `[value] * numValues`\n */\n// tslint:disable-next-line:no-any\nexport function pyListRepeat(value, numValues) {\n    if (Array.isArray(value)) {\n        // tslint:disable-next-line:no-any\n        let newArray = [];\n        for (let i = 0; i < numValues; i++) {\n            newArray = newArray.concat(value);\n        }\n        return newArray;\n    }\n    else {\n        const newArray = new Array(numValues);\n        newArray.fill(value);\n        return newArray;\n    }\n}\nexport function assert(val, message) {\n    if (!val) {\n        throw new AssertionError(message);\n    }\n}\n/**\n * Count the number of elements of the `array` that are equal to `reference`.\n */\nexport function count(array, refernce) {\n    let counter = 0;\n    for (const item of array) {\n        if (item === refernce) {\n            counter++;\n        }\n    }\n    return counter;\n}\n/**\n * If an array is of length 1, just return the first element. Otherwise, return\n * the full array.\n * @param tensors\n */\nexport function singletonOrArray(xs) {\n    if (xs.length === 1) {\n        return xs[0];\n    }\n    return xs;\n}\n/**\n * Normalizes a list/tensor into a list.\n *\n * If a tensor is passed, we return\n * a list of size 1 containing the tensor.\n *\n * @param x target object to be normalized.\n */\n// tslint:disable-next-line:no-any\nexport function toList(x) {\n    if (Array.isArray(x)) {\n        return x;\n    }\n    return [x];\n}\n/**\n * Generate a UID for a list\n */\n// tslint:disable-next-line:no-any\nexport function objectListUid(objs) {\n    const objectList = toList(objs);\n    let retVal = '';\n    for (const obj of objectList) {\n        if (obj.id == null) {\n            throw new ValueError(`Object ${obj} passed to objectListUid without an id`);\n        }\n        if (retVal !== '') {\n            retVal = retVal + ', ';\n        }\n        retVal = `${retVal}${Math.abs(obj.id)}`;\n    }\n    return retVal;\n}\n/**\n * Converts string to snake-case.\n * @param name\n */\nexport function toSnakeCase(name) {\n    const intermediate = name.replace(/(.)([A-Z][a-z0-9]+)/g, '$1_$2');\n    const insecure = intermediate.replace(/([a-z])([A-Z])/g, '$1_$2').toLowerCase();\n    /*\n     If the class is private the name starts with \"_\" which is not secure\n     for creating scopes. We prefix the name with \"private\" in this case.\n     */\n    if (insecure[0] !== '_') {\n        return insecure;\n    }\n    return 'private' + insecure;\n}\nexport function toCamelCase(identifier) {\n    // quick return for empty string or single character strings\n    if (identifier.length <= 1) {\n        return identifier;\n    }\n    // Check for the underscore indicating snake_case\n    if (identifier.indexOf('_') === -1) {\n        return identifier;\n    }\n    return identifier.replace(/[_]+(\\w|$)/g, (m, p1) => p1.toUpperCase());\n}\n// tslint:disable-next-line:no-any\nlet _GLOBAL_CUSTOM_OBJECTS = {};\nexport function serializeKerasObject(instance) {\n    if (instance === null || instance === undefined) {\n        return null;\n    }\n    const dict = {};\n    dict['className'] = instance.getClassName();\n    dict['config'] = instance.getConfig();\n    return dict;\n}\n/**\n * Replace ndarray-style scalar objects in serialization objects with numbers.\n *\n * Background: In some versions of tf.keras, certain scalar values in the HDF5\n * model save file can be serialized as: `{'type': 'ndarray', 'value': num}`,\n * where in `num` is a plain number. This method converts such serialization\n * to a `number`.\n *\n * @param config The keras-format serialization object to be processed\n *   (in place).\n */\nfunction convertNDArrayScalarsInConfig(config) {\n    if (config == null || typeof config !== 'object') {\n        return;\n    }\n    else if (Array.isArray(config)) {\n        config.forEach(configItem => convertNDArrayScalarsInConfig(configItem));\n    }\n    else {\n        const fields = Object.keys(config);\n        for (const field of fields) {\n            const value = config[field];\n            if (value != null && typeof value === 'object') {\n                if (!Array.isArray(value) && value['type'] === 'ndarray' &&\n                    typeof value['value'] === 'number') {\n                    config[field] = value['value'];\n                }\n                else {\n                    convertNDArrayScalarsInConfig(value);\n                }\n            }\n        }\n    }\n}\n/**\n * Deserialize a saved Keras Object\n * @param identifier either a string ID or a saved Keras dictionary\n * @param moduleObjects a list of Python class names to object constructors\n * @param customObjects a list of Python class names to object constructors\n * @param printableModuleName debug text for the object being reconstituted\n * @param fastWeightInit Optional flag to use fast weight initialization\n *   during deserialization. This is applicable to cases in which\n *   the initialization will be immediately overwritten by loaded weight\n *   values. Default: `false`.\n * @returns a TensorFlow.js Layers object\n */\n// tslint:disable:no-any\nexport function deserializeKerasObject(identifier, moduleObjects = {}, customObjects = {}, printableModuleName = 'object', fastWeightInit = false) {\n    // tslint:enable\n    if (typeof identifier === 'string') {\n        const functionName = identifier;\n        let fn;\n        if (functionName in customObjects) {\n            fn = customObjects[functionName];\n        }\n        else if (functionName in _GLOBAL_CUSTOM_OBJECTS) {\n            fn = _GLOBAL_CUSTOM_OBJECTS[functionName];\n        }\n        else {\n            fn = moduleObjects[functionName];\n            if (fn == null) {\n                throw new ValueError(`Unknown ${printableModuleName}: ${identifier}. ` +\n                    `This may be due to one of the following reasons:\\n` +\n                    `1. The ${printableModuleName} is defined in Python, in which ` +\n                    `case it needs to be ported to TensorFlow.js or your JavaScript ` +\n                    `code.\\n` +\n                    `2. The custom ${printableModuleName} is defined in JavaScript, ` +\n                    `but is not registered properly with ` +\n                    `tf.serialization.registerClass().`);\n                // TODO(cais): Add link to tutorial page on custom layers.\n            }\n        }\n        return fn;\n    }\n    else {\n        // In this case we are dealing with a Keras config dictionary.\n        const config = identifier;\n        if (config['className'] == null || config['config'] == null) {\n            throw new ValueError(`${printableModuleName}: Improper config format: ` +\n                `${JSON.stringify(config)}.\\n` +\n                `'className' and 'config' must set.`);\n        }\n        const className = config['className'];\n        let cls, fromConfig;\n        if (className in customObjects) {\n            [cls, fromConfig] = customObjects[className];\n        }\n        else if (className in _GLOBAL_CUSTOM_OBJECTS) {\n            [cls, fromConfig] = _GLOBAL_CUSTOM_OBJECTS['className'];\n        }\n        else if (className in moduleObjects) {\n            [cls, fromConfig] = moduleObjects[className];\n        }\n        if (cls == null) {\n            throw new ValueError(`Unknown ${printableModuleName}: ${className}. ` +\n                `This may be due to one of the following reasons:\\n` +\n                `1. The ${printableModuleName} is defined in Python, in which ` +\n                `case it needs to be ported to TensorFlow.js or your JavaScript ` +\n                `code.\\n` +\n                `2. The custom ${printableModuleName} is defined in JavaScript, ` +\n                `but is not registered properly with ` +\n                `tf.serialization.registerClass().`);\n            // TODO(cais): Add link to tutorial page on custom layers.\n        }\n        if (fromConfig != null) {\n            // Porting notes: Instead of checking to see whether fromConfig accepts\n            // customObjects, we create a customObjects dictionary and tack it on to\n            // config['config'] as config['config'].customObjects. Objects can use it,\n            // if they want.\n            // tslint:disable-next-line:no-any\n            const customObjectsCombined = {};\n            for (const key of Object.keys(_GLOBAL_CUSTOM_OBJECTS)) {\n                customObjectsCombined[key] = _GLOBAL_CUSTOM_OBJECTS[key];\n            }\n            for (const key of Object.keys(customObjects)) {\n                customObjectsCombined[key] = customObjects[key];\n            }\n            // Add the customObjects to config\n            const nestedConfig = config['config'];\n            nestedConfig['customObjects'] = customObjectsCombined;\n            const backupCustomObjects = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);\n            for (const key of Object.keys(customObjects)) {\n                _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];\n            }\n            convertNDArrayScalarsInConfig(config['config']);\n            const returnObj = fromConfig(cls, config['config'], customObjects, fastWeightInit);\n            _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, backupCustomObjects);\n            return returnObj;\n        }\n        else {\n            // Then `cls` may be a function returning a class.\n            // In this case by convention `config` holds\n            // the kwargs of the function.\n            const backupCustomObjects = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);\n            for (const key of Object.keys(customObjects)) {\n                _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];\n            }\n            // In python this is **config['config'], for tfjs-layers we require\n            // classes that use this fall-through construction method to take\n            // a config interface that mimics the expansion of named parameters.\n            const returnObj = new cls(config['config']);\n            _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, backupCustomObjects);\n            return returnObj;\n        }\n    }\n}\n/**\n * Compares two numbers for sorting.\n * @param a\n * @param b\n */\nexport function numberCompare(a, b) {\n    return (a < b) ? -1 : ((a > b) ? 1 : 0);\n}\n/**\n * Comparison of two numbers for reverse sorting.\n * @param a\n * @param b\n */\nexport function reverseNumberCompare(a, b) {\n    return -1 * numberCompare(a, b);\n}\n/**\n * Convert a string into the corresponding DType.\n * @param dtype\n * @returns An instance of DType.\n */\nexport function stringToDType(dtype) {\n    switch (dtype) {\n        case 'float32':\n            return 'float32';\n        default:\n            throw new ValueError(`Invalid dtype: ${dtype}`);\n    }\n}\n/**\n * Test the element-by-element equality of two Arrays of strings.\n * @param xs First array of strings.\n * @param ys Second array of strings.\n * @returns Wether the two arrays are all equal, element by element.\n */\nexport function stringsEqual(xs, ys) {\n    if (xs == null || ys == null) {\n        return xs === ys;\n    }\n    if (xs.length !== ys.length) {\n        return false;\n    }\n    for (let i = 0; i < xs.length; ++i) {\n        if (xs[i] !== ys[i]) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Get the unique elements of an array.\n * @param xs Array.\n * @returns An Array consisting of the unique elements in `xs`.\n */\nexport function unique(xs) {\n    if (xs == null) {\n        return xs;\n    }\n    const out = [];\n    // TODO(cais): Maybe improve performance by sorting.\n    for (const x of xs) {\n        if (out.indexOf(x) === -1) {\n            out.push(x);\n        }\n    }\n    return out;\n}\n/**\n * Determine if an Object is empty (i.e., does not have own properties).\n * @param obj Object\n * @returns Whether the Object is empty.\n * @throws ValueError: If object is `null` or `undefined`.\n */\nexport function isObjectEmpty(obj) {\n    if (obj == null) {\n        throw new ValueError(`Invalid value in obj: ${JSON.stringify(obj)}`);\n    }\n    for (const key in obj) {\n        if (obj.hasOwnProperty(key)) {\n            return false;\n        }\n    }\n    return true;\n}\n/**\n * Helper function used to build type union/enum run-time checkers.\n * @param values The list of allowed values.\n * @param label A string name for the type\n * @param value The value to test.\n * @throws ValueError: If the value is not in values nor `undefined`/`null`.\n */\nexport function checkStringTypeUnionValue(values, label, value) {\n    if (value == null) {\n        return;\n    }\n    if (values.indexOf(value) < 0) {\n        throw new ValueError(`${value} is not a valid ${label}.  Valid values are ${values} or null/undefined.`);\n    }\n}\n/**\n * Helper function for verifying the types of inputs.\n *\n * Ensures that the elements of `x` are all of type `expectedType`.\n * Also verifies that the length of `x` is within bounds.\n *\n * @param x Object to test.\n * @param expectedType The string expected type of all of the elements in the\n * Array.\n * @param minLength Return false if x.length is less than this.\n * @param maxLength Return false if x.length is greater than this.\n * @returns true if and only if `x` is an `Array<expectedType>` with\n * length >= `minLength` and <= `maxLength`.\n */\n// tslint:disable:no-any\nexport function checkArrayTypeAndLength(x, expectedType, minLength = 0, maxLength = Infinity) {\n    assert(minLength >= 0);\n    assert(maxLength >= minLength);\n    return (Array.isArray(x) && x.length >= minLength && x.length <= maxLength &&\n        x.every(e => typeof e === expectedType));\n}\n// tslint:enable:no-any\n/**\n * Assert that a value or an array of value are positive integer.\n *\n * @param value The value being asserted on. May be a single number or an array\n *   of numbers.\n * @param name Name of the value, used to make the error message.\n */\nexport function assertPositiveInteger(value, name) {\n    if (Array.isArray(value)) {\n        util.assert(value.length > 0, () => `${name} is unexpectedly an empty array.`);\n        value.forEach((v, i) => assertPositiveInteger(v, `element ${i + 1} of ${name}`));\n    }\n    else {\n        util.assert(Number.isInteger(value) && value > 0, () => `Expected ${name} to be a positive integer, but got ` +\n            `${formatAsFriendlyString(value)}.`);\n    }\n}\n/**\n * Format a value into a display-friendly, human-readable fashion.\n *\n * - `null` is formatted as `'null'`\n * - Strings are formated with flanking pair of quotes.\n * - Arrays are formatted with flanking pair of square brackets.\n *\n * @param value The value to display.\n * @return Formatted string.\n */\n// tslint:disable-next-line:no-any\nexport function formatAsFriendlyString(value) {\n    if (value === null) {\n        return 'null';\n    }\n    else if (Array.isArray(value)) {\n        return '[' + value.map(v => formatAsFriendlyString(v)).join(',') + ']';\n    }\n    else if (typeof value === 'string') {\n        return `\"${value}\"`;\n    }\n    else {\n        return `${value}`;\n    }\n}\n/**\n * Returns a function `f2` (decorator) which wraps the original function\n * `f`. `f2` guarantees that `f` can be called at most once\n * every `waitMs` ms. If `f2` is called more often, it will return\n * the last returned result of `f`.\n *\n * @param f The original function `f` to wrap.\n * @param waitMs The time between two consecutive calls to `f` in ms.\n */\nexport function debounce(f, waitMs) {\n    let lastTime = util.now();\n    let lastResult;\n    const f2 = (...args) => {\n        const now = util.now();\n        if (now - lastTime < waitMs) {\n            return lastResult;\n        }\n        lastTime = now;\n        lastResult = f(...args);\n        return lastResult;\n    };\n    return f2;\n}\n/**\n * Returns the fusable activation given a layers identifier.\n *\n * @param activationName The layers identifier string.\n * @return The name of the fusable activation.\n */\nexport function mapActivationToFusedKernel(activationName) {\n    if (activationName === 'relu') {\n        return 'relu';\n    }\n    if (activationName === 'linear') {\n        return 'linear';\n    }\n    if (activationName === 'elu') {\n        return 'elu';\n    }\n    return null;\n}\n/**\n * Returns the cartesian product of sets of values.\n * This works the same as itertools.product in Python.\n *\n * Example:\n *\n * filters = [128, 256, 512]\n * paddings = ['same', 'valid']\n *\n * product = [ [128, 'same'], [128, 'valid'], [256, 'same'], [256, 'valid'],\n * [512, 'same'], [512, 'valid']]\n *\n * @param arrayOfValues List/array of values.\n * @return The cartesian product.\n */\nexport function getCartesianProductOfValues(...arrayOfValues) {\n    assert(arrayOfValues.length > 0, 'arrayOfValues is empty');\n    for (const values of arrayOfValues) {\n        assert(Array.isArray(values), 'one of the values is not an array');\n        assert(values.length > 0, 'one of the values is empty');\n    }\n    return arrayOfValues.reduce((products, values) => {\n        if (products.length === 0) {\n            return values.map(value => [value]);\n        }\n        return values\n            .map(value => {\n            return products.map((prevValue) => [...prevValue, value]);\n        })\n            .reduce((flattenedProduct, unflattenedProduct) => {\n            return flattenedProduct.concat(unflattenedProduct);\n        }, []);\n    }, []);\n}\n//# sourceMappingURL=generic_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original Source: losses.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { epsilon } from './backend/common';\nimport * as K from './backend/tfjs_backend';\nimport { ValueError } from './errors';\n/**\n * Normalizes a tensor wrt the L2 norm alongside the specified axis.\n * @param x\n * @param axis Axis along which to perform normalization.\n */\nexport function l2Normalize(x, axis) {\n    return tidy(() => {\n        if (x.dtype !== 'float32') {\n            x = x.asType('float32');\n        }\n        const squareSum = tfc.sum(K.square(x), axis, true);\n        const epsilonTensor = tfc.fill(squareSum.shape, epsilon());\n        const norm = tfc.sqrt(tfc.maximum(squareSum, epsilonTensor));\n        return tfc.div(x, norm);\n    });\n}\nexport function meanSquaredError(yTrue, yPred) {\n    return tidy(() => tfc.mean(K.square(tfc.sub(yPred, yTrue)), -1));\n}\nexport function meanAbsoluteError(yTrue, yPred) {\n    return tidy(() => tfc.mean(tfc.abs(tfc.sub(yPred, yTrue)), -1));\n}\nexport function meanAbsolutePercentageError(yTrue, yPred) {\n    return tidy(() => {\n        const diff = tfc.sub(yTrue, yPred);\n        const clippedTrue = tfc.clipByValue(tfc.abs(yTrue), epsilon(), Number.MAX_VALUE);\n        const absResult = tfc.abs(tfc.div(diff, clippedTrue));\n        return tfc.mul(100, tfc.mean(absResult, -1));\n    });\n}\nexport function meanSquaredLogarithmicError(yTrue, yPred) {\n    return tidy(() => {\n        const clippedPred = tfc.clipByValue(yPred, epsilon(), Number.MAX_VALUE);\n        const firstLog = tfc.log(tfc.add(1, clippedPred));\n        const clippedTrue = tfc.clipByValue(yTrue, epsilon(), Number.MAX_VALUE);\n        const secondLog = tfc.log(tfc.add(1, clippedTrue));\n        return tfc.mean(K.square(tfc.sub(firstLog, secondLog)), -1);\n    });\n}\nexport function squaredHinge(yTrue, yPred) {\n    return tidy(() => {\n        const maxResult = tfc.maximum(0, tfc.sub(1, tfc.mul(yTrue, yPred)));\n        return tfc.mean(K.square(maxResult), -1);\n    });\n}\nexport function hinge(yTrue, yPred) {\n    return tidy(() => {\n        const maxResult = tfc.maximum(0, tfc.sub(1, tfc.mul(yTrue, yPred)));\n        return tfc.mean(maxResult, -1);\n    });\n}\nexport function categoricalHinge(yTrue, yPred) {\n    return tidy(() => {\n        const pos = tfc.sum(tfc.mul(yTrue, yPred), -1);\n        const neg = tfc.max(tfc.mul(tfc.sub(1, yTrue), yPred), -1);\n        return tfc.maximum(0, tfc.add(1, tfc.sub(neg, pos)));\n    });\n}\n/**\n * Logarithm of the hyperbolic cosine of the prediction error.\n *\n * `log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and\n * to `abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly\n * like the mean squared error, but will not be so strongly affected by the\n * occasional wildly incorrect prediction.\n */\nexport function logcosh(yTrue, yPred) {\n    return tidy(() => {\n        const log2 = Math.log(2);\n        const predictionDiff = tfc.sub(yPred, yTrue);\n        const logcoshResult = tfc.sub(tfc.add(predictionDiff, tfc.softplus(tfc.mul(-2, predictionDiff))), log2);\n        return tfc.mean(logcoshResult, -1);\n    });\n}\nexport function categoricalCrossentropy(target, output, fromLogits = false) {\n    return tidy(() => {\n        if (fromLogits) {\n            output = tfc.softmax(output);\n        }\n        else {\n            // scale preds so that the class probabilities of each sample sum to 1.\n            const outputSum = tfc.sum(output, output.shape.length - 1, true);\n            output = tfc.div(output, outputSum);\n        }\n        output = tfc.clipByValue(output, epsilon(), 1 - epsilon());\n        return tfc.neg(tfc.sum(tfc.mul(target.toFloat(), tfc.log(output)), output.shape.length - 1));\n    });\n}\n/**\n * Categorical crossentropy with integer targets.\n *\n * @param target An integer tensor.\n * @param output A tensor resulting from a softmax (unless `fromLogits` is\n *  `true`, in which case `output` is expected to be the logits).\n * @param fromLogits Boolean, whether `output` is the result of a softmax, or is\n *   a tensor of logits.\n */\nexport function sparseCategoricalCrossentropy(target, output, fromLogits = false) {\n    return tidy(() => {\n        const flatTarget = tfc.floor(K.flatten(target)).toInt();\n        output = tfc.clipByValue(output, epsilon(), 1 - epsilon());\n        const outputShape = output.shape;\n        const oneHotTarget = tfc.oneHot(flatTarget, outputShape[outputShape.length - 1])\n            .reshape(outputShape);\n        return categoricalCrossentropy(oneHotTarget, output, fromLogits);\n    });\n}\n/**\n * From TensorFlow's implementation in nn_impl.py:\n *\n * For brevity, let `x = logits`, `z = labels`.  The logistic loss is\n *      z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))\n *    = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))\n *    = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))\n *    = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))\n *    = (1 - z) * x + log(1 + exp(-x))\n *    = x - x * z + log(1 + exp(-x))\n * For x < 0, to avoid overflow in exp(-x), we reformulate the above\n *      x - x * z + log(1 + exp(-x))\n *    = log(exp(x)) - x * z + log(1 + exp(-x))\n *    = - x * z + log(1 + exp(x))\n * Hence, to ensure stability and avoid overflow, the implementation uses this\n * equivalent formulation\n *    max(x, 0) - x * z + log(1 + exp(-abs(x)))\n *\n * @param labels The labels.\n * @param logits The logits.\n */\nexport function sigmoidCrossEntropyWithLogits(labels, logits) {\n    if (!util.arraysEqual(labels.shape, logits.shape)) {\n        throw new ValueError(`logits and labels must have the same shape, but got shapes ` +\n            `${JSON.stringify(labels.shape)} and ${JSON.stringify(logits.shape)}`);\n    }\n    return tidy(() => {\n        // The logistic loss formula from above is\n        //   x - x * z + log(1 + exp(-x))\n        // For x < 0, a more numerically stable formula is\n        //   -x * z + log(1 + exp(x))\n        // Note that these two expressions can be combined into the following:\n        //   max(x, 0) - x * z + log(1 + exp(-abs(x)))\n        const reluLogits = logits.relu();\n        const negAbsLogits = logits.abs().neg();\n        return reluLogits.sub(logits.mul(labels)).add(negAbsLogits.exp().log1p());\n    });\n}\nexport function binaryCrossentropy(yTrue, yPred) {\n    return tidy(() => {\n        let y;\n        y = tfc.clipByValue(yPred, epsilon(), 1 - epsilon());\n        y = tfc.log(tfc.div(y, tfc.sub(1, y)));\n        return tfc.mean(sigmoidCrossEntropyWithLogits(yTrue, y), -1);\n    });\n}\nexport function kullbackLeiblerDivergence(yTrue, yPred) {\n    return tidy(() => {\n        const clippedTrue = tfc.clipByValue(yTrue, epsilon(), 1);\n        const clippedPred = tfc.clipByValue(yPred, epsilon(), 1);\n        return tfc.sum(tfc.mul(yTrue, tfc.log(tfc.div(clippedTrue, clippedPred))), -1);\n    });\n}\nexport function poisson(yTrue, yPred) {\n    return tidy(() => {\n        const logPred = tfc.log(tfc.add(epsilon(), yPred));\n        return tfc.mean(tfc.sub(yPred, tfc.mul(yTrue, logPred)), -1);\n    });\n}\nexport function cosineProximity(yTrue, yPred) {\n    return tidy(() => {\n        const trueNormalized = l2Normalize(yTrue, -1);\n        const predNormalized = l2Normalize(yPred, -1);\n        const trueXPred = tfc.mul(trueNormalized, predNormalized);\n        return tfc.neg(tfc.sum(trueXPred, -1));\n    });\n}\nexport const mse = meanSquaredError;\nexport const MSE = meanSquaredError;\nexport const mae = meanAbsoluteError;\nexport const MAE = meanAbsoluteError;\nexport const mape = meanAbsolutePercentageError;\nexport const MAPE = meanAbsolutePercentageError;\nexport const msle = meanSquaredLogarithmicError;\nexport const MSLE = meanSquaredLogarithmicError;\nexport const kld = kullbackLeiblerDivergence;\nexport const KLD = kullbackLeiblerDivergence;\nexport const cosine = cosineProximity;\n// TODO(michaelterry): Add deserialize() function.\nexport const lossesMap = {\n    meanSquaredError,\n    meanAbsoluteError,\n    meanAbsolutePercentageError,\n    meanSquaredLogarithmicError,\n    squaredHinge,\n    hinge,\n    categoricalHinge,\n    logcosh,\n    categoricalCrossentropy,\n    sparseCategoricalCrossentropy,\n    binaryCrossentropy,\n    kullbackLeiblerDivergence,\n    poisson,\n    cosineProximity\n};\n// Porting note: This diverges from the PyKeras implementation and may need to\n// change based on (de)serialization requirements.\nexport function get(identifierOrFn) {\n    if (typeof identifierOrFn === 'string') {\n        if (identifierOrFn in lossesMap) {\n            return lossesMap[identifierOrFn];\n        }\n        let errMsg = `Unknown loss ${identifierOrFn}`;\n        if (identifierOrFn.toLowerCase().includes('softmaxcrossentropy')) {\n            errMsg = `Unknown loss ${identifierOrFn}. ` +\n                'Use \"categoricalCrossentropy\" as the string name for ' +\n                'tf.losses.softmaxCrossEntropy';\n        }\n        throw new ValueError(errMsg);\n    }\n    else {\n        return identifierOrFn;\n    }\n}\n//# sourceMappingURL=losses.js.map","/** @license See the LICENSE file. */\n// This code is auto-generated, do not modify this file!\nconst version = '3.6.0';\nexport { version };\n//# sourceMappingURL=version.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Count the elements in an Array of LayerVariables.\n *\n * @param weights: The LayerVariables of which the constituent numbers are to\n *   be counted.\n * @returns A count of the elements in all the LayerVariables\n */\nexport function countParamsInWeights(weights) {\n    let count = 0;\n    for (const weight of weights) {\n        if (weight.shape.length === 0) {\n            count += 1;\n        }\n        else {\n            count += weight.shape.reduce((a, b) => a * b);\n        }\n    }\n    return count;\n}\n//# sourceMappingURL=variable_utils.js.map","/**\n * @license React\n * use-sync-external-store-shim.production.js\n *\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\"use strict\";\nvar React = require(\"react\");\nfunction is(x, y) {\n  return (x === y && (0 !== x || 1 / x === 1 / y)) || (x !== x && y !== y);\n}\nvar objectIs = \"function\" === typeof Object.is ? Object.is : is,\n  useState = React.useState,\n  useEffect = React.useEffect,\n  useLayoutEffect = React.useLayoutEffect,\n  useDebugValue = React.useDebugValue;\nfunction useSyncExternalStore$2(subscribe, getSnapshot) {\n  var value = getSnapshot(),\n    _useState = useState({ inst: { value: value, getSnapshot: getSnapshot } }),\n    inst = _useState[0].inst,\n    forceUpdate = _useState[1];\n  useLayoutEffect(\n    function () {\n      inst.value = value;\n      inst.getSnapshot = getSnapshot;\n      checkIfSnapshotChanged(inst) && forceUpdate({ inst: inst });\n    },\n    [subscribe, value, getSnapshot]\n  );\n  useEffect(\n    function () {\n      checkIfSnapshotChanged(inst) && forceUpdate({ inst: inst });\n      return subscribe(function () {\n        checkIfSnapshotChanged(inst) && forceUpdate({ inst: inst });\n      });\n    },\n    [subscribe]\n  );\n  useDebugValue(value);\n  return value;\n}\nfunction checkIfSnapshotChanged(inst) {\n  var latestGetSnapshot = inst.getSnapshot;\n  inst = inst.value;\n  try {\n    var nextValue = latestGetSnapshot();\n    return !objectIs(inst, nextValue);\n  } catch (error) {\n    return !0;\n  }\n}\nfunction useSyncExternalStore$1(subscribe, getSnapshot) {\n  return getSnapshot();\n}\nvar shim =\n  \"undefined\" === typeof window ||\n  \"undefined\" === typeof window.document ||\n  \"undefined\" === typeof window.document.createElement\n    ? useSyncExternalStore$1\n    : useSyncExternalStore$2;\nexports.useSyncExternalStore =\n  void 0 !== React.useSyncExternalStore ? React.useSyncExternalStore : shim;\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { ValueError } from '../errors';\n// tslint:enable\n/**\n * Determine whether the input is an Array of Shapes.\n */\nexport function isArrayOfShapes(x) {\n    return Array.isArray(x) && Array.isArray(x[0]);\n}\n/**\n * Special case of normalizing shapes to lists.\n *\n * @param x A shape or list of shapes to normalize into a list of Shapes.\n * @return A list of Shapes.\n */\nexport function normalizeShapeList(x) {\n    if (x.length === 0) {\n        return [];\n    }\n    if (!Array.isArray(x[0])) {\n        return [x];\n    }\n    return x;\n}\n/**\n * Helper function to obtain exactly one Tensor.\n * @param xs: A single `tf.Tensor` or an `Array` of `tf.Tensor`s.\n * @return A single `tf.Tensor`. If `xs` is an `Array`, return the first one.\n * @throws ValueError: If `xs` is an `Array` and its length is not 1.\n */\nexport function getExactlyOneTensor(xs) {\n    let x;\n    if (Array.isArray(xs)) {\n        if (xs.length !== 1) {\n            throw new ValueError(`Expected Tensor length to be 1; got ${xs.length}`);\n        }\n        x = xs[0];\n    }\n    else {\n        x = xs;\n    }\n    return x;\n}\n/**\n * Helper function to obtain exactly on instance of Shape.\n *\n * @param shapes Input single `Shape` or Array of `Shape`s.\n * @returns If input is a single `Shape`, return it unchanged. If the input is\n *   an `Array` containing exactly one instance of `Shape`, return the instance.\n *   Otherwise, throw a `ValueError`.\n * @throws ValueError: If input is an `Array` of `Shape`s, and its length is not\n *   1.\n */\nexport function getExactlyOneShape(shapes) {\n    if (Array.isArray(shapes) && Array.isArray(shapes[0])) {\n        if (shapes.length === 1) {\n            shapes = shapes;\n            return shapes[0];\n        }\n        else {\n            throw new ValueError(`Expected exactly 1 Shape; got ${shapes.length}`);\n        }\n    }\n    else {\n        return shapes;\n    }\n}\n//# sourceMappingURL=types_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { ValueError } from '../errors';\nimport { pyListRepeat } from './generic_utils';\nimport { isInteger, max } from './math_utils';\n/**\n * Transforms a single number of array of numbers into an array of numbers.\n * @param value\n * @param n: The size of the tuple to be returned.\n * @param name: Name of the parameter, used for generating error messages.\n * @returns An array of numbers.\n */\nexport function normalizeArray(value, n, name) {\n    if (typeof value === 'number') {\n        return pyListRepeat(value, n);\n    }\n    else {\n        if (value.length !== n) {\n            throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers.` +\n                ` Received: ${value.length} elements.`);\n        }\n        for (let i = 0; i < n; ++i) {\n            const singleValue = value[i];\n            if (!isInteger(singleValue)) {\n                throw new ValueError(`The ${name} argument must be an integer or tuple of ${n}` +\n                    ` integers. Received: ${JSON.stringify(value)} including a` +\n                    ` non-integer number ${singleValue}`);\n            }\n        }\n        return value;\n    }\n}\n/**\n * Determines output length of a convolution given input length.\n * @param inputLength\n * @param filterSize\n * @param padding\n * @param stride\n * @param dilation: dilation rate.\n */\nexport function convOutputLength(inputLength, filterSize, padding, stride, dilation = 1) {\n    if (inputLength == null) {\n        return inputLength;\n    }\n    const dilatedFilterSize = filterSize + (filterSize - 1) * (dilation - 1);\n    let outputLength;\n    if (padding === 'same') {\n        outputLength = inputLength;\n    }\n    else { // VALID\n        outputLength = inputLength - dilatedFilterSize + 1;\n    }\n    return Math.floor((outputLength + stride - 1) / stride);\n}\nexport function deconvLength(dimSize, strideSize, kernelSize, padding) {\n    if (dimSize == null) {\n        return null;\n    }\n    if (padding === 'valid') {\n        dimSize = dimSize * strideSize + max([kernelSize - strideSize, 0]);\n    }\n    else if (padding === 'same') {\n        dimSize = dimSize * strideSize;\n    }\n    else {\n        throw new ValueError(`Unsupport padding mode: ${padding}.`);\n    }\n    return dimSize;\n}\n//# sourceMappingURL=conv_utils.js.map","'use strict';\n\nif (process.env.NODE_ENV === 'production') {\n  module.exports = require('../cjs/use-sync-external-store-shim/with-selector.production.js');\n} else {\n  module.exports = require('../cjs/use-sync-external-store-shim/with-selector.development.js');\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { variableGrads } from '@tensorflow/tfjs-core';\nimport { getNextUniqueTensorId } from './backend/state';\nimport { getScopedTensorName, getUniqueTensorName } from './common';\nimport { NotImplementedError } from './errors';\nconst DEFAULT_VARIABLE_NAME_PREFIX = 'Variable';\n/**\n * A `tf.layers.LayerVariable` is similar to a `tf.Tensor` in that it has a\n * dtype and shape, but its value is mutable.  The value is itself represented\n * as a`tf.Tensor`, and can be read with the `read()` method and updated with\n * the `write()` method.\n */\nexport class LayerVariable {\n    /**\n     * Construct Variable from a `tf.Tensor`.\n     *\n     * If not explicitly named, the Variable will be given a name with the\n     * prefix 'Variable'. Variable names are unique. In the case of name\n     * collision, suffixies '_<num>' will be added to the name.\n     *\n     * @param val Initial value of the Variable.\n     * @param name Name of the variable. If `null` or `undefined` is provided, it\n     *   will default a name with the prefix 'Variable'.\n     * @param constraint Optional, projection function to be applied to the\n     * variable after optimize updates\n     * @throws ValueError if `name` is `null` or `undefined`.\n     */\n    constructor(val, dtype = 'float32', name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true, constraint = null) {\n        this.dtype = dtype == null ? 'float32' : dtype;\n        this.shape = val.shape;\n        this.id = getNextUniqueTensorId();\n        name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;\n        this.originalName = getScopedTensorName(name);\n        this.name = getUniqueTensorName(this.originalName);\n        this.trainable_ = trainable;\n        this.constraint = constraint;\n        this.val = tfc.variable(val, this.trainable_, this.name, this.dtype);\n    }\n    /**\n     * Get a snapshot of the Variable's value.\n     *\n     * The returned value is a snapshot of the Variable's value at the time of\n     * the invocation. Future mutations in the value of the tensor will only\n     * be reflected by future calls to this method.\n     */\n    read() {\n        this.assertNotDisposed();\n        return this.val;\n    }\n    /**\n     * Update the value of the Variable.\n     *\n     * @param newVal: The new value to update to. Must be consistent with the\n     *   dtype and shape of the Variable.\n     * @return This Variable.\n     */\n    write(newVal) {\n        // TODO(cais): Once  TF.js Core supports Tensor.dtype, check dtype match.\n        this.assertNotDisposed();\n        checkShapesMatch(this.val, newVal);\n        // Skip updating if this is the exact same tensor.\n        if (this.val.id !== newVal.id) {\n            this.val.assign(newVal);\n            if (this.constraint != null) {\n                this.val.assign(this.constraint.apply(this.val));\n            }\n        }\n        return this;\n    }\n    /**\n     * Dispose this LayersVariable instance from memory.\n     */\n    dispose() {\n        this.assertNotDisposed();\n        this.val.dispose();\n    }\n    assertNotDisposed() {\n        if (this.val.isDisposed) {\n            throw new Error(`LayersVariable ${this.name} is already disposed.`);\n        }\n    }\n    get trainable() {\n        return this.trainable_;\n    }\n    set trainable(trainable) {\n        this.trainable_ = trainable;\n        this.val.trainable = trainable;\n    }\n}\nfunction checkShapesMatch(x, y) {\n    if (x.shape.toString() !== y.shape.toString()) {\n        throw new Error('Shape mismatch: ' + JSON.stringify(x.shape) + ' vs. ' +\n            JSON.stringify(y.shape));\n    }\n}\n/**\n * Create a Variable.\n * @param x The initial value of the `Variable`.\n * @param dtype optional, the type of the variable.\n * @param name optional, the name of the variable, default provided by\n * Variable.\n * @param constraint optional, a constraint to be applied after every update.\n * @return The newly instantiated `Variable`.\n */\nexport function variable(x, dtype, name, constraint) {\n    return new LayerVariable(x, dtype, name, true, constraint);\n}\n/**\n * Instantiates an all-zeros Variable and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-zero Variable.\n */\nexport function zerosVariable(shape, dtype, name) {\n    // TODO(cais): Implement logic for dtype.\n    return new LayerVariable(tfc.zeros(shape), dtype, name);\n}\n/**\n * Instantiates an all-zeros tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\nexport function zerosLike(x, dtype, name) {\n    return new LayerVariable(tfc.zerosLike(x), dtype, name);\n}\n/**\n * Instantiates an all-ones tensor and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-ones Variable.\n */\nexport function onesVariable(shape, dtype, name) {\n    // TODO(cais): Implement logic for dtype.\n    const allocated = tfc.ones(shape);\n    return new LayerVariable(allocated, dtype, name);\n}\n/**\n * Instantiates an all-ones tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\nexport function onesLike(x, dtype, name) {\n    const allocated = tfc.onesLike(x);\n    return new LayerVariable(allocated, dtype, name);\n}\n/**\n * Instantiate an identity matrix and returns it, as a Variable\n *\n * @param size Number of rows/columns.\n * @param dtype Data type of returned Variable.\n * @param name Name of returned Variable.\n * @return A Variable, an identity matrix.\n */\nexport function eyeVariable(size, dtype, name) {\n    return new LayerVariable(tfc.eye(size), dtype, name);\n}\n/**\n * Get a Variable with uniform distribution of values.\n * @param shape Shape of the tensor.\n * @param minval Lower bound of the uniform distribution.\n * @param maxval Upper bound of the uniform distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The uniform-random Variable.\n */\nexport function randomUniformVariable(shape, minval, maxval, dtype, seed, name = 'randomUniform') {\n    return new LayerVariable(tfc.randomUniform(shape, minval, maxval, dtype), dtype, name);\n}\n/**\n * Get a Variable with truncated-normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\nexport function truncatedNormalVariable(shape, mean = 0.0, stddev = 1.0, dtype, seed, name = 'truncatedNormal') {\n    // TODO(cais): Implement logic for dtype and seed once they are supported\n    // by deeplearn.js.\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);\n    }\n    return new LayerVariable(tfc.truncatedNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Get a Variable with normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\nexport function randomNormalVariable(shape, mean = 0.0, stddev = 1.0, dtype, seed, name = 'randomNormal') {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`randomNormalVariable does not support dType ${dtype}.`);\n    }\n    return new LayerVariable(tfc.randomNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Update the value of a Variable.\n * @param x The Variable to be updated.\n * @param xNew The new value to update to.\n * @return The Variable updated.\n */\nexport function update(x, xNew) {\n    return x.write(xNew);\n}\n/**\n * Update the value of a Variable by adding an increment.\n * @param x The Variable to be updated.\n * @param increment The incrment to add to `x`.\n * @return The Variable updated.\n */\nexport function updateAdd(x, increment) {\n    return x.write(tfc.add(x.read(), increment));\n}\n/**\n * Update the value of a Variable by subtracting a decrement.\n * @param x The Variable to be updated.\n * @param decrement The decrement to subtract from `x`.\n * @return The Variable updated.\n */\nexport function updateSub(x, decrement) {\n    return x.write(tfc.sub(x.read(), decrement));\n}\n/**\n * Get the values of an array of Variables.\n *\n * @param tensors An `Array` of `Variable`s to get the values of.\n * @return The values of the inputs, as an `Array` of`tf.Tensor`s.\n */\nexport function batchGetValue(xs) {\n    return xs.map(x => x.read());\n}\n/**\n * Update the value of multiple Variables at once.\n *\n * @param variablesAndValues An `Array`, each element is of type\n *   [Variable, Tensor]. The first item is the\n *   `Variable` of which the value is to be updated. The second item\n *   carries the new value.\n */\nexport function batchSetValue(variablesAndValues) {\n    variablesAndValues.forEach(variableAndValue => {\n        const variable = variableAndValue[0];\n        variable.write(variableAndValue[1]);\n    });\n}\n/**\n * Returns the gradients of `variables` w.r.t. the return value of `lossFn`.\n * @param lossFn A function which returns a Scalar to be used as the function\n *   value (i.e., numerator) for differentiation.\n * @param variables List of variables to be used as the independent variables\n *   (i.e., denominator) for differentiation.\n * @returns An Array of gradients tensors.\n */\nexport function gradients(lossFn, variables) {\n    // TODO(cais): The return type signature can be simplified if deeplearn makes\n    //   the corresponding type public.\n    const variableList = variables.map(variable => variable.read());\n    const valudAndGrads = variableGrads(lossFn, variableList);\n    return variables.map(variable => valudAndGrads.grads[variable.name]);\n}\n//# sourceMappingURL=variables.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Math utility functions.\n *\n * This file contains some frequently used math function that operates on\n * number[] or Float32Array and return a number. Many of these functions are\n * not-so-thick wrappers around TF.js Core functions. But they offer the\n * convenience of\n * 1) not having to convert the inputs into Tensors,\n * 2) not having to convert the returned Tensors to numbers.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { scalar, tensor1d } from '@tensorflow/tfjs-core';\nimport { ValueError } from '../errors';\n/**\n * Determine if a number is an integer.\n */\nexport function isInteger(x) {\n    return x === parseInt(x.toString(), 10);\n}\n/**\n * Calculate the product of an array of numbers.\n * @param array The array to calculate the product over.\n * @param begin Beginning index, inclusive.\n * @param end Ending index, exclusive.\n * @return The product.\n */\nexport function arrayProd(array, begin, end) {\n    if (begin == null) {\n        begin = 0;\n    }\n    if (end == null) {\n        end = array.length;\n    }\n    let prod = 1;\n    for (let i = begin; i < end; ++i) {\n        prod *= array[i];\n    }\n    return prod;\n}\n/**\n * A helper function transforms the two input types to an instance of Tensor1D,\n * so the return value can be fed directly into various TF.js Core functions.\n * @param array\n */\nfunction toArray1D(array) {\n    array = Array.isArray(array) ? new Float32Array(array) : array;\n    return tensor1d(array);\n}\n/**\n * Compute minimum value.\n * @param array\n * @return minimum value.\n */\nexport function min(array) {\n    return tfc.min(toArray1D(array)).dataSync()[0];\n}\n/**\n * Compute maximum value.\n * @param array\n * @return maximum value\n */\nexport function max(array) {\n    return tfc.max(toArray1D(array)).dataSync()[0];\n}\n/**\n * Compute sum of array.\n * @param array\n * @return The sum.\n */\nexport function sum(array) {\n    return tfc.sum(toArray1D(array)).dataSync()[0];\n}\n/**\n * Compute mean of array.\n * @param array\n * @return The mean.\n */\nexport function mean(array) {\n    return sum(array) / array.length;\n}\n/**\n * Compute variance of array.\n * @param array\n * @return The variance.\n */\nexport function variance(array) {\n    const demeaned = tfc.sub(toArray1D(array), scalar(mean(array)));\n    const sumSquare = tfc.sum(tfc.mul(demeaned, demeaned)).dataSync()[0];\n    return sumSquare / array.length;\n}\n/**\n * Compute median of array.\n * @param array\n * @return The median value.\n */\nexport function median(array) {\n    const arraySorted = array.slice().sort((a, b) => a - b);\n    const lowIdx = Math.floor((arraySorted.length - 1) / 2);\n    const highIdx = Math.ceil((arraySorted.length - 1) / 2);\n    if (lowIdx === highIdx) {\n        return arraySorted[lowIdx];\n    }\n    return (arraySorted[lowIdx] + arraySorted[highIdx]) / 2;\n}\n/**\n * Generate an array of integers in [begin, end).\n * @param begin Beginning integer, inclusive.\n * @param end Ending integer, exclusive.\n * @returns Range array.\n * @throws ValueError, iff `end` < `begin`.\n */\nexport function range(begin, end) {\n    if (end < begin) {\n        throw new ValueError(`end (${end}) < begin (${begin}) is forbidden.`);\n    }\n    const out = [];\n    for (let i = begin; i < end; ++i) {\n        out.push(i);\n    }\n    return out;\n}\n//# sourceMappingURL=math_utils.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* original source: keras/regularizers.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { abs, add, serialization, sum, tidy, zeros } from '@tensorflow/tfjs-core';\nimport * as K from './backend/tfjs_backend';\nimport { deserializeKerasObject, serializeKerasObject } from './utils/generic_utils';\nfunction assertObjectArgs(args) {\n    if (args != null && typeof args !== 'object') {\n        throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an ` +\n            `object, but received: ${args}`);\n    }\n}\n/**\n * Regularizer base class.\n */\nexport class Regularizer extends serialization.Serializable {\n}\nexport class L1L2 extends Regularizer {\n    constructor(args) {\n        super();\n        assertObjectArgs(args);\n        this.l1 = args == null || args.l1 == null ? 0.01 : args.l1;\n        this.l2 = args == null || args.l2 == null ? 0.01 : args.l2;\n        this.hasL1 = this.l1 !== 0;\n        this.hasL2 = this.l2 !== 0;\n    }\n    /**\n     * Porting note: Renamed from __call__.\n     * @param x Variable of which to calculate the regularization score.\n     */\n    apply(x) {\n        return tidy(() => {\n            let regularization = zeros([1]);\n            if (this.hasL1) {\n                regularization = add(regularization, sum(tfc.mul(this.l1, abs(x))));\n            }\n            if (this.hasL2) {\n                regularization =\n                    add(regularization, sum(tfc.mul(this.l2, K.square(x))));\n            }\n            return regularization.asScalar();\n        });\n    }\n    getConfig() {\n        return { 'l1': this.l1, 'l2': this.l2 };\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls({ l1: config['l1'], l2: config['l2'] });\n    }\n}\n/** @nocollapse */\nL1L2.className = 'L1L2';\nserialization.registerClass(L1L2);\nexport function l1(args) {\n    assertObjectArgs(args);\n    return new L1L2({ l1: args != null ? args.l1 : null, l2: 0 });\n}\nexport function l2(args) {\n    assertObjectArgs(args);\n    return new L1L2({ l2: args != null ? args.l2 : null, l1: 0 });\n}\n// Maps the JavaScript-like identifier keys to the corresponding keras symbols.\nexport const REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {\n    'l1l2': 'L1L2'\n};\nexport function serializeRegularizer(constraint) {\n    return serializeKerasObject(constraint);\n}\nexport function deserializeRegularizer(config, customObjects = {}) {\n    return deserializeKerasObject(config, serialization.SerializationMap.getMap().classNameMap, customObjects, 'regularizer');\n}\nexport function getRegularizer(identifier) {\n    if (identifier == null) {\n        return null;\n    }\n    if (typeof identifier === 'string') {\n        const className = identifier in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ?\n            REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] :\n            identifier;\n        const config = { className, config: {} };\n        return deserializeRegularizer(config);\n    }\n    else if (identifier instanceof Regularizer) {\n        return identifier;\n    }\n    else {\n        return deserializeRegularizer(identifier);\n    }\n}\n//# sourceMappingURL=regularizers.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as generic_utils from '../utils/generic_utils';\n// tslint:enable\n/**\n * Test whether a value in an array is the name of a LayersModel or Layer.\n * @param key The key name that the value is found under. Note that the key\n *   may not be at the level immediately above the value, if the value is in a\n *   nested array.\n * @param index Index of the value in the Array that it is found in.\n * @param value The value object.\n * @returns A boolean indicating whether value is a name.\n */\nfunction isArrayItemInputOrOutputName(key, index, value) {\n    return (key === 'inboundNodes' || key === 'outputLayers' ||\n        key === 'inputLayers') &&\n        index === 0 && typeof value === 'string';\n}\n/**\n * Convert a Pythonic config object to TypeScript config object.\n * @param pythonicConfig The config object to convert.\n * @param key Optional key name of the object being converted.\n * @returns Result of the conversion.\n */\nexport function convertPythonicToTs(pythonicConfig, key) {\n    if (pythonicConfig === null) {\n        return null;\n    }\n    else if (typeof pythonicConfig === 'string') {\n        return generic_utils.toCamelCase(pythonicConfig);\n    }\n    else if ((typeof pythonicConfig === 'number') ||\n        (typeof pythonicConfig === 'boolean')) {\n        return pythonicConfig;\n    }\n    else if (pythonicConfig instanceof Array) {\n        const tsArray = [];\n        const arrayLength = pythonicConfig.length;\n        for (let i = 0; i < arrayLength; ++i) {\n            const item = pythonicConfig[i];\n            if (isArrayItemInputOrOutputName(key, i, item)) {\n                tsArray.push(item);\n            }\n            else {\n                tsArray.push(convertPythonicToTs(item, key));\n            }\n        }\n        return tsArray;\n    }\n    else {\n        const tsDict = {};\n        for (const pythonicKey of Object.keys(pythonicConfig)) {\n            const pythonicValue = pythonicConfig[pythonicKey];\n            if (pythonicKey === 'name' && typeof pythonicValue === 'string') {\n                // Special case the 'name' key with a string value. Name values, such as\n                // the names of LayersModel and Layer instances, should not undergo the\n                // camel-case conversion.\n                tsDict[pythonicKey] = pythonicValue;\n            }\n            else {\n                const tsKey = generic_utils.toCamelCase(pythonicKey);\n                tsDict[tsKey] = convertPythonicToTs(pythonicValue, tsKey);\n            }\n        }\n        return tsDict;\n    }\n}\n/**\n * Convert a TypeScript config object to Python config object.\n * @param tsConfig The config object to convert.\n * @param key Optional key name of the object being converted.\n * @returns Result of the conversion.\n */\nexport function convertTsToPythonic(tsConfig, key) {\n    if (tsConfig === null || tsConfig === undefined) {\n        return null;\n    }\n    else if (typeof tsConfig === 'string') {\n        return generic_utils.toSnakeCase(tsConfig);\n    }\n    else if ((typeof tsConfig === 'number') || (typeof tsConfig === 'boolean')) {\n        return tsConfig;\n    }\n    else if (tsConfig instanceof Array) {\n        const pyArray = [];\n        const arrayLength = tsConfig.length;\n        for (let i = 0; i < arrayLength; ++i) {\n            const item = tsConfig[i];\n            if (isArrayItemInputOrOutputName(key, i, item)) {\n                pyArray.push(item);\n            }\n            else {\n                pyArray.push(convertTsToPythonic(item, key));\n            }\n        }\n        return pyArray;\n    }\n    else {\n        const pyDict = {};\n        for (const tsKey of Object.keys(tsConfig)) {\n            const tsValue = tsConfig[tsKey];\n            const pyKey = generic_utils.toSnakeCase(tsKey);\n            if ((tsKey === 'name' || tsKey === 'className') &&\n                typeof tsValue === 'string') {\n                // Special case the 'name' key with a string value. Name values, such as\n                // the names of LayersModel and Layer instances, should not undergo the\n                // snake-case conversion.\n                pyDict[pyKey] = tsValue;\n            }\n            else {\n                pyDict[pyKey] = convertTsToPythonic(tsValue, tsKey);\n            }\n        }\n        return pyDict;\n    }\n}\n//# sourceMappingURL=serialization_utils.js.map","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/** Utility functions related to user-defined metadata. */\n// Maximum recommended serialized size for user-defined metadata.\n// Beyond this limit, a warning message will be printed during model loading and\n// saving.\nexport const MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH = 1 * 1024 * 1024;\n/**\n * Check validity of user-defined metadata.\n *\n * @param userDefinedMetadata\n * @param modelName Name of the model that the user-defined metadata belongs to.\n *   Used during construction of error messages.\n * @param checkSize Whether to check the size of the metadata is under\n *   recommended limit. Default: `false`. If `true`, will try stringify the\n *   JSON object and print a console warning if the serialzied size is above the\n *   limit.\n * @throws Error if `userDefinedMetadata` is not a plain JSON object.\n */\nexport function checkUserDefinedMetadata(userDefinedMetadata, modelName, checkSize = false) {\n    if (userDefinedMetadata == null ||\n        typeof userDefinedMetadata !== 'object' ||\n        Object.getPrototypeOf(userDefinedMetadata) !== Object.prototype ||\n        !plainObjectCheck(userDefinedMetadata)) {\n        throw new Error('User-defined metadata is expected to be a JSON object, but is not.');\n    }\n    if (checkSize) {\n        const out = JSON.stringify(userDefinedMetadata);\n        if (out.length > MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH) {\n            console.warn(`User-defined metadata of model \"${modelName}\" is too large in ` +\n                `size (length=${out.length} when serialized). It is not ` +\n                `recommended to store such large objects in user-defined metadata. ` +\n                `Please make sure its serialized length is <= ` +\n                `${MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH}.`);\n        }\n    }\n}\n/**\n * Check if an input is plain JSON object or any valid subfield of it.\n *\n * @param x The input to be checked.\n * @param assertObject Whether to assert `x` is a JSON object, i.e., reject\n *   cases of arrays and primitives.\n * @return Returns `true` if and only if `x` is a plain JSON object,\n *   a JSON-valid primitive including string, number, boolean and null,\n *   or an array of the said types.\n */\n// tslint:disable-next-line:no-any\nexport function plainObjectCheck(x) {\n    if (x === null) {\n        // Note: typeof `null` is 'object', and `null` is valid in JSON.\n        return true;\n    }\n    else if (typeof x === 'object') {\n        if (Object.getPrototypeOf(x) === Object.prototype) {\n            // `x` is a JavaScript object and its prototype is Object.\n            const keys = Object.keys(x);\n            for (const key of keys) {\n                if (typeof key !== 'string') {\n                    // JSON keys must be strings.\n                    return false;\n                }\n                if (!plainObjectCheck(x[key])) { // Recursive call.\n                    return false;\n                }\n            }\n            return true;\n        }\n        else {\n            // `x` is a JavaScript object but its prototype is not Object.\n            if (Array.isArray(x)) {\n                // `x` is a JavaScript array.\n                for (const item of x) {\n                    if (!plainObjectCheck(item)) { // Recursive call.\n                        return false;\n                    }\n                }\n                return true;\n            }\n            else {\n                // `x` is a JavaScript object and its prototype is not Object,\n                // and it's not an Array. I.e., it's a complex object such as\n                // `Error` and `Date`.\n                return false;\n            }\n        }\n    }\n    else {\n        // `x` is not a JavaScript object or `null`.\n        const xType = typeof x;\n        return xType === 'string' || xType === 'number' || xType === 'boolean';\n    }\n}\n//# sourceMappingURL=user_defined_metadata.js.map","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { dispose } from '@tensorflow/tfjs-core';\n/**\n * Turn any Scalar values in a Logs object into actual number values.\n *\n * @param logs The `Logs` object to be resolved in place.\n */\nexport async function resolveScalarsInLogs(logs) {\n    if (logs == null) {\n        return;\n    }\n    const promises = [];\n    const keys = [];\n    const scalarsToDispose = [];\n    for (const key in logs) {\n        const value = logs[key];\n        if (typeof value !== 'number') {\n            const valueScalar = value;\n            promises.push(valueScalar.data());\n            keys.push(key);\n            scalarsToDispose.push(valueScalar);\n        }\n    }\n    if (promises.length > 0) {\n        const values = await Promise.all(promises);\n        for (let i = 0; i < values.length; ++i) {\n            logs[keys[i]] = values[i][0];\n        }\n        // Dispose the original scalar tensors.\n        dispose(scalarsToDispose);\n    }\n}\n/**\n * Dispose all Tensors in an UnresolvedLogs object.\n *\n * @param logs An `UnresolvedLogs` object potentially containing `tf.Tensor`s in\n *   places where the values can be `tf.Tensor` or `number`.\n */\nexport function disposeTensorsInLogs(logs) {\n    if (logs == null) {\n        return;\n    }\n    for (const key in logs) {\n        const value = logs[key];\n        if (typeof value !== 'number') {\n            value.dispose();\n        }\n    }\n}\n//# sourceMappingURL=logs.js.map"],"names":["printSummary","model","lineLength","positions","printFn","console","log","sequentialLike","nodesByDepth","nodes","depth","push","depthNodes","length","inboundLayers","layer","layers","flag","node","inboundNodes","indexOf","isModelSequentialLike","toDisplay","relevantNodes","map","p","Math","floor","repeat","printRow","i","printLayerSummary","printLayerSummaryWithConnections","checkTrainableWeightsConsistency","trainableCount","collectedTrainableWeights","trainableWeights","countTrainableParams","nonTrainableCount","nonTrainableWeights","fields","line","slice","outputShape","JSON","stringify","err","name","getClassName","countParams","toString","connections","inboundLayer","inboundLayerIndex","nodeIndices","inboundTensorIndex","tensorIndices","className","firstConnection","Sequential","constructor","args","super","inputs","outputs","this","trainable","built","add","checkShape","outputTensors","shape","some","x","inputTensors","isLayerModelInstance","modelLayer","batchInputShape","batchShape","dtype","apply","outboundLayer","inputMasks","outputMasks","inputShapes","outputShapes","outputTensor","Array","isArray","TypeError","pop","outboundNodes","lastLayerIndex","output","call","kwargs","build","inputShape","supportsMasking","inputLayers","inputLayersNodeIndices","inputLayersTensorIndices","outputLayers","outputLayersNodeIndices","outputLayersTensorIndices","containerNodes","outputNames","inputNames","summary","setWeights","weights","evaluate","y","evaluateDataset","dataset","predict","predictOnBatch","compile","optimizer_","optimizer","isOptimizerOwned","loss","metrics","metricsTensors","metricsNames","undefined","fit","fitDataset","trainOnBatch","fromConfig","cls","config","customObjects","fastWeightInit","configArray","extraModelConfig","util","conf","setFastWeightInitDuringBuild","stopTraining","stop","getConfig","dict","serialization","module","exports","React","shim","objectIs","Object","is","useSyncExternalStore","useRef","useEffect","useMemo","useDebugValue","useSyncExternalStoreWithSelector","subscribe","getSnapshot","getServerSnapshot","selector","isEqual","instRef","current","inst","hasValue","value","memoizedSelector","nextSnapshot","hasMemo","memoizedSnapshot","currentSelection","memoizedSelection","nextSelection","maybeGetServerSnapshot","getOptimizer","identifier","optimizerMap","train","adagrad","adadelta","adam","adamax","rmsprop","sgd","version_core","binaryAccuracy","yTrue","yPred","tidy","threshold","yPredThresholded","categoricalAccuracy","truePositives","equal","sum","cast","binaryCrossentropy","sparseCategoricalAccuracy","rank","squeeze","argMax","asType","mse","MSE","mae","MAE","mape","MAPE","categoricalCrossentropy","cosine","sparseCategoricalCrossentropy","metricsMap","precision","tp","fp","falsePositives","denominator","div","get","getLossOrMetricName","fn","fnName","key","keys","pyListRepeat","numValues","newArray","concat","fill","assert","val","message","count","array","refernce","counter","item","singletonOrArray","xs","toList","toSnakeCase","insecure","replace","toLowerCase","toCamelCase","m","p1","toUpperCase","_GLOBAL_CUSTOM_OBJECTS","serializeKerasObject","instance","convertNDArrayScalarsInConfig","forEach","configItem","field","deserializeKerasObject","moduleObjects","printableModuleName","functionName","customObjectsCombined","backupCustomObjects","assign","returnObj","reverseNumberCompare","a","b","numberCompare","unique","out","isObjectEmpty","obj","hasOwnProperty","checkStringTypeUnionValue","values","label","checkArrayTypeAndLength","expectedType","minLength","maxLength","Infinity","every","e","assertPositiveInteger","v","Number","isInteger","formatAsFriendlyString","join","debounce","f","waitMs","lastResult","lastTime","now","mapActivationToFusedKernel","activationName","l2Normalize","axis","squareSum","epsilonTensor","norm","meanSquaredError","meanAbsoluteError","meanAbsolutePercentageError","diff","clippedTrue","MAX_VALUE","absResult","meanSquaredLogarithmicError","clippedPred","firstLog","secondLog","target","fromLogits","outputSum","toFloat","flatTarget","toInt","reshape","labels","logits","reluLogits","relu","negAbsLogits","abs","neg","sub","mul","exp","log1p","sigmoidCrossEntropyWithLogits","kullbackLeiblerDivergence","cosineProximity","trueNormalized","predNormalized","trueXPred","lossesMap","squaredHinge","maxResult","hinge","categoricalHinge","pos","logcosh","log2","predictionDiff","logcoshResult","poisson","logPred","identifierOrFn","errMsg","includes","version","countParamsInWeights","weight","reduce","useState","useLayoutEffect","checkIfSnapshotChanged","latestGetSnapshot","nextValue","error","window","document","createElement","_useState","forceUpdate","isArrayOfShapes","normalizeShapeList","getExactlyOneTensor","getExactlyOneShape","shapes","normalizeArray","n","singleValue","convOutputLength","inputLength","filterSize","padding","stride","dilation","outputLength","deconvLength","dimSize","strideSize","kernelSize","DEFAULT_VARIABLE_NAME_PREFIX","LayerVariable","constraint","id","originalName","trainable_","read","assertNotDisposed","write","newVal","Error","checkShapesMatch","dispose","isDisposed","batchGetValue","batchSetValue","variablesAndValues","variableAndValue","parseInt","arrayProd","begin","end","prod","toArray1D","Float32Array","tensor1d","min","dataSync","max","range","assertObjectArgs","Regularizer","L1L2","l1","l2","hasL1","hasL2","regularization","zeros","asScalar","REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP","serializeRegularizer","deserializeRegularizer","getMap","classNameMap","getRegularizer","isArrayItemInputOrOutputName","index","convertPythonicToTs","pythonicConfig","tsArray","arrayLength","tsDict","pythonicKey","pythonicValue","tsKey","convertTsToPythonic","tsConfig","pyArray","pyDict","tsValue","pyKey","checkUserDefinedMetadata","userDefinedMetadata","modelName","checkSize","getPrototypeOf","prototype","plainObjectCheck","xType","async","resolveScalarsInLogs","logs","promises","scalarsToDispose","valueScalar","data","Promise","all","disposeTensorsInLogs"],"sourceRoot":""}