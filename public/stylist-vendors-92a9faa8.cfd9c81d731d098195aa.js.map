{"version":3,"file":"stylist-vendors-92a9faa8.cfd9c81d731d098195aa.js","mappings":"6KA4CO,SAASA,EAAOC,EAAOC,EAAQ,UAAWC,GAG7C,OAFAD,EAAQA,GAAS,UACjB,KAAwCD,GACjC,IAAI,KAAaA,EAAOC,EAAOC,EAC1C,C,uICeO,MAAMC,GAAW,IAAAC,IAAG,CAAEC,UAV7B,SAAmBC,EAAGC,GAElB,IAAIC,GAAK,QAAgBF,EAAG,IAAK,OAC7BG,GAAK,QAAgBF,EAAG,IAAK,QAChCC,EAAIC,IAAM,IAAAC,gBAAeF,EAAIC,GAC9B,MAAME,GAAY,OAAIH,EAAIC,GACpBG,GAAQ,OAAUD,GAClBE,GAAc,OAAMJ,EAAIG,GAC9B,OAAO,OAAMC,EAAaD,EAAOD,EACrC,G,6HCIO,MAAMG,GAAS,IAAAV,IAAG,CAAEW,QAhC3B,SAAiBC,EAAGC,EAAQC,EAAQC,EAAKC,EAAa,MAAOC,EAAW,EAAGC,GACvE,MAAMC,GAAK,QAAgBP,EAAG,IAAK,UAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,UAClD,IAAIQ,EAAMF,EACNG,GAAe,EACH,IAAZH,EAAGI,OACHD,GAAe,EACfD,GAAM,OAAQF,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,MAEhD,KAAyB,IAAbyB,EAAIE,MAAY,IAAM,uDAAuDF,EAAIE,UAC7F,KAA6B,IAAjBH,EAAQG,MAAY,IAC5B,wDAAGH,EAAQG,UACQ,MAAnBL,GACA,KAAY,KAAWH,IAAM,IACzB,uEAAmBG,iBAA+BH,OAE1D,KAAYM,EAAIzB,MAAM,KAAOwB,EAAQxB,MAAM,IAAI,IAAM,oCAAoCyB,EAAIzB,MAAM,yCACrEwB,EAAQxB,MAAM,QAC5C,KAAY,KAAyCkB,EAAQG,IAAW,IACpE,oEAAcH,mBAAwBG,OAC1C,KAA2B,QAAfD,GAAsB,IAAM,sCAAsCA,2CAC9E,MAAMQ,GAAW,OAAQJ,EAAS,CAAC,EAAGA,EAAQxB,MAAM,GAAIwB,EAAQxB,MAAM,GAAIwB,EAAQxB,MAAM,KAClF6B,GAAU,OAAQJ,EAAK,CAACA,EAAIzB,MAAM,GAAI,EAAGyB,EAAIzB,MAAM,GAAIyB,EAAIzB,MAAM,KACjE8B,EAAU,CAAC,EAAGZ,GACda,EAAY,CAAC,EAAGV,GAEhBW,GAAM,OAAOH,EAASD,EAAUE,EAASX,EADtB,OAC6CY,EAAWT,GACjF,OAAII,GACO,OAAQM,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,MAE1C,OAAQgC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,IAC/D,G,4FCtBO,MAAMiC,GAAM,E,SAAA7B,IAAG,CAAE8B,KAXxB,SAAclB,GACV,MAAMO,GAAK,QAAgBP,EAAG,IAAK,OACnC,GAAiB,cAAbO,EAAGtB,MAAuB,CAC1B,MAAMkC,EAAS,CAAEnB,EAAGO,GACpB,OAAO,KAAOa,UAAU,KAAYD,EACxC,CACK,CACD,MAAMA,EAAS,CAAEnB,EAAGO,GACpB,OAAO,KAAOa,UAAU,KAAKD,EACjC,CACJ,G,4FCLO,MAAME,GAAM,E,SAAAjC,IAAG,CAAEkC,KALxB,SAActB,GACV,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,QAEnC,OAAO,KAAOoB,UAAU,KAAKD,EACjC,G,uGCQO,MAAMI,GAAa,E,SAAAnC,IAAG,CAAEoC,YAP/B,SAAqBxB,EAAGyB,EAAO,GAC3B,MAAMlB,GAAK,QAAgBP,EAAG,IAAK,aAAc,qBACjD,KAAYyB,GAAQlB,EAAGI,MAAM,IAAM,uCACnC,MAAMQ,EAAS,CAAEO,MAAOnB,GAClBoB,EAAQ,CAAEC,IAAKH,GACrB,OAAO,KAAOL,UAAU,KAAYD,EAAQQ,EAChD,G,kHCwCO,MAAME,GAAY,E,SAAAzC,IAAG,CAAE0C,WAlC9B,SAAoB9B,EAAG+B,EAAMC,EAAUC,EAAQC,EAAOC,GAC3B,MAAnBA,IACAA,EAAkB,MAEtB,MAAM5B,GAAK,QAAgBP,EAAG,IAAK,aAC7BoC,GAAQ,QAAgBL,EAAM,OAAQ,aACtCM,GAAY,QAAgBL,EAAU,WAAY,aACxD,IAAIM,EAIAC,EAHS,MAATL,IACAI,GAAS,QAAgBJ,EAAO,QAAS,cAG/B,MAAVD,IACAM,GAAU,QAAgBN,EAAQ,SAAU,cAEhD,KAAYG,EAAMzB,OAAS0B,EAAU1B,MAAM,IAAM,iFAEjD,KAAuB,MAAX4B,GAAmBH,EAAMzB,OAAS4B,EAAQ5B,MAAM,IAAM,+EAElE,KAAsB,MAAV2B,GAAkBF,EAAMzB,OAAS2B,EAAO3B,MAAM,IAAM,8EAEhE,MACMQ,EAAS,CACXnB,ECvED,SAAeA,GAClB,IAAIwC,EAaJ,OAXIA,EADW,IAAXxC,EAAEW,MAAyB,IAAXX,EAAEW,MACZ,EAAA8B,EAAA,GAAQzC,EAAG,CAAC,EAAG,EAAG,EAAGA,EAAE0C,OAEb,IAAX1C,EAAEW,MACD,EAAA8B,EAAA,GAAQzC,EAAG,CAAC,EAAG,EAAGA,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,KAE5B,IAAXgB,EAAEW,MACD,EAAA8B,EAAA,GAAQzC,EAAG,CAAC,EAAGA,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,KAG/CgB,EAEHwC,CACX,CDsDgBG,CAAMpC,GAGd2B,MAAOI,EACPL,OAAQM,EACRR,KAAMK,EACNJ,SAAUK,GAERV,EAAQ,CAAEQ,mBAEVnB,EAAM,KAAOI,UAAU,KAAgBD,EAAQQ,GACrD,OAAO,EAAAc,EAAA,GAAQzB,EAAKT,EAAGvB,MAC3B,G,6FElCO,MAAM4D,GAAO,E,SAAAxD,IAAG,CAAEyD,MALzB,SAAe7C,GACX,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,SAEnC,OAAO,KAAOoB,UAAU,KAAMD,EAClC,G,8HCiDO,MAAM2B,GAAkB,IAAA1D,IAAG,CAAE2D,iBA7BpC,SAA0B/C,EAAGC,EAAQa,EAASX,EAAKC,EAAa,OAAQW,EAAY,CAAC,EAAG,GAAIT,GACxF,MAAMC,GAAK,QAAgBP,EAAG,IAAK,mBAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,mBAClD,IAAIuC,EAAMjC,EACNyC,GAAe,EACH,IAAZzC,EAAGI,OACHqC,GAAe,EACfR,GAAM,OAAQjC,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,MAE7D,KAAyB,IAAbwD,EAAI7B,MAAY,IACxB,gEAAQ6B,EAAI7B,UAChB,KAA6B,IAAjBH,EAAQG,MAAY,IAC5B,iEAAGH,EAAQG,UACf,KAAY6B,EAAIxD,MAAM,KAAOwB,EAAQxB,MAAM,IAAI,IAC3C,uDAAIwD,EAAIxD,MAAM,qDACJwB,EAAQxB,MAAM,QACL,MAAnBsB,GACA,KAAY,KAAWH,IAAM,IACzB,gFAAmBG,iBAA+BH,OAE1D,MAAMgB,EAAS,CAAEnB,EAAGwC,EAAKvC,OAAQO,GAC3BmB,EAAQ,CAAEb,UAASX,MAAKC,aAAYW,YAAWT,mBAE/CU,EAAM,KAAOI,UAAU,KAAuBD,EAAQQ,GAC5D,OAAIqB,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,6FC7CO,MAAMiC,GAAS,E,SAAA7D,IAAG,CAAE8D,QAN3B,SAAiBlD,EAAGyB,EAAO,GACvB,MACMN,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,WAE7B2B,EAAQ,CAAEF,QAChB,OAAO,KAAOL,UAAU,KAAQD,EAAQQ,EAC5C,G,iLCjCO,MAAMwB,EAAQ,SACRC,EAAS,WACTC,GAAU,WACVC,EAAS,YACTC,GAAU,YACVC,EAAS,W,6FCkCf,MAAMC,GAAM,E,SAAArE,IAAG,CAAEsE,KANxB,SAAc1D,EAAGyB,EAAO,KAAMkC,GAAW,GACrC,MACMxC,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,MAAO,SAEpC2B,EAAQ,CAAEF,OAAMkC,YACtB,OAAO,KAAOvC,UAAU,KAAKD,EAAQQ,EACzC,G,8FCrCO,SAASiC,EAAuBC,EAAQpC,GAC3C,MAAMd,EAAOkD,EAAO,GAAGC,OACvBD,EAAOE,SAAQ,CAAC/E,EAAOgF,KACnB,KAAYhF,EAAM8E,SAAWnD,GAAM,IAAM,kBAAkBA,uBAA0BqD,gDACrDrD,MAAQ,IAE5C,KAAYc,GAAQ,GAAKA,EAAOd,GAAM,IAAM,kBAAkBA,kCAAqCA,EAAO,OAC1G,MAAMsD,EAAaJ,EAAO,GAC1BA,EAAOE,SAAQ,CAAC/E,EAAOgF,KACnB,IAAK,IAAIE,EAAI,EAAGA,EAAIvD,EAAMuD,IACtB,KAAaA,IAAMzC,GAAUzC,EAAMkF,KAAOD,EAAWC,IAAK,IAAM,kBAAkBvD,wBAA2BqD,OAAOhF,4CACvEiF,sCACND,MAC3C,GAER,CACO,SAASG,EAAgBN,EAAQpC,GACpC,MAAM2C,EAAcP,EAAO,GAAGQ,QAC9B,IAAK,IAAIL,EAAI,EAAGA,EAAIH,EAAOC,OAAQE,IAC/BI,EAAY3C,IAASoC,EAAOG,GAAGvC,GAEnC,OAAO2C,CACX,C,6FCHO,MAAME,GAAO,E,SAAAlF,IAAG,CAAEmF,MALzB,SAAevE,GACX,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,SAEnC,OAAO,KAAOoB,UAAU,KAAMD,EAClC,G,mHCUO,MAAMqD,GAAQ,E,SAAApF,IAAG,CAAEqF,OAR1B,SAAgBnF,EAAGC,GACf,IAAIC,GAAK,QAAgBF,EAAG,IAAK,SAC7BG,GAAK,QAAgBF,EAAG,IAAK,UAChCC,EAAIC,IAAM,IAAAC,gBAAeF,EAAIC,IAC9B,QAA2BD,EAAGR,MAAOS,EAAGT,OACxC,MAAMmC,EAAS,CAAE7B,EAAGE,EAAID,EAAGE,GAC3B,OAAO,KAAO2B,UAAU,KAAOD,EACnC,G,4FCDO,MAAMuD,GAAc,E,SAAAtF,IAAG,CAAEuF,aA5BhC,SAAsB3E,EAAG+B,EAAMC,EAAUC,EAAQC,EAAOC,GACpD,MAAM5B,GAAK,QAAgBP,EAAG,IAAK,aAC7BoC,GAAQ,QAAgBL,EAAM,OAAQ,aACtCM,GAAY,QAAgBL,EAAU,WAAY,aACxD,IAAIM,EAIAC,EAkBJ,OArBa,MAATL,IACAI,GAAS,QAAgBJ,EAAO,QAAS,cAG/B,MAAVD,IACAM,GAAU,QAAgBN,EAAQ,SAAU,cAEhD,KAAwB,IAAZ1B,EAAGI,MAAY,IACvB,uDAAGJ,EAAGI,UACV,KAA2B,IAAfyB,EAAMzB,MAA6B,IAAfyB,EAAMzB,MAAY,IAC9C,oEAAYyB,EAAMzB,UACtB,KAA+B,IAAnB0B,EAAU1B,MAAiC,IAAnB0B,EAAU1B,MAAY,IACtD,wEAAgB0B,EAAU1B,UAChB,MAAV2B,GACA,KAA4B,IAAhBA,EAAO3B,MAA8B,IAAhB2B,EAAO3B,MAAY,IAChD,qEAAgB2B,EAAO3B,UAEhB,MAAX4B,GACA,KAA6B,IAAjBA,EAAQ5B,MAA+B,IAAjB4B,EAAQ5B,MAAY,IAClD,sEAAgB4B,EAAQ5B,WAEzB,OAAUJ,EAAI6B,EAAOC,EAAWE,EAASD,EAAQH,EAC5D,G,wGCWO,MAAMyC,GAAO,E,SAAAxF,IAAG,CAAEyF,MAnBzB,SAAeC,GACX,KAAYC,MAAMC,QAAQF,IAAU,IAAM,+DAC1C,KAAYA,EAAQhB,QAAU,GAAG,IAC7B,uDAAGgB,EAAQhB,WACf,MAAMmB,EAAWH,EAAQI,KAAI,CAACC,EAAGnB,KAAM,QAAgBmB,EAAG,UAAUnB,IAAK,UACnEoB,EAAcH,EAAS,GAC7BA,EAASlB,SAAQoB,IACb,GAAIA,EAAElG,QAAUmG,EAAYnG,MACxB,MAAM,IAAIoG,MAAM,2DACpB,IAEJJ,EAASlB,SAAQoB,IACb,IAAK,KAAiBA,EAAEnG,MAAOoG,EAAYpG,OACvC,MAAM,IAAIqG,MAAM,2DACpB,IAEJ,MAAMlE,EAAS8D,EACf,OAAO,KAAO7D,UAAU,KAAMD,EAClC,G,kKCSO,MAAMmE,GAAU,IAAAlG,IAAG,CAAEmG,SAb5B,SAAkBvF,EAAGwF,EAAMC,EAAYC,GACnC,MAAMnF,GAAK,QAAgBP,EAAG,IAAK,WAInC,GAHA,KAAyB,YAAbO,EAAGtB,OAAqB,IAChC,gFAAqBsB,EAAGtB,0BAC5B,KAAYuG,GAAQ,GAAKA,EAAO,GAAG,IAAM,qDAAqDA,OACjF,IAATA,EACA,OAAOxF,aAAa,KAASO,EAAGoF,QAAUpF,EAE9C,MAAMqF,EC/BH,SAAuB5F,EAAGyF,GAC7B,GAAkB,MAAdA,EACA,OAAOzF,EAAEhB,MAAMqF,QAEnB,GAAI,KAAiBrE,EAAEhB,MAAOyG,GAC1B,OAAOA,EAEX,GAAIzF,EAAEhB,MAAM8E,SAAW2B,EAAW3B,OAAQ,CACtC,MAAM+B,EAAe,GACrB,IAAK,IAAI7B,EAAI,EAAGA,EAAIhE,EAAEhB,MAAM8E,OAAQE,IACX,MAAjByB,EAAWzB,IAA4B,MAAdhE,EAAEhB,MAAMgF,GACjC6B,EAAaC,KAAK9F,EAAEhB,MAAMgF,IAG1B6B,EAAaC,KAAKL,EAAWzB,IAGrC,OAAO6B,CACX,CACA,OAAOJ,CACX,CDWwBM,CAAcxF,EAAIkF,GAChCO,EAAW,EAAIR,EACfS,GAAa,EAAAC,EAAA,IAAI,EAAAC,EAAA,IAAM,EAAAC,EAAA,IAAI,OAAcR,EAAa,EAAG,EAAG,UAAWF,GAAOM,IAAYA,GAChG,OAAO,EAAAK,EAAA,GAAI9F,EAAI0F,EACnB,G,uEE5BO,MAAMK,GAAW,E,SAAAlH,IAAG,CAAEmH,UAH7B,SAAmBzB,EAASrD,GACxB,OAAO,OAAOqD,EAASrD,EAC3B,G,gPCVO,SAAS+E,EAAqBC,EAAM9F,GACvC,IAAK,IAAIqD,EAAI,EAAGA,EAAIyC,EAAK3C,SAAUE,EAC/B,GAAIyC,EAAKA,EAAK3C,OAASE,EAAI,KAAOrD,EAAO,EAAIqD,EACzC,OAAO,EAGf,OAAO,CACX,CACO,SAAS0C,EAAiBC,EAAWC,EAAWH,GACnD,MAAM9F,EAAOgG,EAAU7C,OAAS8C,EAAU9C,OACpC+C,EAAM,GACZ,IAAIC,EAAS,EACTC,EAAY,EAChB,IAAK,IAAInF,EAAM,EAAGA,EAAMjB,EAAMiB,KACC,IAAvB6E,EAAKO,QAAQpF,GACbiF,EAAIf,KAAKa,EAAUG,MAGnBD,EAAIf,KAAKc,EAAUG,MAG3B,OAAOF,CACX,CACO,SAASI,EAA0BC,EAAQT,GAC9C,MAAMU,EAAW,GACXxG,EAAOuG,EAAOpD,OACpB,IAAK,IAAIlC,EAAM,EAAGA,EAAMjB,EAAMiB,KACC,IAAvB6E,EAAKO,QAAQpF,IACbuF,EAASrB,KAAKoB,EAAOtF,IAI7B,MAAO,CAACuF,EADYV,EAAKvB,KAAItD,GAAOsF,EAAOtF,KAE/C,CACO,SAASwF,EAAqBpI,EAAOyH,GAExC,OAAOC,EAAiB1H,EADDyH,EAAKvB,KAAIlF,GAAK,IACUyG,EACnD,CACO,SAASY,EAA2BC,EAAKb,EAAM9F,GAClD,KAAY6F,EAAqBC,EAAM9F,IAAO,IAAM,GAAG2G,qDACvCb,cAAiB9F,YACrC,CAMO,SAAS4G,EAAmBd,EAAM9F,GACrC,GAAI6F,EAAqBC,EAAM9F,GAC3B,OAAO,KAEX,MAAM6G,EAAS,GACf,IAAK,IAAIxD,EAAI,EAAGA,EAAIrD,IAAQqD,GACC,IAArByC,EAAKO,QAAQhD,IACbwD,EAAO1B,KAAK9B,GAIpB,OADAyC,EAAK1C,SAAQtC,GAAQ+F,EAAO1B,KAAKrE,KAC1B+F,CACX,CAEO,SAASC,EAAuBhB,GACnC,OAAOA,EAAKvB,KAAI,CAACzD,EAAMuC,IAAM,CAACA,EAAGvC,KAC5BiG,MAAK,CAACpI,EAAGC,IAAMD,EAAE,GAAKC,EAAE,KACxB2F,KAAIlF,GAAKA,EAAE,IACpB,CACO,SAAS2H,EAAiBC,EAASjH,GACtC,MAAMK,EAAM,GACZ,IAAK,IAAIgD,EAAIrD,EAAOiH,EAAS5D,EAAIrD,IAAQqD,EACrChD,EAAI8E,KAAK9B,GAEb,OAAOhD,CACX,C,wGCjDO,MAAM6G,GAAQ,E,SAAAzI,IAAG,CAAE0I,OAP1B,SAAgBxI,EAAGC,GACf,IAAIC,GAAK,QAAgBF,EAAG,IAAK,SAC7BG,GAAK,QAAgBF,EAAG,IAAK,UAChCC,EAAIC,IAAM,IAAAC,gBAAeF,EAAIC,GAC9B,MAAM0B,EAAS,CAAE7B,EAAGE,EAAID,EAAGE,GAC3B,OAAO,KAAO2B,UAAU,KAAOD,EACnC,G,mHCqCO,MAAM4G,GAAS,E,SAAA3I,IAAG,CAAE4I,QAlB3B,SAAiBlD,EAASrD,EAAO,IAC7B,QAAOqD,EAAQhB,QAAU,GAAG,IAAM,uCAClC,MAAMmB,GAAW,QAAqBH,EAAS,UAAW,SAAU,qBASpE,GAR0B,cAAtBG,EAAS,GAAGhG,OACZgG,EAASlB,SAAQkE,IACb,GAAqB,cAAjBA,EAAOhJ,MACP,MAAM,IAAIoG,MAAM,4EACT4C,EAAOhJ,UAClB,IAGgB,IAApBgG,EAASnB,OACT,OAAO,OAAMmB,EAAS,IAE1B,MAAM9D,EAAS8D,EACTiD,EAAO,CAAEzG,QACf,OAAO,KAAOL,UAAU,KAAQD,EAAQ+G,EAC5C,G,mHCRO,MAAMC,GAAuB,IAAA/I,IAAG,CAAEgJ,sBA9BzC,SAA+BpI,EAAGqI,EAAIC,EAAaxH,EAASX,EAAKC,EAAa,OAAQE,GAClF,IAAIkC,EAAMxC,EACK,IAAXA,EAAEW,OACF6B,GAAM,OAAQxC,EAAG,CAAC,EAAGA,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,MAEzD,IAAIuJ,EAAOF,EACO,IAAdE,EAAK5H,OACL4H,GAAO,OAAQF,EAAI,CAAC,EAAGA,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,MAE9D,KAAyB,IAAbwD,EAAI7B,MAAY,IACxB,iEAAG6B,EAAIxD,WACX,KAA0B,IAAduJ,EAAK5H,MAAY,IACzB,8DAAG4H,EAAKvJ,WACZ,KAAmC,IAAvBsJ,EAAYxE,QAAc,IAClC,mEAAGwE,OACP,MAAME,EAAyB,SAAfpI,EAAwBoC,EAAIxD,MAAM,GAAKwD,EAAIxD,MAAM,GAC3DyJ,EAA0B,SAAfrI,EAAwBmI,EAAKvJ,MAAM,GAAKuJ,EAAKvJ,MAAM,GACpE,KAAYwJ,IAAYF,EAAY,IAAI,IAAM,4CAA4CE,wCACtDF,EAAY,QAChD,KAAYG,IAAaH,EAAY,IAAI,IAAM,0CAA0CG,0CACnDH,EAAY,SAC3B,MAAnBhI,GACA,KAAY,KAAWH,IAAM,IACzB,gFAAmBG,iBAA+BH,OAE1D,MAAMgB,EAAS,CAAEnB,EAAGwC,EAAK6F,GAAIE,GACvB5G,EAAQ,CAAEb,UAASX,MAAKC,aAAYE,kBAAiBgI,eAE3D,OAAO,KAAOlH,UAAU,KAAsBD,EAAQQ,EAC1D,G,8HCNO,MAAM+G,GAAc,IAAAtJ,IAAG,CAAEuJ,aA1BhC,SAAsBN,EAAI3G,EAAOkH,EAAY9H,EAASX,GAClD,MAAM0I,GAAM,QAAgBR,EAAI,KAAM,eAChCS,GAAS,QAAgBpH,EAAO,QAAS,eAC/C,KAAYoH,EAAOnI,OAASkI,EAAIlI,MAAM,IAAM,kBAAkBmI,EAAOnI,oCAAoCkI,EAAIlI,UAC7G,IAAIE,EAAUiI,EACVP,EAAOM,EACP7F,GAAe,EACC,IAAhB8F,EAAOnI,OACPqC,GAAe,EACfnC,GACI,OAAQiI,EAAQ,CAAC,EAAGA,EAAO9J,MAAM,GAAI8J,EAAO9J,MAAM,GAAI8J,EAAO9J,MAAM,KACvEuJ,GAAO,OAAQM,EAAK,CAAC,EAAGA,EAAI7J,MAAM,GAAI6J,EAAI7J,MAAM,GAAI6J,EAAI7J,MAAM,MAElE,KAA0B,IAAduJ,EAAK5H,MAAY,IACzB,wDAAG4H,EAAK5H,UACZ,KAA6B,IAAjBE,EAAQF,MAAY,IAC5B,2DAAGE,EAAQF,UACf,MAAMQ,EAAS,CAAEkH,GAAIE,EAAM7G,MAAOb,GAC5Bc,EAAQ,CAAEiH,aAAY9H,UAASX,OAE/Ba,EAAM,KAAOI,UAAU,KAAaD,EAAQQ,GAClD,OAAIqB,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,6FC1BO,MAAM+H,GAAO,E,SAAA3J,IAAG,CAAE4J,MALzB,SAAehJ,GACX,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,SAEnC,OAAO,KAAOoB,UAAU,KAAMD,EAClC,G,kPCXA,IAAI8H,EA0BJ,SAASC,EAAYC,EAAQC,EAAc,GAEvC,GAAIA,EAAc,EACd,MAAM,IAAI/D,MAAM,kEAEpB,GAAc,MAAV8D,EACA,MAAM,IAAI9D,MAAM,4DAEpB,IAAIgE,GAAc,EACdC,GAAc,EACdC,GAAU,EACVC,GAAU,EACVC,GAAe,EACfC,GAAgB,EACpB,GAAIP,EAAOQ,gBAAgBC,WACvBP,GAAc,OAEb,GAA2B,qBAAhB,WAA+BF,aAAkBU,UAC7DP,GAAc,OAEb,GAAkC,qBAAvB,kBACZH,aAAkBW,iBAClBP,GAAU,OAET,GAAkC,qBAAvB,kBACZJ,aAAkBY,iBAClBP,GAAU,OAGT,GAAyB,MAArBL,EAAOa,WACZP,GAAe,MAEd,MAA6B,qBAAlB,aAAiCN,aAAkBc,aAI/D,MAAM,IAAI5E,MAIN,qPAAW8D,EAAOe,YAAYC,QAPlCT,GAAgB,CAQpB,CACA,GAAIH,EAAS,CACT,MAAMa,EAAgC,EACtC,GAAIb,GACAJ,EAAOkB,WACHD,EACJ,MAAM,IAAI/E,MAAM,wGAGxB,CAIA,GAAc,OADC,QAAU,KAAY,KAAOiF,aACxB,CAChB,MAAMnJ,EAAS,CAAEgI,UACXxH,EAAQ,CAAEyH,eAChB,OAAO,KAAOhI,UAAU,KAAYD,EAAQQ,EAChD,CACA,MAAO4I,EAAOC,GAAUjB,EACpB,CACIJ,EAAOsB,WACPtB,EAAOuB,aAEX,CAACvB,EAAOoB,MAAOpB,EAAOqB,QAC1B,IAAIG,EAkBAzL,EACJ,GAlBIuK,EACAkB,EAEIxB,EAAOa,WAAW,MAAMY,aAAa,EAAG,EAAGL,EAAOC,GAAQb,KAEzDL,GAAeD,EACpBsB,EAAOxB,EAAOQ,MAETH,GAAWD,GAAWG,KACA,MAAvBT,IACAA,EAAsB4B,SAASC,cAAc,UAAUd,WAAW,OAEtEf,EAAoB8B,OAAOR,MAAQA,EACnCtB,EAAoB8B,OAAOP,OAASA,EACpCvB,EAAoB+B,UAAU7B,EAAQ,EAAG,EAAGoB,EAAOC,GACnDG,EAAO1B,EAAoB2B,aAAa,EAAG,EAAGL,EAAOC,GAAQb,MAG7C,IAAhBP,EACAlK,EAAS,IAAI+L,WAAWN,OAEvB,CACD,MAAMO,EAAYX,EAAQC,EAC1BtL,EAAS,IAAI+L,WAAWC,EAAY9B,GACpC,IAAK,IAAIpF,EAAI,EAAGA,EAAIkH,EAAWlH,IAC3B,IAAK,IAAImH,EAAU,EAAGA,EAAU/B,IAAe+B,EAC3CjM,EAAO8E,EAAIoF,EAAc+B,GAAWR,EAAS,EAAJ3G,EAAQmH,EAG7D,CACA,MAAMhE,EAAW,CAACqD,EAAQD,EAAOnB,GACjC,OAAO,OAASlK,EAAQiI,EAAU,QACtC,CAcA,SAASiE,EAA2BjC,GAChC,MARyB,qBAAXkC,QACe,qBAAlB,aACPA,OAAOC,eAAe,wBAMgBnC,aAAkBc,cAJhE,SAA0Bd,GACtB,OAAiB,MAAVA,GAAmC,IAAjBA,EAAOoB,OAAiC,IAAlBpB,EAAOqB,MAC1D,CAGQe,CAAiBpC,KAbzB,SAAqBA,GACjB,OAAkB,MAAVA,GAAoBA,EAAOQ,gBAAgBC,UACvD,CAWqCP,CAAYF,EACjD,CA2BOqC,eAAeC,EAAgBtC,EAAQC,EAAc,GACxD,IAAIjI,EAAS,KAGb,IAAI,UAAMuK,QAAQ,wBACdN,EAA2BjC,GAAS,CAGpC,IAAIwC,EACJ,IAKIA,QAAoBC,kBAAkBzC,EAAQ,CAAE0C,iBAAkB,QACtE,CACA,MAAOC,GACHH,EAAc,IAClB,CASIxK,EAFe,MAAfwK,GAAuBA,EAAYpB,QAAUpB,EAAOoB,OACpDoB,EAAYnB,SAAWrB,EAAOqB,OACrBmB,EAGAxC,CAEjB,MAEIhI,EAASgI,EAEb,OAAOD,EAAY/H,EAAQiI,EAC/B,CAqBOoC,eAAeO,EAASC,EAAKjB,GAChC,IAAIkB,GAAO,QAAgBD,EAAK,MAAO,YACvC,KAAMA,aAAe,MAAS,CAE1B,MAAME,EAAoBD,EAC1BA,GAAO,OAAKC,EAAmB,SAC/BA,EAAkBC,SACtB,CACA,GAAkB,IAAdF,EAAKtL,MAA4B,IAAdsL,EAAKtL,KACxB,MAAM,IAAI0E,MAAM,wDAAwD4G,EAAKtL,SAEjF,MAAO6J,EAAQD,GAAS0B,EAAKjN,MAAMqF,MAAM,EAAG,GACtC+H,EAAsB,IAAdH,EAAKtL,KAAa,EAAIsL,EAAKjN,MAAM,GAC/C,GAAIoN,EAAQ,GAAe,IAAVA,EACb,MAAM,IAAI/G,MACN,0DAAqB+G,KAE7B,GAAmB,YAAfH,EAAKhN,OAAsC,UAAfgN,EAAKhN,MACjC,MAAM,IAAIoG,MAAM,kCAAkC4G,EAAKhN,+CAG3D,MAAM0K,QAAasC,EAAKtC,OAClB1D,EAA4B,YAAfgG,EAAKhN,MAAsB,IAAM,EAC9CoN,EAAQ,IAAIC,kBAAkB/B,EAAQC,EAAS,GACrD,IAAK,IAAIxG,EAAI,EAAGA,EAAIwG,EAASD,IAASvG,EAAG,CACrC,MAAMuI,EAAO,CAAC,EAAG,EAAG,EAAG,KACvB,IAAK,IAAIC,EAAI,EAAGA,EAAIJ,EAAOI,IAAK,CAC5B,MAAMC,EAAQ9C,EAAK3F,EAAIoI,EAAQI,GAC/B,GAAmB,YAAfP,EAAKhN,OACL,GAAIwN,EAAQ,GAAKA,EAAQ,EACrB,MAAM,IAAIpH,MACN,mFAAiCoH,WAGxC,GAAmB,UAAfR,EAAKhN,QACNwN,EAAQ,GAAKA,EAAQ,KACrB,MAAM,IAAIpH,MACN,mFAAmCoH,MAGjC,IAAVL,GACAG,EAAK,GAAKE,EAAQxG,EAClBsG,EAAK,GAAKE,EAAQxG,EAClBsG,EAAK,GAAKE,EAAQxG,GAGlBsG,EAAKC,GAAKC,EAAQxG,CAE1B,CACA,MAAMyG,EAAQ,EAAJ1I,EACVqI,EAAMK,EAAI,GAAKC,KAAKC,MAAML,EAAK,IAC/BF,EAAMK,EAAI,GAAKC,KAAKC,MAAML,EAAK,IAC/BF,EAAMK,EAAI,GAAKC,KAAKC,MAAML,EAAK,IAC/BF,EAAMK,EAAI,GAAKC,KAAKC,MAAML,EAAK,GACnC,CACA,GAAc,MAAVxB,EAAgB,CAChBA,EAAOR,MAAQA,EACfQ,EAAOP,OAASA,EAChB,MAAMqC,EAAM9B,EAAOf,WAAW,MACxB8C,EAAY,IAAIjD,UAAUwC,EAAO9B,EAAOC,GAC9CqC,EAAIE,aAAaD,EAAW,EAAG,EACnC,CAIA,OAHIb,IAASD,GACTC,EAAKE,UAEFE,CACX,CACO,MAAMW,GAAa,IAAA5N,IAAG,CAAE8J,e,4FCnRxB,MAAM+D,GAAc,E,SAAA7N,IAAG,CAAE8N,aA5BhC,SAAsBlN,EAAG+B,EAAMC,EAAUC,EAAQC,EAAOC,GACpD,MAAM5B,GAAK,QAAgBP,EAAG,IAAK,aAC7BoC,GAAQ,QAAgBL,EAAM,OAAQ,aACtCM,GAAY,QAAgBL,EAAU,WAAY,aACxD,IAAIM,EAIAC,EAkBJ,OArBa,MAATL,IACAI,GAAS,QAAgBJ,EAAO,QAAS,cAG/B,MAAVD,IACAM,GAAU,QAAgBN,EAAQ,SAAU,cAEhD,KAAwB,IAAZ1B,EAAGI,MAAY,IACvB,uDAAGJ,EAAGI,UACV,KAA2B,IAAfyB,EAAMzB,MAA6B,IAAfyB,EAAMzB,MAAY,IAC9C,oEAAYyB,EAAMzB,UACtB,KAA+B,IAAnB0B,EAAU1B,MAAiC,IAAnB0B,EAAU1B,MAAY,IACtD,wEAAgB0B,EAAU1B,UAChB,MAAV2B,GACA,KAA4B,IAAhBA,EAAO3B,MAA8B,IAAhB2B,EAAO3B,MAAY,IAChD,qEAAgB2B,EAAO3B,UAEhB,MAAX4B,GACA,KAA6B,IAAjBA,EAAQ5B,MAA+B,IAAjB4B,EAAQ5B,MAAY,IAClD,sEAAgB4B,EAAQ5B,WAEzB,OAAUJ,EAAI6B,EAAOC,EAAWE,EAASD,EAAQH,EAC5D,G,yIC2CO,MAAMgL,GAAS,IAAA/N,IAAG,CAAEgO,QA9B3B,SAAiBpN,EAAGC,EAAQa,EAASX,EAAKC,EAAa,OAAQW,EAAY,CAAC,EAAG,GAAIT,GAC/E,MAAMC,GAAK,QAAgBP,EAAG,IAAK,UAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,UAClD,IAAIuC,EAAMjC,EACNyC,GAAe,EACH,IAAZzC,EAAGI,OACHqC,GAAe,EACfR,GAAM,OAAQjC,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,MAE7D,KAAyB,IAAbwD,EAAI7B,MAAY,IAAM,uDAAuD6B,EAAI7B,UAC7F,KAA6B,IAAjBH,EAAQG,MAAY,IAC5B,wDAAGH,EAAQG,UACQ,MAAnBL,GACA,KAAY,KAAWH,IAAM,IACzB,uEAAmBG,iBAA+BH,OAE1D,MAAMqI,EAAyB,SAAfpI,EAAwBoC,EAAIxD,MAAM,GAAKwD,EAAIxD,MAAM,GACjE,KAAYwJ,IAAYhI,EAAQxB,MAAM,IAAI,IAAM,oCAAoCwJ,wCACtDhI,EAAQxB,MAAM,QAC5C,KAAY,KAAyC8B,EAASC,IAAY,IACtE,uEAAeD,oBAA0BC,OAC7C,MAAMI,EAAS,CAAEnB,EAAGwC,EAAKvC,OAAQO,GAC3BmB,EAAQ,CAAEb,UAASX,MAAKC,aAAYW,YAAWT,mBAE/CU,EAAM,KAAOI,UAAU,KAAQD,EAAQQ,GAC7C,OAAIqB,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,6FC/CO,MAAMqM,GAAO,E,SAAAjO,IAAG,CAAEkO,MALzB,SAAetN,GACX,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,SAEnC,OAAO,KAAOoB,UAAU,KAAMD,EAClC,G,wGCWO,MAAMoM,GAAO,E,SAAAnO,IAAG,CAAEoO,MAdzB,SAAexN,EAAGf,GACd,MAAMsB,GAAK,QAAgBP,EAAG,IAAK,QAEnC,IAAK,KAAkBf,GACnB,MAAM,IAAIoG,MAAM,mCAAmCpG,KAEvD,GAAc,WAAVA,GAAmC,WAAbsB,EAAGtB,OACf,WAAVA,GAAmC,WAAbsB,EAAGtB,MACzB,MAAM,IAAIoG,MAAM,yCAEpB,MAAMlE,EAAS,CAAEnB,EAAGO,GACdoB,EAAQ,CAAE1C,SAChB,OAAO,KAAOmC,UAAU,KAAMD,EAAQQ,EAC1C,G,6FCTO,MAAM8L,GAAO,E,SAAArO,IAAG,CAAEsO,MALzB,SAAe1N,GACX,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,SAEnC,OAAO,KAAOoB,UAAU,KAAMD,EAClC,G,wGCsCO,MAAMwM,GAAe,E,SAAAvO,IAAG,CAAEwO,cAhBjC,SAAuB5N,EAAG6N,EAAWzN,EAAa,QAC9C,MAAMG,GAAK,QAAgBP,EAAG,IAAK,gBAC7B8N,EAA8B,SAAf1N,EAAyBG,EAAGvB,MAAM,GAAKuB,EAAGvB,MAAM,GAC/D+O,EAA6B,SAAf3N,EAAyBG,EAAGvB,MAAM,GAAKuB,EAAGvB,MAAM,GAC9DgP,EAA6B,SAAf5N,EAAyBG,EAAGvB,MAAM,GAAKuB,EAAGvB,MAAM,GACpE,KAAY8O,EAAcD,GAAa,GAAG,IAAM,oEAC9CC,SAAmBD,6CACnBtN,EAAGvB,UACL,KAAY+O,EAAaF,GAAa,GAAG,IAAM,oEAC7CE,SAAkBF,gDACdtN,EAAGvB,UACT,KAAagP,GAAcH,EAAYA,KAAe,GAAI,IAAM,8CAA8CA,EAAYA,YAAoBG,uCAAgDzN,EAAGvB,UACjM,MAAMmC,EAAS,CAAEnB,EAAGO,GACdoB,EAAQ,CAAEkM,YAAWzN,cAC3B,OAAO,KAAOgB,UAAU,KAAcD,EAAQQ,EAClD,G,mHCFO,MAAMsM,GAAsB,IAAA7O,IAAG,CAAE8O,qBAhCxC,SAA8BC,EAAQ9F,EAAIpI,EAAQa,EAASX,GACvD,KAAYgO,EAAOrK,SAAWuE,EAAG1H,MAAM,IACnC,sBAAIwN,EAAOrK,2BAA2BuE,EAAG1H,qBAC7C,IAAIyN,EAAWD,EACXE,EAAOhG,EACPiG,GAAe,EACH,IAAZjG,EAAG1H,OACH2N,GAAe,EACfD,GAAO,OAAQhG,EAAI,CAAC,EAAGA,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,KACvEoP,EAAW,CAAC,EAAGD,EAAO,GAAIA,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAE3D,MAAM3F,EAAU4F,EAAS,GACnB3F,EAAW4F,EAAKrP,MAAM,GAC5B,KAAgC,IAApBoP,EAAStK,QAAc,IAC/B,qEAAGsK,EAAStK,YAChB,KAA0B,IAAduK,EAAK1N,MAAY,IACzB,4DAAQ0N,EAAK1N,SACjB,KAA4B,IAAhBV,EAAOU,MAAY,IAC3B,gEAAQV,EAAOU,SACnB,KAAY6H,IAAYvI,EAAOjB,MAAM,IAAI,IAAM,4CAA4CwJ,wCACvDvI,EAAOjB,MAAM,QACjD,KAAYyJ,IAAaxI,EAAOjB,MAAM,IAAI,IAAM,6CAA6CyJ,yCACxDxI,EAAOjB,MAAM,QAClD,MAAMmC,EAAS,CAAEkH,GAAIgG,EAAMpO,UACrB0B,EAAQ,CAAExB,MAAKW,UAASyN,WAAYH,GAEpCpN,EAAM,KAAOI,UAAU,KAAuBD,EAAQQ,GAC5D,OAAI2M,GACO,OAAQtN,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAEtEgC,CACX,G,6HCEO,MAAMwN,EAhCbhD,eAAiCvD,EAAQwG,EAAMhN,GAC3C,MAAMiN,GAAU,QAAgBzG,EAAQ,SAAU,YAC5C0G,GAAQ,QAAgBF,EAAM,OAAQ,WAAY,QAClDG,EAAmB,MAARnN,EAAe,EAAIA,EAC9BoN,EAAUF,EAAMhO,KAChBmO,EAAcJ,EAAQ1P,MAC5B,KAAY6P,EAAU,GAAG,IAAM,0BAC/B,KAAuBC,EAAYzK,MAAMuK,EAAUA,EAAWC,GAAUF,EAAM3P,MAAO,qEACrF,IAAI+P,EAAc,EAClB,IAAK,IAAI/K,EAAI4K,EAAU5K,EAAI4K,EAAWC,EAAS7K,IAC3C+K,GAAeD,EAAY9K,GAE/B,MAAMgL,EAAoBF,EAAYzK,MAAM,EAAGuK,GAC1C7G,OAAO,CAACgH,GAAcD,EAAYzK,MAAMuK,EAAWC,IAClDI,GAAiB,OAAQP,EAASM,GAClCE,GAAe,OAAQP,EAAO,EAAE,IAChCQ,QAA0B,OAAWD,GACrCE,GAAU,OAAQD,EAAmB,CAAC,IACtCnO,GAAM,OAAOiO,EAAgBG,EAASR,GAY5C,OAVI3G,IAAWyG,GACXA,EAAQvC,UAERsC,IAASE,GACTA,EAAMxC,UAEViD,EAAQjD,UACR8C,EAAe9C,UACf+C,EAAa/C,UACbgD,EAAkBhD,UACXnL,CACX,C,wGCtBO,MAAMqO,GAAU,E,SAAAjQ,IAAG,CAAEkQ,SAR5B,SAAkBC,EAAMC,GACpB,MAAMC,GAAQ,QAAgBF,EAAM,OAAQ,WACtCG,GAAQ,QAAgBF,EAAM,OAAQ,WAC5C,KAAuBC,EAAMzQ,MAAO0Q,EAAM1Q,MAAO,yBAAyByQ,EAAMzQ,aAAa0Q,EAAM1Q,8CAEnG,MAAMmC,EAAS,CAAEoO,KAAME,EAAOD,KAAME,GACpC,OAAO,KAAOtO,UAAU,KAASD,EACrC,G,wGCGO,MAAMiF,GAAM,E,SAAAhH,IAAG,CAAEuQ,KAPxB,SAAcrQ,EAAGC,GACb,IAAIC,GAAK,QAAgBF,EAAG,IAAK,OAC7BG,GAAK,QAAgBF,EAAG,IAAK,QAChCC,EAAIC,IAAM,IAAAC,gBAAeF,EAAIC,GAC9B,MAAM0B,EAAS,CAAE7B,EAAGE,EAAID,EAAGE,GAC3B,OAAO,KAAO2B,UAAU,KAAKD,EACjC,G,6FCZO,MAAMyO,GAAQ,E,SAAAxQ,IAAG,CAAEyQ,OAL1B,SAAgB7P,GACZ,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,UAEnC,OAAO,KAAOoB,UAAU,KAAOD,EACnC,G,6FCCO,MAAM2O,GAAQ,E,SAAA1Q,IAAG,CAAE2Q,OAL1B,SAAgB/P,GACZ,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,UAEnC,OAAO,KAAOoB,UAAU,KAAOD,EACnC,G,wGCcO,MAAM6O,GAAW,E,SAAA5Q,IAAG,CAAE6Q,UAb7B,SAAmBjQ,EAAGkQ,EAASxN,GAC3B,MAAMnC,GAAK,QAAgBP,EAAG,IAAK,YAC7BmQ,GAAW,QAAgBD,EAAS,UAAW,YACrD,KAAyB,UAAb3P,EAAGtB,OAAmB,IAC9B,yDAAgCsB,EAAGtB,UACvC,KAAYyD,GAAQ,GAAG,IAAM,sCAAsCA,OACnE,KAAYyN,EAASzN,OAASnC,EAAGmC,MAA0B,IAAlByN,EAASzN,MAAY,IAC1D,gGAAkCnC,EAAGvB,yBAClCmR,EAASnR,WAChB,MAAMmC,EAAS,CAAEnB,EAAGO,EAAI2P,QAASC,GAC3BxO,EAAQ,CAAEe,QAChB,OAAO,KAAOtB,UAAU,KAAUD,EAAQQ,EAC9C,G,kFCtBO,MAAMyO,GAAkB,E,SAAAhR,IAAG,CAAEiR,iBALpC,SAA0BrQ,EAAGC,EAAQmE,EAAatD,EAASX,EAAKG,GAC5D,MAAMC,GAAK,QAAgBP,EAAG,IAAK,mBAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,mBAClD,OAAO,OAAoBmE,EAAa7D,EAAIC,EAASM,EAASX,EAAK,OAAQG,EAC/E,G,kFCAO,MAAMgQ,GAAkB,E,SAAAlR,IAAG,CAAEmR,iBALpC,SAA0BvQ,EAAGC,EAAQmE,EAAatD,EAASX,GACvD,MAAMI,GAAK,QAAgBP,EAAG,IAAK,mBAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,mBAClD,OAAO,IAAAuQ,GAAoBpM,EAAa7D,EAAIC,EAASM,EAASX,EAClE,G,wGCQO,MAAMsQ,GAAsC,IAAArR,IAAG,CAAEsR,qCAdxD,SAA8C1Q,EAAGqI,EAAIC,EAAaxH,EAASX,EAAKY,EAAY,CAAC,EAAG,GAAIT,GAChG,IAAIkC,EAAMxC,EACK,IAAXA,EAAEW,OACF6B,GAAM,OAAQxC,EAAG,CAAC,EAAGA,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,MAEzD,IAAIuJ,EAAOF,EACO,IAAdE,EAAK5H,OACL4H,GAAO,OAAQF,EAAI,CAAC,EAAGA,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,MAE9D,MAAMmC,EAAS,CAAEnB,EAAGwC,EAAK6F,GAAIE,GACvB5G,EAAQ,CAAEb,UAASX,MAAKG,kBAAiBS,YAAWuH,eAE1D,OAAO,KAAOlH,UAAU,KAAqCD,EAAQQ,EACzE,G,uECjBO,MAAMgP,GAAW,E,SAAAvR,IAAG,CAAEwR,UAH7B,SAAmB9L,GACf,OAAO,OAAOA,EAAS,EAC3B,G,wBCyBO,SAAS+L,EAAsBtC,EAAYjG,EAAaxH,EAASX,EAAKC,EAAa,OAAQW,GAQ9F,OAAO+P,EAAkBvC,EAFJ,IAAIjG,EADHiG,EAAW,IAGkBzN,EAASC,EAAWZ,EAAK,KAAyB,KADjF4Q,EAAwB3Q,GAEhD,CACO,SAAS4Q,EAAkBC,EAASrI,EAAY9H,EAASC,EAAWZ,EAAK+Q,EAAc9Q,EAAa,gBACvG,MAAO+Q,EAAcC,GAAeC,EAAgBzI,GACpD,IAAIN,EACJ,GAAmB,iBAAflI,EACAkI,EAAc,CAAC6I,EAAcC,EAAaH,EAAQ,GAAIA,EAAQ,QAE7D,IAAmB,kBAAf7Q,EAIL,MAAM,IAAIiF,MAAM,sBAAsBjF,KAHtCkI,EAAc,CAAC6I,EAAcC,EAAaH,EAAQ,GAAIA,EAAQ,GAIlE,CACA,OAAOH,EAAkBG,EAAS3I,EAAaxH,EAASC,EAAWZ,EAAK+Q,GAAc,EAAO9Q,EACjG,CAIO,SAASkR,EAAkBL,EAASrI,EAAY9H,EAASC,EAAWZ,EAAK+Q,EAAc9Q,EAAa,SACvG,MAAOmR,EAAaJ,EAAcC,GAAeI,EAAiB5I,GAClE,IAAIN,EACAmJ,EACJ,GAAmB,UAAfrR,EACAqR,EAAc,eACdnJ,EACI,CAACiJ,EAAaJ,EAAcC,EAAaH,EAAQ,GAAIA,EAAQ,QAEhE,IAAmB,UAAf7Q,EAML,MAAM,IAAIiF,MAAM,sBAAsBjF,KALtCqR,EAAc,gBACdnJ,EACI,CAACiJ,EAAaJ,EAAcC,EAAaH,EAAQ,GAAIA,EAAQ,GAIrE,CACA,OAAOS,EAAkBT,EAAS3I,EAAaxH,EAASC,EAAWZ,GAAK,EAAOsR,EAAaP,EAChG,CAKO,SAASJ,EAAkBG,EAAS3I,EAAaxH,EAASC,EAAWZ,EAAK+Q,EAAcS,GAAY,EAAOvR,EAAa,gBAC3H,IAAKwR,EAAWC,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAC/D,GAAmB,iBAAf3R,GACCwR,EAAWC,EAAUC,EAASC,GAAcd,MAE5C,IAAmB,kBAAf7Q,EAIL,MAAM,IAAIiF,MAAM,sBAAsBjF,MAHrCwR,EAAWG,EAAYF,EAAUC,GAAWb,CAIjD,CACA,MAAOE,EAAcC,EAAa,CAAEY,GAAkB1J,GAC/C2J,EAAcC,GAAeb,EAAgBvQ,IAC7CqR,EAAgBC,GAAiBf,EAAgBtQ,GAClDsR,EAAwBC,EAAuBnB,EAAcgB,GAC7DI,EAAuBD,EAAuBlB,EAAagB,IAC3D,QAAEI,EAAO,UAAEC,EAAS,SAAEC,GAkJhC,SAA0BvS,EAAK0R,EAAUC,EAASG,EAAcC,EAAaf,EAAcC,EAAaF,EAAc9Q,GAClH,IAAIoS,EACAC,EACAC,EACJ,GAAmB,kBAARvS,EAAkB,CAEzBqS,EAAU,CAAEG,IAAKxS,EAAKyS,OAAQzS,EAAK0S,KAAM1S,EAAK2S,MAAO3S,EAAK4S,KADjC,IAAR5S,EAAa,QAAU,UAExC,MAAMgH,EA9Dd,SAA8B8J,EAAS+B,EAAW9S,EAAQ+S,EAAS/B,GAChD,MAAX+B,IACAA,EAAUC,EAAkBjC,EAAS+B,EAAW9S,IAEpD,MAAMiT,EAAYlC,EAAQ,GACpBmC,EAAYnC,EAAQ,GACpBoC,EAAazG,GAAOuG,EAAYH,EAAY,EAAIC,GAAW/S,EAAS,EAAGgR,GACvEoC,EAAa1G,GAAOwG,EAAYJ,EAAY,EAAIC,GAAW/S,EAAS,EAAGgR,GAC7E,MAAO,CAACmC,EAAYC,EACxB,CAqDyBC,CAAqB,CAAC1B,EAAUC,GAAUX,EAAcc,EAAc9R,EAAK+Q,GAC5FuB,EAAYtL,EAAS,GACrBuL,EAAWvL,EAAS,EACxB,MACK,GAAY,SAARhH,EAAgB,CACrBsS,EAAY9F,KAAKc,KAAKoE,EAAWI,GACjCS,EAAW/F,KAAKc,KAAKqE,EAAUI,GAC/B,MAAMsB,EAAiB7G,KAAK8G,IAAI,GAAIhB,EAAY,GAAKR,EAAed,EAAeU,GAC7E6B,EAAgB/G,KAAK8G,IAAI,GAAIf,EAAW,GAAKR,EAAcd,EAAcU,GACzEa,EAAMhG,KAAKxG,MAAMqN,EAAiB,GAClCZ,EAASY,EAAiBb,EAC1BE,EAAOlG,KAAKxG,MAAMuN,EAAgB,GAExClB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBY,EAAgBb,EACQE,KAAM,OAChD,MACK,GAAY,UAAR5S,EACLqS,EAAU,CAAEG,IAAK,EAAGC,OAAQ,EAAGC,KAAM,EAAGC,MAAO,EAAGC,KAAM,SACxDN,EAAY9F,KAAKc,MAAMoE,EAAWV,EAAe,GAAKc,GACtDS,EAAW/F,KAAKc,MAAMqE,EAAUV,EAAc,GAAKc,OAElD,IAAmB,kBAAR/R,EAaZ,MAAMkF,MAAM,8BAA8BlF,KAbZ,CAC9B,MAAMwS,EAAqB,iBAAfvS,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GACzDyS,EAAwB,iBAAfxS,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC5D0S,EAAsB,iBAAfzS,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GAC1D2S,EAAuB,iBAAf1S,EAAgCD,EAAI,GAAG,GAAKA,EAAI,GAAG,GAIjEqS,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,QAAOC,KAHb,IAARJ,GAAwB,IAAXC,GAAyB,IAATC,GAAwB,IAAVC,EACxD,QACA,YAEJL,EAAY7F,GAAOiF,EAAWV,EAAewB,EAAMC,GAAUX,EAAe,EAAGf,GAC/EwB,EAAW9F,GAAOkF,EAAUV,EAAcyB,EAAOC,GAASZ,EAAc,EAAGhB,EAC/E,CAGA,CACA,MAAO,CAAEsB,UAASC,YAAWC,WACjC,CA7L6CiB,CAAiBxT,EAAK0R,EAAUC,EAASG,EAAcC,EAAaG,EAAuBE,EAAsBrB,EAAc9Q,GAClKwT,EAAcjC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAI7K,EAOJ,MANmB,kBAAf/G,EACA+G,EAAW,CAACyK,EAAWgC,EAAanB,EAAWC,GAE3B,iBAAftS,IACL+G,EAAW,CAACyK,EAAWa,EAAWC,EAAUkB,IAEzC,CACHhC,YACAxR,aACAyR,WACAC,UACAC,aACAU,YACAC,WACAkB,cACApB,UACAP,eACAC,cACAf,eACAC,cACAiB,wBACAE,uBACAJ,iBACAC,gBACAnB,UACA9J,WACAmB,cAER,CAKO,SAASoJ,EAAkBT,EAAS3I,EAAaxH,EAASC,EAAWZ,EAAKwR,GAAY,EAAOvR,EAAa,eAAgB8Q,GAC7H,IAAKU,EAAWpJ,EAASqJ,EAAUC,EAASC,GAAc,EAAE,GAAI,GAAI,GAAI,GAAI,GAC5E,GAAmB,iBAAf3R,GACCwR,EAAWpJ,EAASqJ,EAAUC,EAASC,GAAcd,MAErD,IAAmB,kBAAf7Q,EAIL,MAAM,IAAIiF,MAAM,sBAAsBjF,MAHrCwR,EAAWG,EAAYvJ,EAASqJ,EAAUC,GAAWb,CAI1D,CACA,MAAOM,EAAaJ,EAAcC,EAAa,CAAEY,GAAkB1J,GAC5DuL,EAAa5B,EAAcC,GAAeV,EAAiB1Q,IAC3DgT,EAAe3B,EAAgBC,GAAiBZ,EAAiBzQ,GAClEgT,EAAuBzB,EAAuBf,EAAauC,GAC3DzB,EAAwBC,EAAuBnB,EAAcgB,GAC7DI,EAAuBD,EAAuBlB,EAAagB,IAC3D,QAAEI,EAAO,SAAE/J,EAAQ,UAAEgK,EAAS,SAAEC,GAyI1C,SAA4BvS,EAAKqI,EAASqJ,EAAUC,EAAS+B,EAAa5B,EAAcC,EAAaX,EAAaJ,EAAcC,EAAaF,GACzI,IAAIsB,EACA/J,EACAgK,EACAC,EACJ,GAAmB,kBAARvS,EAAkB,CAEzBqS,EAAU,CACNG,IAAKxS,EACLyS,OAAQzS,EACR0S,KAAM1S,EACN2S,MAAO3S,EACP6T,MAAO7T,EACP8T,KAAM9T,EACN4S,KARqB,IAAR5S,EAAa,QAAU,UAUxC,MAAMgH,EAzGd,SAA8B8J,EAAS+B,EAAWY,EAAa1T,EAAQ+S,EAAS/B,GAC7D,MAAX+B,IACAA,EAAUC,EAAkBjC,EAAS+B,EAAW9S,IAEpD,MAAM8N,EAAaiD,EAAQ,GACrBkC,EAAYlC,EAAQ,GACpBmC,EAAYnC,EAAQ,GACpBiD,EAAetH,GAAOoB,EAAagF,EAAY,EAAIC,GAAW/S,EAAS,EAAGgR,GAC1EmC,EAAazG,GAAOuG,EAAYH,EAAY,EAAIC,GAAW/S,EAAS,EAAGgR,GACvEoC,EAAa1G,GAAOwG,EAAYJ,EAAY,EAAIC,GAAW/S,EAAS,EAAGgR,GAC7E,MAAO,CAACgD,EAAcb,EAAYC,EAAYM,EAClD,CA8FyBO,CAAqB,CAAC3L,EAASqJ,EAAUC,EAAS,GAAIP,EAAa,EAAGsC,EAAa1T,EAAK+Q,GACzGzI,EAAWtB,EAAS,GACpBsL,EAAYtL,EAAS,GACrBuL,EAAWvL,EAAS,EACxB,MACK,GAAY,SAARhH,EAAgB,CACrBsI,EAAWkE,KAAKc,KAAKjF,EAAUqL,GAC/BpB,EAAY9F,KAAKc,KAAKoE,EAAWI,GACjCS,EAAW/F,KAAKc,KAAKqE,EAAUI,GAC/B,MAAMkC,GAAiB3L,EAAW,GAAKoL,EAActC,EAAc/I,EAC7DgL,GAAkBf,EAAY,GAAKR,EAAed,EAAeU,EACjE6B,GAAiBhB,EAAW,GAAKR,EAAcd,EAAcU,EAC7DkC,EAAQrH,KAAKxG,MAAMiO,EAAgB,GACnCH,EAAOG,EAAgBJ,EACvBrB,EAAMhG,KAAKxG,MAAMqN,EAAiB,GAClCZ,EAASY,EAAiBb,EAC1BE,EAAOlG,KAAKxG,MAAMuN,EAAgB,GAExClB,EAAU,CAAEG,MAAKC,SAAQC,OAAMC,MADjBY,EAAgBb,EACQmB,QAAOC,OAAMlB,KAAM,OAC7D,KACK,IAAY,UAAR5S,EAeL,MAAMkF,MAAM,8BAA8BlF,KAd1CqS,EAAU,CACNG,IAAK,EACLC,OAAQ,EACRC,KAAM,EACNC,MAAO,EACPkB,MAAO,EACPC,KAAM,EACNlB,KAAM,SAEVtK,EAAWkE,KAAKc,MAAMjF,EAAU+I,EAAc,GAAKsC,GACnDpB,EAAY9F,KAAKc,MAAMoE,EAAWV,EAAe,GAAKc,GACtDS,EAAW/F,KAAKc,MAAMqE,EAAUV,EAAc,GAAKc,EAIvD,CACA,MAAO,CAAEM,UAAS/J,WAAUgK,YAAWC,WAC3C,CA/LuD2B,CAAmBlU,EAAKqI,EAASqJ,EAAUC,EAAS+B,EAAa5B,EAAcC,EAAa6B,EAAsB1B,EAAuBE,EAAsBrB,GAC5M0C,EAAcjC,EAAYK,EAAiBD,EAAaC,EAC9D,IAAI7K,EAOJ,MANmB,kBAAf/G,EACA+G,EAAW,CAACyK,EAAWgC,EAAanL,EAAUgK,EAAWC,GAErC,iBAAftS,IACL+G,EAAW,CAACyK,EAAWnJ,EAAUgK,EAAWC,EAAUkB,IAEnD,CACHhC,YACAxR,aACAoI,UACAqJ,WACAC,UACAC,aACAtJ,WACAgK,YACAC,WACAkB,cACApB,UACAqB,cACA5B,eACAC,cACAX,cACAJ,eACAC,cACA2C,uBACA1B,wBACAE,uBACAuB,gBACA3B,iBACAC,gBACAnB,UACA9J,WACAmB,cAER,CAuBO,SAAS4K,EAAkB3E,EAAYyE,EAAW9S,EAAQG,EAAW,GACxE,MAAMiU,EAAqBhC,EAAuBU,EAAW3S,GAC7D,OAAOsM,KAAKxG,OAAOoI,EAAW,IAAMrO,EAAS,GAAKA,EAASoU,GAAsB,EACrF,CACA,SAASjD,EAAgBkD,GACrB,MAAqB,kBAAVA,EACA,CAACA,EAAOA,EAAOA,GAEL,IAAjBA,EAAMzQ,OACC,CAACyQ,EAAM,GAAIA,EAAM,GAAI,GAEzBA,CACX,CACA,SAAS/C,EAAiB+C,GACtB,MAAwB,kBAAVA,EAAqB,CAACA,EAAOA,EAAOA,GAASA,CAC/D,CAYA,SAASjC,EAAuB1J,EAAYvI,GACxC,OAAIA,GAAY,EACLuI,EAEJA,GAAcA,EAAa,IAAMvI,EAAW,EACvD,CA0GA,SAASuM,EAAMH,EAAOyE,GAClB,IAAKA,EACD,OAAOvE,KAAK6H,MAAM/H,GAEtB,OAAQyE,GACJ,IAAK,QAED,OAAOvE,KAAKC,MAAMH,GACtB,IAAK,OAED,OAAOE,KAAKc,KAAKhB,GACrB,IAAK,QACD,OAAOE,KAAKxG,MAAMsG,GACtB,QACI,MAAM,IAAIpH,MAAM,wBAAwB6L,KAEpD,CACO,SAASuD,EAAkBF,GAC9B,MAAOG,EAAMC,EAAMC,GAAQvD,EAAgBkD,GAC3C,OAAgB,IAATG,GAAuB,IAATC,GAAuB,IAATC,CACvC,CACO,SAASC,EAA+B/T,EAASC,GACpD,OAAO0T,EAAkB3T,IAAY2T,EAAkB1T,EAC3D,CAQO,SAASgQ,EAAwB3Q,GACpC,GAAmB,SAAfA,EACA,MAAO,eAEN,GAAmB,SAAfA,EACL,MAAO,gBAGP,MAAM,IAAIiF,MAAM,sBAAsBjF,IAE9C,C,8VCtUO,MAAM0U,GAAgB,IAAA1V,IAAG,CAAE2V,eA9BlC,SAAwB1M,EAAI3G,EAAOkH,EAAY9H,EAASX,EAAKG,GACzD,MAAMuI,GAAM,QAAgBR,EAAI,KAAM,iBAChCS,GAAS,QAAgBpH,EAAO,QAAS,iBAC/C,IAAI2M,EAAOxF,EACPmM,EAAUlM,EACVwF,GAAe,EACC,IAAhBxF,EAAOnI,OACP2N,GAAe,EACfD,GAAO,OAAQxF,EAAK,CAAC,EAAGA,EAAI7J,MAAM,GAAI6J,EAAI7J,MAAM,GAAI6J,EAAI7J,MAAM,GAAI6J,EAAI7J,MAAM,KAC5EgW,GAAU,OAAQlM,EAAQ,CACtB,EAAGA,EAAO9J,MAAM,GAAI8J,EAAO9J,MAAM,GAAI8J,EAAO9J,MAAM,GAAI8J,EAAO9J,MAAM,MAG3E,KAA0B,IAAdqP,EAAK1N,MAAY,IACzB,0DAAG0N,EAAK1N,UACZ,KAA6B,IAAjBqU,EAAQrU,MAAY,IAC5B,6DAAGqU,EAAQrU,UACQ,MAAnBL,GACA,KAAY,KAAWH,IAAM,IACzB,8EAA0BG,iBAA+BH,OAEjE,MAAMgB,EAAS,CAAEkH,GAAIgG,EAAM3M,MAAOsT,GAC5BrT,EAAQ,CAAEiH,aAAY9H,UAASX,MAAKG,mBAEpCU,EAAM,KAAOI,UAAU,KAAeD,EAAQQ,GACpD,OAAI2M,GACO,OAAQtN,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAEtEgC,CACX,G,6FCjCO,MAAMiU,GAAQ,E,SAAA7V,IAAG,CAAE8V,OAL1B,SAAgBlV,GACZ,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,UAEnC,OAAO,KAAOoB,UAAU,KAAOD,EACnC,G,gHCgCO,MAAMgU,GAAM,IAAA/V,IAAG,CAAEgW,KAlCxB,SAAcC,EAASC,EAAYC,EAAYtW,EAAQ,WACjC,MAAdqW,IACAA,EAAaD,GAEjB,MAAMG,GAAO,OAAO,CAACH,EAASC,GAAarW,GACrCwW,EAAIJ,GAAWC,EAAaD,EAAUC,EAC5C,IAAK,IAAItR,EAAI,EAAGA,EAAIyR,IAAKzR,EACrBwR,EAAKE,IAAI,EAAG1R,EAAGA,GAEnB,MAAM2R,GAAM,OAAQH,EAAKI,WAAY,CAACP,EAASC,IAC/C,GAAkB,MAAdC,EACA,OAAOI,EAGP,GAA0B,IAAtBJ,EAAWzR,OACX,OAAO,QAAK,OAAW6R,EAAK,GAAI,CAACJ,EAAW,GAAI,EAAG,IAElD,GAA0B,IAAtBA,EAAWzR,OAEhB,OAAO,QAAK,QAAW,OAAW6R,EAAK,GAAI,GAAI,CAACJ,EAAW,GAAIA,EAAW,GAAI,EAAG,IAEhF,GAA0B,IAAtBA,EAAWzR,OAEhB,OAAO,QAAK,QAAW,QAAW,OAAW6R,EAAK,GAAI,GAAI,GAAI,CAC1DJ,EAAW,GAAIA,EAAW,GAAIA,EAAW,GAAI,EAAG,IAIpD,MAAM,IAAIlQ,MAEN,qEAA6BkQ,EAAWzR,WAGxD,G,yICgBO,MAAM+R,GAAY,IAAAzW,IAAG,CAAE0W,WAzB9B,SAAoB9V,EAAG4I,EAAY9H,EAASX,EAAKG,EAAiBF,EAAa,SAC3E,MAAMG,GAAK,QAAgBP,EAAG,IAAK,YAAa,WAChD,IAAI+V,EAAMxV,EACN+N,GAAe,EACH,IAAZ/N,EAAGI,OACH2N,GAAe,EACfyH,GAAM,OAAQxV,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,MAE1E,KAAyB,IAAb+W,EAAIpV,MAAY,IAAM,qDAAqDoV,EAAIpV,UAC3F,KAA2B,UAAfP,GAAwB,IAChC,gFAAyBA,MACN,MAAnBE,GACA,KAAY,KAAWH,IAAM,IACzB,0EAAmBG,iBAA+BH,OAE1D,MAAMgB,EAAS,CAAEnB,EAAG+V,GACdpU,EAAQ,CAAEiH,aAAY9H,UAASX,MAAKG,kBAAiBF,cAE3D,IAAIY,EAAM,KAAOI,UAAU,KAAWD,EAAQQ,GAE9C,OADAX,GAAM,OAAKA,EAAK+U,EAAI9W,OAChBqP,GACO,OAAQtN,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAEtEgC,CACX,G,oJCbO,MAAMgV,GAAU,IAAA5W,IAAG,CAAE6W,SA1B5B,SAAkBjW,EAAG4I,EAAY9H,EAASX,EAAKG,GAC3C,MAAMC,GAAK,QAAgBP,EAAG,IAAK,UAAW,WAE9C,KAAY,KAAyCc,EADnC,IACwD,IACtE,wEAAeA,wBACnB,IAAI0B,EAAMjC,EACNyC,GAAe,EACH,IAAZzC,EAAGI,OACHqC,GAAe,EACfR,GAAM,OAAQjC,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,MAE7D,KAAyB,IAAbwD,EAAI7B,MAAY,IAAM,mDAAmD6B,EAAI7B,UAClE,MAAnBL,GACA,KAAY,KAAWH,IAAM,IACzB,wEAAmBG,iBAA+BH,OAE1D,MAAMgB,EAAS,CAAEnB,EAAGwC,GACdb,EAAQ,CAAEiH,aAAY9H,UAASX,MAAKG,mBAE1C,IAAIU,EAAM,KAAOI,UAAU,KAASD,EAAQQ,GAE5C,OADAX,GAAM,OAAKA,EAAKT,EAAGtB,OACf+D,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,6FCnBO,MAAMkV,GAAS,E,SAAA9W,IAAG,CAAE+W,QAN3B,SAAiBnW,EAAGyB,EAAO,GACvB,MACMN,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,WAE7B2B,EAAQ,CAAEF,QAChB,OAAO,KAAOL,UAAU,KAAQD,EAAQQ,EAC5C,G,uECbO,MAAMyU,GAAW,E,SAAAhX,IAAG,CAAEiX,UAH7B,SAAmBvR,EAASrD,GACxB,OAAO,OAAOqD,EAASrD,EAC3B,G,uECtBO,MAAM6U,GAAW,E,SAAAlX,IAAG,CAAEmX,UAH7B,SAAmBzR,EAASrD,GACxB,OAAO,OAAOqD,EAASrD,EAC3B,G,wBCaO,SAAS+U,EAAiBvF,EAAS9J,GACtC,MAAMsP,EAASxF,EAAQnN,OACjB4S,EAAO,GACb,IAAK,IAAI1S,EAAI,EAAGA,EAAIyS,EAAQzS,IAAK,CAC7B,MAAMpC,EAAM6U,EAAS,EAAIzS,EACnB1E,EAAI2R,EAAQrP,IAAQ,GAChBuF,EAASA,EAASrD,OAAS,EAAIE,IAAM,GACvC,GAAW,IAAN1E,GACToX,EAAKC,QAAQ/U,EAErB,CACA,OAAO8U,CACX,CAKO,SAASE,EAAiB3F,EAAS9J,GACtC,MAAMK,EAAS,GACf,IAAK,IAAIxD,EAAI,EAAGA,EAAImD,EAASrD,OAAQE,IAAK,CACtC,MAAM6S,EAAQ5F,EAAQA,EAAQnN,OAASE,EAAI,GACrC8S,EAAU3P,EAASrD,OAASE,EAAI,EAChC+S,EAAS5P,EAAS2P,IACX,MAATD,GAA4B,IAAVA,GAAeE,EAAS,IAC1CvP,EAAOmP,QAAQG,EAEvB,CACA,OAAOtP,CACX,CACO,SAASwP,EAA2BC,EAAQC,GAC/C,MAAM1P,EAAS,GACT2P,EAAIxK,KAAK8G,IAAIwD,EAAOnT,OAAQoT,EAAOpT,QACzC,IAAK,IAAIE,EAAI,EAAGA,EAAImT,EAAGnT,IAAK,CACxB,IAAI1E,EAAI2X,EAAOA,EAAOnT,OAASE,EAAI,GAC1B,MAAL1E,IACAA,EAAI,GAER,IAAIC,EAAI2X,EAAOA,EAAOpT,OAASE,EAAI,GAInC,GAHS,MAALzE,IACAA,EAAI,GAEE,IAAND,EACAkI,EAAOmP,QAAQpX,QAEd,GAAU,IAANA,EACLiI,EAAOmP,QAAQrX,OAEd,IAAIA,IAAMC,EAAG,CAGd,MAAM8F,MADF,wDAAG4R,SAAcC,KAEzB,CAEI1P,EAAOmP,QAAQrX,EACnB,CACJ,CACA,OAAOkI,CACX,C,8MCXO,MAAM4P,GAAc,IAAAhY,IAAG,CAAEiY,aAnChC,SAAsBrX,EAAGhB,GACrB,IAAI0C,GAAQ,QAAgB1B,EAAG,cAAe,KAC9C,MAAMmO,EAASzM,EAAM1C,MACrB,GAAIA,EAAMsY,MAAK9K,KAAOA,EAAI,IAAMA,EAAI,IAAM,IACtC,MAAM,IAAInH,MAAM,2CAA2CrG,OAE/D,GAAIA,EAAM8E,OAASpC,EAAMf,KACrB,MAAM,IAAI0E,MAAM,+BAA+BrG,EAAM8E,uBAAuBpC,EAAMf,SAEtF,GAAI3B,EAAM8E,OAASpC,EAAMf,KAAM,CAC3B,MAAM4W,EAAW7V,EAAM1C,MAAMqF,QAC7B,KAAOkT,EAASzT,OAAS9E,EAAM8E,QAC3ByT,EAASZ,QAAQ,GAErBjV,GAAQ,OAAQA,EAAO6V,EAC3B,CACA,MAAMhJ,EAAa7M,EAAM1C,MACnBwY,EAAOzS,MAAM0S,KAAKzY,GACxB,IAAK,IAAIgF,EAAIhF,EAAM8E,OAAS,EAAGE,GAAK,EAAGA,IACnC,GAAIuK,EAAWvK,KAAOhF,EAAMgF,GACxBwT,EAAKxT,GAAK,OAET,GAAuB,IAAnBtC,EAAM1C,MAAMgF,GACjB,MAAM,IAAIqB,MAAM,mBAAmB8I,8BAAmCnP,OAI9E,GAAoB,IADPwY,EAAKtS,KAAI,CAACuQ,EAAGzR,IAAMyR,EAAI,EAAIzR,GAAK,IAAG/D,QAAO+D,GAAKA,GAAK,IACxDF,OACL,OAAO,OAAMpC,GAGjB,MAAMP,EAAS,CAAEnB,EAAG0B,GACdC,EAAQ,CAAE6V,QAChB,OAAO,KAAOpW,UAAU,KAAMD,EAAQQ,EAC1C,G,6FChCO,MAAM+V,GAAQ,E,SAAAtY,IAAG,CAAEuY,OAL1B,SAAgB3X,GACZ,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,UAEnC,OAAO,KAAOoB,UAAU,KAAOD,EACnC,G,mHCwBO,MAAMyW,GAAuB,IAAAxY,IAAG,CAAEyY,sBAxBzC,SAA+B7X,EAAGqI,EAAIC,EAAaxH,EAASX,GACxD,IAAI4V,EAAM/V,EACK,IAAXA,EAAEW,OACFoV,GAAM,OAAQ/V,EAAG,CAAC,EAAGA,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,GAAIgB,EAAEhB,MAAM,MAErE,IAAIqP,EAAOhG,EACO,IAAdgG,EAAK1N,OACL0N,GAAO,OAAQhG,EAAI,CAAC,EAAGA,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,MAE3E,KAAyB,IAAb+W,EAAIpV,MAAY,IACxB,iEAAGoV,EAAI/W,WACX,KAA0B,IAAdqP,EAAK1N,MAAY,IACzB,8DAAG0N,EAAKrP,WACZ,KAAmC,IAAvBsJ,EAAYxE,QAAc,IAClC,mEAAGwE,OACP,KAAYyN,EAAI/W,MAAM,KAAOsJ,EAAY,IAAI,IAAM,4CAA4CyN,EAAI/W,MAAM,yCACrEsJ,EAAY,QAChD,KAAY+F,EAAKrP,MAAM,KAAOsJ,EAAY,IAAI,IAAM,0CAA0C+F,EAAKrP,MAAM,2CACnEsJ,EAAY,SAClD,MAAMnH,EAAS,CAAEnB,EAAG+V,EAAK1N,GAAIgG,GACvB1M,EAAQ,CAAEb,UAASX,MAAKmI,eAE9B,OAAO,KAAOlH,UAAU,KAAwBD,EAAQQ,EAC5D,G,6FCxBO,MAAMmW,GAAO,E,SAAA1Y,IAAG,CAAE2Y,MALzB,SAAe/X,GACX,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,SAEnC,OAAO,KAAOoB,UAAU,KAAMD,EAClC,G,mHCmCO,MAAM6W,GAAM,IAAA5Y,IAAG,CAAE6Y,KAhCxB,SAAcC,EAAIC,GACd,MAAMC,GAAM,QAAgBF,EAAI,KAAM,OAChCG,GAAM,QAAgBF,EAAI,KAAM,OACtC,MAA0B,IAAbC,EAAIzX,MAA2B,IAAbyX,EAAIzX,QAA6B,IAAb0X,EAAI1X,MAA2B,IAAb0X,EAAI1X,OAAa,IAClF,+DAAGyX,EAAIzX,YAAY0X,EAAI1X,UAC3B,MAAM2X,EAAwB,IAAbF,EAAIzX,KAAayX,EAAI1V,KAAO0V,EAAIpZ,MAAM,GACjDuZ,EAAwB,IAAbF,EAAI1X,KAAa0X,EAAI3V,KAAO2V,EAAIrZ,MAAM,GAGvD,GAFA,KAAYsZ,IAAYC,GAAS,IAC7B,gEAAGD,SAAeC,OACL,IAAbH,EAAIzX,MAA2B,IAAb0X,EAAI1X,KAAY,CAClC,MAAM6X,GAAO,OAAQJ,EAAK,CAAC,GAAI,IACzBK,GAAO,OAAQJ,EAAK,EAAE,EAAG,IACzBK,GAAO,OAAOF,EAAMC,GAC1B,OAAO,OAAQC,EAAM,GACzB,CACK,GAAiB,IAAbN,EAAIzX,MAA2B,IAAb0X,EAAI1X,KAAY,CACvC,MAAM6X,GAAO,OAAQJ,EAAK,CAAC,GAAI,IACzBK,GAAO,OAAQJ,EAAK,CAACA,EAAIrZ,MAAM,GAAIqZ,EAAIrZ,MAAM,KAC7C0Z,GAAO,OAAOF,EAAMC,GAC1B,OAAO,OAAQC,EAAM,CAACA,EAAKhW,MAC/B,CACK,GAAiB,IAAb0V,EAAIzX,MAA2B,IAAb0X,EAAI1X,KAAY,CACvC,MAAM8X,GAAO,OAAQJ,EAAK,EAAE,EAAG,IACzBK,GAAO,OAAON,EAAKK,GACzB,OAAO,OAAQC,EAAM,CAACA,EAAKhW,MAC/B,CACK,CACD,MAAM+V,GAAO,OAAQJ,EAAK,CAACA,EAAIrZ,MAAM,GAAIqZ,EAAIrZ,MAAM,KAEnD,OADa,OAAOoZ,EAAKK,EAE7B,CACJ,G,wGCWO,MAAME,GAAiB,E,SAAAvZ,IAAG,CAAEwZ,gBAXnC,SAAyB5Y,EAAG6Y,EAAYC,GACpC,MAAMvY,GAAK,QAAgBP,EAAG,IAAK,kBAC7B+Y,EAAOF,EAAWG,QAAO,CAAC1Z,EAAGC,IAAMD,EAAIC,IAC7C,KAAYgB,EAAGI,MAAQ,EAAIkY,EAAW/U,QAAQ,IAAM,iBAAiBvD,EAAGI,+CAA+CkY,EAAW/U,WAClI,KAAYgV,EAAMhV,SAAW+U,EAAW/U,QAAQ,IAAM,mBAAmBgV,EAAMhV,oDAAoD+U,EAAW/U,WAC9I,KAAYvD,EAAGvB,MAAM,GAAK+Z,IAAS,GAAG,IAAM,yBAAyBxY,EAAGvB,MAAM,wEAC5C6Z,EAAWI,KAAK,cAAcF,MAChE,MAAM5X,EAAS,CAAEnB,EAAGO,GACdoB,EAAQ,CAAEkX,aAAYC,SAC5B,OAAO,KAAO1X,UAAU,KAAgBD,EAAQQ,EACpD,G,8JChBO,MAAMuX,GAAgB,IAAA9Z,IAAG,CAAE+Z,eAtBlC,SAAwBC,EAAYC,EAAYC,EAAU3P,EAAM6G,EAAG+I,GAC/D,MAAMC,GAAc,QAAgBJ,EAAY,aAAc,iBACxDK,GAAc,QAAgBJ,EAAY,aAAc,iBACxDK,GAAY,QAAgBJ,EAAU,WAAY,iBAClDK,GAAQ,QAAgBhQ,EAAM,OAAQ,iBACtCiQ,GAAK,QAAgBpJ,EAAG,IAAK,iBAC7BqJ,GAAK,QAAgBN,EAAG,IAAK,iBAC7BO,GAAW,OAAO,CAACH,EAAOE,GAAK,GAC/BE,GAAW,OAAOD,EAAUL,GAC5BzY,GAAM,OAAI+Y,EAAUL,GAEpB9H,EAAY5Q,EAAIhC,MAAM,GACtBgb,EAAYhZ,EAAIhC,MAAM,GAAK,EAC3Bib,EAAY,CAACrI,EAAWoI,GACxBhW,GAAI,OAAMhD,EAAK,CAAC,EAAG,GAAIiZ,GACvBvN,GAAI,OAAM1L,EAAK,CAAC,EAAGgZ,GAAYC,GAC/BC,GAAI,OAAMlZ,EAAK,CAAC,EAAe,EAAZgZ,GAAgBC,GACnCE,GAAI,OAAMnZ,EAAK,CAAC,EAAe,EAAZgZ,GAAgBC,GACnCG,GAAO,QAAI,QAAI,OAAQpW,IAAI,OAAK0I,KAAK,OAAIkN,GAAI,QAAQ,OAAIJ,EAAaU,MAE5E,MAAO,CAACE,GADK,QAAI,OAAKA,IAAO,OAAQD,IAEzC,G,6FCrBO,MAAMxU,GAAQ,E,SAAAvG,IAAG,CAAEib,OAP1B,SAAgBra,GACZ,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,QAAS,sBAI5C,OAAO,KAAOoB,UAAU,KAAUD,EACtC,G,8FCvBO,SAASmZ,KAAQhT,IACf,UAAMoE,QAAQ,UAGvB,CACO,SAAS6O,KAAOjT,IACd,UAAMoE,QAAQ,UAGvB,C,4FCiBO,MAAM8O,GAAc,E,SAAApb,IAAG,CAAEqb,aA5BhC,SAAsBza,EAAG+B,EAAMC,EAAUC,EAAQC,EAAOC,GACpD,MAAM5B,GAAK,QAAgBP,EAAG,IAAK,aAC7BoC,GAAQ,QAAgBL,EAAM,OAAQ,aACtCM,GAAY,QAAgBL,EAAU,WAAY,aACxD,IAAIM,EAIAC,EAkBJ,OArBa,MAATL,IACAI,GAAS,QAAgBJ,EAAO,QAAS,cAG/B,MAAVD,IACAM,GAAU,QAAgBN,EAAQ,SAAU,cAEhD,KAAwB,IAAZ1B,EAAGI,MAAY,IACvB,uDAAGJ,EAAGI,UACV,KAA2B,IAAfyB,EAAMzB,MAA6B,IAAfyB,EAAMzB,MAAY,IAC9C,oEAAYyB,EAAMzB,UACtB,KAA+B,IAAnB0B,EAAU1B,MAAiC,IAAnB0B,EAAU1B,MAAY,IACtD,wEAAgB0B,EAAU1B,UAChB,MAAV2B,GACA,KAA4B,IAAhBA,EAAO3B,MAA8B,IAAhB2B,EAAO3B,MAAY,IAChD,qEAAgB2B,EAAO3B,UAEhB,MAAX4B,GACA,KAA6B,IAAjBA,EAAQ5B,MAA+B,IAAjB4B,EAAQ5B,MAAY,IAClD,sEAAgB4B,EAAQ5B,WAEzB,OAAUJ,EAAI6B,EAAOC,EAAWE,EAASD,EAAQH,EAC5D,G,6FCOO,MAAMuY,GAAS,E,SAAAtb,IAAG,CAAEub,QAN3B,SAAiB3a,EAAGyB,EAAO,EAAGmZ,GAAY,EAAOC,GAAU,GACvD,MACM1Z,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,WAE7B2B,EAAQ,CAAEF,OAAMmZ,YAAWC,WACjC,OAAO,KAAOzZ,UAAU,KAAQD,EAAQQ,EAC5C,G,wGCOO,MAAMmZ,GAAgB,E,SAAA1b,IAAG,CAAE2b,eAflC,SAAwB/a,EAAGkQ,EAASxN,EAAMsY,GAAe,GACrD,MAAMza,GAAK,QAAgBP,EAAG,IAAK,iBAC7BmQ,GAAW,QAAgBD,EAAS,UAAW,iBACrD,KAAyB,UAAb3P,EAAGtB,OAAmB,IAC9B,8DAAgCsB,EAAGtB,UACvC,KAAYsB,EAAGI,MAAQ,GAAG,IACtB,sEAAQJ,EAAGI,UACf,KAAY+B,GAAQ,GAAG,IAAM,sCAAsCA,OACnE,KAAYyN,EAASzN,OAASnC,EAAGmC,MAA0B,IAAlByN,EAASzN,MAAY,IAC1D,+FAA8BnC,EAAGvB,yBAC9BmR,EAASnR,WAChB,MAAMmC,EAAS,CAAEnB,EAAGO,EAAI2P,QAASC,GAC3BxO,EAAQ,CAAEe,OAAMsY,gBACtB,OAAO,KAAO5Z,UAAU,KAAeD,EAAQQ,EACnD,G,6FC+CO,MAAMsZ,GAAS,E,SAAA7b,IAAG,CAAE8b,QALpB,SAAiBC,KAAarW,GACjC,MAAMG,EAAWH,EAAQI,KAAI,CAACC,EAAGnB,KAAM,QAAgBmB,EAAG,UAAUnB,IAAK,YACnErC,EAAQ,CAAEwZ,YAChB,OAAO,KAAO/Z,UAAU,KAAQ6D,EAAUtD,EAC9C,G,mHCnBO,MAAMyZ,GAAsB,IAAAhc,IAAG,CAAEic,qBApCxC,SAA8BlN,EAAQ9F,EAAIpI,EAAQa,EAASX,EAAKC,EAAa,OAAQE,GACjF,KAAY6N,EAAOrK,SAAWuE,EAAG1H,MAAM,IACnC,sBAAIwN,EAAOrK,2BAA2BuE,EAAG1H,qBAC7C,IAAI2a,EAAWnN,EACX5F,EAAOF,EACPrF,GAAe,EACH,IAAZqF,EAAG1H,OACHqC,GAAe,EACfuF,GAAO,OAAQF,EAAI,CAAC,EAAGA,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,KAC1Dsc,EAAW,CAAC,EAAGnN,EAAO,GAAIA,EAAO,GAAIA,EAAO,KAEhD,KAAgC,IAApBmN,EAASxX,QAAc,IAC/B,qEAAGwX,EAASxX,YAChB,KAA0B,IAAdyE,EAAK5H,MAAY,IACzB,4DAAQ4H,EAAK5H,SACjB,KAA4B,IAAhBV,EAAOU,MAAY,IAC3B,gEAAQV,EAAOU,SACnB,MAAM6H,EAAyB,SAAfpI,EAAwBkb,EAAS,GAAKA,EAAS,GACzD7S,EAA0B,SAAfrI,EAAwBmI,EAAKvJ,MAAM,GAAKuJ,EAAKvJ,MAAM,GACpE,KAAYwJ,IAAYvI,EAAOjB,MAAM,IAAI,IAAM,4CAA4CwJ,wCACvDvI,EAAOjB,MAAM,QACjD,KAAYyJ,IAAaxI,EAAOjB,MAAM,IAAI,IAAM,6CAA6CyJ,yCACxDxI,EAAOjB,MAAM,QAC3B,MAAnBsB,GACA,KAAY,KAAWH,IAAM,IACzB,+EAAmBG,iBAA+BH,OAE1D,MAAMgB,EAAS,CAAEkH,GAAIE,EAAMtI,UACrB0B,EAAQ,CAAEb,UAASX,MAAKC,aAAYE,kBAAiBiO,WAAY+M,GAEjEta,EAAM,KAAOI,UAAU,KAAqBD,EAAQQ,GAC1D,OAAIqB,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,wBCxDO,SAASua,EAAYhN,EAAYsK,EAAYE,EAAMyC,GAAe,GACrE,IAAIC,EAAW,GACf,GAAID,EACAC,EAAWA,EAAS1T,OAAO8Q,EAAWxU,MAAM,IAC5CoX,EAAS3V,KAAKyI,EAAW,GAAKwK,GAC9B0C,EAAWA,EAAS1T,OAAOwG,EAAWlK,MAAM,QAE3C,CACDoX,EAAWA,EAAS1T,OAAOwG,EAAW,IACtC,MAAMmN,EAAgB7C,EAAW/U,OACjC,IAAK,IAAIE,EAAI,EAAGA,EAAI0X,IAAiB1X,EACjCyX,EACIA,EAAS1T,OAAO,CAACwG,EAAWvK,EAAI,GAAK6U,EAAW7U,GAAI6U,EAAW7U,KAEvEyX,EAAWA,EAAS1T,OAAOwG,EAAWlK,MAAMqX,EAAgB,GAChE,CACA,OAAOD,CACX,CAUO,SAASE,EAAYC,EAAcC,EAAgBL,GAAe,GACrE,MAAMM,EAAW,GACjB,GAAIN,EAAc,CACdM,EAAShW,KAAK+V,GACd,IAAK,IAAI7X,EAAI6X,EAAiB,EAAG7X,EAAI4X,IAAgB5X,EAC7CA,GAAK,EAAI6X,GACTC,EAAShW,KAAK9B,GACd8X,EAAShW,KAAK9B,GAAK6X,EAAiB,KAGpCC,EAAShW,KAAK9B,EAG1B,KACK,CACD,MAAM+X,EAAsB,GACtBC,EAAqB,GAC3B,IAAK,IAAIhY,EAAI,EAAGA,EAAI4X,IAAgB5X,EAC5BA,GAAsB,EAAjB6X,EAAqB,GAAK7X,EAAI,IAAM,EACzCgY,EAAmBlW,KAAK9B,GAGxB+X,EAAoBjW,KAAK9B,GAGjC8X,EAAShW,QAAQiW,GACjBD,EAAShW,KAAK,GACdgW,EAAShW,QAAQkW,EACrB,CACA,OAAOF,CACX,CAUO,SAASG,EAAoB1N,EAAYsK,EAAYE,EAAMyC,GAAe,GAC7E,MAAMU,EAAmB,GACrBV,EACAU,EAAiBpW,KAAKyI,EAAW,GAAKwK,GAGtCmD,EAAiBpW,KAAKyI,EAAW,GAAKwK,GAE1C,IAAK,IAAI/U,EAAI,EAAGA,EAAIuK,EAAWzK,SAAUE,EACjCA,GAAK6U,EAAW/U,OACZ0X,EACAU,EAAiBpW,KAAK+S,EAAW7U,EAAI,GAAKuK,EAAWvK,IAGrDkY,EAAiBpW,KAAKyI,EAAWvK,GAAK6U,EAAW7U,EAAI,IAIzDkY,EAAiBpW,KAAKyI,EAAWvK,IAGzC,OAAOkY,CACX,CAKO,SAASC,EAAoBrD,EAAOD,GACvC,MAAMuD,EAAmB,CAAC,GAC1B,IAAK,IAAIpY,EAAI,EAAGA,EAAI6U,IAAc7U,EAC9BoY,EAAiBtW,KAAKgT,EAAM9U,GAAG,IAEnC,OAAOoY,CACX,CAYO,SAASC,EAAaC,EAAgBxD,EAAOD,GAChD,MAAMoB,EAAYqC,EAAejY,MAAM,EAAG,GAC1C,IAAK,IAAIL,EAAI,EAAGA,EAAI6U,IAAc7U,EAC9BiW,EAAUnU,KAAKwW,EAAetY,EAAI,GAAK8U,EAAM9U,GAAG,GAAK8U,EAAM9U,GAAG,IAElE,OAAOiW,CACX,C,wOCzGO,MAAMsC,GAAqC,IAAAnd,IAAG,CAAEod,oCAjBvD,SAA6CrO,EAAQ9F,EAAIpI,EAAQa,EAASX,EAAKY,EAAY,CAAC,EAAG,GAAIT,GAC/F,IAAIiI,EAAOF,EACPrF,GAAe,EACH,IAAZqF,EAAG1H,OACHqC,GAAe,EACfuF,GAAO,OAAQF,EAAI,CAAC,EAAGA,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,GAAIqJ,EAAGrJ,MAAM,MAE9D,MAAMmC,EAAS,CAAEkH,GAAIE,EAAMtI,UACrB0B,EAAQ,CAAEb,UAASX,MAAKG,kBAAiBS,YAAWwN,WAAYJ,GAChEnN,EAEN,KAAOI,UAAU,KAAoCD,EAAQQ,GAC7D,OAAIqB,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,6FCCO,MAAMyb,GAAM,E,SAAArd,IAAG,CAAEsd,KALxB,SAAc1c,GACV,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,QAEnC,OAAO,KAAOoB,UAAU,IAAKD,EACjC,G,6FCoBO,MAAMwb,GAAM,E,SAAAvd,IAAG,CAAEwd,KAPxB,SAAc5c,EAAGyB,EAAO,KAAMkC,GAAW,GACrC,MACMxC,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,MAAO,SAEpC2B,EAAQ,CAAEF,OAAMkC,YACtB,OAAO,KAAOvC,UAAU,KAAKD,EAAQQ,EACzC,G,mHCIO,MAAMuE,GAAM,E,SAAA9G,IAAG,CAAEyd,KAZxB,SAAcvd,EAAGC,GACb,IAAIC,GAAK,QAAgBF,EAAG,IAAK,OAC7BG,GAAK,QAAgBF,EAAG,IAAK,OAEjC,IADCC,EAAIC,IAAM,IAAAC,gBAAeF,EAAIC,GACb,UAAbD,EAAGP,OAAkC,UAAbQ,EAAGR,MAC3B,OAAO,OAASO,EAAIC,GAExB,MAAM0B,EAAS,CAAE7B,EAAGE,EAAID,EAAGE,GAG3B,OAAO,KAAO2B,UAAU,KAASD,EAFnB,CAAC,EAGnB,G,yICwBO,MAAM2b,GAAS,IAAA1d,IAAG,CAAE2d,QA1B3B,SAAiB/c,EAAGC,EAAQa,EAASX,EAAKC,EAAa,QAASW,EAAY,CAAC,EAAG,EAAG,IAC/E,MAAMR,GAAK,QAAgBP,EAAG,IAAK,UAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,UAClD,IAAI8V,EAAMxV,EACN+N,GAAe,EACH,IAAZ/N,EAAGI,OACH2N,GAAe,EACfyH,GAAM,OAAQxV,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,MAE1E,KAAyB,IAAb+W,EAAIpV,MAAY,IAAM,uDAAuDoV,EAAIpV,UAC7F,KAA6B,IAAjBH,EAAQG,MAAY,IAC5B,wDAAGH,EAAQG,UACf,KAAYoV,EAAI/W,MAAM,KAAOwB,EAAQxB,MAAM,IAAI,IAAM,oCAAoC+W,EAAI/W,MAAM,yCACrEwB,EAAQxB,MAAM,QAC5C,MAAY,QAA+B8B,EAASC,IAAY,IAC5D,uEAAeD,oBAA0BC,OAC7C,KAA2B,UAAfX,GAAwB,IAAM,sCAAsCA,6CAChF,MAAMe,EAAS,CAAEnB,EAAG+V,EAAK9V,OAAQO,GAC3BmB,EAAQ,CAAEb,UAASX,MAAKC,aAAYW,aAEpCC,EAAM,KAAOI,UAAU,KAAQD,EAAQQ,GAC7C,OAAI2M,GACO,OAAQtN,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAEtEgC,CACX,G,8HCHO,MAAMgc,GAAa,IAAA5d,IAAG,CAAE6d,YAxB/B,SAAqBjd,EAAGC,EAAQa,EAASX,EAAKY,EAAY,CAAC,EAAG,GAAIX,EAAa,QAC3E,MAAMG,GAAK,QAAgBP,EAAG,IAAK,cAC7BQ,GAAU,QAAgBP,EAAQ,SAAU,cAClD,KAAwB,IAAZM,EAAGI,MAA0B,IAAZJ,EAAGI,MAAY,IACxC,gEAAGJ,EAAGI,UACV,KAA6B,IAAjBH,EAAQG,MAAY,IAC5B,4DAAGH,EAAQG,UACf,KAA2B,SAAfP,GAAuB,IAC/B,gFAAyBA,MAC7B,IAAIoC,EAAMjC,EACNyC,GAAe,EACH,IAAZzC,EAAGI,OACH6B,GAAM,OAAQjC,EAAI,CAAC,EAAGA,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,GAAIuB,EAAGvB,MAAM,KACzDgE,GAAe,GAEnB,MAAM7B,EAAS,CAAEnB,EAAGwC,EAAKvC,OAAQO,GAC3BmB,EAAQ,CAAEb,UAASX,MAAKY,aAExBC,EAAM,KAAOI,UAAU,KAAYD,EAAQQ,GACjD,OAAIqB,GACO,OAAQhC,EAAK,CAACA,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,GAAIgC,EAAIhC,MAAM,KAExDgC,CACX,G,mHChCO,MAAMkc,GAAM,E,SAAA9d,IAAG,CAAE+d,KATxB,SAAcnd,GACV,IAAIO,GAAK,QAAgBP,EAAG,IAAK,OACjC,KAAyB,UAAbO,EAAGtB,OAAkC,YAAbsB,EAAGtB,OAAqB,IAAM,8CACjD,UAAbsB,EAAGtB,QACHsB,GAAK,OAAKA,EAAI,YAElB,MAAMY,EAAS,CAAEnB,EAAGO,GACpB,OAAO,KAAOa,UAAU,KAAKD,EACjC,G,wGCAO,MAAMic,GAAc,E,SAAAhe,IAAG,CAAEie,aARhC,SAAsBrd,EAAGsd,EAAcC,GACnC,MAAMhd,GAAK,QAAgBP,EAAG,IAAK,eACnC,KAAasd,GAAgBC,GAAe,IAAM,uBAAuBD,yCACvCC,QAClC,MAAMpc,EAAS,CAAEnB,EAAGO,GACdoB,EAAQ,CAAE2b,eAAcC,gBAC9B,OAAO,KAAOnc,UAAU,IAAaD,EAAQQ,EACjD,G,6JC+BO,MAAM6b,GAAkB,IAAApe,IAAG,CAAEqe,iBArB7B,SAA0BC,EAAQC,EAAaC,GAClD,MAAMC,GAAU,QAAgBH,EAAQ,SAAU,mBAC5CI,GAAe,QAAgBH,EAAa,cAAe,mBACjE,KAA0B,MAAdC,GAAsBA,EAAa,GAAKG,OAAOC,UAAUJ,IAAa,IAC9E,+DAAWA,MACf,KAA6B,IAAjBC,EAAQld,MAAY,IAAM,gDAAgDkd,EAAQld,SAC9F,KAAkC,IAAtBmd,EAAand,MAAY,IACjC,qDAAWmd,EAAand,SAC5B,KAAYkd,EAAQ7e,MAAM,KAAO8e,EAAa9e,MAAM,IAAI,IACpD,uCAAG6e,EAAQ7e,MAAM,UAAU8e,EAAa9e,MAAM,wEAElD,KAAY4e,EAAa,GAAKG,OAAOC,UAAUJ,IAAa,IACxD,4DAAGA,MAGP,MAAMK,GAAe,QAAO,EAAA1Q,EAAA,GAAKsQ,EAAS,SAAUD,GAC9CM,GAAoB,QAAO,EAAA3Q,EAAA,GAAKuQ,EAAc,SAAUF,GACxDO,GAAgB,EAAAC,EAAA,GAAUH,GAC1BI,GAAU,OAAOF,EAAeD,GACtC,OAAO,EAAA3Q,EAAA,GAAK8Q,EAAS,QACzB,G,6FCnCO,MAAMC,GAAM,E,SAAAlf,IAAG,CAAEmf,KALxB,SAAcve,GACV,MACMmB,EAAS,CAAEnB,GADN,QAAgBA,EAAG,IAAK,QAEnC,OAAO,KAAOoB,UAAU,KAAKD,EACjC,G","sources":["webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/abs.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/exp.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/diag.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/all.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/acos.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/equal.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/add_n.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/concat.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_grad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/browser.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/atan.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/cast.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/complex.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/add.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/eye.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/asin.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/dot.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/clone.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/log.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/einsum.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/elu.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/any.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/div.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/erf.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/confusion_matrix.js","webpack://StylistWidget/./node_modules/@tensorflow/tfjs-core/dist/ops/cos.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { TensorBuffer } from '../tensor';\nimport * as util from '../util';\n/**\n * Creates an empty `tf.TensorBuffer` with the specified `shape` and `dtype`.\n *\n * The values are stored in CPU as `TypedArray`. Fill the buffer using\n * `buffer.set()`, or by modifying directly `buffer.values`.\n *\n * When done, call `buffer.toTensor()` to get an immutable `tf.Tensor` with\n * those values.\n *\n * ```js\n * // Create a buffer and set values at particular indices.\n * const buffer = tf.buffer([2, 2]);\n * buffer.set(3, 0, 0);\n * buffer.set(5, 1, 0);\n *\n * // Convert the buffer back to a tensor.\n * buffer.toTensor().print();\n * ```\n *\n * @param shape An array of integers defining the output tensor shape.\n * @param dtype The dtype of the buffer. Defaults to 'float32'.\n * @param values The values of the buffer as `TypedArray`. Defaults to\n * zeros.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nexport function buffer(shape, dtype = 'float32', values) {\n    dtype = dtype || 'float32';\n    util.assertNonNegativeIntegerDimensions(shape);\n    return new TensorBuffer(shape, dtype, values);\n}\n//# sourceMappingURL=buffer.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { div } from './div';\nimport { equal } from './equal';\nimport { op } from './operation';\nimport { where } from './where';\nimport { zerosLike } from './zeros_like';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting. Return 0\n * if denominator is 0.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n * const c = tf.tensor1d([0, 0, 0, 0]);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n * const c = tf.scalar(0);\n *\n * a.divNoNan(b).print();  // or tf.divNoNan(a, b)\n * a.divNoNan(c).print();  // or tf.divNoNan(a, c)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction divNoNan_(a, b) {\n    // TODO: Make this into its own kernel.\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const divResult = div($a, $b);\n    const zeros = zerosLike(divResult);\n    const bEqualsZero = equal($b, zeros);\n    return where(bEqualsZero, zeros, divResult);\n}\nexport const divNoNan = op({ divNoNan_ });\n//# sourceMappingURL=div_no_nan.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { conv2d } from './conv2d';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 1D convolution over the input x.\n *\n * @param x The input tensor, of rank 3 or rank 2, of shape\n *     `[batch, width, inChannels]`. If rank 2, batch of 1 is assumed.\n * @param filter The filter, rank 3, of shape\n *     `[filterWidth, inDepth, outDepth]`.\n * @param stride The number of entries by which the filter is moved right at\n *     each step.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat An optional string from \"NWC\", \"NCW\". Defaults to \"NWC\",\n *     the data is stored in the order of [batch, in_width, in_channels]. Only\n *     \"NWC\" is currently supported.\n * @param dilation The dilation rate in which we sample input values in\n *     atrous convolution. Defaults to `1`. If it is greater than 1, then\n *     stride must be `1`.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv1d_(x, filter, stride, pad, dataFormat = 'NWC', dilation = 1, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv1d');\n    const $filter = convertToTensor(filter, 'filter', 'conv1d');\n    let x3D = $x;\n    let reshapedTo3D = false;\n    if ($x.rank === 2) {\n        reshapedTo3D = true;\n        x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);\n    }\n    util.assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);\n    util.assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv1d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    util.assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match ` +\n        `input depth for filter ${$filter.shape[1]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(stride, dilation), () => 'Error in conv1D: Either stride or dilation must be 1. ' +\n        `Got stride ${stride} and dilation '${dilation}'`);\n    util.assert(dataFormat === 'NWC', () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);\n    const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);\n    const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);\n    const strides = [1, stride];\n    const dilations = [1, dilation];\n    const conv2dDataFormat = 'NHWC';\n    const res = conv2d(input4D, filter4D, strides, pad, conv2dDataFormat, dilations, dimRoundingMode);\n    if (reshapedTo3D) {\n        return reshape(res, [res.shape[2], res.shape[3]]);\n    }\n    return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);\n}\nexport const conv1d = op({ conv1d_ });\n//# sourceMappingURL=conv1d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Abs, ComplexAbs } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes absolute value element-wise: `abs(x)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.abs().print();  // or tf.abs(x)\n * ```\n * @param x The input `tf.Tensor`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction abs_(x) {\n    const $x = convertToTensor(x, 'x', 'abs');\n    if ($x.dtype === 'complex64') {\n        const inputs = { x: $x };\n        return ENGINE.runKernel(ComplexAbs, inputs);\n    }\n    else {\n        const inputs = { x: $x };\n        return ENGINE.runKernel(Abs, inputs);\n    }\n}\nexport const abs = op({ abs_ });\n//# sourceMappingURL=abs.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Exp } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` element-wise. `e ^ x`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.exp().print();  // or tf.exp(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction exp_(x) {\n    const $x = convertToTensor(x, 'x', 'exp');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Exp, inputs);\n}\nexport const exp = op({ exp_ });\n//# sourceMappingURL=exp.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ExpandDims } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Returns a `tf.Tensor` that has expanded rank, by inserting a dimension\n * into the tensor's shape.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n * const axis = 1;\n * x.expandDims(axis).print();\n * ```\n *\n * @param x The input tensor whose dimensions to be expanded.\n * @param axis The dimension index at which to insert shape of `1`. Defaults\n *     to 0 (the first dimension).\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction expandDims_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'expandDims', 'string_or_numeric');\n    util.assert(axis <= $x.rank, () => 'Axis must be <= rank of the tensor');\n    const inputs = { input: $x };\n    const attrs = { dim: axis };\n    return ENGINE.runKernel(ExpandDims, inputs, attrs);\n}\nexport const expandDims = op({ expandDims_ });\n//# sourceMappingURL=expand_dims.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { FusedBatchNorm } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { xAs4D } from './batchnorm_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Batch normalization.\n *\n * As described in\n * [http://arxiv.org/abs/1502.03167](http://arxiv.org/abs/1502.03167).\n *\n * Mean, variance, scale, and offset can be of two shapes:\n *   - The same shape as the input.\n *   - In the common case, the depth dimension is the last dimension of x, so\n *     the values would be an `tf.Tensor1D` of shape [depth].\n *\n * Also available are stricter rank-specific methods with the same signature\n * as this method that assert that parameters passed are of given rank\n *   - `tf.batchNorm2d`\n *   - `tf.batchNorm3d`\n *   - `tf.batchNorm4d`\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\nfunction batchNorm_(x, mean, variance, offset, scale, varianceEpsilon) {\n    if (varianceEpsilon == null) {\n        varianceEpsilon = 0.001;\n    }\n    const $x = convertToTensor(x, 'x', 'batchNorm');\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n    let $scale;\n    if (scale != null) {\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    let $offset;\n    if (offset != null) {\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($mean.rank === $variance.rank, () => 'Batch normalization gradient requires mean and variance to have ' +\n        'equal ranks.');\n    util.assert($offset == null || $mean.rank === $offset.rank, () => 'Batch normalization gradient requires mean and offset to have ' +\n        'equal ranks.');\n    util.assert($scale == null || $mean.rank === $scale.rank, () => 'Batch normalization gradient requires mean and scale to have ' +\n        'equal ranks.');\n    const x4D = xAs4D($x);\n    const inputs = {\n        x: x4D,\n        scale: $scale,\n        offset: $offset,\n        mean: $mean,\n        variance: $variance\n    };\n    const attrs = { varianceEpsilon };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);\n    return reshape(res, $x.shape);\n}\nexport const batchNorm = op({ batchNorm_ });\n//# sourceMappingURL=batchnorm.js.map","import { reshape } from './reshape';\nexport function xAs4D(x) {\n    let x4D;\n    if (x.rank === 0 || x.rank === 1) {\n        x4D = reshape(x, [1, 1, 1, x.size]);\n    }\n    else if (x.rank === 2) {\n        x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);\n    }\n    else if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    else {\n        x4D = x;\n    }\n    return x4D;\n}\n//# sourceMappingURL=batchnorm_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Diag } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns a diagonal tensor with a given diagonal values.\n *\n * Given a diagonal, this operation returns a tensor with the diagonal and\n * everything else padded with zeros.\n *\n * Assume the input has dimensions `[D1,..., Dk]`, then the output is a tensor\n * of rank 2k with dimensions `[D1,..., Dk, D1,..., Dk]`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4]);\n *\n * tf.diag(x).print()\n * ```\n * ```js\n * const x = tf.tensor1d([1, 2, 3, 4, 5, 6, 6, 8], [4, 2])\n *\n * tf.diag(x).print()\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction diag_(x) {\n    const $x = convertToTensor(x, 'x', 'diag');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Diag, inputs);\n}\nexport const diag = op({ diag_ });\n//# sourceMappingURL=diag.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNative } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Depthwise 2D convolution.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction depthwiseConv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'depthwiseConv2d');\n    const $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got ` +\n        `rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(x4D.shape[3] === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels ` +\n        `(${x4D.shape[3]}) must match the inChannels dimension in ` +\n        `filter ${$filter.shape[2]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in depthwiseConv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2d = op({ depthwiseConv2d_ });\n//# sourceMappingURL=depthwise_conv2d.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ArgMax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the indices of the maximum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMax().print();  // or tf.argMax(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMax(axis).print();  // or tf.argMax(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMax_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'argMax');\n    const inputs = { x: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(ArgMax, inputs, attrs);\n}\nexport const argMax = op({ argMax_ });\n//# sourceMappingURL=arg_max.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nexport const ERF_P = 0.3275911;\nexport const ERF_A1 = 0.254829592;\nexport const ERF_A2 = -0.284496736;\nexport const ERF_A3 = 1.421413741;\nexport const ERF_A4 = -1.453152027;\nexport const ERF_A5 = 1.061405429;\n//# sourceMappingURL=erf_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { All } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the logical and of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.all().print();  // or tf.all(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.all(axis).print();  // or tf.all(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction all_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'all', 'bool');\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(All, inputs, attrs);\n}\nexport const all = op({ all_ });\n//# sourceMappingURL=all.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\nexport function assertParamsConsistent(shapes, axis) {\n    const rank = shapes[0].length;\n    shapes.forEach((shape, i) => {\n        util.assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same ` +\n            `as the rank of the rest (${rank})`);\n    });\n    util.assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);\n    const firstShape = shapes[0];\n    shapes.forEach((shape, i) => {\n        for (let r = 0; r < rank; r++) {\n            util.assert((r === axis) || (shape[r] === firstShape[r]), () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) ` +\n                `does not match the shape of the rest (${firstShape}) ` +\n                `along the non-concatenated axis ${i}.`);\n        }\n    });\n}\nexport function computeOutShape(shapes, axis) {\n    const outputShape = shapes[0].slice();\n    for (let i = 1; i < shapes.length; i++) {\n        outputShape[axis] += shapes[i][axis];\n    }\n    return outputShape;\n}\n//# sourceMappingURL=concat_util.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Acos } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes acos of the input `tf.Tensor` element-wise: `acos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.acos().print();  // or tf.acos(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acos_(x) {\n    const $x = convertToTensor(x, 'x', 'acos');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Acos, inputs);\n}\nexport const acos = op({ acos_ });\n//# sourceMappingURL=acos.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Equal } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\n/**\n * Returns the truth value of (a == b) element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n * const b = tf.tensor1d([2, 2, 2]);\n *\n * a.equal(b).print();\n * ```\n *\n * @param a The first input tensor.\n * @param b The second input tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Logical'}\n */\nfunction equal_(a, b) {\n    let $a = convertToTensor(a, 'a', 'equal');\n    let $b = convertToTensor(b, 'b', 'equal');\n    [$a, $b] = makeTypesMatch($a, $b);\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Equal, inputs);\n}\nexport const equal = op({ equal_ });\n//# sourceMappingURL=equal.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { batchNorm } from './batchnorm';\nimport { op } from './operation';\n/**\n * Batch normalization, strictly for 2D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm2d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    const $x = convertToTensor(x, 'x', 'batchNorm');\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n    let $scale;\n    if (scale != null) {\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    let $offset;\n    if (offset != null) {\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ` +\n        `${$x.rank}.`);\n    util.assert($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but ` +\n        `got rank ${$mean.rank}.`);\n    util.assert($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 ` +\n        `but got rank ${$variance.rank}.`);\n    if ($scale != null) {\n        util.assert($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 ` +\n            `but got rank ${$scale.rank}.`);\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 ` +\n            `but got rank ${$offset.rank}.`);\n    }\n    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\nexport const batchNorm2d = op({ batchNorm2d_ });\n//# sourceMappingURL=batchnorm2d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AddN } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Adds a list of `tf.Tensor`s element-wise, each with the same shape and dtype.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n *\n * tf.addN([a, b, c]).print();\n * ```\n * @param tensors A list of tensors with the same shape and dtype.\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction addN_(tensors) {\n    util.assert(Array.isArray(tensors), () => 'The argument passed to tf.addN() must be a list of tensors');\n    util.assert(tensors.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ` +\n        `${tensors.length}`);\n    const $tensors = tensors.map((t, i) => convertToTensor(t, `tensors${i}`, 'addN'));\n    const firstTensor = $tensors[0];\n    $tensors.forEach(t => {\n        if (t.dtype !== firstTensor.dtype) {\n            throw new Error('All tensors passed to tf.addN() must have the same dtype');\n        }\n    });\n    $tensors.forEach(t => {\n        if (!util.arraysEqual(t.shape, firstTensor.shape)) {\n            throw new Error('All tensors passed to tf.addN() must have the same shape');\n        }\n    });\n    const inputs = $tensors;\n    return ENGINE.runKernel(AddN, inputs);\n}\nexport const addN = op({ addN_ });\n//# sourceMappingURL=add_n.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { add } from './add';\nimport { div } from './div';\nimport { getNoiseShape } from './dropout_util';\nimport { floor } from './floor';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { randomUniform } from './random_uniform';\n/**\n * Computes dropout.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 2, 1]);\n * const rate = 0.75;\n * const output = tf.dropout(x, rate);\n * output.print();\n * ```\n *\n * @param x A floating point Tensor or TensorLike.\n * @param rate A float in the range [0, 1). The probability that each element\n *   of x is discarded.\n * @param noiseShape An array of numbers of type int32, representing the\n * shape for randomly generated keep/drop flags. If the noiseShape has null\n * value, it will be automatically replaced with the x's relative dimension\n * size. Optional.\n * @param seed Used to create random seeds. Optional.\n * @returns A Tensor of the same shape of x.\n *\n * @doc {heading: 'Operations', subheading: 'Dropout'}\n */\nfunction dropout_(x, rate, noiseShape, seed) {\n    const $x = convertToTensor(x, 'x', 'dropout');\n    util.assert($x.dtype === 'float32', () => `x has to be a floating point tensor since it's going to be ` +\n        `scaled, but got a ${$x.dtype} tensor instead.`);\n    util.assert(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);\n    if (rate === 0) {\n        return x instanceof Tensor ? $x.clone() : $x;\n    }\n    const $noiseShape = getNoiseShape($x, noiseShape);\n    const keepProb = 1 - rate;\n    const multiplier = div(floor(add(randomUniform($noiseShape, 0, 1, 'float32', seed), keepProb)), keepProb);\n    return mul($x, multiplier);\n}\nexport const dropout = op({ dropout_ });\n//# sourceMappingURL=dropout.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\n/**\n * Normalize noise shape based on provided tensor and noise shape.\n *\n * @param x Tensor.\n * @param noiseShape The shape for the randomly generated keep/drop flags, as\n *   an array of numbers. Optional.\n * @returns Normalized noise shape.\n */\nexport function getNoiseShape(x, noiseShape) {\n    if (noiseShape == null) {\n        return x.shape.slice();\n    }\n    if (util.arraysEqual(x.shape, noiseShape)) {\n        return noiseShape;\n    }\n    if (x.shape.length === noiseShape.length) {\n        const newDimension = [];\n        for (let i = 0; i < x.shape.length; i++) {\n            if (noiseShape[i] == null && x.shape[i] != null) {\n                newDimension.push(x.shape[i]);\n            }\n            else {\n                newDimension.push(noiseShape[i]);\n            }\n        }\n        return newDimension;\n    }\n    return noiseShape;\n}\n//# sourceMappingURL=dropout_util.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of`tf.Tensor2D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *\n * B: shape(2, 3) = | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * C = tf.concat2d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 3) = | r1, g1, b1 |\n *                  | r2, g2, b2 |\n *                  | r3, g3, b3 |\n *                  | r4, g4, b4 |\n *\n * if axis = 1:\n * C = shape(2, 6) = | r1, g1, b1, r3, g3, b3 |\n *                   | r2, g2, b2, r4, g4, b4 |\n *\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concatenate along.\n * @return The concatenated array.\n */\nfunction concat2d_(tensors, axis) {\n    return concat(tensors, axis);\n}\nexport const concat2d = op({ concat2d_ });\n//# sourceMappingURL=concat_2d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as util from '../util';\n/**\n * Returns true if the axis specifies the inner most dimensions of the\n * array.\n */\nexport function axesAreInnerMostDims(axes, rank) {\n    for (let i = 0; i < axes.length; ++i) {\n        if (axes[axes.length - i - 1] !== rank - 1 - i) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function combineLocations(outputLoc, reduceLoc, axes) {\n    const rank = outputLoc.length + reduceLoc.length;\n    const loc = [];\n    let outIdx = 0;\n    let reduceIdx = 0;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            loc.push(outputLoc[outIdx++]);\n        }\n        else {\n            loc.push(reduceLoc[reduceIdx++]);\n        }\n    }\n    return loc;\n}\nexport function computeOutAndReduceShapes(aShape, axes) {\n    const outShape = [];\n    const rank = aShape.length;\n    for (let dim = 0; dim < rank; dim++) {\n        if (axes.indexOf(dim) === -1) {\n            outShape.push(aShape[dim]);\n        }\n    }\n    const reduceShape = axes.map(dim => aShape[dim]);\n    return [outShape, reduceShape];\n}\nexport function expandShapeToKeepDim(shape, axes) {\n    const reduceSubShape = axes.map(x => 1);\n    return combineLocations(shape, reduceSubShape, axes);\n}\nexport function assertAxesAreInnerMostDims(msg, axes, rank) {\n    util.assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. ` +\n        `Got axes ${axes} and rank-${rank} input.`);\n}\n/**\n * Returns the axes permutation to be used with `tf.transpose`, if such\n * permutation is necessary. Otherwise it returns null. This method is used by\n * operations that operate only on inner-most axes.\n */\nexport function getAxesPermutation(axes, rank) {\n    if (axesAreInnerMostDims(axes, rank)) {\n        return null;\n    }\n    const result = [];\n    for (let i = 0; i < rank; ++i) {\n        if (axes.indexOf(i) === -1) {\n            result.push(i);\n        }\n    }\n    axes.forEach(axis => result.push(axis));\n    return result;\n}\n/** Returns the axes permutation that undoes the original permutation. */\nexport function getUndoAxesPermutation(axes) {\n    return axes.map((axis, i) => [i, axis])\n        .sort((a, b) => a[1] - b[1])\n        .map(x => x[0]);\n}\nexport function getInnerMostAxes(numAxes, rank) {\n    const res = [];\n    for (let i = rank - numAxes; i < rank; ++i) {\n        res.push(i);\n    }\n    return res;\n}\n//# sourceMappingURL=axis_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atan2 } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes arctangent of `tf.Tensor`s a / b element-wise: `atan2(a, b)`.\n * Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1.0, 1.0, -1.0, .7]);\n * const b = tf.tensor1d([2.0, 13.0, 3.5, .21]);\n *\n * tf.atan2(a, b).print()\n * ```\n *\n * @param a The first tensor.\n * @param b The second tensor. Must have the same dtype as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan2_(a, b) {\n    let $a = convertToTensor(a, 'a', 'atan2');\n    let $b = convertToTensor(b, 'b', 'atan2');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Atan2, inputs);\n}\nexport const atan2 = op({ atan2_ });\n//# sourceMappingURL=atan2.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Concat } from '../kernel_names';\nimport { convertToTensorArray } from '../tensor_util_env';\nimport { assert } from '../util';\nimport { clone } from './clone';\nimport { op } from './operation';\n/**\n * Concatenates a list of `tf.Tensor`s along a given axis.\n *\n * The tensors ranks and types must match, and their sizes must match in all\n * dimensions except `axis`.\n *\n * Also available are stricter rank-specific methods that assert that\n * `tensors` are of the given rank:\n *   - `tf.concat1d`\n *   - `tf.concat2d`\n *   - `tf.concat3d`\n *   - `tf.concat4d`\n *\n * Except `tf.concat1d` (which does not have axis param), all methods have\n * same signature as this method.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * a.concat(b).print();  // or a.concat(b)\n * ```\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor1d([3, 4]);\n * const c = tf.tensor1d([5, 6]);\n * tf.concat([a, b, c]).print();\n * ```\n *\n * ```js\n * const a = tf.tensor2d([[1, 2], [10, 20]]);\n * const b = tf.tensor2d([[3, 4], [30, 40]]);\n * const axis = 1;\n * tf.concat([a, b], axis).print();\n * ```\n * @param tensors A list of tensors to concatenate.\n * @param axis The axis to concate along. Defaults to 0 (the first dim).\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nfunction concat_(tensors, axis = 0) {\n    assert(tensors.length >= 1, () => 'Pass at least one tensor to concat');\n    const $tensors = convertToTensorArray(tensors, 'tensors', 'concat', 'string_or_numeric');\n    if ($tensors[0].dtype === 'complex64') {\n        $tensors.forEach(tensor => {\n            if (tensor.dtype !== 'complex64') {\n                throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${tensor.dtype}. `);\n            }\n        });\n    }\n    if ($tensors.length === 1) {\n        return clone($tensors[0]);\n    }\n    const inputs = $tensors;\n    const attr = { axis };\n    return ENGINE.runKernel(Concat, inputs, attr);\n}\nexport const concat = op({ concat_ });\n//# sourceMappingURL=concat.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropFilter } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 2D convolution.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     [batch, height, width, inChannels]. If rank 3, batch of 1 is assumed.\n * @param dy The dy image, of rank 4 or rank 3, of shape\n *     [batch, height, width, outDepth]. If rank 3, batch of 1 is assumed.\n * @param filterShape The shape of the filter, length 4,\n *     [filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropFilter_(x, dy, filterShape, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ` +\n        `${x4D.shape}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ` +\n        `${dy4D.shape}.`);\n    util.assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ` +\n        `${filterShape}.`);\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must ` +\n        `match input depth in filter (${filterShape[2]}.`);\n    util.assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must ` +\n        `match output depth for filter (${filterShape[3]}).`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerFilter: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);\n}\nexport const conv2DBackpropFilter = op({ conv2DBackpropFilter_ });\n//# sourceMappingURL=conv2d_backprop_filter.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPoolGrad } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the backprop of an 2D avg pool.\n *\n * @param dy The dy error, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param input The input image, of rank 4 or rank 3 of shape\n *     [batchSize, height, width, channels]. If rank 3, batch of 1 is\n * assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction avgPoolGrad_(dy, input, filterSize, strides, pad) {\n    const $dy = convertToTensor(dy, 'dy', 'avgPoolGrad');\n    const $input = convertToTensor(input, 'input', 'avgPoolGrad');\n    util.assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);\n    let input4D = $input;\n    let dy4D = $dy;\n    let reshapedTo4D = false;\n    if ($input.rank === 3) {\n        reshapedTo4D = true;\n        input4D =\n            reshape($input, [1, $input.shape[0], $input.shape[1], $input.shape[2]]);\n        dy4D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2]]);\n    }\n    util.assert(dy4D.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ` +\n        `${dy4D.rank}.`);\n    util.assert(input4D.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ` +\n        `${input4D.rank}.`);\n    const inputs = { dy: dy4D, input: input4D };\n    const attrs = { filterSize, strides, pad };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(AvgPoolGrad, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const avgPoolGrad = op({ avgPoolGrad_ });\n//# sourceMappingURL=avg_pool_grad.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cosh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes hyperbolic cos of the input `tf.Tensor` element-wise: `cosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.cosh().print();  // or tf.cosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cosh_(x) {\n    const $x = convertToTensor(x, 'x', 'cosh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Cosh, inputs);\n}\nexport const cosh = op({ cosh_ });\n//# sourceMappingURL=cosh.js.map","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { env } from '../environment';\nimport { FromPixels } from '../kernel_names';\nimport { getKernel } from '../kernel_registry';\nimport { Tensor } from '../tensor';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { tensor3d } from './tensor3d';\nlet fromPixels2DContext;\n/**\n * Creates a `tf.Tensor` from an image.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * tf.browser.fromPixels(image).print();\n * ```\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @returns A Tensor3D with the shape `[height, width, numChannels]`.\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nfunction fromPixels_(pixels, numChannels = 3) {\n    // Sanity checks.\n    if (numChannels > 4) {\n        throw new Error('Cannot construct Tensor with more than 4 channels from pixels.');\n    }\n    if (pixels == null) {\n        throw new Error('pixels passed to tf.browser.fromPixels() can not be null');\n    }\n    let isPixelData = false;\n    let isImageData = false;\n    let isVideo = false;\n    let isImage = false;\n    let isCanvasLike = false;\n    let isImageBitmap = false;\n    if (pixels.data instanceof Uint8Array) {\n        isPixelData = true;\n    }\n    else if (typeof (ImageData) !== 'undefined' && pixels instanceof ImageData) {\n        isImageData = true;\n    }\n    else if (typeof (HTMLVideoElement) !== 'undefined' &&\n        pixels instanceof HTMLVideoElement) {\n        isVideo = true;\n    }\n    else if (typeof (HTMLImageElement) !== 'undefined' &&\n        pixels instanceof HTMLImageElement) {\n        isImage = true;\n        // tslint:disable-next-line: no-any\n    }\n    else if (pixels.getContext != null) {\n        isCanvasLike = true;\n    }\n    else if (typeof (ImageBitmap) !== 'undefined' && pixels instanceof ImageBitmap) {\n        isImageBitmap = true;\n    }\n    else {\n        throw new Error('pixels passed to tf.browser.fromPixels() must be either an ' +\n            `HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData ` +\n            `in browser, or OffscreenCanvas, ImageData in webworker` +\n            ` or {data: Uint32Array, width: number, height: number}, ` +\n            `but was ${pixels.constructor.name}`);\n    }\n    if (isVideo) {\n        const HAVE_CURRENT_DATA_READY_STATE = 2;\n        if (isVideo &&\n            pixels.readyState <\n                HAVE_CURRENT_DATA_READY_STATE) {\n            throw new Error('The video element has not loaded data yet. Please wait for ' +\n                '`loadeddata` event on the <video> element.');\n        }\n    }\n    // If the current backend has 'FromPixels' registered, it has a more\n    // efficient way of handling pixel uploads, so we call that.\n    const kernel = getKernel(FromPixels, ENGINE.backendName);\n    if (kernel != null) {\n        const inputs = { pixels };\n        const attrs = { numChannels };\n        return ENGINE.runKernel(FromPixels, inputs, attrs);\n    }\n    const [width, height] = isVideo ?\n        [\n            pixels.videoWidth,\n            pixels.videoHeight\n        ] :\n        [pixels.width, pixels.height];\n    let vals;\n    if (isCanvasLike) {\n        vals =\n            // tslint:disable-next-line:no-any\n            pixels.getContext('2d').getImageData(0, 0, width, height).data;\n    }\n    else if (isImageData || isPixelData) {\n        vals = pixels.data;\n    }\n    else if (isImage || isVideo || isImageBitmap) {\n        if (fromPixels2DContext == null) {\n            fromPixels2DContext = document.createElement('canvas').getContext('2d');\n        }\n        fromPixels2DContext.canvas.width = width;\n        fromPixels2DContext.canvas.height = height;\n        fromPixels2DContext.drawImage(pixels, 0, 0, width, height);\n        vals = fromPixels2DContext.getImageData(0, 0, width, height).data;\n    }\n    let values;\n    if (numChannels === 4) {\n        values = new Int32Array(vals);\n    }\n    else {\n        const numPixels = width * height;\n        values = new Int32Array(numPixels * numChannels);\n        for (let i = 0; i < numPixels; i++) {\n            for (let channel = 0; channel < numChannels; ++channel) {\n                values[i * numChannels + channel] = vals[i * 4 + channel];\n            }\n        }\n    }\n    const outShape = [height, width, numChannels];\n    return tensor3d(values, outShape, 'int32');\n}\n// Helper functions for |fromPixelsAsync| to check whether the input can\n// be wrapped into imageBitmap.\nfunction isPixelData(pixels) {\n    return (pixels != null) && (pixels.data instanceof Uint8Array);\n}\nfunction isImageBitmapFullySupported() {\n    return typeof window !== 'undefined' &&\n        typeof (ImageBitmap) !== 'undefined' &&\n        window.hasOwnProperty('createImageBitmap');\n}\nfunction isNonEmptyPixels(pixels) {\n    return pixels != null && pixels.width !== 0 && pixels.height !== 0;\n}\nfunction canWrapPixelsToImageBitmap(pixels) {\n    return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) &&\n        isNonEmptyPixels(pixels) && !isPixelData(pixels);\n}\n/**\n * Creates a `tf.Tensor` from an image in async way.\n *\n * ```js\n * const image = new ImageData(1, 1);\n * image.data[0] = 100;\n * image.data[1] = 150;\n * image.data[2] = 200;\n * image.data[3] = 255;\n *\n * (await tf.browser.fromPixelsAsync(image)).print();\n * ```\n * This API is the async version of fromPixels. The API will first\n * check |WRAP_TO_IMAGEBITMAP| flag, and try to wrap the input to\n * imageBitmap if the flag is set to true.\n *\n * @param pixels The input image to construct the tensor from. The\n * supported image types are all 4-channel. You can also pass in an image\n * object with following attributes:\n * `{data: Uint8Array; width: number; height: number}`\n * @param numChannels The number of channels of the output tensor. A\n * numChannels value less than 4 allows you to ignore channels. Defaults to\n * 3 (ignores alpha channel of input image).\n *\n * @doc {heading: 'Browser', namespace: 'browser', ignoreCI: true}\n */\nexport async function fromPixelsAsync(pixels, numChannels = 3) {\n    let inputs = null;\n    // Check whether the backend needs to wrap |pixels| to imageBitmap and\n    // whether |pixels| can be wrapped to imageBitmap.\n    if (env().getBool('WRAP_TO_IMAGEBITMAP') &&\n        canWrapPixelsToImageBitmap(pixels)) {\n        // Force the imageBitmap creation to not do any premultiply alpha\n        // ops.\n        let imageBitmap;\n        try {\n            // wrap in try-catch block, because createImageBitmap may not work\n            // properly in some browsers, e.g.\n            // https://bugzilla.mozilla.org/show_bug.cgi?id=1335594\n            // tslint:disable-next-line: no-any\n            imageBitmap = await createImageBitmap(pixels, { premultiplyAlpha: 'none' });\n        }\n        catch (e) {\n            imageBitmap = null;\n        }\n        // createImageBitmap will clip the source size.\n        // In some cases, the input will have larger size than its content.\n        // E.g. new Image(10, 10) but with 1 x 1 content. Using\n        // createImageBitmap will clip the size from 10 x 10 to 1 x 1, which\n        // is not correct. We should avoid wrapping such resouce to\n        // imageBitmap.\n        if (imageBitmap != null && imageBitmap.width === pixels.width &&\n            imageBitmap.height === pixels.height) {\n            inputs = imageBitmap;\n        }\n        else {\n            inputs = pixels;\n        }\n    }\n    else {\n        inputs = pixels;\n    }\n    return fromPixels_(inputs, numChannels);\n}\n/**\n * Draws a `tf.Tensor` of pixel values to a byte array or optionally a\n * canvas.\n *\n * When the dtype of the input is 'float32', we assume values in the range\n * [0-1]. Otherwise, when input is 'int32', we assume values in the range\n * [0-255].\n *\n * Returns a promise that resolves when the canvas has been drawn to.\n *\n * @param img A rank-2 tensor with shape `[height, width]`, or a rank-3 tensor\n * of shape `[height, width, numChannels]`. If rank-2, draws grayscale. If\n * rank-3, must have depth of 1, 3 or 4. When depth of 1, draws\n * grayscale. When depth of 3, we draw with the first three components of\n * the depth dimension corresponding to r, g, b and alpha = 1. When depth of\n * 4, all four components of the depth dimension correspond to r, g, b, a.\n * @param canvas The canvas to draw to.\n *\n * @doc {heading: 'Browser', namespace: 'browser'}\n */\nexport async function toPixels(img, canvas) {\n    let $img = convertToTensor(img, 'img', 'toPixels');\n    if (!(img instanceof Tensor)) {\n        // Assume int32 if user passed a native array.\n        const originalImgTensor = $img;\n        $img = cast(originalImgTensor, 'int32');\n        originalImgTensor.dispose();\n    }\n    if ($img.rank !== 2 && $img.rank !== 3) {\n        throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);\n    }\n    const [height, width] = $img.shape.slice(0, 2);\n    const depth = $img.rank === 2 ? 1 : $img.shape[2];\n    if (depth > 4 || depth === 2) {\n        throw new Error(`toPixels only supports depth of size ` +\n            `1, 3 or 4 but got ${depth}`);\n    }\n    if ($img.dtype !== 'float32' && $img.dtype !== 'int32') {\n        throw new Error(`Unsupported type for toPixels: ${$img.dtype}.` +\n            ` Please use float32 or int32 tensors.`);\n    }\n    const data = await $img.data();\n    const multiplier = $img.dtype === 'float32' ? 255 : 1;\n    const bytes = new Uint8ClampedArray(width * height * 4);\n    for (let i = 0; i < height * width; ++i) {\n        const rgba = [0, 0, 0, 255];\n        for (let d = 0; d < depth; d++) {\n            const value = data[i * depth + d];\n            if ($img.dtype === 'float32') {\n                if (value < 0 || value > 1) {\n                    throw new Error(`Tensor values for a float32 Tensor must be in the ` +\n                        `range [0 - 1] but encountered ${value}.`);\n                }\n            }\n            else if ($img.dtype === 'int32') {\n                if (value < 0 || value > 255) {\n                    throw new Error(`Tensor values for a int32 Tensor must be in the ` +\n                        `range [0 - 255] but encountered ${value}.`);\n                }\n            }\n            if (depth === 1) {\n                rgba[0] = value * multiplier;\n                rgba[1] = value * multiplier;\n                rgba[2] = value * multiplier;\n            }\n            else {\n                rgba[d] = value * multiplier;\n            }\n        }\n        const j = i * 4;\n        bytes[j + 0] = Math.round(rgba[0]);\n        bytes[j + 1] = Math.round(rgba[1]);\n        bytes[j + 2] = Math.round(rgba[2]);\n        bytes[j + 3] = Math.round(rgba[3]);\n    }\n    if (canvas != null) {\n        canvas.width = width;\n        canvas.height = height;\n        const ctx = canvas.getContext('2d');\n        const imageData = new ImageData(bytes, width, height);\n        ctx.putImageData(imageData, 0, 0);\n    }\n    if ($img !== img) {\n        $img.dispose();\n    }\n    return bytes;\n}\nexport const fromPixels = op({ fromPixels_ });\n//# sourceMappingURL=browser.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { batchNorm } from './batchnorm';\nimport { op } from './operation';\n/**\n * Batch normalization, strictly for 4D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm4d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    const $x = convertToTensor(x, 'x', 'batchNorm');\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n    let $scale;\n    if (scale != null) {\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    let $offset;\n    if (offset != null) {\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ` +\n        `${$x.rank}.`);\n    util.assert($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but ` +\n        `got rank ${$mean.rank}.`);\n    util.assert($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 ` +\n        `but got rank ${$variance.rank}.`);\n    if ($scale != null) {\n        util.assert($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 ` +\n            `but got rank ${$scale.rank}.`);\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 ` +\n            `but got rank ${$offset.rank}.`);\n    }\n    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\nexport const batchNorm4d = op({ batchNorm4d_ });\n//# sourceMappingURL=batchnorm4d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 2D convolution over the input x.\n *\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `dilations` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2d_(x, filter, strides, pad, dataFormat = 'NHWC', dilations = [1, 1], dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2d');\n    const $filter = convertToTensor(filter, 'filter', 'conv2d');\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);\n    util.assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ` +\n        `${$filter.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inDepth = dataFormat === 'NHWC' ? x4D.shape[3] : x4D.shape[1];\n    util.assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match ` +\n        `input depth for filter ${$filter.shape[2]}.`);\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in conv2D: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv2D, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2d = op({ conv2d_ });\n//# sourceMappingURL=conv2d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atan } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes atan of the input `tf.Tensor` element-wise: `atan(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.atan().print();  // or tf.atan(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atan_(x) {\n    const $x = convertToTensor(x, 'x', 'atan');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Atan, inputs);\n}\nexport const atan = op({ atan_ });\n//# sourceMappingURL=atan.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cast } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Casts a `tf.Tensor` to a new dtype.\n *\n * ```js\n * const x = tf.tensor1d([1.5, 2.5, 3]);\n * tf.cast(x, 'int32').print();\n * ```\n * @param x The input tensor to be casted.\n * @param dtype The dtype to cast the input tensor to.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction cast_(x, dtype) {\n    const $x = convertToTensor(x, 'x', 'cast');\n    // Sanity checks.\n    if (!util.isValidDtype(dtype)) {\n        throw new Error(`Failed to cast to unknown dtype ${dtype}`);\n    }\n    if (dtype === 'string' && $x.dtype !== 'string' ||\n        dtype !== 'string' && $x.dtype === 'string') {\n        throw new Error('Only strings can be casted to strings');\n    }\n    const inputs = { x: $x };\n    const attrs = { dtype };\n    return ENGINE.runKernel(Cast, inputs, attrs);\n}\nexport const cast = op({ cast_ });\n//# sourceMappingURL=cast.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Ceil } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes ceiling of input `tf.Tensor` element-wise: `ceil(x)`\n *\n * ```js\n * const x = tf.tensor1d([.6, 1.1, -3.3]);\n *\n * x.ceil().print();  // or tf.ceil(x)\n * ```\n * @param x The input Tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction ceil_(x) {\n    const $x = convertToTensor(x, 'x', 'ceil');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Ceil, inputs);\n}\nexport const ceil = op({ ceil_ });\n//# sourceMappingURL=ceil.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthToSpace } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Rearranges data from depth into blocks of spatial data. More specifically,\n * this op outputs a copy of the input tensor where values from the `depth`\n * dimension are moved in spatial blocks to the `height` and `width` dimensions.\n * The attr `blockSize` indicates the input block size and how the data is\n * moved.\n *\n *  - Chunks of data of size `blockSize * blockSize` from depth are rearranged\n * into non-overlapping blocks of size `blockSize x blockSize`\n *\n *  - The width the output tensor is `inputWidth * blockSize`, whereas the\n * height is `inputHeight * blockSize`\n *\n *  - The Y, X coordinates within each block of the output image are determined\n * by the high order component of the input channel index\n *\n *  - The depth of the input tensor must be divisible by `blockSize *\n * blockSize`\n *\n * The `dataFormat` attr specifies the layout of the input and output tensors\n * with the following options: \"NHWC\": [ `batch, height, width, channels` ]\n * \"NCHW\": [ `batch, channels, height, width` ]\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [1, 1, 1, 4]);\n * const blockSize = 2;\n * const dataFormat = \"NHWC\";\n *\n * tf.depthToSpace(x, blockSize, dataFormat).print();\n * ```\n *\n * @param x The input tensor of rank 4\n * @param blockSIze  An `int` that is `>= 2`. The size of the spatial block\n * @param dataFormat An optional string from: \"NHWC\", \"NCHW\". Defaults to \"NHWC\"\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction depthToSpace_(x, blockSize, dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'depthToSpace');\n    const inputHeight = (dataFormat === 'NHWC') ? $x.shape[1] : $x.shape[2];\n    const inputWidth = (dataFormat === 'NHWC') ? $x.shape[2] : $x.shape[3];\n    const inputDepth = (dataFormat === 'NHWC') ? $x.shape[3] : $x.shape[1];\n    util.assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying\n    ${inputHeight} and ${blockSize}  for depthToSpace with input shape\n    ${$x.shape}`);\n    util.assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying\n    ${inputWidth} and ${blockSize} for depthToSpace with input shape\n        ${$x.shape}`);\n    util.assert((inputDepth % (blockSize * blockSize) === 0), () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);\n    const inputs = { x: $x };\n    const attrs = { blockSize, dataFormat };\n    return ENGINE.runKernel(DepthToSpace, inputs, attrs);\n}\nexport const depthToSpace = op({ depthToSpace_ });\n//# sourceMappingURL=depth_to_space.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropInputV2 } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 3D convolution.\n *\n * @param xShape The shape of the input: [batch, depth, height, width,\n * in_channels]. If length of 4, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 5 or rank 4 of shape\n *   `[batch, outDepth, outHeight, outWidth, in_channels]`.\n * If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n */\nfunction conv3DBackpropInput_(xShape, dy, filter, strides, pad) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape5D = xShape;\n    let dy5D = dy;\n    let reshapedTo5D = false;\n    if (dy.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n        xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];\n    }\n    const inDepth = xShape5D[4];\n    const outDepth = dy5D.shape[4];\n    util.assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ` +\n        `${xShape5D.length}.`);\n    util.assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got ` +\n        `rank ${dy5D.rank}`);\n    util.assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got ` +\n        `rank ${filter.rank}`);\n    util.assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[3]}.`);\n    util.assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[4]}.`);\n    const inputs = { dy: dy5D, filter };\n    const attrs = { pad, strides, inputShape: xShape5D };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const conv3DBackpropInput = op({ conv3DBackpropInput_ });\n//# sourceMappingURL=conv3d_backprop_input.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { gather } from './gather';\nimport { reshape } from './reshape';\nimport { squeeze } from './squeeze';\nimport { whereAsync } from './where_async';\n/**\n * Apply boolean mask to tensor.\n *\n * ```js\n * const tensor = tf.tensor2d([1, 2, 3, 4, 5, 6], [3, 2]);\n * const mask = tf.tensor1d([1, 0, 1], 'bool');\n * const result = await tf.booleanMaskAsync(tensor, mask);\n * result.print();\n * ```\n *\n * @param tensor N-D tensor.\n * @param mask K-D boolean tensor, K <= N and K must be known statically.\n * @param axis A 0-D int Tensor representing the axis in tensor to mask from.\n *     By default, axis is 0 which will mask from the first dimension.\n *     Otherwise K + axis <= N.\n *\n * @doc {heading: 'Tensors', subheading: 'Slicing and Joining'}\n */\nasync function booleanMaskAsync_(tensor, mask, axis) {\n    const $tensor = convertToTensor(tensor, 'tensor', 'boolMask');\n    const $mask = convertToTensor(mask, 'mask', 'boolMask', 'bool');\n    const axisFrom = axis == null ? 0 : axis;\n    const maskDim = $mask.rank;\n    const tensorShape = $tensor.shape;\n    util.assert(maskDim > 0, () => 'mask cannot be scalar');\n    util.assertShapesMatch(tensorShape.slice(axisFrom, axisFrom + maskDim), $mask.shape, `mask's shape must match the first K dimensions of tensor's shape,`);\n    let leadingSize = 1;\n    for (let i = axisFrom; i < axisFrom + maskDim; i++) {\n        leadingSize *= tensorShape[i];\n    }\n    const targetTensorShape = tensorShape.slice(0, axisFrom)\n        .concat([leadingSize], tensorShape.slice(axisFrom + maskDim));\n    const reshapedTensor = reshape($tensor, targetTensorShape);\n    const reshapedMask = reshape($mask, [-1]);\n    const positivePositions = await whereAsync(reshapedMask);\n    const indices = squeeze(positivePositions, [1]);\n    const res = gather(reshapedTensor, indices, axisFrom);\n    // Ensure no memory leak.\n    if (tensor !== $tensor) {\n        $tensor.dispose();\n    }\n    if (mask !== $mask) {\n        $mask.dispose();\n    }\n    indices.dispose();\n    reshapedTensor.dispose();\n    reshapedMask.dispose();\n    positivePositions.dispose();\n    return res;\n}\nexport const booleanMaskAsync = booleanMaskAsync_;\n//# sourceMappingURL=boolean_mask.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Complex } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Converts two real numbers to a complex number.\n *\n * Given a tensor `real` representing the real part of a complex number, and a\n * tensor `imag` representing the imaginary part of a complex number, this\n * operation returns complex numbers elementwise of the form [r0, i0, r1, i1],\n * where r represents the real part and i represents the imag part.\n *\n * The input tensors real and imag must have the same shape.\n *\n * ```js\n * const real = tf.tensor1d([2.25, 3.25]);\n * const imag = tf.tensor1d([4.75, 5.75]);\n * const complex = tf.complex(real, imag);\n *\n * complex.print();\n * ```\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction complex_(real, imag) {\n    const $real = convertToTensor(real, 'real', 'complex');\n    const $imag = convertToTensor(imag, 'imag', 'complex');\n    util.assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, ` +\n        `must match in call to tf.complex().`);\n    const inputs = { real: $real, imag: $imag };\n    return ENGINE.runKernel(Complex, inputs);\n}\nexport const complex = op({ complex_ });\n//# sourceMappingURL=complex.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Add } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Adds two `tf.Tensor`s element-wise, A + B. Supports broadcasting.\n *\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3, 4]);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n *\n * ```js\n * // Broadcast add a with b.\n * const a = tf.scalar(5);\n * const b = tf.tensor1d([10, 20, 30, 40]);\n *\n * a.add(b).print();  // or tf.add(a, b)\n * ```\n * @param a The first `tf.Tensor` to add.\n * @param b The second `tf.Tensor` to add. Must have the same type as `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction add_(a, b) {\n    let $a = convertToTensor(a, 'a', 'add');\n    let $b = convertToTensor(b, 'b', 'add');\n    [$a, $b] = makeTypesMatch($a, $b);\n    const inputs = { a: $a, b: $b };\n    return ENGINE.runKernel(Add, inputs);\n}\nexport const add = op({ add_ });\n//# sourceMappingURL=add.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Acosh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the inverse hyperbolic cos of the input `tf.Tensor` element-wise:\n * `acosh(x)`\n *\n * ```js\n * const x = tf.tensor1d([10, 1, 3, 5.7]);\n *\n * x.acosh().print();  // or tf.acosh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction acosh_(x) {\n    const $x = convertToTensor(x, 'x', 'acosh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Acosh, inputs);\n}\nexport const acosh = op({ acosh_ });\n//# sourceMappingURL=acosh.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Expm1 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential of the input `tf.Tensor` minus one element-wise.\n * `e ^ x - 1`\n *\n * ```js\n * const x = tf.tensor1d([1, 2, -3]);\n *\n * x.expm1().print();  // or tf.expm1(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction expm1_(x) {\n    const $x = convertToTensor(x, 'x', 'expm1');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Expm1, inputs);\n}\nexport const expm1 = op({ expm1_ });\n//# sourceMappingURL=expm1.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Bincount } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Outputs a vector with length `size` and the same dtype as `weights`.\n *\n * If `weights` are empty, then index `i` stores the number of times the value\n * `i` is counted in `x`. If `weights` are non-empty, then index `i` stores the\n * sum of the value in `weights` at each index where the corresponding value in\n * `x` is `i`.\n *\n * Values in `x` outside of the range [0, size) are ignored.\n *\n * @param x The input int tensor, rank 1.\n * @param weights The weights tensor, must have the same shape as x, or a\n *     length-0 Tensor, in which case it acts as all weights equal to 1.\n * @param size Non-negative integer.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction bincount_(x, weights, size) {\n    const $x = convertToTensor(x, 'x', 'bincount');\n    const $weights = convertToTensor(weights, 'weights', 'bincount');\n    util.assert($x.dtype === 'int32', () => `Error in bincount: input ` +\n        `dtype must be int32, but got ${$x.dtype}`);\n    util.assert(size >= 0, () => `size must be non-negative, but got ${size}.`);\n    util.assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or` +\n        `0-length, but got input shape: ${$x.shape}, weights shape: ` +\n        `${$weights.shape}.`);\n    const inputs = { x: $x, weights: $weights };\n    const attrs = { size };\n    return ENGINE.runKernel(Bincount, inputs, attrs);\n}\nexport const bincount = op({ bincount_ });\n//# sourceMappingURL=bincount.js.map","import { convertToTensor } from '../tensor_util_env';\nimport { conv2DBackpropInput } from './conv2d_backprop_input';\nimport { op } from './operation';\n/**\n * Computes the transposed 2D convolution of an image, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 4 or rank 3, of shape\n *   `[batch, height, width, inDepth]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 4 or rank 3:\n *     `[batch, height, width, outDepth]`. If rank 3, batch of 1 is assumed.\n * @param strides The strides of the original convolution:\n *     `[strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv2dTranspose_(x, filter, outputShape, strides, pad, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'conv2dTranspose');\n    const $filter = convertToTensor(filter, 'filter', 'conv2dTranspose');\n    return conv2DBackpropInput(outputShape, $x, $filter, strides, pad, 'NHWC', dimRoundingMode);\n}\nexport const conv2dTranspose = op({ conv2dTranspose_ });\n//# sourceMappingURL=conv2d_transpose.js.map","import { convertToTensor } from '../tensor_util_env';\nimport { conv3DBackpropInput } from './conv3d_backprop_input';\nimport { op } from './operation';\n/**\n * Computes the transposed 3D convolution of a volume, also known as a\n * deconvolution.\n *\n * @param x The input image, of rank 5 or rank 4, of shape\n *   `[batch, depth, height, width, inDepth]`. If rank 4, batch of 1 is assumed.\n * @param filter The filter, rank 4, of shape\n *     `[depth, filterHeight, filterWidth, outDepth, inDepth]`.\n *     `inDepth` must match `inDepth` in `x`.\n * @param outputShape Output shape, of rank 5 or rank 4:\n *     `[batch, depth, height, width, outDepth]`. If rank 3, batch of 1 is\n *    assumed.\n * @param strides The strides of the original convolution:\n *     `[strideDepth, strideHeight, strideWidth]`.\n * @param pad  The type of padding algorithm used in the non-transpose version\n *    of the op.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv3dTranspose_(x, filter, outputShape, strides, pad) {\n    const $x = convertToTensor(x, 'x', 'conv3dTranspose');\n    const $filter = convertToTensor(filter, 'filter', 'conv3dTranspose');\n    return conv3DBackpropInput(outputShape, $x, $filter, strides, pad);\n}\nexport const conv3dTranspose = op({ conv3dTranspose_ });\n//# sourceMappingURL=conv3d_transpose.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropFilter } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad, dilations = [1, 1], dimRoundingMode) {\n    let x4D = x;\n    if (x.rank === 3) {\n        x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);\n    }\n    let dy4D = dy;\n    if (dy4D.rank === 3) {\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const inputs = { x: x4D, dy: dy4D };\n    const attrs = { strides, pad, dimRoundingMode, dilations, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);\n}\nexport const depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_filter.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of`tf.Tensor1D`s along an axis. See `concat` for details.\n *\n * For example, if:\n * A: shape(3) = |r1, g1, b1|\n * B: shape(2) = |r2, g2|\n * C = tf.concat1d([A, B]) == |r1, g1, b1, r2, g2|\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @return The concatenated array.\n */\nfunction concat1d_(tensors) {\n    return concat(tensors, 0 /* axis */);\n}\nexport const concat1d = op({ concat1d_ });\n//# sourceMappingURL=concat_1d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n *\n * @param inputShape Input tensor shape is of the following dimensions:\n *     `[batch, height, width, inChannels]`.\n * @param filterShape The filter shape is of the following dimensions:\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat The data format of the input and output data.\n *     Defaults to 'NHWC'.\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`.\n *     Defaults to `[1, 1]`. If `dilations` is a single number, then\n *     `dilationHeight == dilationWidth`.\n */\nexport function computeDilation2DInfo(inputShape, filterShape, strides, pad, dataFormat = 'NHWC', dilations) {\n    // `computerConv2DInfo` require filterShape to be in the dimension of:\n    // `[filterHeight, filterWidth, depth, outDepth]`, dilation2d doesn't have\n    // outDepth, it should have the same depth as the input.\n    // Input shape: [batch, height, width, inChannels]\n    const inputChannels = inputShape[3];\n    const $filterShape = [...filterShape, inputChannels];\n    const $dataFormat = convertConv2DDataFormat(dataFormat);\n    return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad, null /* roundingMode */, null /* depthWise */, $dataFormat);\n}\nexport function computePool2DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'channelsLast') {\n    const [filterHeight, filterWidth] = parseTupleParam(filterSize);\n    let filterShape;\n    if (dataFormat === 'channelsLast') {\n        filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];\n    }\n    else if (dataFormat === 'channelsFirst') {\n        filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, false, dataFormat);\n}\n/**\n * Computes the information for a forward pass of a pooling3D operation.\n */\nexport function computePool3DInfo(inShape, filterSize, strides, dilations, pad, roundingMode, dataFormat = 'NDHWC') {\n    const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);\n    let filterShape;\n    let $dataFormat;\n    if (dataFormat === 'NDHWC') {\n        $dataFormat = 'channelsLast';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];\n    }\n    else if (dataFormat === 'NCDHW') {\n        $dataFormat = 'channelsFirst';\n        filterShape =\n            [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    return computeConv3DInfo(inShape, filterShape, strides, dilations, pad, false, $dataFormat, roundingMode);\n}\n/**\n * Computes the information for a forward pass of a convolution/pooling\n * operation.\n */\nexport function computeConv2DInfo(inShape, filterShape, strides, dilations, pad, roundingMode, depthwise = false, dataFormat = 'channelsLast') {\n    let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideHeight, strideWidth] = parseTupleParam(strides);\n    const [dilationHeight, dilationWidth] = parseTupleParam(dilations);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inHeight,\n        inWidth,\n        inChannels,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideHeight,\n        strideWidth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\n/**\n * Computes the information for a forward pass of a 3D convolution/pooling\n * operation.\n */\nexport function computeConv3DInfo(inShape, filterShape, strides, dilations, pad, depthwise = false, dataFormat = 'channelsLast', roundingMode) {\n    let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];\n    if (dataFormat === 'channelsLast') {\n        [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;\n    }\n    else if (dataFormat === 'channelsFirst') {\n        [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n    const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;\n    const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);\n    const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);\n    const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);\n    const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);\n    const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);\n    const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);\n    const outChannels = depthwise ? filterChannels * inChannels : filterChannels;\n    let outShape;\n    if (dataFormat === 'channelsFirst') {\n        outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];\n    }\n    else if (dataFormat === 'channelsLast') {\n        outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];\n    }\n    return {\n        batchSize,\n        dataFormat,\n        inDepth,\n        inHeight,\n        inWidth,\n        inChannels,\n        outDepth,\n        outHeight,\n        outWidth,\n        outChannels,\n        padInfo,\n        strideDepth,\n        strideHeight,\n        strideWidth,\n        filterDepth,\n        filterHeight,\n        filterWidth,\n        effectiveFilterDepth,\n        effectiveFilterHeight,\n        effectiveFilterWidth,\n        dilationDepth,\n        dilationHeight,\n        dilationWidth,\n        inShape,\n        outShape,\n        filterShape\n    };\n}\nfunction computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputRows = inShape[0];\n    const inputCols = inShape[1];\n    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    return [outputRows, outputCols];\n}\nfunction computeOutputShape4D(inShape, fieldSize, outChannels, stride, zeroPad, roundingMode) {\n    if (zeroPad == null) {\n        zeroPad = computeDefaultPad(inShape, fieldSize, stride);\n    }\n    const inputDepth = inShape[0];\n    const inputRows = inShape[1];\n    const inputCols = inShape[2];\n    const outputDepths = round((inputDepth - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputRows = round((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    const outputCols = round((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);\n    return [outputDepths, outputRows, outputCols, outChannels];\n}\nexport function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {\n    const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);\n    return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);\n}\nfunction parseTupleParam(param) {\n    if (typeof param === 'number') {\n        return [param, param, param];\n    }\n    if (param.length === 2) {\n        return [param[0], param[1], 1];\n    }\n    return param;\n}\nfunction parse3TupleParam(param) {\n    return typeof param === 'number' ? [param, param, param] : param;\n}\n/* See https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d\n * Atrous convolution is equivalent to standard convolution with upsampled\n * filters with effective_filter_height =\n * filter_height + (filter_height - 1) * (dilation - 1)\n * and effective_filter_width =\n * filter_width + (filter_width - 1) * (dilation - 1),\n * produced by inserting dilation - 1 zeros along consecutive elements across\n * the filters' spatial dimensions.\n * When there is a dilation, this converts a filter dimension to the\n * effective filter dimension, so it can be used in a standard convolution.\n */\nfunction getEffectiveFilterSize(filterSize, dilation) {\n    if (dilation <= 1) {\n        return filterSize;\n    }\n    return filterSize + (filterSize - 1) * (dilation - 1);\n}\nfunction getPadAndOutInfo(pad, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {\n    let padInfo;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = { top: pad, bottom: pad, left: pad, right: pad, type: padType };\n        const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad, roundingMode);\n        outHeight = outShape[0];\n        outWidth = outShape[1];\n    }\n    else if (pad === 'same') {\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);\n        const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: 'VALID' };\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else if (typeof pad === 'object') {\n        const top = dataFormat === 'channelsLast' ? pad[1][0] : pad[2][0];\n        const bottom = dataFormat === 'channelsLast' ? pad[1][1] : pad[2][1];\n        const left = dataFormat === 'channelsLast' ? pad[2][0] : pad[3][0];\n        const right = dataFormat === 'channelsLast' ? pad[2][1] : pad[3][1];\n        const padType = (top === 0 && bottom === 0 && left === 0 && right === 0) ?\n            'VALID' :\n            'EXPLICIT';\n        padInfo = { top, bottom, left, right, type: padType };\n        outHeight = round((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);\n        outWidth = round((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outHeight, outWidth };\n}\nfunction get3DPadAndOutInfo(pad, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {\n    let padInfo;\n    let outDepth;\n    let outHeight;\n    let outWidth;\n    if (typeof pad === 'number') {\n        const padType = (pad === 0) ? 'VALID' : 'NUMBER';\n        padInfo = {\n            top: pad,\n            bottom: pad,\n            left: pad,\n            right: pad,\n            front: pad,\n            back: pad,\n            type: padType\n        };\n        const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], filterDepth, 1, strideDepth, pad, roundingMode);\n        outDepth = outShape[0];\n        outHeight = outShape[1];\n        outWidth = outShape[2];\n    }\n    else if (pad === 'same') {\n        outDepth = Math.ceil(inDepth / strideDepth);\n        outHeight = Math.ceil(inHeight / strideHeight);\n        outWidth = Math.ceil(inWidth / strideWidth);\n        const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;\n        const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;\n        const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;\n        const front = Math.floor(padAlongDepth / 2);\n        const back = padAlongDepth - front;\n        const top = Math.floor(padAlongHeight / 2);\n        const bottom = padAlongHeight - top;\n        const left = Math.floor(padAlongWidth / 2);\n        const right = padAlongWidth - left;\n        padInfo = { top, bottom, left, right, front, back, type: 'SAME' };\n    }\n    else if (pad === 'valid') {\n        padInfo = {\n            top: 0,\n            bottom: 0,\n            left: 0,\n            right: 0,\n            front: 0,\n            back: 0,\n            type: 'VALID'\n        };\n        outDepth = Math.ceil((inDepth - filterDepth + 1) / strideDepth);\n        outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);\n        outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);\n    }\n    else {\n        throw Error(`Unknown padding parameter: ${pad}`);\n    }\n    return { padInfo, outDepth, outHeight, outWidth };\n}\n/**\n * Rounds a value depending on the rounding mode\n * @param value\n * @param roundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction round(value, roundingMode) {\n    if (!roundingMode) {\n        return Math.trunc(value);\n    }\n    switch (roundingMode) {\n        case 'round':\n            // used for Caffe Conv\n            return Math.round(value);\n        case 'ceil':\n            // used for Caffe Pool\n            return Math.ceil(value);\n        case 'floor':\n            return Math.floor(value);\n        default:\n            throw new Error(`Unknown roundingMode ${roundingMode}`);\n    }\n}\nexport function tupleValuesAreOne(param) {\n    const [dimA, dimB, dimC] = parseTupleParam(param);\n    return dimA === 1 && dimB === 1 && dimC === 1;\n}\nexport function eitherStridesOrDilationsAreOne(strides, dilations) {\n    return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);\n}\n/**\n * Convert Conv2D dataFormat from 'NHWC'|'NCHW' to\n *    'channelsLast'|'channelsFirst'\n * @param dataFormat in 'NHWC'|'NCHW' mode\n * @return dataFormat in 'channelsLast'|'channelsFirst' mode\n * @throws unknown dataFormat\n */\nexport function convertConv2DDataFormat(dataFormat) {\n    if (dataFormat === 'NHWC') {\n        return 'channelsLast';\n    }\n    else if (dataFormat === 'NCHW') {\n        return 'channelsFirst';\n    }\n    else {\n        throw new Error(`Unknown dataFormat ${dataFormat}`);\n    }\n}\n//# sourceMappingURL=conv_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool3DGrad } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the backprop of a 3d avg pool.\n *\n * @param dy The dy error, of rank 5 of shape\n *     [batchSize, depth, height, width, channels].\n * assumed.\n * @param input The original input image, of rank 5 or rank4 of shape\n *     [batchSize, depth, height, width, channels].\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction avgPool3dGrad_(dy, input, filterSize, strides, pad, dimRoundingMode) {\n    const $dy = convertToTensor(dy, 'dy', 'avgPool3dGrad');\n    const $input = convertToTensor(input, 'input', 'avgPool3dGrad');\n    let dy5D = $dy;\n    let input5D = $input;\n    let reshapedTo5D = false;\n    if ($input.rank === 4) {\n        reshapedTo5D = true;\n        dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);\n        input5D = reshape($input, [\n            1, $input.shape[0], $input.shape[1], $input.shape[2], $input.shape[3]\n        ]);\n    }\n    util.assert(dy5D.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ` +\n        `${dy5D.rank}.`);\n    util.assert(input5D.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ` +\n        `${input5D.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in avgPool3dGrad: pad must be an integer when ` +\n            `using, dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { dy: dy5D, input: input5D };\n    const attrs = { filterSize, strides, pad, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(AvgPool3DGrad, inputs, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const avgPool3dGrad = op({ avgPool3dGrad_ });\n//# sourceMappingURL=avg_pool_3d_grad.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Asinh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes inverse hyperbolic sin of the input `tf.Tensor` element-wise:\n * `asinh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asinh().print();  // or tf.asinh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asinh_(x) {\n    const $x = convertToTensor(x, 'x', 'asinh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Asinh, inputs);\n}\nexport const asinh = op({ asinh_ });\n//# sourceMappingURL=asinh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { buffer } from './buffer';\nimport { expandDims } from './expand_dims';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nimport { tile } from './tile';\n/**\n * Create an identity matrix.\n *\n * @param numRows Number of rows.\n * @param numColumns Number of columns. Defaults to `numRows`.\n * @param batchShape If provided, will add the batch shape to the beginning\n *   of the shape of the returned `tf.Tensor` by repeating the identity\n *   matrix.\n * @param dtype Data type.\n * @returns Identity matrix of the specified size and data type, possibly\n *   with batch repetition if `batchShape` is specified.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction eye_(numRows, numColumns, batchShape, dtype = 'float32') {\n    if (numColumns == null) {\n        numColumns = numRows;\n    }\n    const buff = buffer([numRows, numColumns], dtype);\n    const n = numRows <= numColumns ? numRows : numColumns;\n    for (let i = 0; i < n; ++i) {\n        buff.set(1, i, i);\n    }\n    const out = reshape(buff.toTensor(), [numRows, numColumns]);\n    if (batchShape == null) {\n        return out;\n    }\n    else {\n        if (batchShape.length === 1) {\n            return tile(expandDims(out, 0), [batchShape[0], 1, 1]);\n        }\n        else if (batchShape.length === 2) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);\n        }\n        else if (batchShape.length === 3) {\n            // tslint:disable-next-line:no-unnecessary-type-assertion\n            return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [\n                batchShape[0], batchShape[1], batchShape[2], 1, 1\n            ]);\n        }\n        else {\n            throw new Error(`eye() currently supports only 1D and 2D ` +\n                // tslint:disable-next-line:no-any\n                `batchShapes, but received ${batchShape.length}D.`);\n        }\n    }\n}\nexport const eye = op({ eye_ });\n//# sourceMappingURL=eye.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool3D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the 3D average pooling.\n *\n * ```js\n * const x = tf.tensor5d([1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 2, 2, 1]);\n * const result = tf.avgPool3d(x, 2, 1, 'valid');\n * result.print();\n * ```\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     `[batch, depth, height, width, inChannels]`.\n * @param filterSize The filter size:\n *     `[filterDepth, filterHeight, filterWidth]`.\n *     If `filterSize` is a single number,\n *     then `filterDepth == filterHeight == filterWidth`.\n * @param strides The strides of the pooling:\n *     `[strideDepth, strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideDepth == strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n * @param dataFormat An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction avgPool3d_(x, filterSize, strides, pad, dimRoundingMode, dataFormat = 'NDHWC') {\n    const $x = convertToTensor(x, 'x', 'avgPool3d', 'float32');\n    let x5D = $x;\n    let reshapedTo5D = false;\n    if ($x.rank === 4) {\n        reshapedTo5D = true;\n        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);\n    }\n    util.assert(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);\n    util.assert(dataFormat === 'NDHWC', () => `Error in avgPool3d: Only NDHWC is currently supported, ` +\n        `but got dataFormat of ${dataFormat}`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in avgPool3d: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x5D };\n    const attrs = { filterSize, strides, pad, dimRoundingMode, dataFormat };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    let res = ENGINE.runKernel(AvgPool3D, inputs, attrs);\n    res = cast(res, x5D.dtype);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const avgPool3d = op({ avgPool3d_ });\n//# sourceMappingURL=avg_pool_3d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { AvgPool } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport * as conv_util from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the 2D average pooling of an image.\n *\n * @param x The input tensor, of rank 4 or rank 3 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filterSize The filter size: `[filterHeight, filterWidth]`. If\n *     `filterSize` is a single number, then `filterHeight == filterWidth`.\n * @param strides The strides of the pooling: `[strideHeight, strideWidth]`. If\n *     `strides` is a single number, then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *         https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction avgPool_(x, filterSize, strides, pad, dimRoundingMode) {\n    const $x = convertToTensor(x, 'x', 'avgPool', 'float32');\n    const dilations = 1;\n    util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        reshapedTo4D = true;\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n    }\n    util.assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in avgPool: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { x: x4D };\n    const attrs = { filterSize, strides, pad, dimRoundingMode };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    let res = ENGINE.runKernel(AvgPool, inputs, attrs);\n    res = cast(res, $x.dtype);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const avgPool = op({ avgPool_ });\n//# sourceMappingURL=avg_pool.js.map","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ArgMin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Returns the indices of the minimum values along an `axis`.\n *\n * The result has the same shape as `input` with the dimension along `axis`\n * removed.\n *\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n *\n * x.argMin().print();  // or tf.argMin(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 2, 4, 3], [2, 2]);\n *\n * const axis = 1;\n * x.argMin(axis).print();  // or tf.argMin(x, axis)\n * ```\n *\n * @param x The input tensor.\n * @param axis The dimension to reduce. Defaults to 0 (outer-most dimension).\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction argMin_(x, axis = 0) {\n    const $x = convertToTensor(x, 'x', 'argMin');\n    const inputs = { x: $x };\n    const attrs = { axis };\n    return ENGINE.runKernel(ArgMin, inputs, attrs);\n}\nexport const argMin = op({ argMin_ });\n//# sourceMappingURL=arg_min.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of `tf.Tensor3D`s along an axis.\n * See `concat` for details.\n *\n * For example, if:\n * A: shape(2, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *\n * B: shape(2, 1, 3) = | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * C = tf.concat3d([A, B], axis)\n *\n * if axis = 0:\n * C: shape(4, 1, 3) = | r1, g1, b1 |\n *                     | r2, g2, b2 |\n *                     | r3, g3, b3 |\n *                     | r4, g4, b4 |\n *\n * if axis = 1:\n * C: shape(2, 2, 3) = | r1, g1, b1, r3, g3, b3 |\n *                     | r2, g2, b2, r4, g4, b4 |\n *\n * if axis = 2:\n * C = shape(2, 1, 6) = | r1, g1, b1, r3, g3, b3 |\n *                      | r2, g2, b2, r4, g4, b4 |\n *\n * @param tensors A list of`tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat3d_(tensors, axis) {\n    return concat(tensors, axis);\n}\nexport const concat3d = op({ concat3d_ });\n//# sourceMappingURL=concat_3d.js.map","import { concat } from './concat';\nimport { op } from './operation';\n/**\n * Concatenates a list of `tf.Tensor4D`s along an axis.\n * See `concat` for details.\n *\n * @param tensors A list of `tf.Tensor`s to concatenate.\n * @param axis The axis to concate along.\n * @return The concatenated array.\n */\nfunction concat4d_(tensors, axis) {\n    return concat(tensors, axis);\n}\nexport const concat4d = op({ concat4d_ });\n//# sourceMappingURL=concat_4d.js.map","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Returns the dimensions in the input shape that are broadcasted to\n * produce the provided output shape.\n *\n * The returned dimensions are 0-indexed and sorted. An example:\n * inShape = [4, 1, 3]\n * outShape = [5, 4, 3, 3]\n * result = [1]. Dimension 1 (2nd dimension of input) gets broadcasted 1 => 3.\n */\nexport function getBroadcastDims(inShape, outShape) {\n    const inRank = inShape.length;\n    const dims = [];\n    for (let i = 0; i < inRank; i++) {\n        const dim = inRank - 1 - i;\n        const a = inShape[dim] || 1;\n        const b = outShape[outShape.length - 1 - i] || 1;\n        if (b > 1 && a === 1) {\n            dims.unshift(dim);\n        }\n    }\n    return dims;\n}\n/**\n * Returns the axes in the output space that should be reduced to produce\n * the input space.\n */\nexport function getReductionAxes(inShape, outShape) {\n    const result = [];\n    for (let i = 0; i < outShape.length; i++) {\n        const inDim = inShape[inShape.length - i - 1];\n        const outAxis = outShape.length - i - 1;\n        const outDim = outShape[outAxis];\n        if (inDim == null || (inDim === 1 && outDim > 1)) {\n            result.unshift(outAxis);\n        }\n    }\n    return result;\n}\nexport function assertAndGetBroadcastShape(shapeA, shapeB) {\n    const result = [];\n    const l = Math.max(shapeA.length, shapeB.length);\n    for (let i = 0; i < l; i++) {\n        let a = shapeA[shapeA.length - i - 1];\n        if (a == null) {\n            a = 1;\n        }\n        let b = shapeB[shapeB.length - i - 1];\n        if (b == null) {\n            b = 1;\n        }\n        if (a === 1) {\n            result.unshift(b);\n        }\n        else if (b === 1) {\n            result.unshift(a);\n        }\n        else if (a !== b) {\n            const errMsg = `Operands could not be broadcast together with shapes ` +\n                `${shapeA} and ${shapeB}.`;\n            throw Error(errMsg);\n        }\n        else {\n            result.unshift(a);\n        }\n    }\n    return result;\n}\n//# sourceMappingURL=broadcast_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Tile } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { clone } from './clone';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Broadcast an array to a compatible shape NumPy-style.\n *\n * The tensor's shape is compared to the broadcast shape from end to beginning.\n * Ones are prepended to the tensor's shape until is has the same length as\n * the broadcast shape. If input.shape[i]==shape[i], the (i+1)-th axis is\n * already broadcast-compatible. If input.shape[i]==1 and shape[i]==N, then\n * the input tensor is tiled N times along that axis (using tf.tile).\n *\n * @param input The tensor that is to be broadcasted.\n * @param shape The input is to be broadcast to this shape.\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction broadcastTo_(x, shape) {\n    let input = convertToTensor(x, 'broadcastTo', 'x');\n    const xShape = input.shape;\n    if (shape.some(d => !(d > 0) || d % 1 !== 0)) {\n        throw new Error(`broadcastTo(): Invalid broadcast shape [${shape}].`);\n    }\n    if (shape.length < input.rank) {\n        throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input.rank}.`);\n    }\n    if (shape.length > input.rank) {\n        const newShape = input.shape.slice();\n        while (newShape.length < shape.length) {\n            newShape.unshift(1);\n        }\n        input = reshape(input, newShape);\n    }\n    const inputShape = input.shape;\n    const reps = Array.from(shape);\n    for (let i = shape.length - 1; i >= 0; i--) {\n        if (inputShape[i] === shape[i]) {\n            reps[i] = 1;\n        }\n        else if (input.shape[i] !== 1) {\n            throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);\n        }\n    }\n    const axes = reps.map((n, i) => n > 1 ? i : -1).filter(i => i >= 0);\n    if (axes.length === 0) {\n        return clone(input);\n    }\n    // TODO call broadcastTo kernel directly once backends implement broadcstTo\n    const inputs = { x: input };\n    const attrs = { reps };\n    return ENGINE.runKernel(Tile, inputs, attrs);\n}\nexport const broadcastTo = op({ broadcastTo_ });\n//# sourceMappingURL=broadcast_to.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Atanh } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes inverse hyperbolic tan of the input `tf.Tensor` element-wise:\n * `atanh(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.atanh().print();  // or tf.atanh(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction atanh_(x) {\n    const $x = convertToTensor(x, 'x', 'atanh');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Atanh, inputs);\n}\nexport const atanh = op({ atanh_ });\n//# sourceMappingURL=atanh.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3DBackpropFilterV2 } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the filter of a 3D convolution.\n *\n * @param x The input tensor, of rank 5 or rank 4 of shape\n *     [batch, depth, height, width, inChannels]. If rank 4, batch of 1 is\n *     assumed.\n * @param dy The dy image, of rank 5 or rank 4, of shape\n *     [batch, depth, height, width, outDepth]. If rank 4, batch of 1 is\n *     assumed.\n * @param filterShape The shape of the filter, length 5,\n *     [filterDepth, filterHeight, filterWidth, inDepth, outDepth].\n * @param strides The strides of the convolution: [strideDepth, strideHeight,\n * strideWidth].\n * @param pad A string from: 'same', 'valid'. The type of padding algorithm\n *     used in the forward prop of the op.\n */\nfunction conv3DBackpropFilter_(x, dy, filterShape, strides, pad) {\n    let x5D = x;\n    if (x.rank === 4) {\n        x5D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]]);\n    }\n    let dy5D = dy;\n    if (dy5D.rank === 4) {\n        dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);\n    }\n    util.assert(x5D.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ` +\n        `${x5D.shape}.`);\n    util.assert(dy5D.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ` +\n        `${dy5D.shape}.`);\n    util.assert(filterShape.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ` +\n        `${filterShape}.`);\n    util.assert(x5D.shape[4] === filterShape[3], () => `Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must ` +\n        `match input depth in filter (${filterShape[3]}.`);\n    util.assert(dy5D.shape[4] === filterShape[4], () => `Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must ` +\n        `match output depth for filter (${filterShape[4]}).`);\n    const inputs = { x: x5D, dy: dy5D };\n    const attrs = { strides, pad, filterShape };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(Conv3DBackpropFilterV2, inputs, attrs);\n}\nexport const conv3DBackpropFilter = op({ conv3DBackpropFilter_ });\n//# sourceMappingURL=conv3d_backprop_filter.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Asin } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes asin of the input `tf.Tensor` element-wise: `asin(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, 1, -1, .7]);\n *\n * x.asin().print();  // or tf.asin(x)\n * ```\n * @param x The input tensor.\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction asin_(x) {\n    const $x = convertToTensor(x, 'x', 'asin');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Asin, inputs);\n}\nexport const asin = op({ asin_ });\n//# sourceMappingURL=asin.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { matMul } from './mat_mul';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the dot product of two matrices and/or vectors, `t1` and `t2`.\n *\n * ```js\n * const a = tf.tensor1d([1, 2]);\n * const b = tf.tensor2d([[1, 2], [3, 4]]);\n * const c = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n *\n * a.dot(b).print();  // or tf.dot(a, b)\n * b.dot(a).print();\n * b.dot(c).print();\n * ```\n * @param t1 The first tensor in the dot operation.\n * @param t2 The second tensor in the dot operation.\n *\n * @doc {heading: 'Operations', subheading: 'Matrices'}\n */\nfunction dot_(t1, t2) {\n    const $t1 = convertToTensor(t1, 't1', 'dot');\n    const $t2 = convertToTensor(t2, 't2', 'dot');\n    util.assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ` +\n        `${$t1.rank} and ${$t2.rank}.`);\n    const t1Inner = ($t1.rank === 1 ? $t1.size : $t1.shape[1]);\n    const t2Inner = ($t2.rank === 1 ? $t2.size : $t2.shape[0]);\n    util.assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ` +\n        `${t1Inner} and ${t2Inner}.`);\n    if ($t1.rank === 1 && $t2.rank === 1) {\n        const t12D = reshape($t1, [1, -1]);\n        const t22D = reshape($t2, [-1, 1]);\n        const t1t2 = matMul(t12D, t22D);\n        return reshape(t1t2, []);\n    }\n    else if ($t1.rank === 1 && $t2.rank === 2) {\n        const t12D = reshape($t1, [1, -1]);\n        const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n        const t1t2 = matMul(t12D, t22D);\n        return reshape(t1t2, [t1t2.size]);\n    }\n    else if ($t1.rank === 2 && $t2.rank === 1) {\n        const t22D = reshape($t2, [-1, 1]);\n        const t1t2 = matMul($t1, t22D);\n        return reshape(t1t2, [t1t2.size]);\n    }\n    else {\n        const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);\n        const t1t2 = matMul($t1, t22D);\n        return t1t2;\n    }\n}\nexport const dot = op({ dot_ });\n//# sourceMappingURL=dot.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { BatchToSpaceND } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of\n * shape `blockShape + [batch]`, interleaves these blocks back into the grid\n * defined by the spatial dimensions `[1, ..., M]`, to obtain a result with\n * the same rank as the input. The spatial dimensions of this intermediate\n * result are then optionally cropped according to `crops` to produce the\n * output. This is the reverse of `tf.spaceToBatchND`. See below for a precise\n * description.\n *\n * ```js\n * const x = tf.tensor4d([1, 2, 3, 4], [4, 1, 1, 1]);\n * const blockShape = [2, 2];\n * const crops = [[0, 0], [0, 0]];\n *\n * x.batchToSpaceND(blockShape, crops).print();\n * ```\n *\n * @param x A `tf.Tensor`. N-D with `x.shape` = `[batch] + spatialShape +\n * remainingShape`, where spatialShape has `M` dimensions.\n * @param blockShape A 1-D array. Must have shape `[M]`, all values must\n * be >= 1.\n * @param crops A 2-D array.  Must have shape `[M, 2]`, all values must be >= 0.\n * `crops[i] = [cropStart, cropEnd]` specifies the amount to crop from input\n * dimension `i + 1`, which corresponds to spatial dimension `i`. It is required\n * that `cropStart[i] + cropEnd[i] <= blockShape[i] * inputShape[i + 1]`\n *\n * This operation is equivalent to the following steps:\n *\n * 1. Reshape `x` to `reshaped` of shape: `[blockShape[0], ...,\n * blockShape[M-1], batch / prod(blockShape), x.shape[1], ...,\n * x.shape[N-1]]`\n *\n * 2. Permute dimensions of `reshaped`to produce `permuted` of shape `[batch /\n * prod(blockShape),x.shape[1], blockShape[0], ..., x.shape[M],\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 3. Reshape `permuted` to produce `reshapedPermuted` of shape `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0], ..., x.shape[M] *\n * blockShape[M-1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * 4. Crop the start and end of dimensions `[1, ..., M]` of `reshapedPermuted`\n * according to `crops` to produce the output of shape: `[batch /\n * prod(blockShape),x.shape[1] * blockShape[0] - crops[0,0] - crops[0,1],\n * ..., x.shape[M] * blockShape[M-1] - crops[M-1,0] -\n * crops[M-1,1],x.shape[M+1], ..., x.shape[N-1]]`\n *\n * @doc {heading: 'Tensors', subheading: 'Transformations'}\n */\nfunction batchToSpaceND_(x, blockShape, crops) {\n    const $x = convertToTensor(x, 'x', 'batchToSpaceND');\n    const prod = blockShape.reduce((a, b) => a * b);\n    util.assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);\n    util.assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);\n    util.assert($x.shape[0] % prod === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of ` +\n        `the elements of blockShape ${blockShape.join(' * ')} === ${prod}`);\n    const inputs = { x: $x };\n    const attrs = { blockShape, crops };\n    return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);\n}\nexport const batchToSpaceND = op({ batchToSpaceND_ });\n//# sourceMappingURL=batch_to_space_nd.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport { add } from './add';\nimport { concat } from './concat';\nimport { matMul } from './mat_mul';\nimport { mul } from './mul';\nimport { op } from './operation';\nimport { sigmoid } from './sigmoid';\nimport { slice } from './slice';\nimport { tanh } from './tanh';\n/**\n * Computes the next state and output of a BasicLSTMCell.\n *\n * Returns `[newC, newH]`.\n *\n * Derived from tf.contrib.rnn.BasicLSTMCell.\n *\n * @param forgetBias Forget bias for the cell.\n * @param lstmKernel The weights for the cell.\n * @param lstmBias The bias for the cell.\n * @param data The input to the cell.\n * @param c Previous cell state.\n * @param h Previous cell output.\n *\n * @doc {heading: 'Operations', subheading: 'RNN'}\n */\nfunction basicLSTMCell_(forgetBias, lstmKernel, lstmBias, data, c, h) {\n    const $forgetBias = convertToTensor(forgetBias, 'forgetBias', 'basicLSTMCell');\n    const $lstmKernel = convertToTensor(lstmKernel, 'lstmKernel', 'basicLSTMCell');\n    const $lstmBias = convertToTensor(lstmBias, 'lstmBias', 'basicLSTMCell');\n    const $data = convertToTensor(data, 'data', 'basicLSTMCell');\n    const $c = convertToTensor(c, 'c', 'basicLSTMCell');\n    const $h = convertToTensor(h, 'h', 'basicLSTMCell');\n    const combined = concat([$data, $h], 1);\n    const weighted = matMul(combined, $lstmKernel);\n    const res = add(weighted, $lstmBias);\n    // i = input_gate, j = new_input, f = forget_gate, o = output_gate\n    const batchSize = res.shape[0];\n    const sliceCols = res.shape[1] / 4;\n    const sliceSize = [batchSize, sliceCols];\n    const i = slice(res, [0, 0], sliceSize);\n    const j = slice(res, [0, sliceCols], sliceSize);\n    const f = slice(res, [0, sliceCols * 2], sliceSize);\n    const o = slice(res, [0, sliceCols * 3], sliceSize);\n    const newC = add(mul(sigmoid(i), tanh(j)), mul($c, sigmoid(add($forgetBias, f))));\n    const newH = mul(tanh(newC), sigmoid(o));\n    return [newC, newH];\n}\nexport const basicLSTMCell = op({ basicLSTMCell_ });\n//# sourceMappingURL=basic_lstm_cell.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Identity } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Creates a new tensor with the same values and shape as the specified\n * tensor.\n *\n * ```js\n * const x = tf.tensor([1, 2]);\n *\n * x.clone().print();\n * ```\n *\n * @param x The tensor to clone.\n *\n * @doc {heading: 'Tensors', subheading: 'Creation'}\n */\nfunction clone_(x) {\n    const $x = convertToTensor(x, 'x', 'clone', 'string_or_numeric');\n    const inputs = { x: $x };\n    // Note this op is called tf.identity in python. Hence the kernel name used\n    // here.\n    return ENGINE.runKernel(Identity, inputs);\n}\nexport const clone = op({ clone_ });\n//# sourceMappingURL=clone.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from './environment';\nexport function warn(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.warn(...msg);\n    }\n}\nexport function log(...msg) {\n    if (!env().getBool('IS_TEST')) {\n        console.log(...msg);\n    }\n}\n//# sourceMappingURL=log.js.map","import { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { batchNorm } from './batchnorm';\nimport { op } from './operation';\n/**\n * Batch normalization, strictly for 3D. For the more relaxed version, see\n * `tf.batchNorm`.\n *\n * @param x The input Tensor.\n * @param mean A mean Tensor.\n * @param variance A variance Tensor.\n * @param offset An offset Tensor.\n * @param scale A scale Tensor.\n * @param varianceEpsilon A small float number to avoid dividing by 0.\n */\nfunction batchNorm3d_(x, mean, variance, offset, scale, varianceEpsilon) {\n    const $x = convertToTensor(x, 'x', 'batchNorm');\n    const $mean = convertToTensor(mean, 'mean', 'batchNorm');\n    const $variance = convertToTensor(variance, 'variance', 'batchNorm');\n    let $scale;\n    if (scale != null) {\n        $scale = convertToTensor(scale, 'scale', 'batchNorm');\n    }\n    let $offset;\n    if (offset != null) {\n        $offset = convertToTensor(offset, 'offset', 'batchNorm');\n    }\n    util.assert($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ` +\n        `${$x.rank}.`);\n    util.assert($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but ` +\n        `got rank ${$mean.rank}.`);\n    util.assert($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 ` +\n        `but got rank ${$variance.rank}.`);\n    if ($scale != null) {\n        util.assert($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 ` +\n            `but got rank ${$scale.rank}.`);\n    }\n    if ($offset != null) {\n        util.assert($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 ` +\n            `but got rank ${$offset.rank}.`);\n    }\n    return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);\n}\nexport const batchNorm3d = op({ batchNorm3d_ });\n//# sourceMappingURL=batchnorm3d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cumsum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the cumulative sum of a `tf.Tensor` along `axis`.\n *\n * ```js\n * const x = tf.tensor([1, 2, 3, 4]);\n * x.cumsum().print();\n * ```\n * ```js\n * const x = tf.tensor([[1, 2], [3, 4]]);\n * x.cumsum().print();\n * ```\n *\n * @param x The input tensor to be summed.\n * @param axis The axis along which to sum. Optional. Defaults to 0.\n * @param exclusive Whether to perform exclusive cumulative sum. Optional.\n *     Defaults to false. If set to true then the sum of each tensor entry\n *     does not include its own value, but only the values previous to it\n *     along the specified axis.\n * @param reverse Whether to sum in the opposite direction. Optional.\n *     Defaults to false.\n *\n * @doc {heading: 'Operations', subheading: 'Scan'}\n */\nfunction cumsum_(x, axis = 0, exclusive = false, reverse = false) {\n    const $x = convertToTensor(x, 'x', 'cumsum');\n    const inputs = { x: $x };\n    const attrs = { axis, exclusive, reverse };\n    return ENGINE.runKernel(Cumsum, inputs, attrs);\n}\nexport const cumsum = op({ cumsum_ });\n//# sourceMappingURL=cumsum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DenseBincount } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Outputs a vector with length `size` and the same dtype as `weights`.\n *\n * If `weights` are empty, then index `i` stores the number of times the value\n * `i` is counted in `x`. If `weights` are non-empty, then index `i` stores the\n * sum of the value in `weights` at each index where the corresponding value in\n * `x` is `i`.\n *\n * Values in `x` outside of the range [0, size) are ignored.\n *\n * @param x The input int tensor, rank 1 or rank 2.\n * @param weights The weights tensor, must have the same shape as x, or a\n *     length-0 Tensor, in which case it acts as all weights equal to 1.\n * @param size Non-negative integer.\n * @param binaryOutput Optional. Whether the kernel should count the appearance\n *     or number of occurrences. Defaults to False.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction denseBincount_(x, weights, size, binaryOutput = false) {\n    const $x = convertToTensor(x, 'x', 'denseBincount');\n    const $weights = convertToTensor(weights, 'weights', 'denseBincount');\n    util.assert($x.dtype === 'int32', () => `Error in denseBincount: input ` +\n        `dtype must be int32, but got ${$x.dtype}`);\n    util.assert($x.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got ` +\n        `rank ${$x.rank}.`);\n    util.assert(size >= 0, () => `size must be non-negative, but got ${size}.`);\n    util.assert($weights.size === $x.size || $weights.size === 0, () => `Error in denseBincount: weights must have the same shape as x or ` +\n        `0-length, but got x shape: ${$x.shape}, weights shape: ` +\n        `${$weights.shape}.`);\n    const inputs = { x: $x, weights: $weights };\n    const attrs = { size, binaryOutput };\n    return ENGINE.runKernel(DenseBincount, inputs, attrs);\n}\nexport const denseBincount = op({ denseBincount_ });\n//# sourceMappingURL=dense_bincount.js.map","/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Einsum } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Tensor contraction over specified indices and outer product.\n *\n * `einsum` allows defining Tensors by defining their element-wise computation.\n * This computation is based on\n * [Einstein summation](https://en.wikipedia.org/wiki/Einstein_notation).\n *\n * Some special cases include:\n *\n * Matrix multiplication:\n * ```js\n * const x = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n * const y = tf.tensor2d([[0, 1], [2, 3], [4, 5]]);\n * x.print();\n * y.print();\n * tf.einsum('ij,jk->ik', x, y).print();\n * ```\n *\n * Dot product:\n * ```js\n * const x = tf.tensor1d([1, 2, 3]);\n * const y = tf.tensor1d([0, 1, 2]);\n * x.print();\n * y.print();\n * tf.einsum('i,i->', x, y).print();\n * ```\n *\n * Batch dot product:\n * ```js\n * const x = tf.tensor2d([[1, 2, 3], [4, 5, 6]]);\n * const y = tf.tensor2d([[0, 1, 2], [3, 4, 5]]);\n * x.print();\n * y.print();\n * tf.einsum('bi,bi->b', x, y).print();\n * ```\n *\n * Outer prouduct:\n * ```js\n * const x = tf.tensor1d([1, 3, 5]);\n * const y = tf.tensor1d([2, 4, 6]);\n * x.print();\n * y.print();\n * tf.einsum('i,j->ij', x, y).print();\n * ```\n *\n * Matrix transpose:\n * ```js\n * const x = tf.tensor2d([[1, 2], [3, 4]]);\n * x.print();\n * tf.einsum('ij->ji', x).print();\n * ```\n *\n * Batch matrix transpose:\n * ```js\n * const x = tf.tensor3d([[[1, 2], [3, 4]], [[-1, -2], [-3, -4]]]);\n * x.print();\n * tf.einsum('bij->bji', x).print();\n * ```\n *\n * Limitations:\n *\n * This implementation of einsum has the following limitations:\n *\n * - Does not support >2 input tensors.\n * - Does not support duplicate axes for any given input tensor. E.g., equation\n *   'ii->' is not suppoted.\n * - The `...` notation is not supported.\n *\n * @param equation a string describing the contraction, in the same format as\n * [numpy.einsum](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html).\n * @param tensors the input(s) to contract (each one a Tensor), whose shapes\n *     should be consistent with equation.\n * @returns The output tensor.\n *\n * @doc {heading: 'Tensors', subheading: 'Matrices'}\n */\nexport function einsum_(equation, ...tensors) {\n    const $tensors = tensors.map((t, i) => convertToTensor(t, `tensors${i}`, 'einsum'));\n    const attrs = { equation };\n    return ENGINE.runKernel(Einsum, $tensors, attrs);\n}\nexport const einsum = op({ einsum_ });\n//# sourceMappingURL=einsum.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv2DBackpropInput } from '../kernel_names';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the derivative of the input of a 2D convolution.\n *\n * @param xShape The shape of the input: [batch, height, width, inDepth].\n * If length of 3, batch of 1 is assumed.\n * @param dy The derivative of the output, of rank 4 or rank 3 of shape\n *   `[batch, outHeight, outWidth, outDepth]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter, rank 4, of shape\n *     `[filterHeight, filterWidth, inDepth, outDepth]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm used:\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels].\n * @param dimRoundingMode A string from: 'ceil', 'round', 'floor'. If none is\n *     provided, it will default to truncate.\n */\nfunction conv2DBackpropInput_(xShape, dy, filter, strides, pad, dataFormat = 'NHWC', dimRoundingMode) {\n    util.assert(xShape.length === dy.rank, () => `Length of inShape ` +\n        `(${xShape.length}) and rank of dy (${dy.rank}) must match`);\n    let xShape4D = xShape;\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n        xShape4D = [1, xShape[0], xShape[1], xShape[2]];\n    }\n    util.assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ` +\n        `${xShape4D.length}.`);\n    util.assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got ` +\n        `rank ${dy4D.rank}`);\n    util.assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got ` +\n        `rank ${filter.rank}`);\n    const inDepth = dataFormat === 'NHWC' ? xShape4D[3] : xShape4D[1];\n    const outDepth = dataFormat === 'NHWC' ? dy4D.shape[3] : dy4D.shape[1];\n    util.assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must ` +\n        `match input depth for filter ${filter.shape[2]}.`);\n    util.assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must ` +\n        `match output depth for filter ${filter.shape[3]}.`);\n    if (dimRoundingMode != null) {\n        util.assert(util.isInt(pad), () => `Error in conv2dDerInput: pad must be an integer when using, ` +\n            `dimRoundingMode ${dimRoundingMode} but got pad ${pad}.`);\n    }\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dataFormat, dimRoundingMode, inputShape: xShape4D };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const conv2DBackpropInput = op({ conv2DBackpropInput_ });\n//# sourceMappingURL=conv2d_backprop_input.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * Gets the new shape of the input Tensor after it's been reshaped\n * to:\n * [blockShape[0], ..., blockShape[M-1], batch / prod(blockShape),\n * inputShape[1], ..., inputShape[N-1]]\n *\n * See step 1: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshaped(inputShape, blockShape, prod, batchToSpace = true) {\n    let reshaped = [];\n    if (batchToSpace) {\n        reshaped = reshaped.concat(blockShape.slice(0));\n        reshaped.push(inputShape[0] / prod);\n        reshaped = reshaped.concat(inputShape.slice(1));\n    }\n    else {\n        reshaped = reshaped.concat(inputShape[0]);\n        const spatialLength = blockShape.length;\n        for (let i = 0; i < spatialLength; ++i) {\n            reshaped =\n                reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);\n        }\n        reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));\n    }\n    return reshaped;\n}\n/**\n * Gets the permutation that will transpose the dimensions of the\n * reshaped tensor to shape:\n *\n * [batch / prod(block_shape),inputShape[1], blockShape[0], ...,\n * inputShape[M], blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * see step 2: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {\n    const permuted = [];\n    if (batchToSpace) {\n        permuted.push(blockShapeRank);\n        for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {\n            if (i <= 2 * blockShapeRank) {\n                permuted.push(i);\n                permuted.push(i - (blockShapeRank + 1));\n            }\n            else {\n                permuted.push(i);\n            }\n        }\n    }\n    else {\n        const permutedBeforeBatch = [];\n        const permutedAfterBatch = [];\n        for (let i = 1; i < reshapedRank; ++i) {\n            if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {\n                permutedAfterBatch.push(i);\n            }\n            else {\n                permutedBeforeBatch.push(i);\n            }\n        }\n        permuted.push(...permutedBeforeBatch);\n        permuted.push(0);\n        permuted.push(...permutedAfterBatch);\n    }\n    return permuted;\n}\n/**\n * Gets the shape of the reshaped and permuted input Tensor before any cropping\n * is applied.  The new shape will be:\n *\n * [batch / prod(blockShape),inputShape[1] * blockShape[0], ...,\n * inputShape[M] * blockShape[M-1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 3: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getReshapedPermuted(inputShape, blockShape, prod, batchToSpace = true) {\n    const reshapedPermuted = [];\n    if (batchToSpace) {\n        reshapedPermuted.push(inputShape[0] / prod);\n    }\n    else {\n        reshapedPermuted.push(inputShape[0] * prod);\n    }\n    for (let i = 1; i < inputShape.length; ++i) {\n        if (i <= blockShape.length) {\n            if (batchToSpace) {\n                reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);\n            }\n            else {\n                reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);\n            }\n        }\n        else {\n            reshapedPermuted.push(inputShape[i]);\n        }\n    }\n    return reshapedPermuted;\n}\n/**\n * Converts the crops argument into the beginning coordinates of a slice\n * operation.\n */\nexport function getSliceBeginCoords(crops, blockShape) {\n    const sliceBeginCoords = [0];\n    for (let i = 0; i < blockShape; ++i) {\n        sliceBeginCoords.push(crops[i][0]);\n    }\n    return sliceBeginCoords;\n}\n/**\n * Converts the crops argument into the size of a slice operation.  When\n * combined with getSliceBeginCoords this function allows the reshaped and\n * permuted Tensor to be cropped to its final output shape of:\n *\n * inputShape[1] * blockShape[0] - crops[0,0] - crops[0,1], ...,\n * inputShape[M] * blockShape[M-1] -crops[M-1,0] -\n * crops[M-1,1],inputShape[M+1], ..., inputShape[N-1]]\n *\n * See step 4: https://www.tensorflow.org/api_docs/python/tf/batch_to_space_nd\n */\nexport function getSliceSize(uncroppedShape, crops, blockShape) {\n    const sliceSize = uncroppedShape.slice(0, 1);\n    for (let i = 0; i < blockShape; ++i) {\n        sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);\n    }\n    return sliceSize;\n}\n//# sourceMappingURL=array_ops_util.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { DepthwiseConv2dNativeBackpropInput } from '../kernel_names';\nimport { op } from './operation';\nimport { reshape } from './reshape';\nfunction depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad, dilations = [1, 1], dimRoundingMode) {\n    let dy4D = dy;\n    let reshapedTo4D = false;\n    if (dy.rank === 3) {\n        reshapedTo4D = true;\n        dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);\n    }\n    const inputs = { dy: dy4D, filter };\n    const attrs = { strides, pad, dimRoundingMode, dilations, inputShape: xShape };\n    const res = \n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });\n//# sourceMappingURL=depthwise_conv2d_native_backprop_input.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Elu } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes exponential linear element-wise: `x > 0 ? e ^ x - 1 : 0`.\n *\n * ```js\n * const x = tf.tensor1d([-1, 1, -3, 2]);\n *\n * x.elu().print();  // or tf.elu(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction elu_(x) {\n    const $x = convertToTensor(x, 'x', 'elu');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Elu, inputs);\n}\nexport const elu = op({ elu_ });\n//# sourceMappingURL=elu.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Any } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes the logical or of elements across dimensions of a `tf.Tensor`.\n *\n * Reduces the input along the dimensions given in `axes`. Unless `keepDims`\n * is true, the rank of the `tf.Tensor` is reduced by 1 for each entry in\n * `axes`. If `keepDims` is true, the reduced dimensions are retained with\n * length 1. If `axes` has no entries, all dimensions are reduced, and an\n * `tf.Tensor` with a single element is returned.\n *\n * ```js\n * const x = tf.tensor1d([1, 1, 1], 'bool');\n *\n * x.any().print();  // or tf.any(x)\n * ```\n *\n * ```js\n * const x = tf.tensor2d([1, 1, 0, 0], [2, 2], 'bool');\n *\n * const axis = 1;\n * x.any(axis).print();  // or tf.any(x, axis)\n * ```\n *\n * @param x The input tensor. Must be of dtype bool.\n * @param axis The dimension(s) to reduce. By default it reduces\n *     all dimensions.\n * @param keepDims If true, retains reduced dimensions with size 1.\n *\n * @doc {heading: 'Operations', subheading: 'Reduction'}\n */\nfunction any_(x, axis = null, keepDims = false) {\n    const $x = convertToTensor(x, 'x', 'any', 'bool');\n    const inputs = { x: $x };\n    const attrs = { axis, keepDims };\n    return ENGINE.runKernel(Any, inputs, attrs);\n}\n// tslint:disable-next-line:variable-name\nexport const any = op({ any_ });\n//# sourceMappingURL=any.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { RealDiv } from '../kernel_names';\nimport { makeTypesMatch } from '../tensor_util';\nimport { convertToTensor } from '../tensor_util_env';\nimport { floorDiv } from './floorDiv';\nimport { op } from './operation';\n/**\n * Divides two `tf.Tensor`s element-wise, A / B. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([1, 4, 9, 16]);\n * const b = tf.tensor1d([1, 2, 3, 4]);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * ```js\n * // Broadcast div a with b.\n * const a = tf.tensor1d([2, 4, 6, 8]);\n * const b = tf.scalar(2);\n *\n * a.div(b).print();  // or tf.div(a, b)\n * ```\n *\n * @param a The first tensor as the numerator.\n * @param b The second tensor as the denominator. Must have the same dtype as\n * `a`.\n *\n * @doc {heading: 'Operations', subheading: 'Arithmetic'}\n */\nfunction div_(a, b) {\n    let $a = convertToTensor(a, 'a', 'div');\n    let $b = convertToTensor(b, 'b', 'div');\n    [$a, $b] = makeTypesMatch($a, $b);\n    if ($a.dtype === 'int32' && $b.dtype === 'int32') {\n        return floorDiv($a, $b);\n    }\n    const inputs = { a: $a, b: $b };\n    const attrs = {};\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    return ENGINE.runKernel(RealDiv, inputs, attrs);\n}\nexport const div = op({ div_ });\n//# sourceMappingURL=div.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Conv3D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { eitherStridesOrDilationsAreOne } from './conv_util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes a 3D convolution over the input x.\n *\n * @param x The input tensor, of rank 5 or rank 4, of shape\n *     `[batch, depth, height, width, channels]`. If rank 4,\n * batch of 1 is assumed.\n * @param filter The filter, rank 5, of shape\n *     `[filterDepth, filterHeight, filterWidth, inChannels, outChannels]`.\n *      inChannels must match between input and filter.\n * @param strides The strides of the convolution: `[strideDepth, strideHeight,\n * strideWidth]`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat: An optional string from: \"NDHWC\", \"NCDHW\". Defaults to\n *     \"NDHWC\". Specify the data format of the input and output data. With the\n *     default format \"NDHWC\", the data is stored in the order of: [batch,\n *     depth, height, width, channels]. Only \"NDHWC\" is currently supported.\n * @param dilations The dilation rates: `[dilationDepth, dilationHeight,\n *     dilationWidth]` in which we sample input values across the height\n *     and width dimensions in atrous convolution. Defaults to `[1, 1, 1]`.\n *     If `dilations` is a single number, then\n *     `dilationDepth == dilationHeight == dilationWidth`. If it is greater\n *     than 1, then all values of `strides` must be 1.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction conv3d_(x, filter, strides, pad, dataFormat = 'NDHWC', dilations = [1, 1, 1]) {\n    const $x = convertToTensor(x, 'x', 'conv3d');\n    const $filter = convertToTensor(filter, 'filter', 'conv3d');\n    let x5D = $x;\n    let reshapedTo5D = false;\n    if ($x.rank === 4) {\n        reshapedTo5D = true;\n        x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);\n    }\n    util.assert(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);\n    util.assert($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match ` +\n        `input depth for filter ${$filter.shape[3]}.`);\n    util.assert(eitherStridesOrDilationsAreOne(strides, dilations), () => 'Error in conv3D: Either strides or dilations must be 1. ' +\n        `Got strides ${strides} and dilations '${dilations}'`);\n    util.assert(dataFormat === 'NDHWC', () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);\n    const inputs = { x: x5D, filter: $filter };\n    const attrs = { strides, pad, dataFormat, dilations };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Conv3D, inputs, attrs);\n    if (reshapedTo5D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);\n    }\n    return res;\n}\nexport const conv3d = op({ conv3d_ });\n//# sourceMappingURL=conv3d.js.map","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Dilation2D } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\nimport { reshape } from './reshape';\n/**\n * Computes the grayscale dilation over the input `x`.\n *\n * @param x The input tensor, rank 3 or rank 4 of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is assumed.\n * @param filter The filter tensor, rank 3, of shape\n *     `[filterHeight, filterWidth, depth]`.\n * @param strides The strides of the sliding window for each dimension of the\n *     input tensor: `[strideHeight, strideWidth]`.\n *     If `strides` is a single number,\n *     then `strideHeight == strideWidth`.\n * @param pad The type of padding algorithm.\n *    - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *    - `valid`: output will be smaller than input if filter is larger\n *       than 1*1x1.\n *    - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dataFormat Specify the data format of the input and output data.\n *      Defaults to 'NHWC'. Only 'NHWC' is currently supported. With the\n *      default format \"NHWC\", the data is stored in the order of: [batch,\n *      height, width, channels].\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     for atrous morphological dilation. Defaults to `[1, 1]`. If `dilations`\n *     is a single number, then `dilationHeight == dilationWidth`. If it is\n *     greater than 1, then all values of `strides` must be 1.\n *\n * @doc {heading: 'Operations', subheading: 'Convolution'}\n */\nfunction dilation2d_(x, filter, strides, pad, dilations = [1, 1], dataFormat = 'NHWC') {\n    const $x = convertToTensor(x, 'x', 'dilation2d');\n    const $filter = convertToTensor(filter, 'filter', 'dilation2d');\n    util.assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ` +\n        `${$x.rank}.`);\n    util.assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ` +\n        `${$filter.rank}.`);\n    util.assert(dataFormat === 'NHWC', () => `Error in dilation2d: Only NHWC is currently supported, ` +\n        `but got dataFormat of ${dataFormat}`);\n    let x4D = $x;\n    let reshapedTo4D = false;\n    if ($x.rank === 3) {\n        x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n        reshapedTo4D = true;\n    }\n    const inputs = { x: x4D, filter: $filter };\n    const attrs = { strides, pad, dilations };\n    // tslint:disable-next-line: no-unnecessary-type-assertion\n    const res = ENGINE.runKernel(Dilation2D, inputs, attrs);\n    if (reshapedTo4D) {\n        return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n    }\n    return res;\n}\nexport const dilation2d = op({ dilation2d_ });\n//# sourceMappingURL=dilation2d.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Erf } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport { op } from './operation';\n/**\n * Computes gause error function of the input `tf.Tensor` element-wise:\n * `erf(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, .1, -.1, .7]);\n *\n * x.erf().print(); // or tf.erf(x);\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction erf_(x) {\n    let $x = convertToTensor(x, 'x', 'erf');\n    util.assert($x.dtype === 'int32' || $x.dtype === 'float32', () => 'Input dtype must be `int32` or `float32`.');\n    if ($x.dtype === 'int32') {\n        $x = cast($x, 'float32');\n    }\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Erf, inputs);\n}\nexport const erf = op({ erf_ });\n//# sourceMappingURL=erf.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { ClipByValue } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { op } from './operation';\n/**\n * Clips values element-wise. `max(min(x, clipValueMax), clipValueMin)`\n *\n * ```js\n * const x = tf.tensor1d([-1, 2, -3, 4]);\n *\n * x.clipByValue(-2, 3).print();  // or tf.clipByValue(x, -2, 3)\n * ```\n * @param x The input tensor.\n * @param clipValueMin Lower-bound of range to be clipped to.\n * @param clipValueMax Upper-bound of range to be clipped to.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction clipByValue_(x, clipValueMin, clipValueMax) {\n    const $x = convertToTensor(x, 'x', 'clipByValue');\n    util.assert((clipValueMin <= clipValueMax), () => `Error in clip: min (${clipValueMin}) must be ` +\n        `less than or equal to max (${clipValueMax}).`);\n    const inputs = { x: $x };\n    const attrs = { clipValueMin, clipValueMax };\n    return ENGINE.runKernel(ClipByValue, inputs, attrs);\n}\nexport const clipByValue = op({ clipByValue_ });\n//# sourceMappingURL=clip_by_value.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { convertToTensor } from '../tensor_util_env';\nimport * as util from '../util';\nimport { cast } from './cast';\nimport { matMul } from './mat_mul';\nimport { oneHot } from './one_hot';\nimport { op } from './operation';\nimport { transpose } from './transpose';\n/**\n * Computes the confusion matrix from true labels and predicted labels.\n *\n * ```js\n * const labels = tf.tensor1d([0, 1, 2, 1, 0], 'int32');\n * const predictions = tf.tensor1d([0, 2, 2, 1, 0], 'int32');\n * const numClasses = 3;\n * const out = tf.math.confusionMatrix(labels, predictions, numClasses);\n * out.print();\n * // Expected output matrix:\n * // [[2, 0, 0],\n * //  [0, 1, 1],\n * //  [0, 0, 1]]\n * ```\n *\n * @param labels The target labels, assumed to be 0-based integers\n *   for the classes. The shape is `[numExamples]`, where\n *   `numExamples` is the number of examples included.\n * @param predictions The predicted classes, assumed to be\n *   0-based integers for the classes. Must have the same shape as `labels`.\n * @param numClasses Number of all classes, as an integer.\n *   Its value must be larger than the largest element in `labels` and\n *   `predictions`.\n * @returns The confusion matrix as a int32-type 2D tensor. The value at\n *   row `r` and column `c` is the number of times examples of actual class\n *   `r` were predicted as class `c`.\n *\n * @doc {heading: 'Operations', subheading: 'Evaluation'}\n */\nexport function confusionMatrix_(labels, predictions, numClasses) {\n    const $labels = convertToTensor(labels, 'labels', 'confusionMatrix');\n    const $predictions = convertToTensor(predictions, 'predictions', 'confusionMatrix');\n    util.assert(numClasses == null || numClasses > 0 && Number.isInteger(numClasses), () => `If provided, numClasses must be a positive integer, ` +\n        `but got ${numClasses}`);\n    util.assert($labels.rank === 1, () => `Expected the rank of labels to be 1, but got ${$labels.rank}`);\n    util.assert($predictions.rank === 1, () => `Expected the rank of predictions to be 1, ` +\n        `but got ${$predictions.rank}`);\n    util.assert($labels.shape[0] === $predictions.shape[0], () => `Mismatch in the number of examples: ` +\n        `${$labels.shape[0]} vs. ${$predictions.shape[0]}. ` +\n        `Labels and predictions should have the same number of elements.`);\n    util.assert(numClasses > 0 && Number.isInteger(numClasses), () => `numClasses is required to be a positive integer, but got ` +\n        `${numClasses}`);\n    // TODO(cais): In the future, if oneHot supports tensors inputs for\n    //   `numClasses`, `confusionMatrix` can make `numClasses` optional.\n    const oneHotLabels = oneHot(cast($labels, 'int32'), numClasses);\n    const oneHotPredictions = oneHot(cast($predictions, 'int32'), numClasses);\n    const oneHotLabelsT = transpose(oneHotLabels);\n    const product = matMul(oneHotLabelsT, oneHotPredictions);\n    return cast(product, 'int32');\n}\nexport const confusionMatrix = op({ confusionMatrix_ });\n//# sourceMappingURL=confusion_matrix.js.map","/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { Cos } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { op } from './operation';\n/**\n * Computes cos of the input `tf.Tensor` element-wise: `cos(x)`\n *\n * ```js\n * const x = tf.tensor1d([0, Math.PI / 2, Math.PI * 3 / 4]);\n *\n * x.cos().print();  // or tf.cos(x)\n * ```\n * @param x The input tensor.\n *\n * @doc {heading: 'Operations', subheading: 'Basic math'}\n */\nfunction cos_(x) {\n    const $x = convertToTensor(x, 'x', 'cos');\n    const inputs = { x: $x };\n    return ENGINE.runKernel(Cos, inputs);\n}\nexport const cos = op({ cos_ });\n//# sourceMappingURL=cos.js.map"],"names":["buffer","shape","dtype","values","divNoNan","op","divNoNan_","a","b","$a","$b","makeTypesMatch","divResult","zeros","bEqualsZero","conv1d","conv1d_","x","filter","stride","pad","dataFormat","dilation","dimRoundingMode","$x","$filter","x3D","reshapedTo3D","rank","filter4D","input4D","strides","dilations","res","abs","abs_","inputs","runKernel","exp","exp_","expandDims","expandDims_","axis","input","attrs","dim","batchNorm","batchNorm_","mean","variance","offset","scale","varianceEpsilon","$mean","$variance","$scale","$offset","x4D","reshape","size","xAs4D","diag","diag_","depthwiseConv2d","depthwiseConv2d_","reshapedTo4D","argMax","argMax_","ERF_P","ERF_A1","ERF_A2","ERF_A3","ERF_A4","ERF_A5","all","all_","keepDims","assertParamsConsistent","shapes","length","forEach","i","firstShape","r","computeOutShape","outputShape","slice","acos","acos_","equal","equal_","batchNorm2d","batchNorm2d_","addN","addN_","tensors","Array","isArray","$tensors","map","t","firstTensor","Error","dropout","dropout_","rate","noiseShape","seed","clone","$noiseShape","newDimension","push","getNoiseShape","keepProb","multiplier","div","floor","add","mul","concat2d","concat2d_","axesAreInnerMostDims","axes","combineLocations","outputLoc","reduceLoc","loc","outIdx","reduceIdx","indexOf","computeOutAndReduceShapes","aShape","outShape","expandShapeToKeepDim","assertAxesAreInnerMostDims","msg","getAxesPermutation","result","getUndoAxesPermutation","sort","getInnerMostAxes","numAxes","atan2","atan2_","concat","concat_","tensor","attr","conv2DBackpropFilter","conv2DBackpropFilter_","dy","filterShape","dy4D","inDepth","outDepth","avgPoolGrad","avgPoolGrad_","filterSize","$dy","$input","cosh","cosh_","fromPixels2DContext","fromPixels_","pixels","numChannels","isPixelData","isImageData","isVideo","isImage","isCanvasLike","isImageBitmap","data","Uint8Array","ImageData","HTMLVideoElement","HTMLImageElement","getContext","ImageBitmap","constructor","name","HAVE_CURRENT_DATA_READY_STATE","readyState","backendName","width","height","videoWidth","videoHeight","vals","getImageData","document","createElement","canvas","drawImage","Int32Array","numPixels","channel","canWrapPixelsToImageBitmap","window","hasOwnProperty","isNonEmptyPixels","async","fromPixelsAsync","getBool","imageBitmap","createImageBitmap","premultiplyAlpha","e","toPixels","img","$img","originalImgTensor","dispose","depth","bytes","Uint8ClampedArray","rgba","d","value","j","Math","round","ctx","imageData","putImageData","fromPixels","batchNorm4d","batchNorm4d_","conv2d","conv2d_","atan","atan_","cast","cast_","ceil","ceil_","depthToSpace","depthToSpace_","blockSize","inputHeight","inputWidth","inputDepth","conv3DBackpropInput","conv3DBackpropInput_","xShape","xShape5D","dy5D","reshapedTo5D","inputShape","booleanMaskAsync","mask","$tensor","$mask","axisFrom","maskDim","tensorShape","leadingSize","targetTensorShape","reshapedTensor","reshapedMask","positivePositions","indices","complex","complex_","real","imag","$real","$imag","add_","acosh","acosh_","expm1","expm1_","bincount","bincount_","weights","$weights","conv2dTranspose","conv2dTranspose_","conv3dTranspose","conv3dTranspose_","c","depthwiseConv2dNativeBackpropFilter","depthwiseConv2dNativeBackpropFilter_","concat1d","concat1d_","computeDilation2DInfo","computeConv2DInfo","convertConv2DDataFormat","computePool2DInfo","inShape","roundingMode","filterHeight","filterWidth","parseTupleParam","computePool3DInfo","filterDepth","parse3TupleParam","$dataFormat","computeConv3DInfo","depthwise","batchSize","inHeight","inWidth","inChannels","filterChannels","strideHeight","strideWidth","dilationHeight","dilationWidth","effectiveFilterHeight","getEffectiveFilterSize","effectiveFilterWidth","padInfo","outHeight","outWidth","top","bottom","left","right","type","fieldSize","zeroPad","computeDefaultPad","inputRows","inputCols","outputRows","outputCols","computeOutputShape2D","padAlongHeight","max","padAlongWidth","getPadAndOutInfo","outChannels","strideDepth","dilationDepth","effectiveFilterDepth","front","back","outputDepths","computeOutputShape4D","padAlongDepth","get3DPadAndOutInfo","effectiveFieldSize","param","trunc","tupleValuesAreOne","dimA","dimB","dimC","eitherStridesOrDilationsAreOne","avgPool3dGrad","avgPool3dGrad_","input5D","asinh","asinh_","eye","eye_","numRows","numColumns","batchShape","buff","n","set","out","toTensor","avgPool3d","avgPool3d_","x5D","avgPool","avgPool_","argMin","argMin_","concat3d","concat3d_","concat4d","concat4d_","getBroadcastDims","inRank","dims","unshift","getReductionAxes","inDim","outAxis","outDim","assertAndGetBroadcastShape","shapeA","shapeB","l","broadcastTo","broadcastTo_","some","newShape","reps","from","atanh","atanh_","conv3DBackpropFilter","conv3DBackpropFilter_","asin","asin_","dot","dot_","t1","t2","$t1","$t2","t1Inner","t2Inner","t12D","t22D","t1t2","batchToSpaceND","batchToSpaceND_","blockShape","crops","prod","reduce","join","basicLSTMCell","basicLSTMCell_","forgetBias","lstmKernel","lstmBias","h","$forgetBias","$lstmKernel","$lstmBias","$data","$c","$h","combined","weighted","sliceCols","sliceSize","f","o","newC","clone_","warn","log","batchNorm3d","batchNorm3d_","cumsum","cumsum_","exclusive","reverse","denseBincount","denseBincount_","binaryOutput","einsum","einsum_","equation","conv2DBackpropInput","conv2DBackpropInput_","xShape4D","getReshaped","batchToSpace","reshaped","spatialLength","getPermuted","reshapedRank","blockShapeRank","permuted","permutedBeforeBatch","permutedAfterBatch","getReshapedPermuted","reshapedPermuted","getSliceBeginCoords","sliceBeginCoords","getSliceSize","uncroppedShape","depthwiseConv2dNativeBackpropInput","depthwiseConv2dNativeBackpropInput_","elu","elu_","any","any_","div_","conv3d","conv3d_","dilation2d","dilation2d_","erf","erf_","clipByValue","clipByValue_","clipValueMin","clipValueMax","confusionMatrix","confusionMatrix_","labels","predictions","numClasses","$labels","$predictions","Number","isInteger","oneHotLabels","oneHotPredictions","oneHotLabelsT","transpose","product","cos","cos_"],"sourceRoot":""}