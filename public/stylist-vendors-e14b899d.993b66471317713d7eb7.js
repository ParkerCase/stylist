"use strict";(self.webpackChunkStylistWidget=self.webpackChunkStylistWidget||[]).push([[623],{59297:function(t,e,s){var i=s(9495),n=s(47661),r=s(39459),a=s(79730),l=s(15841),o=s(59351),h=s(69184),u=s(44813),c=s(63057),p=s(76481),d=function(t,e){var s={};for(var i in t)Object.prototype.hasOwnProperty.call(t,i)&&e.indexOf(i)<0&&(s[i]=t[i]);if(null!=t&&"function"===typeof Object.getOwnPropertySymbols){var n=0;for(i=Object.getOwnPropertySymbols(t);n<i.length;n++)e.indexOf(i[n])<0&&Object.prototype.propertyIsEnumerable.call(t,i[n])&&(s[i[n]]=t[i[n]])}return s};class g extends p.VS{constructor(t){if(t.unroll)throw new l.EH("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new l.EH("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new a.eO({ndim:5})]}call(t,e){return i.tidy((()=>{if(null!=this.cell.dropoutMask&&(i.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(i.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new l.Qp("ConvRNN2D cell does not support constants");const s=null==e?null:e.mask,n=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:s,training:n,initialState:r})}))}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return i.tidy((()=>{const{stateSize:e}=this.cell,s=t.shape,n=this.computeSingleOutputShape(s),r=[n[0],...n.slice(2)],a=i.zeros(r);return Array.isArray(e)?Array(e.length).fill(a):[a]}))}resetStates(t,e=!1){i.tidy((()=>{if(!this.stateful)throw new l.l7("Cannot call resetStates() on an RNN Layer that is not stateful.");const s=this.inputSpec[0].shape,n=this.computeSingleOutputShape(s),r=[n[0],...n.slice(2)];if(null==s[0])throw new l.Qp("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>i.zeros(r))):this.states_=[i.zeros(r)];else if(null==t)i.dispose(this.states_),null!=this.keptStates&&(i.dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>i.zeros(r))):this.states_[0]=i.zeros(r);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new l.Qp(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e?this.keptStates.push(this.states_.slice()):i.dispose(this.states_);for(let e=0;e<this.states_.length;++e){const s=t[e],n=r;if(!i.util.arraysEqual(s.shape,n))throw new l.Qp(`State ${e} is incompatible with layer ${this.name}: expected shape=${n}, received shape=${s.shape}`);this.states_[e]=s}}this.states_=this.states_.map((t=>i.keep(t.clone())))}))}computeSingleOutputShape(t){const{dataFormat:e,filters:s,kernelSize:i,padding:n,strides:r,dilationRate:a}=this.cell,l="channelsFirst"===e,o=t[l?3:2],u=t[l?4:3],c=(0,h.Ol)(o,i[0],n,r[0],a[0]),p=(0,h.Ol)(u,i[1],n,r[1],a[1]);return[...t.slice(0,2),...l?[s,c,p]:[c,p,s]]}}g.className="ConvRNN2D";class f extends p.Tu{constructor(t){const{filters:e,kernelSize:s,strides:i,padding:n,dataFormat:a,dilationRate:l}=t;super(Object.assign(Object.assign({},t),{units:e})),this.filters=e,(0,u.oo)(this.filters,"filters"),this.kernelSize=(0,h.J)(s,2,"kernelSize"),this.kernelSize.forEach((t=>(0,u.oo)(t,"kernelSize"))),this.strides=(0,h.J)(i||1,2,"strides"),this.strides.forEach((t=>(0,u.oo)(t,"strides"))),this.padding=n||"valid",(0,r.tB)(this.padding),this.dataFormat=a||"channelsLast",(0,r.uM)(this.dataFormat),this.dilationRate=(0,h.J)(l||1,2,"dilationRate"),this.dilationRate.forEach((t=>(0,u.oo)(t,"dilationRate")))}build(t){var e;t=(0,c.U$)(t);const s="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[s])throw new l.Qp(`The channel dimension of the input should be defined. Found ${t[s]}`);const r=t[s],a=this.kernelSize.concat([r,4*this.filters]);this.kernel=this.addWeight("kernel",a,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const h=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",h,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let t;if(this.unitForgetBias){const s=this.biasInitializer,r=this.filters;t=new((e=class extends o.H4{apply(t,e){const a=s.apply([r]),l=i.ones([r]),o=s.apply([2*r]);return n.u1([a,l,o])}}).className="CustomInit",e)}else t=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,t,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return i.tidy((()=>{if(3!==t.length)throw new l.Qp(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const s=e.training||!1,n=t[0],r=t[1],a=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=(0,p.FW)({ones:()=>i.onesLike(n),rate:this.dropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const o=this.dropoutMask,h=(t,e,s)=>e&&e[s]?i.mul(e[s],t):t;let u=h(n,o,0),c=h(n,o,1),d=h(n,o,2),g=h(n,o,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=(0,p.FW)({ones:()=>i.onesLike(r),rate:this.recurrentDropout,training:s,count:4,dropoutFunc:this.dropoutFunc}));const f=this.recurrentDropoutMask;let S=h(r,f,0),y=h(r,f,1),k=h(r,f,2),m=h(r,f,3);const[b,v,z,C]=i.split(this.kernel.read(),4,3),[w,O,F,N]=this.useBias?i.split(this.bias.read(),4):[null,null,null,null];u=this.inputConv(u,b,w,this.padding),c=this.inputConv(c,v,O,this.padding),d=this.inputConv(d,z,F,this.padding),g=this.inputConv(g,C,N,this.padding);const[R,A,M,I]=i.split(this.recurrentKernel.read(),4,3);S=this.recurrentConv(S,R),y=this.recurrentConv(y,A),k=this.recurrentConv(k,M),m=this.recurrentConv(m,I);const D=this.recurrentActivation.apply(i.add(u,S)),_=this.recurrentActivation.apply(i.add(c,y)),W=i.add(i.mul(_,a),i.mul(D,this.activation.apply(i.add(d,k)))),$=i.mul(this.recurrentActivation.apply(i.add(g,m)),this.activation.apply(W));return[$,$,W]}))}getConfig(){const t=super.getConfig(),{units:e}=t,s=d(t,["units"]),i={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign(Object.assign({},s),i)}inputConv(t,e,s,r){const a=i.conv2d(t,e,this.strides,r||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return s?n.ni(a,s,this.dataFormat):a}recurrentConv(t,e){return i.conv2d(t,e,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}f.className="ConvLSTM2DCell",i.serialization.registerClass(f);class S extends g{constructor(t){const e=new f(t);super(Object.assign(Object.assign({},t),{cell:e}))}static fromConfig(t,e){return new t(e)}}S.className="ConvLSTM2D",i.serialization.registerClass(S)}}]);
//# sourceMappingURL=stylist-vendors-e14b899d.993b66471317713d7eb7.js.map