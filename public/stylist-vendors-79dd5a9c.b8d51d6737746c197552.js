"use strict";(self.webpackChunkStylistWidget=self.webpackChunkStylistWidget||[]).push([[9587],{7580:function(t,i,e){var s=e(9495),n=e(59885),a=e(47661),r=e(87504),l=e(79730),h=e(15841),o=e(59351),u=e(84379),p=e(44813),d=e(73072),c=e(63057);class g extends l.Wd{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(null==this.noiseShape)return this.noiseShape;const i=t.shape,e=[];for(let s=0;s<this.noiseShape.length;++s)e.push(null==this.noiseShape[s]?i[s]:this.noiseShape[s]);return e}call(t,i){return(0,s.tidy)((()=>{this.invokeCallHook(t,i);const e=(0,c.un)(t);if(0<this.rate&&this.rate<1){const t=null!=i.training&&i.training,s=this.getNoiseShape(e);return a.Ls((()=>a.EZ(e,this.rate,s,this.seed)),(()=>e),t)}return t}))}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},i=super.getConfig();return Object.assign(t,i),t}dispose(){return super.dispose()}}g.className="Dropout",s.serialization.registerClass(g);class f extends g{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const i=t.shape;return[i[0],1,i[2]]}}f.className="SpatialDropout1D",s.serialization.registerClass(f);class m extends l.Wd{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==t.batchInputShape&&null==t.inputShape&&null!=t.inputDim){let i=null;null!=t.batchSize&&(i=t.batchSize),this.batchInputShape=[i,t.inputDim]}this.units=t.units,(0,p.oo)(this.units,"units"),this.activation=(0,n.b_)(t.activation),null!=t.useBias&&(this.useBias=t.useBias),this.kernelInitializer=(0,o.Fe)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=(0,o.Fe)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=(0,r.YZ)(t.kernelConstraint),this.biasConstraint=(0,r.YZ)(t.biasConstraint),this.kernelRegularizer=(0,u.Bm)(t.kernelRegularizer),this.biasRegularizer=(0,u.Bm)(t.biasRegularizer),this.activityRegularizer=(0,u.Bm)(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){const i=(t=(0,c.U$)(t))[t.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[i,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:i}}],this.built=!0}computeOutputShape(t){const i=(t=(0,c.U$)(t)).slice();return i[i.length-1]=this.units,i}call(t,i){return(0,s.tidy)((()=>{this.invokeCallHook(t,i);const e=(0,c.un)(t),s=(0,p.Cd)(this.activation.getClassName());let n;return null!=s?n=a.Om(e,this.kernel.read(),s,this.bias?this.bias.read():null):(n=a.Om(e,this.kernel.read()),null!=this.bias&&(n=a.ni(n,this.bias.read())),null!=this.activation&&(n=this.activation.apply(n))),n}))}getConfig(){const t={units:this.units,activation:(0,n.Bu)(this.activation),useBias:this.useBias,kernelInitializer:(0,o.zo)(this.kernelInitializer),biasInitializer:(0,o.zo)(this.biasInitializer),kernelRegularizer:(0,u.R9)(this.kernelRegularizer),biasRegularizer:(0,u.R9)(this.biasRegularizer),activityRegularizer:(0,u.R9)(this.activityRegularizer),kernelConstraint:(0,r.uH)(this.kernelConstraint),biasConstraint:(0,r.uH)(this.biasConstraint)},i=super.getConfig();return Object.assign(t,i),t}}m.className="Dense",s.serialization.registerClass(m);class k extends l.Wd{constructor(t){super(t=t||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=(0,c.U$)(t);for(const i of t.slice(1))if(null==i)throw new h.Qp(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],(0,d.no)(t,1)]}call(t,i){return(0,s.tidy)((()=>{this.invokeCallHook(t,i);let e=(0,c.un)(t);if("channelsFirst"===this.dataFormat&&e.rank>1){const t=[0];for(let i=2;i<e.rank;++i)t.push(i);t.push(1),e=e.transpose(t)}return a.PS(e)}))}getConfig(){const t={};null!=this.dataFormat&&(t.dataFormat=this.dataFormat);const i=super.getConfig();return Object.assign(t,i),t}}k.className="Flatten",s.serialization.registerClass(k);class b extends l.Wd{constructor(t){super(t),this.supportsMasking=!0,this.activation=(0,n.b_)(t.activation)}call(t,i){return(0,s.tidy)((()=>{this.invokeCallHook(t,i);const e=(0,c.un)(t);return this.activation.apply(e)}))}getConfig(){const t={activation:(0,n.Bu)(this.activation)},i=super.getConfig();return Object.assign(t,i),t}}b.className="Activation",s.serialization.registerClass(b);class z extends l.Wd{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,i){return(0,s.tidy)((()=>(t=(0,c.un)(t),a.ux(t,this.n))))}getConfig(){const t={n:this.n},i=super.getConfig();return Object.assign(t,i),t}}z.className="RepeatVector",s.serialization.registerClass(z);class w extends l.Wd{constructor(t){super(t),this.targetShape=t.targetShape;for(let i=0;i<this.targetShape.length;++i)this.isUnknown(this.targetShape[i])&&(this.targetShape[i]=null)}isUnknown(t){return t<0||null==t}fixUnknownDimension(t,i){const e="Total size of new array must be unchanged.",s=i.slice();let n=1,a=null;for(let l=0;l<s.length;++l){const t=s[l];if(this.isUnknown(t)){if(null!==a)throw new h.Qp("Can only specifiy one unknown dimension.");a=l}else n*=t}const r=(0,d.no)(t);if(null!==a){if(0===n||r%n!==0)throw new h.Qp(e);s[a]=r/n}else if(r!==n)throw new h.Qp(e);return s}computeOutputShape(t){let i=!1;for(let e=0;e<t.length;++e)if(this.isUnknown(t[e])){i=!0;break}return i?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,i){return(0,s.tidy)((()=>{this.invokeCallHook(t,i);const e=(0,c.un)(t),s=e.shape,n=s.slice(0,1).concat(this.fixUnknownDimension(s.slice(1),this.targetShape));return e.reshape(n)}))}getConfig(){const t={targetShape:this.targetShape},i=super.getConfig();return Object.assign(t,i),t}}w.className="Reshape",s.serialization.registerClass(w);class C extends l.Wd{constructor(t){if(super(t),null==t.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);const i=(0,d.y1)(1,t.dims.length+1);if(!s.util.arraysEqual(t.dims.slice().sort(),i))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new l.eO({ndim:this.dims.length+1})]}computeOutputShape(t){const i=(t=(0,c.U$)(t)).slice();return this.dims.forEach(((e,s)=>{i[s+1]=t[e]})),i}call(t,i){return(0,s.transpose)((0,c.un)(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},i=super.getConfig();return Object.assign(t,i),t}}C.className="Permute",s.serialization.registerClass(C);class S extends l.Wd{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,this.maskValue=null!=t?null==t.maskValue?0:t.maskValue:0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),i={maskValue:this.maskValue};return Object.assign(i,t),i}computeMask(t,i){const e=(0,c.un)(t);return(0,s.any)((0,s.notEqual)(e,this.maskValue),-1)}call(t,i){return(0,s.tidy)((()=>{this.invokeCallHook(t,i);const e=(0,c.un)(t),n=(0,s.any)((0,s.notEqual)(e,this.maskValue),-1,!0);return e.mul(n.asType(e.dtype))}))}}S.className="Masking",s.serialization.registerClass(S)},8955:function(t,i,e){var s=e(9495),n=e(59885),a=e(47661),r=e(87504),l=e(79730),h=e(15841),o=e(59351),u=e(84379),p=e(63057);class d extends l.Wd{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,null!=t&&(this.maxValue=t.maxValue)}call(t,i){t=(0,p.un)(t);let e=(0,s.relu)(t);return null!=this.maxValue&&(e=(0,s.clipByValue)(e,0,this.maxValue)),e}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},i=super.getConfig();return Object.assign(t,i),t}}d.className="ReLU",s.serialization.registerClass(d);class c extends l.Wd{constructor(t){super(null==t?{}:t),this.DEFAULT_ALPHA=.3,null==t&&(t={}),this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,i){const e=(0,p.un)(t);return(0,s.leakyRelu)(e,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},i=super.getConfig();return Object.assign(t,i),t}}c.className="LeakyReLU",s.serialization.registerClass(c);class g extends l.Wd{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==t&&(t={}),this.supportsMasking=!0,this.alphaInitializer=(0,o.Fe)(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=(0,u.Bm)(t.alphaRegularizer),this.alphaConstraint=(0,r.YZ)(t.alphaConstraint),null==t.sharedAxes)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else{if("number"!==typeof t.sharedAxes)throw new h.Qp(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`);this.sharedAxes=[t.sharedAxes]}}build(t){const i=(t=(0,p.U$)(t)).slice(1);if(null!=this.sharedAxes)for(const s of this.sharedAxes)i[s-1]=1;this.alpha=this.addWeight("alpha",i,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const e={};if(null!=this.sharedAxes)for(let s=1;s<t.length;++s)e[s]=t[s];this.inputSpec=[new l.eO({ndim:t.length,axes:e})],this.built=!0}call(t,i){return t=(0,p.un)(t),(0,s.prelu)(t,this.alpha.read())}getConfig(){const t={alphaInitializer:(0,o.zo)(this.alphaInitializer),alphaRegularizer:(0,u.R9)(this.alphaRegularizer),alphaConstraint:(0,r.uH)(this.alphaConstraint),sharedAxes:this.sharedAxes},i=super.getConfig();return Object.assign(t,i),t}}g.className="PReLU",s.serialization.registerClass(g);class f extends l.Wd{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA=1,null==t&&(t={}),null!=t.alpha&&t.alpha!==this.DEFAULT_ALPHA)throw new h.EH(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,i){const e=(0,p.un)(t);return(0,s.elu)(e)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},i=super.getConfig();return Object.assign(t,i),t}}f.className="ELU",s.serialization.registerClass(f);class m extends l.Wd{constructor(t){super(null==t?{}:t),this.DEFAULT_THETA=1,null==t&&(t={}),this.theta=null==t.theta?this.DEFAULT_THETA:t.theta}call(t,i){const e=(0,p.un)(t);return e.mul((0,a.wg)(e.greater(this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},i=super.getConfig();return Object.assign(t,i),t}}m.className="ThresholdedReLU",s.serialization.registerClass(m);class k extends l.Wd{constructor(t){super(null==t?{}:t),this.DEFAULT_AXIS=1,null==t&&(t={}),this.softmax=(new n.rF).apply,this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis}call(t,i){const e=(0,p.un)(t);return this.softmax(e,this.axis)}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},i=super.getConfig();return Object.assign(t,i),t}}k.className="Softmax",s.serialization.registerClass(k)},9548:function(t,i,e){e.d(i,{RK:function(){return m},al:function(){return k},kO:function(){return C}});var s=e(9495),n=e(59885),a=e(6090),r=e(47661),l=e(39459),h=e(87504),o=e(79730),u=e(15841),p=e(59351),d=e(84379),c=e(69184),g=e(44813),f=e(63057);function m(t,i){return(0,s.tidy)((()=>((0,l.uM)(i),"channelsFirst"===i?s.transpose(t,[0,2,3,1]):t)))}function k(t,i){return(0,s.tidy)((()=>((0,l.uM)(i),"channelsFirst"===i?s.transpose(t,[0,2,3,4,1]):t)))}function b(t,i,e,n=1,h="valid",o,p=1){return(0,s.tidy)((()=>{if(null==o&&(o=(0,a.VI)()),(0,l.uM)(o),3!==t.shape.length)throw new u.Qp(`The input of a conv1dWithBias operation should be 3, but is ${t.shape.length} instead.`);if(3!==i.shape.length)throw new u.Qp(`The kernel for a conv1dWithBias operation should be 3, but is ${i.shape.length} instead`);if(null!=e&&1!==e.shape.length)throw new u.Qp(`The bias for a conv1dWithBias operation should be 1, but is ${i.shape.length} instead`);if("channelsFirst"===o&&(t=s.transpose(t,[0,2,1])),"causal"===h)throw new u.EH("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let d=s.conv1d(t,i,n,"same"===h?"same":"valid","NWC",p);return null!=e&&(d=r.ni(d,e)),d}))}function z(t,i,e,n=[1,1],r="valid",h,o,p=null){return(0,s.tidy)((()=>{if(null==h&&(h=(0,a.VI)()),(0,l.uM)(h),3!==t.rank&&4!==t.rank)throw new u.Qp(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${t.rank}.`);if(3!==i.rank&&4!==i.rank)throw new u.Qp(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${t.rank}.`);let d=m(t,h);if("causal"===r)throw new u.EH("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return d=s.fused.conv2d({x:d,filter:i,strides:n,pad:"same"===r?"same":"valid",dilations:o,dataFormat:"NHWC",bias:e,activation:p}),"channelsFirst"===h&&(d=s.transpose(d,[0,3,1,2])),d}))}function w(t,i,e,n=[1,1,1],h="valid",o,p){return(0,s.tidy)((()=>{if(null==o&&(o=(0,a.VI)()),(0,l.uM)(o),4!==t.rank&&5!==t.rank)throw new u.Qp(`conv3dWithBias expects input to be of rank 4 or 5, but received ${t.rank}.`);if(4!==i.rank&&5!==i.rank)throw new u.Qp(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${t.rank}.`);let d=k(t,o);if("causal"===h)throw new u.EH("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return d=s.conv3d(d,i,n,"same"===h?"same":"valid","NDHWC",p),null!=e&&(d=r.ni(d,e)),"channelsFirst"===o&&(d=s.transpose(d,[0,4,1,2,3])),d}))}class C extends o.Wd{constructor(t,i){if(super(i),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",C.verifyArgs(i),this.rank=t,g.oo(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new u.EH(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=(0,c.J)(i.kernelSize,t,"kernelSize"),this.strides=(0,c.J)(null==i.strides?1:i.strides,t,"strides"),this.padding=null==i.padding?"valid":i.padding,(0,l.tB)(this.padding),this.dataFormat=null==i.dataFormat?"channelsLast":i.dataFormat,(0,l.uM)(this.dataFormat),this.activation=(0,n.b_)(i.activation),this.useBias=null==i.useBias||i.useBias,this.biasInitializer=(0,p.Fe)(i.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=(0,h.YZ)(i.biasConstraint),this.biasRegularizer=(0,d.Bm)(i.biasRegularizer),this.activityRegularizer=(0,d.Bm)(i.activityRegularizer),this.dilationRate=(0,c.J)(null==i.dilationRate?1:i.dilationRate,t,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new u.Qp(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"===typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new u.Qp(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"===typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new u.Qp(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(t){if(g.vA("kernelSize"in t,"required key 'kernelSize' not in config"),"number"!==typeof t.kernelSize&&!g.HP(t.kernelSize,"number",1,3))throw new u.Qp(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:(0,n.Bu)(this.activation),useBias:this.useBias,biasInitializer:(0,p.zo)(this.biasInitializer),biasRegularizer:(0,d.R9)(this.biasRegularizer),activityRegularizer:(0,d.R9)(this.activityRegularizer),biasConstraint:(0,h.uH)(this.biasConstraint)},i=super.getConfig();return Object.assign(t,i),t}}class S extends C{constructor(t,i){super(t,i),this.kernel=null,S.verifyArgs(i),this.filters=i.filters,g.oo(this.filters,"filters"),this.kernelInitializer=(0,p.Fe)(i.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=(0,h.YZ)(i.kernelConstraint),this.kernelRegularizer=(0,d.Bm)(i.kernelRegularizer)}build(t){t=(0,f.U$)(t);const i="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[i])throw new u.Qp(`The channel dimension of the input should be defined. Found ${t[i]}`);const e=t[i],s=this.kernelSize.concat([e,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[i]:e}}],this.built=!0}call(t,i){return(0,s.tidy)((()=>{let i;t=(0,f.un)(t);const e=null==this.bias?null:this.bias.read(),s=g.Cd(this.activation.getClassName());if(null!=s&&2===this.rank)i=z(t,this.kernel.read(),e,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)i=b(t,this.kernel.read(),e,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)i=z(t,this.kernel.read(),e,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new u.EH("convolutions greater than 3D are not implemented yet.");i=w(t,this.kernel.read(),e,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(i=this.activation.apply(i))}return i}))}computeOutputShape(t){t=(0,f.U$)(t);const i=[],e="channelsLast"===this.dataFormat?t.slice(1,t.length-1):t.slice(2);for(let n=0;n<e.length;++n){const t=(0,c.Ol)(e[n],this.kernelSize[n],this.padding,this.strides[n],"number"===typeof this.dilationRate?this.dilationRate:this.dilationRate[n]);i.push(t)}let s=[t[0]];return"channelsLast"===this.dataFormat?(s=s.concat(i),s.push(this.filters)):(s.push(this.filters),s=s.concat(i)),s}getConfig(){const t={filters:this.filters,kernelInitializer:(0,p.zo)(this.kernelInitializer),kernelRegularizer:(0,d.R9)(this.kernelRegularizer),kernelConstraint:(0,h.uH)(this.kernelConstraint)},i=super.getConfig();return Object.assign(t,i),t}static verifyArgs(t){if(!("filters"in t)||"number"!==typeof t.filters||t.filters<1)throw new u.Qp(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`)}}class v extends S{constructor(t){super(2,t),v.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!==typeof t.kernelSize&&!g.HP(t.kernelSize,"number",1,2))throw new u.Qp(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}v.className="Conv2D",s.serialization.registerClass(v);class y extends S{constructor(t){super(3,t),y.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!==typeof t.kernelSize&&(!Array.isArray(t.kernelSize)||1!==t.kernelSize.length&&3!==t.kernelSize.length))throw new u.Qp(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}y.className="Conv3D",s.serialization.registerClass(y);class I extends v{constructor(t){if(super(t),this.inputSpec=[new o.eO({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new u.Qp(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(4!==(t=(0,f.U$)(t)).length)throw new u.Qp("Input should have rank 4; Received input shape: "+JSON.stringify(t));const i="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[i])throw new u.Qp("The channel dimension of the inputs should be defined. Found `None`.");const e=t[i],s=this.kernelSize.concat([this.filters,e]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new o.eO({ndim:4,axes:{[i]:e}})],this.built=!0}call(t,i){return s.tidy((()=>{let i=(0,f.un)(t);if(4!==i.shape.length)throw new u.Qp(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${i.shape.length}`);const e=i.shape,n=e[0];let a,l;"channelsFirst"===this.dataFormat?(a=2,l=3):(a=1,l=2);const h=e[a],o=e[l],p=this.kernelSize[0],d=this.kernelSize[1],g=this.strides[0],m=this.strides[1],k=[n,(0,c.mW)(h,g,p,this.padding),(0,c.mW)(o,m,d,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(i=s.transpose(i,[0,2,3,1]));let b=s.conv2dTranspose(i,this.kernel.read(),k,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(b=s.transpose(b,[0,3,1,2])),null!=this.bias&&(b=r.ni(b,this.bias.read(),this.dataFormat)),null!=this.activation&&(b=this.activation.apply(b)),b}))}computeOutputShape(t){const i=(t=(0,f.U$)(t)).slice();let e,s,n;"channelsFirst"===this.dataFormat?(e=1,s=2,n=3):(e=3,s=1,n=2);const a=this.kernelSize[0],r=this.kernelSize[1],l=this.strides[0],h=this.strides[1];return i[e]=this.filters,i[s]=(0,c.mW)(i[s],l,a,this.padding),i[n]=(0,c.mW)(i[n],h,r,this.padding),i}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}I.className="Conv2DTranspose",s.serialization.registerClass(I);class R extends y{constructor(t){if(super(t),this.inputSpec=[new o.eO({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new u.Qp(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(5!==(t=(0,f.U$)(t)).length)throw new u.Qp("Input should have rank 5; Received input shape: "+JSON.stringify(t));const i="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[i])throw new u.Qp("The channel dimension of the inputs should be defined. Found `None`.");const e=t[i],s=this.kernelSize.concat([this.filters,e]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new o.eO({ndim:5,axes:{[i]:e}})],this.built=!0}call(t,i){return s.tidy((()=>{let i=(0,f.un)(t);if(5!==i.shape.length)throw new u.Qp(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${i.shape.length}`);const e=i.shape,n=e[0];let a,l,h;"channelsFirst"===this.dataFormat?(h=2,a=3,l=4):(h=1,a=2,l=3);const o=e[h],p=e[a],d=e[l],g=this.kernelSize[0],m=this.kernelSize[1],k=this.kernelSize[2],b=this.strides[0],z=this.strides[1],w=this.strides[2],C=[n,(0,c.mW)(o,b,g,this.padding),(0,c.mW)(p,z,m,this.padding),(0,c.mW)(d,w,k,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(i=s.transpose(i,[0,2,3,4,1]));let S=s.conv3dTranspose(i,this.kernel.read(),C,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(S=s.transpose(S,[0,4,1,2,3])),null!==this.bias&&(S=r.ni(S,this.bias.read(),this.dataFormat)),null!==this.activation&&(S=this.activation.apply(S)),S}))}computeOutputShape(t){const i=(t=(0,f.U$)(t)).slice();let e,s,n,a;"channelsFirst"===this.dataFormat?(e=1,s=2,n=3,a=4):(e=4,s=1,n=2,a=3);const r=this.kernelSize[0],l=this.kernelSize[1],h=this.kernelSize[2],o=this.strides[0],u=this.strides[1],p=this.strides[2];return i[e]=this.filters,i[s]=(0,c.mW)(i[s],o,r,this.padding),i[n]=(0,c.mW)(i[n],u,l,this.padding),i[a]=(0,c.mW)(i[a],p,h,this.padding),i}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}R.className="Conv3DTranspose",s.serialization.registerClass(R);class F extends S{constructor(t,i){if(super(t,i),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==i.filters)throw new u.Qp("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=i.kernelInitializer||null!=i.kernelRegularizer||null!=i.kernelConstraint)throw new u.Qp("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=i.padding&&"same"!==i.padding&&"valid"!==i.padding)throw new u.Qp(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(i.padding)}`);this.depthMultiplier=null==i.depthMultiplier?1:i.depthMultiplier,this.depthwiseInitializer=(0,p.Fe)(i.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=(0,d.Bm)(i.depthwiseRegularizer),this.depthwiseConstraint=(0,h.YZ)(i.depthwiseConstraint),this.pointwiseInitializer=(0,p.Fe)(i.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=(0,d.Bm)(i.pointwiseRegularizer),this.pointwiseConstraint=(0,h.YZ)(i.pointwiseConstraint)}build(t){if((t=(0,f.U$)(t)).length<this.rank+2)throw new u.Qp(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(t)}`);const i="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[i]||t[i]<0)throw new u.Qp(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[i])}`);const e=t[i],s=this.kernelSize.concat([e,this.depthMultiplier]),n=[];for(let r=0;r<this.rank;++r)n.push(1);n.push(e*this.depthMultiplier,this.filters);const a=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",s,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,a,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",n,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,a,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,a,this.biasConstraint):this.bias=null,this.inputSpec=[new o.eO({ndim:this.rank+2,axes:{[i]:e}})],this.built=!0}call(t,i){return(0,s.tidy)((()=>{let i;if(t=(0,f.un)(t),1===this.rank)throw new u.EH("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(t=s.transpose(t,[0,2,3,1])),i=s.separableConv2d(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(i=r.ni(i,this.bias.read(),this.dataFormat)),null!=this.activation&&(i=this.activation.apply(i)),"channelsFirst"===this.dataFormat&&(i=s.transpose(i,[0,3,1,2])),i}))}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=(0,p.zo)(this.depthwiseInitializer),t.pointwiseInitializer=(0,p.zo)(this.pointwiseInitializer),t.depthwiseRegularizer=(0,d.R9)(this.depthwiseRegularizer),t.pointwiseRegularizer=(0,d.R9)(this.pointwiseRegularizer),t.depthwiseConstraint=(0,h.uH)(this.depthwiseConstraint),t.pointwiseConstraint=(0,h.uH)(this.pointwiseConstraint),t}}F.className="SeparableConv";class A extends F{constructor(t){super(2,t)}}A.className="SeparableConv2D",s.serialization.registerClass(A);class N extends S{constructor(t){super(1,t),N.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if("number"!==typeof t.kernelSize&&!g.HP(t.kernelSize,"number",1,1))throw new u.Qp(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}N.className="Conv1D",s.serialization.registerClass(N);class x extends o.Wd{constructor(t){super(t),"number"===typeof t.cropping?this.cropping=[[t.cropping,t.cropping],[t.cropping,t.cropping]]:"number"===typeof t.cropping[0]?this.cropping=[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:this.cropping=t.cropping,this.dataFormat=void 0===t.dataFormat?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,i){return(0,s.tidy)((()=>{if(t=(0,f.un)(t),"channelsLast"===this.dataFormat){const i=r.r0(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return r.r0(i,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const i=r.r0(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return r.r0(i,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}}))}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},i=super.getConfig();return Object.assign(t,i),t}}x.className="Cropping2D",s.serialization.registerClass(x);class D extends o.Wd{constructor(t){super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==t.size?this.DEFAULT_SIZE:t.size,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,(0,l.uM)(this.dataFormat),this.interpolation=null==t.interpolation?"nearest":t.interpolation,(0,l.uU)(this.interpolation)}computeOutputShape(t){if("channelsFirst"===this.dataFormat){const i=null==t[2]?null:this.size[0]*t[2],e=null==t[3]?null:this.size[1]*t[3];return[t[0],t[1],i,e]}{const i=null==t[1]?null:this.size[0]*t[1],e=null==t[2]?null:this.size[1]*t[2];return[t[0],i,e,t[3]]}}call(t,i){return s.tidy((()=>{let i=(0,f.un)(t);const e=i.shape;if("channelsFirst"===this.dataFormat){i=s.transpose(i,[0,2,3,1]);const t=this.size[0]*e[2],n=this.size[1]*e[3],a="nearest"===this.interpolation?i.resizeNearestNeighbor([t,n]):i.resizeBilinear([t,n]);return s.transpose(a,[0,3,1,2])}{const t=this.size[0]*e[1],s=this.size[1]*e[2];return"nearest"===this.interpolation?i.resizeNearestNeighbor([t,s]):i.resizeBilinear([t,s])}}))}getConfig(){const t={size:this.size,dataFormat:this.dataFormat},i=super.getConfig();return Object.assign(t,i),t}}D.className="UpSampling2D",s.serialization.registerClass(D)},14742:function(t,i,e){e.d(i,{A:function(){return s},Nt:function(){return n}});const s=["fanIn","fanOut","fanAvg"],n=["normal","uniform","truncatedNormal"]},42638:function(t,i,e){var s=e(9495),n=e(6090),a=e(47661),r=e(39459),l=e(87504),h=e(15841),o=e(59351),u=e(84379),p=e(69184),d=e(63057),c=e(9548);class g extends c.kO{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=(0,o.Fe)(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=(0,l.YZ)(t.depthwiseConstraint),this.depthwiseRegularizer=(0,u.Bm)(t.depthwiseRegularizer)}build(t){if((t=(0,d.U$)(t)).length<4)throw new h.Qp(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const i="channelsFirst"===this.dataFormat?1:3;if(null==t[i]||t[i]<0)throw new h.Qp(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[i]}).`);const e=t[i],s=[this.kernelSize[0],this.kernelSize[1],e,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",s,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[e*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,i){return(0,s.tidy)((()=>{let i=function(t,i,e=[1,1],a="valid",l,o){return(0,s.tidy)((()=>{null==l&&(l=(0,n.VI)()),(0,r.uM)(l);let u=(0,c.RK)(t,l);if(4!==t.rank)throw new h.Qp(`Input for depthwiseConv2d is required to be 4-D, but is instead ${t.rank}-D`);if(4!==i.rank)throw new h.Qp(`depthwiseKernel is required to be 4-D, but is instead ${i.rank}-D`);return u=s.depthwiseConv2d(u,i,e,"same"===a?"same":"valid","NHWC",o),"channelsFirst"===l&&(u=s.transpose(u,[0,3,1,2])),u}))}(t=(0,d.un)(t),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(i=a.ni(i,this.bias.read(),this.dataFormat)),null!=this.activation&&(i=this.activation.apply(i)),i}))}computeOutputShape(t){t=(0,d.U$)(t);const i="channelsFirst"===this.dataFormat?t[2]:t[1],e="channelsFirst"===this.dataFormat?t[3]:t[2],s="channelsFirst"===this.dataFormat?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,n=(0,p.Ol)(i,this.kernelSize[0],this.padding,this.strides[0]),a=(0,p.Ol)(e,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[t[0],s,n,a]:[t[0],n,a,s]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=(0,o.zo)(this.depthwiseInitializer),t.depthwiseRegularizer=(0,u.R9)(this.depthwiseRegularizer),t.depthwiseConstraint=(0,l.uH)(this.depthwiseRegularizer),t}}g.className="DepthwiseConv2D",s.serialization.registerClass(g)},59297:function(t,i,e){var s=e(9495),n=e(47661),a=e(39459),r=e(79730),l=e(15841),h=e(59351),o=e(69184),u=e(44813),p=e(63057),d=e(76481),c=function(t,i){var e={};for(var s in t)Object.prototype.hasOwnProperty.call(t,s)&&i.indexOf(s)<0&&(e[s]=t[s]);if(null!=t&&"function"===typeof Object.getOwnPropertySymbols){var n=0;for(s=Object.getOwnPropertySymbols(t);n<s.length;n++)i.indexOf(s[n])<0&&Object.prototype.propertyIsEnumerable.call(t,s[n])&&(e[s[n]]=t[s[n]])}return e};class g extends d.VS{constructor(t){if(t.unroll)throw new l.EH("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new l.EH("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new r.eO({ndim:5})]}call(t,i){return s.tidy((()=>{if(null!=this.cell.dropoutMask&&(s.dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(s.dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),i&&i.constants)throw new l.Qp("ConvRNN2D cell does not support constants");const e=null==i?null:i.mask,n=null==i?null:i.training,a=null==i?null:i.initialState;return super.call(t,{mask:e,training:n,initialState:a})}))}computeOutputShape(t){let i=this.computeSingleOutputShape(t);return this.returnSequences||(i=[i[0],...i.slice(2)]),this.returnState&&(i=[i,...Array(2).fill([t[0],...i.slice(-3)])]),i}getInitialState(t){return s.tidy((()=>{const{stateSize:i}=this.cell,e=t.shape,n=this.computeSingleOutputShape(e),a=[n[0],...n.slice(2)],r=s.zeros(a);return Array.isArray(i)?Array(i.length).fill(r):[r]}))}resetStates(t,i=!1){s.tidy((()=>{if(!this.stateful)throw new l.l7("Cannot call resetStates() on an RNN Layer that is not stateful.");const e=this.inputSpec[0].shape,n=this.computeSingleOutputShape(e),a=[n[0],...n.slice(2)];if(null==e[0])throw new l.Qp("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>s.zeros(a))):this.states_=[s.zeros(a)];else if(null==t)s.dispose(this.states_),null!=this.keptStates&&(s.dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>s.zeros(a))):this.states_[0]=s.zeros(a);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new l.Qp(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);i?this.keptStates.push(this.states_.slice()):s.dispose(this.states_);for(let i=0;i<this.states_.length;++i){const e=t[i],n=a;if(!s.util.arraysEqual(e.shape,n))throw new l.Qp(`State ${i} is incompatible with layer ${this.name}: expected shape=${n}, received shape=${e.shape}`);this.states_[i]=e}}this.states_=this.states_.map((t=>s.keep(t.clone())))}))}computeSingleOutputShape(t){const{dataFormat:i,filters:e,kernelSize:s,padding:n,strides:a,dilationRate:r}=this.cell,l="channelsFirst"===i,h=t[l?3:2],u=t[l?4:3],p=(0,o.Ol)(h,s[0],n,a[0],r[0]),d=(0,o.Ol)(u,s[1],n,a[1],r[1]);return[...t.slice(0,2),...l?[e,p,d]:[p,d,e]]}}g.className="ConvRNN2D";class f extends d.Tu{constructor(t){const{filters:i,kernelSize:e,strides:s,padding:n,dataFormat:r,dilationRate:l}=t;super(Object.assign({},t,{units:i})),this.filters=i,(0,u.oo)(this.filters,"filters"),this.kernelSize=(0,o.J)(e,2,"kernelSize"),this.kernelSize.forEach((t=>(0,u.oo)(t,"kernelSize"))),this.strides=(0,o.J)(s||1,2,"strides"),this.strides.forEach((t=>(0,u.oo)(t,"strides"))),this.padding=n||"valid",(0,a.tB)(this.padding),this.dataFormat=r||"channelsLast",(0,a.uM)(this.dataFormat),this.dilationRate=(0,o.J)(l||1,2,"dilationRate"),this.dilationRate.forEach((t=>(0,u.oo)(t,"dilationRate")))}build(t){var i;t=(0,p.U$)(t);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new l.Qp(`The channel dimension of the input should be defined. Found ${t[e]}`);const a=t[e],r=this.kernelSize.concat([a,4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const o=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",o,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let t;if(this.unitForgetBias){const e=this.biasInitializer,a=this.filters;t=new((i=class extends h.H4{apply(t,i){const r=e.apply([a]),l=s.ones([a]),h=e.apply([2*a]);return n.u1([r,l,h])}}).className="CustomInit",i)}else t=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,t,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,i){return s.tidy((()=>{if(3!==t.length)throw new l.Qp(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const e=i.training||!1,n=t[0],a=t[1],r=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=(0,d.FW)({ones:()=>s.onesLike(n),rate:this.dropout,training:e,count:4}));const h=this.dropoutMask,o=(t,i,e)=>i&&i[e]?s.mul(i[e],t):t;let u=o(n,h,0),p=o(n,h,1),c=o(n,h,2),g=o(n,h,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=(0,d.FW)({ones:()=>s.onesLike(a),rate:this.recurrentDropout,training:e,count:4}));const f=this.recurrentDropoutMask;let m=o(a,f,0),k=o(a,f,1),b=o(a,f,2),z=o(a,f,3);const[w,C,S,v]=s.split(this.kernel.read(),4,3),[y,I,R,F]=this.useBias?s.split(this.bias.read(),4):[null,null,null,null];u=this.inputConv(u,w,y,this.padding),p=this.inputConv(p,C,I,this.padding),c=this.inputConv(c,S,R,this.padding),g=this.inputConv(g,v,F,this.padding);const[A,N,x,D]=s.split(this.recurrentKernel.read(),4,3);m=this.recurrentConv(m,A),k=this.recurrentConv(k,N),b=this.recurrentConv(b,x),z=this.recurrentConv(z,D);const E=this.recurrentActivation.apply(s.add(u,m)),O=this.recurrentActivation.apply(s.add(p,k)),L=s.add(s.mul(O,r),s.mul(E,this.activation.apply(s.add(c,b)))),T=s.mul(this.recurrentActivation.apply(s.add(g,z)),this.activation.apply(L));return[T,T,L]}))}getConfig(){const t=super.getConfig(),{units:i}=t,e=c(t,["units"]),s={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign({},e,s)}inputConv(t,i,e,a){const r=s.conv2d(t,i,this.strides,a||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return e?n.ni(r,e,this.dataFormat):r}recurrentConv(t,i){return s.conv2d(t,i,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}f.className="ConvLSTM2DCell",s.serialization.registerClass(f);class m extends g{constructor(t){const i=new f(t);super(Object.assign({},t,{cell:i}))}static fromConfig(t,i){return new t(i)}}m.className="ConvLSTM2D",s.serialization.registerClass(m)},84604:function(t,i,e){e.d(i,{EY:function(){return a},To:function(){return s},bb:function(){return r},ft:function(){return n},r$:function(){return l}});const s=["channelsFirst","channelsLast"],n=["nearest","bilinear"],a=["valid","same","causal"],r=["max","avg"],l=["sum","mul","concat","ave"]}}]);
//# sourceMappingURL=stylist-vendors-79dd5a9c.b8d51d6737746c197552.js.map